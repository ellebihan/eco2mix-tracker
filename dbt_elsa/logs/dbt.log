[0m21:10:53.669778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10670f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e03610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e034d0>]}


============================== 21:10:53.682802 | 81e9fca5-7a24-4940-95a3-c1a09b828f93 ==============================
[0m21:10:53.682802 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:10:53.684248 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:10:53.883928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '81e9fca5-7a24-4940-95a3-c1a09b828f93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107188510>]}
[0m21:10:53.916524 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-_onahcni'
[0m21:10:53.917261 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:10:54.046414 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m21:10:54.048780 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m21:10:54.124070 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m21:10:54.139262 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m21:10:54.206186 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m21:10:54.213370 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m21:10:54.322677 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m21:10:54.338875 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m21:10:54.400923 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m21:10:54.437691 [info ] [MainThread]: Updating lock file in file path: /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/package-lock.yml
[0m21:10:54.443532 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-q91c7br2'
[0m21:10:54.460173 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m21:10:54.858241 [info ] [MainThread]: Installed from version 1.3.0
[0m21:10:54.858822 [info ] [MainThread]: Up to date!
[0m21:10:54.859532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '81e9fca5-7a24-4940-95a3-c1a09b828f93', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fda360>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fda580>]}
[0m21:10:54.860101 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m21:10:56.034038 [info ] [MainThread]: Installed from version 0.10.9
[0m21:10:56.034554 [info ] [MainThread]: Up to date!
[0m21:10:56.035048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '81e9fca5-7a24-4940-95a3-c1a09b828f93', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10800cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff1220>]}
[0m21:10:56.035479 [info ] [MainThread]: Installing elementary-data/elementary
[0m21:10:56.639396 [info ] [MainThread]: Installed from version 0.19.0
[0m21:10:56.640102 [info ] [MainThread]: Updated version available: 0.19.1
[0m21:10:56.640758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '81e9fca5-7a24-4940-95a3-c1a09b828f93', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10803d390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10803c750>]}
[0m21:10:56.641275 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m21:10:56.992015 [info ] [MainThread]: Installed from version 0.14.2
[0m21:10:56.992492 [info ] [MainThread]: Up to date!
[0m21:10:56.992884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '81e9fca5-7a24-4940-95a3-c1a09b828f93', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108005190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108005490>]}
[0m21:10:56.993310 [info ] [MainThread]: 
[0m21:10:56.993671 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m21:10:57.000006 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 3.4379416, "process_in_blocks": "0", "process_kernel_time": 0.947559, "process_mem_max_rss": "114909184", "process_out_blocks": "0", "process_user_time": 2.811262}
[0m21:10:57.000751 [debug] [MainThread]: Command `dbt deps` succeeded at 21:10:57.000601 after 3.44 seconds
[0m21:10:57.001309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108030260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10804ce10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10804cf50>]}
[0m21:10:57.001746 [debug] [MainThread]: Flushing usage events
[0m21:10:57.562720 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:12:09.842896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bc7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062bf610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062bf4d0>]}


============================== 21:12:09.853287 | 71bc8248-77b6-4a92-bf52-567cd93086ae ==============================
[0m21:12:09.853287 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:12:09.854842 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:12:09.862473 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'dbt_elsa'
[0m21:12:09.867832 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.12069084, "process_in_blocks": "0", "process_kernel_time": 0.604643, "process_mem_max_rss": "101576704", "process_out_blocks": "0", "process_user_time": 2.32084}
[0m21:12:09.868764 [debug] [MainThread]: Command `dbt run` failed at 21:12:09.868574 after 0.12 seconds
[0m21:12:09.870784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106187e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106193bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106142be0>]}
[0m21:12:09.871501 [debug] [MainThread]: Flushing usage events
[0m21:12:10.291632 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:13:02.928783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103833770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f2f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f2f4d0>]}


============================== 21:13:02.933880 | 9a867d08-1d17-420d-86bc-40161b1af781 ==============================
[0m21:13:02.933880 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:13:02.934579 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:13:02.938375 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'dbt_elsa'
[0m21:13:02.941228 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.09868052, "process_in_blocks": "0", "process_kernel_time": 0.211411, "process_mem_max_rss": "101703680", "process_out_blocks": "0", "process_user_time": 1.527}
[0m21:13:02.942241 [debug] [MainThread]: Command `dbt run` failed at 21:13:02.942037 after 0.10 seconds
[0m21:13:02.942701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e03e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dfbbf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104db2be0>]}
[0m21:13:02.943127 [debug] [MainThread]: Flushing usage events
[0m21:13:03.395952 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:16:27.582697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b12b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b12b4d0>]}


============================== 21:16:27.587685 | 2b95a0bf-6864-4880-b6c0-0358c01250b2 ==============================
[0m21:16:27.587685 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:16:27.588490 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m21:16:27.591993 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'dbt_elsa'
[0m21:16:27.594665 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.098061256, "process_in_blocks": "0", "process_kernel_time": 0.207765, "process_mem_max_rss": "102080512", "process_out_blocks": "0", "process_user_time": 1.516556}
[0m21:16:27.595385 [debug] [MainThread]: Command `dbt run` failed at 21:16:27.595253 after 0.10 seconds
[0m21:16:27.595792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aff3e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afffbf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afaebe0>]}
[0m21:16:27.596206 [debug] [MainThread]: Flushing usage events
[0m21:16:28.068677 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:17:56.457012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10502f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676b4d0>]}


============================== 21:17:56.465896 | 81047260-5926-45b8-ba16-519cf163263e ==============================
[0m21:17:56.465896 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:17:56.466873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:17:56.471328 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'dbt_elsa'
[0m21:17:56.475368 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.12640713, "process_in_blocks": "0", "process_kernel_time": 0.588992, "process_mem_max_rss": "101617664", "process_out_blocks": "0", "process_user_time": 2.208004}
[0m21:17:56.476099 [debug] [MainThread]: Command `dbt run` failed at 21:17:56.475948 after 0.13 seconds
[0m21:17:56.476556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10663be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106633bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065eabe0>]}
[0m21:17:56.477026 [debug] [MainThread]: Flushing usage events
[0m21:17:56.944523 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:18:43.616938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10551b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c4b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c4b4d0>]}


============================== 21:18:43.626861 | 032e6a31-8ebf-4254-ad04-bcb78c052bd8 ==============================
[0m21:18:43.626861 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:18:43.627959 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt debug --config-dir', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:18:43.660426 [info ] [MainThread]: To view your profiles.yml file, run:

open /Users/elsalebihan/dev/ellebihan/test/dbt_elsa
[0m21:18:43.665012 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.15138541, "process_in_blocks": "0", "process_kernel_time": 0.359112, "process_mem_max_rss": "102486016", "process_out_blocks": "0", "process_user_time": 1.85219}
[0m21:18:43.665781 [debug] [MainThread]: Command `dbt debug` succeeded at 21:18:43.665631 after 0.15 seconds
[0m21:18:43.666284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ced220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b1b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ad2f10>]}
[0m21:18:43.666764 [debug] [MainThread]: Flushing usage events
[0m21:18:44.080125 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:19:33.256163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11321f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11494b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11494b4d0>]}


============================== 21:19:33.264193 | 0b8e5655-c0f3-40b7-981c-4f54557a5e6e ==============================
[0m21:19:33.264193 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:19:33.264955 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m21:19:33.467948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0b8e5655-c0f3-40b7-981c-4f54557a5e6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ca0510>]}
[0m21:19:33.644654 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-kplf4ikr'
[0m21:19:33.645226 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:19:33.770238 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m21:19:33.772370 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m21:19:33.837328 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m21:19:33.846914 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m21:19:33.902467 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m21:19:33.909949 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m21:19:33.974058 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m21:19:33.989397 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m21:19:34.087157 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m21:19:34.094729 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m21:19:34.512529 [info ] [MainThread]: Installed from version 1.3.0
[0m21:19:34.513412 [info ] [MainThread]: Up to date!
[0m21:19:34.514093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '0b8e5655-c0f3-40b7-981c-4f54557a5e6e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147d2be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b2a7a0>]}
[0m21:19:34.514781 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m21:19:35.284254 [info ] [MainThread]: Installed from version 0.10.9
[0m21:19:35.284691 [info ] [MainThread]: Up to date!
[0m21:19:35.285077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '0b8e5655-c0f3-40b7-981c-4f54557a5e6e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b60b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114229220>]}
[0m21:19:35.285489 [info ] [MainThread]: Installing elementary-data/elementary
[0m21:19:35.765028 [info ] [MainThread]: Installed from version 0.19.0
[0m21:19:35.765530 [info ] [MainThread]: Updated version available: 0.19.1
[0m21:19:35.765945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '0b8e5655-c0f3-40b7-981c-4f54557a5e6e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b8cad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b8cf30>]}
[0m21:19:35.766370 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m21:19:36.082313 [info ] [MainThread]: Installed from version 0.14.2
[0m21:19:36.082731 [info ] [MainThread]: Up to date!
[0m21:19:36.083115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '0b8e5655-c0f3-40b7-981c-4f54557a5e6e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b550d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b55490>]}
[0m21:19:36.083530 [info ] [MainThread]: 
[0m21:19:36.083892 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m21:19:36.088184 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.9433646, "process_in_blocks": "0", "process_kernel_time": 1.019544, "process_mem_max_rss": "114679808", "process_out_blocks": "0", "process_user_time": 2.791669}
[0m21:19:36.089112 [debug] [MainThread]: Command `dbt deps` succeeded at 21:19:36.088767 after 2.94 seconds
[0m21:19:36.089742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b843c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b83f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b83c50>]}
[0m21:19:36.090197 [debug] [MainThread]: Flushing usage events
[0m21:19:36.540440 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:19:59.481904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11036f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111aa7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111aa74d0>]}


============================== 21:19:59.493997 | c79a5a8b-3722-4423-92b1-c6f29b8d5782 ==============================
[0m21:19:59.493997 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:19:59.495479 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:19:59.764621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c79a5a8b-3722-4423-92b1-c6f29b8d5782', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110df4510>]}
[0m21:19:59.839259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c79a5a8b-3722-4423-92b1-c6f29b8d5782', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111927df0>]}
[0m21:19:59.841692 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:20:00.044627 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:20:00.046038 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:20:00.046525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c79a5a8b-3722-4423-92b1-c6f29b8d5782', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a19350>]}
[0m21:20:00.063275 [warn ] [MainThread]: [[33mWARNING[0m][DuplicateYAMLKeysDeprecation]: Deprecated functionality
Duplicate key 'columns' in "<unicode string>", line 14, column 5 in file
`models/bronze/_elsa_bronze__models.yml`
[0m21:20:00.065036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'c79a5a8b-3722-4423-92b1-c6f29b8d5782', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ae2d50>]}
[0m21:20:03.763679 [error] [MainThread]: Encountered an error:
Parsing Error
  at path ['tags']: ['bronze', 'realtime', Undefined] is not valid under any of the given schemas
[0m21:20:03.764767 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- DuplicateYAMLKeysDeprecation: 10 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m21:20:03.768890 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.3835497, "process_in_blocks": "0", "process_kernel_time": 0.667844, "process_mem_max_rss": "118923264", "process_out_blocks": "0", "process_user_time": 5.962981}
[0m21:20:03.769800 [debug] [MainThread]: Command `dbt run` failed at 21:20:03.769604 after 4.39 seconds
[0m21:20:03.770611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111993e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b88c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b3a9c0>]}
[0m21:20:03.771607 [debug] [MainThread]: Flushing usage events
[0m21:20:04.183944 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:23:30.782131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10816f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ab610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ab4d0>]}


============================== 21:23:30.786975 | bd74ca0c-620a-4e6b-bdbe-b57e8afd27f6 ==============================
[0m21:23:30.786975 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:23:30.787633 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:23:30.993966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd74ca0c-620a-4e6b-bdbe-b57e8afd27f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf8510>]}
[0m21:23:31.066235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bd74ca0c-620a-4e6b-bdbe-b57e8afd27f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972bdf0>]}
[0m21:23:31.067226 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:23:31.198396 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:23:31.199584 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:23:31.200032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bd74ca0c-620a-4e6b-bdbe-b57e8afd27f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10981d350>]}
[0m21:23:31.206226 [warn ] [MainThread]: [[33mWARNING[0m][DuplicateYAMLKeysDeprecation]: Deprecated functionality
Duplicate key 'columns' in "<unicode string>", line 14, column 5 in file
`models/bronze/_elsa_bronze__models.yml`
[0m21:23:31.207129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'bd74ca0c-620a-4e6b-bdbe-b57e8afd27f6', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e6d50>]}
[0m21:23:34.671945 [error] [MainThread]: Encountered an error:
Parsing Error
  at path ['tags']: ['bronze', 'realtime', Undefined] is not valid under any of the given schemas
[0m21:23:34.672783 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- DuplicateYAMLKeysDeprecation: 10 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m21:23:34.675265 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.9785156, "process_in_blocks": "0", "process_kernel_time": 0.322333, "process_mem_max_rss": "119705600", "process_out_blocks": "0", "process_user_time": 5.329311}
[0m21:23:34.675770 [debug] [MainThread]: Command `dbt run` failed at 21:23:34.675652 after 3.98 seconds
[0m21:23:34.676160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109797e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a98cc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10993e9c0>]}
[0m21:23:34.676524 [debug] [MainThread]: Flushing usage events
[0m21:23:35.142830 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:24:01.913618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5b7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcf3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcf34d0>]}


============================== 21:24:01.918796 | 4ebd7bd4-5c89-44a0-90c3-af2ced6d0540 ==============================
[0m21:24:01.918796 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:24:01.919562 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:24:02.123175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4ebd7bd4-5c89-44a0-90c3-af2ced6d0540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d040510>]}
[0m21:24:02.199808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4ebd7bd4-5c89-44a0-90c3-af2ced6d0540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db73df0>]}
[0m21:24:02.200781 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:24:02.329176 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:24:02.330475 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:24:02.330966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4ebd7bd4-5c89-44a0-90c3-af2ced6d0540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc65350>]}
[0m21:24:02.336690 [warn ] [MainThread]: [[33mWARNING[0m][DuplicateYAMLKeysDeprecation]: Deprecated functionality
Duplicate key 'columns' in "<unicode string>", line 14, column 5 in file
`models/bronze/_elsa_bronze__models.yml`
[0m21:24:02.337182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '4ebd7bd4-5c89-44a0-90c3-af2ced6d0540', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd2ed50>]}
[0m21:24:06.713410 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'production_journaliere' in the 'models' section of file 'models/bronze/_elsa_bronze__models.yml'
[0m21:24:07.071413 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:24:07.085013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ebd7bd4-5c89-44a0-90c3-af2ced6d0540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efb4e50>]}
[0m21:24:07.239185 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:24:07.243905 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:24:07.306308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ebd7bd4-5c89-44a0-90c3-af2ced6d0540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ecd3d40>]}
[0m21:24:07.307034 [info ] [MainThread]: Found 31 models, 2 operations, 1 source, 1569 macros
[0m21:24:07.307561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ebd7bd4-5c89-44a0-90c3-af2ced6d0540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eec87d0>]}
[0m21:24:07.310411 [info ] [MainThread]: 
[0m21:24:07.310998 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:24:07.311456 [info ] [MainThread]: 
[0m21:24:07.312252 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:24:07.313341 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbt_elsa'
[0m21:24:07.443194 [debug] [ThreadPool]: Using postgres connection "list_dbt_elsa"
[0m21:24:07.443784 [debug] [ThreadPool]: On list_dbt_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_dbt_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:24:07.444169 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:24:07.487513 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: FATAL:  database "dbt_elsa" does not exist

[0m21:24:07.491973 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_dbt_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:24:07.492409 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m21:24:07.492817 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m21:24:07.493156 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m21:24:07.493505 [debug] [ThreadPool]: On list_dbt_elsa: No close available on handle
[0m21:24:07.494287 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:24:07.494644 [debug] [MainThread]: Connection 'list_dbt_elsa' was properly closed.
[0m21:24:07.494968 [info ] [MainThread]: 
[0m21:24:07.495337 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.18 seconds (0.18s).
[0m21:24:07.495851 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "localhost" (::1), port 5432 failed: FATAL:  database "dbt_elsa" does not exist
  
[0m21:24:07.496447 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- DuplicateYAMLKeysDeprecation: 10 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m21:24:07.499094 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.671378, "process_in_blocks": "0", "process_kernel_time": 0.406834, "process_mem_max_rss": "135729152", "process_out_blocks": "0", "process_user_time": 6.8069}
[0m21:24:07.499626 [debug] [MainThread]: Command `dbt run` failed at 21:24:07.499502 after 5.67 seconds
[0m21:24:07.500035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec83cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed46b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed46ad0>]}
[0m21:24:07.500444 [debug] [MainThread]: Flushing usage events
[0m21:24:07.913490 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:24:39.392608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bab770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092e7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092e74d0>]}


============================== 21:24:39.399567 | 2be3f5a5-312b-418e-805d-a347b91ca2e0 ==============================
[0m21:24:39.399567 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:24:39.400385 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:24:39.673179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108634510>]}
[0m21:24:39.745124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109167df0>]}
[0m21:24:39.746105 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:24:39.874615 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:24:40.020622 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m21:24:40.021511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a530550>]}
[0m21:24:40.030156 [warn ] [MainThread]: [[33mWARNING[0m][DuplicateYAMLKeysDeprecation]: Deprecated functionality
Duplicate key 'columns' in "<unicode string>", line 14, column 5 in file
`models/bronze/_elsa_bronze__models.yml`
[0m21:24:40.030734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109322e40>]}
[0m21:24:44.346418 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'production_journaliere' in the 'models' section of file 'models/bronze/_elsa_bronze__models.yml'
[0m21:24:44.701689 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m21:24:44.716305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a02f930>]}
[0m21:24:44.863268 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:24:44.866737 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:24:44.893351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a10fe10>]}
[0m21:24:44.893969 [info ] [MainThread]: Found 31 models, 2 operations, 1 source, 1569 macros
[0m21:24:44.894427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a371850>]}
[0m21:24:44.896783 [info ] [MainThread]: 
[0m21:24:44.897284 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:24:44.897631 [info ] [MainThread]: 
[0m21:24:44.898176 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:24:44.899062 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:24:44.949799 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:24:44.950229 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:24:44.950555 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:24:44.977196 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.027 seconds
[0m21:24:44.979126 [debug] [ThreadPool]: On list_elsa: Close
[0m21:24:44.979988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa_bronze_bronze)
[0m21:24:44.980959 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "bronze_bronze"
"
[0m21:24:44.988224 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_bronze"
[0m21:24:44.988687 [debug] [ThreadPool]: On create_elsa_bronze_bronze: BEGIN
[0m21:24:44.989047 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:24:44.994589 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:24:44.995019 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_bronze"
[0m21:24:44.995352 [debug] [ThreadPool]: On create_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "create_elsa_bronze_bronze"} */
create schema if not exists "bronze_bronze"
[0m21:24:44.999037 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.003 seconds
[0m21:24:45.000147 [debug] [ThreadPool]: On create_elsa_bronze_bronze: COMMIT
[0m21:24:45.000512 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_bronze"
[0m21:24:45.000865 [debug] [ThreadPool]: On create_elsa_bronze_bronze: COMMIT
[0m21:24:45.002835 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m21:24:45.003428 [debug] [ThreadPool]: On create_elsa_bronze_bronze: Close
[0m21:24:45.010525 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa_bronze_bronze, now list_elsa_bronze_tec_elsa)
[0m21:24:45.011201 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:24:45.018569 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:24:45.021915 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:24:45.022350 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:24:45.022674 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:24:45.022981 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:24:45.023287 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:24:45.029483 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:24:45.029940 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:24:45.030309 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:24:45.030670 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:24:45.031036 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:24:45.031403 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:24:45.041472 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.010 seconds
[0m21:24:45.041991 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.010 seconds
[0m21:24:45.043469 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:24:45.044745 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:24:45.045304 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:24:45.045685 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:24:45.053122 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:45.053535 [debug] [MainThread]: On master: BEGIN
[0m21:24:45.053848 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:24:45.058994 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:24:45.059393 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:45.059808 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:24:45.085270 [debug] [MainThread]: SQL status: SELECT 0 in 0.025 seconds
[0m21:24:45.086607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa70730>]}
[0m21:24:45.087094 [debug] [MainThread]: On master: ROLLBACK
[0m21:24:45.087611 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:45.087979 [debug] [MainThread]: On master: BEGIN
[0m21:24:45.088587 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:24:45.088931 [debug] [MainThread]: On master: COMMIT
[0m21:24:45.089257 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:45.089570 [debug] [MainThread]: On master: COMMIT
[0m21:24:45.090006 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:24:45.115241 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:24:45.121181 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:24:45.125325 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:24:45.126041 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.04s]
[0m21:24:45.126456 [info ] [MainThread]: 
[0m21:24:45.126928 [debug] [MainThread]: On master: Close
[0m21:24:45.134536 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consommation
[0m21:24:45.135156 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:24:45.135865 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consommation)
[0m21:24:45.136386 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consommation
[0m21:24:45.141096 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consommation"
[0m21:24:45.142126 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consommation
[0m21:24:45.182550 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consommation"
[0m21:24:45.183717 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consommation"
[0m21:24:45.184105 [debug] [Thread-1 (]: On model.dbt_elsa.consommation: BEGIN
[0m21:24:45.184462 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:24:45.189870 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:24:45.190333 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consommation"
[0m21:24:45.190722 [debug] [Thread-1 (]: On model.dbt_elsa.consommation: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consommation"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM rte_eco2mix;
  );
[0m21:24:45.192827 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 24: FROM rte_eco2mix;
                         ^

[0m21:24:45.193407 [debug] [Thread-1 (]: On model.dbt_elsa.consommation: ROLLBACK
[0m21:24:45.194380 [debug] [Thread-1 (]: On model.dbt_elsa.consommation: Close
[0m21:24:45.210009 [debug] [Thread-1 (]: Database Error in model consommation (models/bronze/consommation.sql)
  syntax error at or near ";"
  LINE 24: FROM rte_eco2mix;
                           ^
  compiled code at target/run/dbt_elsa/models/bronze/consommation.sql
[0m21:24:45.212882 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2be3f5a5-312b-418e-805d-a347b91ca2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108599810>]}
[0m21:24:45.213676 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.07s]
[0m21:24:45.214380 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consommation
[0m21:24:45.214968 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consommation' to be skipped because of status 'error'.  Reason: Database Error in model consommation (models/bronze/consommation.sql)
  syntax error at or near ";"
  LINE 24: FROM rte_eco2mix;
                           ^
  compiled code at target/run/dbt_elsa/models/bronze/consommation.sql.
[0m21:24:45.217339 [info ] [MainThread]: 
[0m21:24:45.217833 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:45.218161 [debug] [MainThread]: On master: BEGIN
[0m21:24:45.218459 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:24:45.225809 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:24:45.226256 [debug] [MainThread]: On master: COMMIT
[0m21:24:45.226597 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:45.226903 [debug] [MainThread]: On master: COMMIT
[0m21:24:45.227461 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:24:45.253100 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:24:45.258643 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:24:45.285133 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:24:45.286228 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:24:45.286833 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.06s]
[0m21:24:45.287271 [debug] [MainThread]: On master: Close
[0m21:24:45.287770 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:24:45.288067 [debug] [MainThread]: Connection 'model.dbt_elsa.consommation' was properly closed.
[0m21:24:45.288343 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:24:45.288710 [info ] [MainThread]: 
[0m21:24:45.289062 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.39 seconds (0.39s).
[0m21:24:45.290129 [debug] [MainThread]: Command end result
[0m21:24:45.375306 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:24:45.377762 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:24:45.383848 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:24:45.384331 [info ] [MainThread]: 
[0m21:24:45.384917 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:24:45.385348 [info ] [MainThread]: 
[0m21:24:45.385877 [error] [MainThread]: [31mFailure in model consommation (models/bronze/consommation.sql)[0m
[0m21:24:45.386354 [error] [MainThread]:   Database Error in model consommation (models/bronze/consommation.sql)
  syntax error at or near ";"
  LINE 24: FROM rte_eco2mix;
                           ^
  compiled code at target/run/dbt_elsa/models/bronze/consommation.sql
[0m21:24:45.386766 [info ] [MainThread]: 
[0m21:24:45.387224 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consommation.sql
[0m21:24:45.387584 [info ] [MainThread]: 
[0m21:24:45.387966 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:24:45.388542 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- DuplicateYAMLKeysDeprecation: 10 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m21:24:45.391470 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.089322, "process_in_blocks": "0", "process_kernel_time": 0.384455, "process_mem_max_rss": "139231232", "process_out_blocks": "0", "process_user_time": 7.171393}
[0m21:24:45.392269 [debug] [MainThread]: Command `dbt run` failed at 21:24:45.392040 after 6.09 seconds
[0m21:24:45.392988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10985c750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bc2650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10931a2e0>]}
[0m21:24:45.393486 [debug] [MainThread]: Flushing usage events
[0m21:24:45.810288 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:25:56.842781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cea3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5d7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5d74d0>]}


============================== 21:25:56.847943 | 6c3bc025-a045-425e-8cf7-1d00a08abec4 ==============================
[0m21:25:56.847943 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:25:56.848699 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:25:57.052944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d920510>]}
[0m21:25:57.126177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e453df0>]}
[0m21:25:57.127161 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:25:57.255395 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:25:57.398201 [warn ] [MainThread]: [[33mWARNING[0m][DuplicateYAMLKeysDeprecation]: Deprecated functionality
Duplicate key 'columns' in "<unicode string>", line 14, column 5 in file
`models/bronze/_elsa_bronze__models.yml`
[0m21:25:57.398807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7f8750>]}
[0m21:25:57.491260 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 1 files changed.
[0m21:25:57.491943 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/bronze/consommation_journaliere.sql
[0m21:25:57.492423 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:25:57.492804 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/bronze/consommation.sql
[0m21:25:57.958593 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:25:57.976413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f52bc50>]}
[0m21:25:58.124547 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:25:58.127147 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:25:58.145690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f907d90>]}
[0m21:25:58.146192 [info ] [MainThread]: Found 31 models, 2 operations, 1 source, 1569 macros
[0m21:25:58.146560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcdfee0>]}
[0m21:25:58.148461 [info ] [MainThread]: 
[0m21:25:58.148839 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:25:58.149245 [info ] [MainThread]: 
[0m21:25:58.149811 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:25:58.150707 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:25:58.208661 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:25:58.209094 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:25:58.209417 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:25:58.231506 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.022 seconds
[0m21:25:58.232968 [debug] [ThreadPool]: On list_elsa: Close
[0m21:25:58.239454 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:25:58.240110 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:25:58.251209 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:25:58.251604 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:25:58.251910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:25:58.253671 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:25:58.254094 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:25:58.254406 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:58.257722 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:25:58.258133 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:25:58.258472 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:25:58.259354 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:25:58.259682 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:25:58.260010 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:25:58.262461 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:25:58.263912 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:25:58.264349 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:25:58.265568 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:25:58.265935 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:25:58.266271 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:25:58.273541 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:58.273959 [debug] [MainThread]: On master: BEGIN
[0m21:25:58.274268 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:25:58.279660 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:25:58.280058 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:58.280454 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:25:58.291787 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m21:25:58.293164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc8db50>]}
[0m21:25:58.293655 [debug] [MainThread]: On master: ROLLBACK
[0m21:25:58.294193 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:58.294528 [debug] [MainThread]: On master: BEGIN
[0m21:25:58.295123 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:25:58.295462 [debug] [MainThread]: On master: COMMIT
[0m21:25:58.295788 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:58.296094 [debug] [MainThread]: On master: COMMIT
[0m21:25:58.296534 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:25:58.334950 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:25:58.341035 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:25:58.345170 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:25:58.345849 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:25:58.346243 [info ] [MainThread]: 
[0m21:25:58.346682 [debug] [MainThread]: On master: Close
[0m21:25:58.351412 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consommation_journaliere
[0m21:25:58.352476 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:25:58.353886 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consommation_journaliere)
[0m21:25:58.354393 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consommation_journaliere
[0m21:25:58.358754 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consommation_journaliere"
[0m21:25:58.359586 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consommation_journaliere
[0m21:25:58.398625 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consommation_journaliere"
[0m21:25:58.399503 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consommation_journaliere"
[0m21:25:58.399888 [debug] [Thread-1 (]: On model.dbt_elsa.consommation_journaliere: BEGIN
[0m21:25:58.400245 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:58.405542 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:25:58.406008 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consommation_journaliere"
[0m21:25:58.406404 [debug] [Thread-1 (]: On model.dbt_elsa.consommation_journaliere: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consommation_journaliere"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM rte_eco2mix
  );
[0m21:25:58.407270 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "rte_eco2mix" does not exist
LINE 24: FROM rte_eco2mix
              ^

[0m21:25:58.407665 [debug] [Thread-1 (]: On model.dbt_elsa.consommation_journaliere: ROLLBACK
[0m21:25:58.408293 [debug] [Thread-1 (]: On model.dbt_elsa.consommation_journaliere: Close
[0m21:25:58.414667 [debug] [Thread-1 (]: Database Error in model consommation_journaliere (models/bronze/consommation_journaliere.sql)
  relation "rte_eco2mix" does not exist
  LINE 24: FROM rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consommation_journaliere.sql
[0m21:25:58.416442 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c3bc025-a045-425e-8cf7-1d00a08abec4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff909f0>]}
[0m21:25:58.417116 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.06s]
[0m21:25:58.417771 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consommation_journaliere
[0m21:25:58.418335 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consommation_journaliere' to be skipped because of status 'error'.  Reason: Database Error in model consommation_journaliere (models/bronze/consommation_journaliere.sql)
  relation "rte_eco2mix" does not exist
  LINE 24: FROM rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consommation_journaliere.sql.
[0m21:25:58.420744 [info ] [MainThread]: 
[0m21:25:58.421204 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:58.421520 [debug] [MainThread]: On master: BEGIN
[0m21:25:58.421814 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:25:58.427075 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:25:58.427502 [debug] [MainThread]: On master: COMMIT
[0m21:25:58.427829 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:58.428236 [debug] [MainThread]: On master: COMMIT
[0m21:25:58.428795 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:25:58.465412 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:25:58.470924 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:25:58.496974 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:25:58.497936 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:25:58.498541 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:25:58.498981 [debug] [MainThread]: On master: Close
[0m21:25:58.499454 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:25:58.499754 [debug] [MainThread]: Connection 'model.dbt_elsa.consommation_journaliere' was properly closed.
[0m21:25:58.500020 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:25:58.500367 [info ] [MainThread]: 
[0m21:25:58.500727 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.35 seconds (0.35s).
[0m21:25:58.501812 [debug] [MainThread]: Command end result
[0m21:25:58.584559 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:25:58.587010 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:25:58.594094 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:25:58.594729 [info ] [MainThread]: 
[0m21:25:58.595123 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:25:58.595487 [info ] [MainThread]: 
[0m21:25:58.595931 [error] [MainThread]: [31mFailure in model consommation_journaliere (models/bronze/consommation_journaliere.sql)[0m
[0m21:25:58.596360 [error] [MainThread]:   Database Error in model consommation_journaliere (models/bronze/consommation_journaliere.sql)
  relation "rte_eco2mix" does not exist
  LINE 24: FROM rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consommation_journaliere.sql
[0m21:25:58.596698 [info ] [MainThread]: 
[0m21:25:58.597176 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consommation_journaliere.sql
[0m21:25:58.597515 [info ] [MainThread]: 
[0m21:25:58.597887 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:25:58.598469 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- DuplicateYAMLKeysDeprecation: 10 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m21:25:58.601097 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.8455918, "process_in_blocks": "0", "process_kernel_time": 0.384698, "process_mem_max_rss": "139583488", "process_out_blocks": "0", "process_user_time": 3.044986}
[0m21:25:58.601794 [debug] [MainThread]: Command `dbt run` failed at 21:25:58.601582 after 1.85 seconds
[0m21:25:58.602299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff3c9b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f42dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f58c6d0>]}
[0m21:25:58.602745 [debug] [MainThread]: Flushing usage events
[0m21:25:59.040477 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:29:10.128381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ebf770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075eb610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075eb4d0>]}


============================== 21:29:10.136271 | 4a1c139f-5bf5-48c1-89e5-37f491e0a65e ==============================
[0m21:29:10.136271 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:29:10.137260 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt parse', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:29:10.442076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a1c139f-5bf5-48c1-89e5-37f491e0a65e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106940510>]}
[0m21:29:10.523022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a1c139f-5bf5-48c1-89e5-37f491e0a65e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107473df0>]}
[0m21:29:10.524980 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:29:10.682269 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:29:10.843352 [warn ] [MainThread]: [[33mWARNING[0m][DuplicateYAMLKeysDeprecation]: Deprecated functionality
Duplicate key 'columns' in "<unicode string>", line 14, column 5 in file
`models/bronze/_elsa_bronze__models.yml`
[0m21:29:10.844011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '4a1c139f-5bf5-48c1-89e5-37f491e0a65e', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10883c750>]}
[0m21:29:11.094430 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 1 files changed.
[0m21:29:11.095299 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:29:11.095849 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:29:11.096178 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/bronze/consommation_journaliere.sql
[0m21:29:11.570763 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:29:11.588742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a1c139f-5bf5-48c1-89e5-37f491e0a65e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108553c50>]}
[0m21:29:11.593022 [info ] [MainThread]: Performance info: /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/perf_info.json
[0m21:29:11.749914 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:29:11.754154 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:29:11.754902 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- DuplicateYAMLKeysDeprecation: 10 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m21:29:11.759232 [debug] [MainThread]: Resource report: {"command_name": "parse", "command_success": true, "command_wall_clock_time": 1.7355336, "process_in_blocks": "0", "process_kernel_time": 0.775115, "process_mem_max_rss": "131362816", "process_out_blocks": "0", "process_user_time": 3.452907}
[0m21:29:11.759989 [debug] [MainThread]: Command `dbt parse` succeeded at 21:29:11.759812 after 1.74 seconds
[0m21:29:11.760492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074dfe70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bd3070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076869c0>]}
[0m21:29:11.760947 [debug] [MainThread]: Flushing usage events
[0m21:29:12.234196 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:29:50.417553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfff770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6e7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6e74d0>]}


============================== 21:29:50.422634 | 9c90b8c7-fb72-4743-9299-952db29c6e37 ==============================
[0m21:29:50.422634 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:29:50.423272 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:29:50.577203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9c90b8c7-fb72-4743-9299-952db29c6e37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca7c510>]}
[0m21:29:50.750102 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.41983044, "process_in_blocks": "0", "process_kernel_time": 0.399137, "process_mem_max_rss": "105918464", "process_out_blocks": "0", "process_user_time": 1.838769}
[0m21:29:50.750799 [debug] [MainThread]: Command `dbt clean` succeeded at 21:29:50.750666 after 0.42 seconds
[0m21:29:50.751211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d57f130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d57f020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d66f850>]}
[0m21:29:50.751600 [debug] [MainThread]: Flushing usage events
[0m21:29:51.177625 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:30:01.360534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111947770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11307b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11307b4d0>]}


============================== 21:30:01.365907 | 1263dbd9-35a3-4d5a-9780-e6aad386cb8e ==============================
[0m21:30:01.365907 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:30:01.366669 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:30:01.575833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1263dbd9-35a3-4d5a-9780-e6aad386cb8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123c4510>]}
[0m21:30:01.649248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1263dbd9-35a3-4d5a-9780-e6aad386cb8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ef7df0>]}
[0m21:30:01.650230 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:30:01.744497 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found 3 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_packages. Run "dbt deps" to install package dependencies.
[0m21:30:01.747646 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.4741862, "process_in_blocks": "0", "process_kernel_time": 0.282345, "process_mem_max_rss": "109408256", "process_out_blocks": "0", "process_user_time": 1.869808}
[0m21:30:01.748285 [debug] [MainThread]: Command `dbt run` failed at 21:30:01.748151 after 0.47 seconds
[0m21:30:01.748794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112feac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112feb050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ed6990>]}
[0m21:30:01.749225 [debug] [MainThread]: Flushing usage events
[0m21:30:02.154328 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:30:14.746298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a357770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba4b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba4b4d0>]}


============================== 21:30:14.751248 | 8a4fa3e6-64b0-4c0b-9e72-e931243609bc ==============================
[0m21:30:14.751248 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:30:14.751875 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:30:14.905721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a4fa3e6-64b0-4c0b-9e72-e931243609bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add0510>]}
[0m21:30:14.936203 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-gmwzrvgd'
[0m21:30:14.936693 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:30:15.081254 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m21:30:15.083135 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m21:30:15.156987 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m21:30:15.166497 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m21:30:15.242893 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m21:30:15.251710 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m21:30:15.318176 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m21:30:15.332135 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m21:30:15.397426 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m21:30:15.404068 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m21:30:15.855985 [info ] [MainThread]: Installed from version 1.3.0
[0m21:30:15.856846 [info ] [MainThread]: Up to date!
[0m21:30:15.857972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8a4fa3e6-64b0-4c0b-9e72-e931243609bc', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8d6be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc227a0>]}
[0m21:30:15.858787 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m21:30:16.679553 [info ] [MainThread]: Installed from version 0.10.9
[0m21:30:16.679983 [info ] [MainThread]: Up to date!
[0m21:30:16.680482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8a4fa3e6-64b0-4c0b-9e72-e931243609bc', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc54b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b345220>]}
[0m21:30:16.680895 [info ] [MainThread]: Installing elementary-data/elementary
[0m21:30:17.182475 [info ] [MainThread]: Installed from version 0.19.0
[0m21:30:17.182926 [info ] [MainThread]: Updated version available: 0.19.1
[0m21:30:17.183304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8a4fa3e6-64b0-4c0b-9e72-e931243609bc', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc84ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc84f30>]}
[0m21:30:17.183698 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m21:30:17.580937 [info ] [MainThread]: Installed from version 0.14.2
[0m21:30:17.581515 [info ] [MainThread]: Up to date!
[0m21:30:17.582130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8a4fa3e6-64b0-4c0b-9e72-e931243609bc', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc4d0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc4d490>]}
[0m21:30:17.582671 [info ] [MainThread]: 
[0m21:30:17.583077 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m21:30:17.588609 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.9285426, "process_in_blocks": "0", "process_kernel_time": 0.524071, "process_mem_max_rss": "114716672", "process_out_blocks": "0", "process_user_time": 2.092142}
[0m21:30:17.589273 [debug] [MainThread]: Command `dbt deps` succeeded at 21:30:17.589136 after 2.93 seconds
[0m21:30:17.589711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc7c3c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc73f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc73c50>]}
[0m21:30:17.590519 [debug] [MainThread]: Flushing usage events
[0m21:30:17.978195 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:31:24.322195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11319b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148c7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148c74d0>]}


============================== 21:31:24.330989 | 5b3a206f-acfa-4498-abb0-1888b1845f52 ==============================
[0m21:31:24.330989 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:31:24.331882 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m21:31:24.547990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b3a206f-acfa-4498-abb0-1888b1845f52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c1c510>]}
[0m21:31:24.729102 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-vfycipxa'
[0m21:31:24.729644 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:31:24.819397 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m21:31:24.821646 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m21:31:24.890299 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m21:31:24.899439 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m21:31:24.959005 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m21:31:24.967662 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m21:31:25.034207 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m21:31:25.047846 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m21:31:25.121942 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m21:31:25.129619 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m21:31:25.482171 [info ] [MainThread]: Installed from version 1.3.0
[0m21:31:25.482634 [info ] [MainThread]: Up to date!
[0m21:31:25.483065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '5b3a206f-acfa-4498-abb0-1888b1845f52', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11474ebe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114aa67a0>]}
[0m21:31:25.483486 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m21:31:26.200241 [info ] [MainThread]: Installed from version 0.10.9
[0m21:31:26.200697 [info ] [MainThread]: Up to date!
[0m21:31:26.201088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '5b3a206f-acfa-4498-abb0-1888b1845f52', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ad8b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141a5220>]}
[0m21:31:26.201492 [info ] [MainThread]: Installing elementary-data/elementary
[0m21:31:26.761281 [info ] [MainThread]: Installed from version 0.19.0
[0m21:31:26.762087 [info ] [MainThread]: Updated version available: 0.19.1
[0m21:31:26.763084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '5b3a206f-acfa-4498-abb0-1888b1845f52', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b08ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b08f30>]}
[0m21:31:26.763752 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m21:31:27.067818 [info ] [MainThread]: Installed from version 0.14.2
[0m21:31:27.068284 [info ] [MainThread]: Up to date!
[0m21:31:27.068673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '5b3a206f-acfa-4498-abb0-1888b1845f52', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ad10d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ad1490>]}
[0m21:31:27.069096 [info ] [MainThread]: 
[0m21:31:27.069479 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m21:31:27.074929 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.8585181, "process_in_blocks": "0", "process_kernel_time": 1.05741, "process_mem_max_rss": "114839552", "process_out_blocks": "0", "process_user_time": 2.738507}
[0m21:31:27.076290 [debug] [MainThread]: Command `dbt deps` succeeded at 21:31:27.076102 after 2.86 seconds
[0m21:31:27.076727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b003c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114af7f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114af7c50>]}
[0m21:31:27.077116 [debug] [MainThread]: Flushing usage events
[0m21:31:27.512347 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:33:00.300170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f6f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6a3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6a34d0>]}


============================== 21:33:00.308932 | 441014e4-1ebe-4e48-a32c-0ccabb3e9c2b ==============================
[0m21:33:00.308932 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:33:00.309910 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m21:33:00.611752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9f0510>]}
[0m21:33:00.692542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b523df0>]}
[0m21:33:00.694224 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:33:00.866659 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:33:00.868816 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:33:00.869598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b615350>]}
[0m21:33:00.889974 [warn ] [MainThread]: [[33mWARNING[0m][DuplicateYAMLKeysDeprecation]: Deprecated functionality
Duplicate key 'columns' in "<unicode string>", line 14, column 5 in file
`models/bronze/_elsa_bronze__models.yml`
[0m21:33:00.890685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6ded50>]}
[0m21:33:05.955835 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:33:05.969938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c960e50>]}
[0m21:33:06.132606 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:33:06.137087 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:33:06.180198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccafe10>]}
[0m21:33:06.180762 [info ] [MainThread]: Found 31 models, 2 operations, 1 source, 1569 macros
[0m21:33:06.181164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccb87d0>]}
[0m21:33:06.183213 [info ] [MainThread]: 
[0m21:33:06.183617 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:33:06.183963 [info ] [MainThread]: 
[0m21:33:06.184510 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:33:06.185327 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:33:06.257393 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:33:06.257852 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:33:06.258194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:33:06.308849 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.051 seconds
[0m21:33:06.310907 [debug] [ThreadPool]: On list_elsa: Close
[0m21:33:06.319344 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:33:06.325649 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:33:06.327824 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:33:06.332944 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:33:06.333437 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:33:06.333794 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:33:06.334129 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:33:06.334466 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:33:06.342166 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:33:06.342597 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:33:06.342985 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:33:06.343344 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:33:06.343727 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:33:06.344152 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:33:06.349326 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m21:33:06.349814 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m21:33:06.351167 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:33:06.352390 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:33:06.352951 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:33:06.353350 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:33:06.360623 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:06.361064 [debug] [MainThread]: On master: BEGIN
[0m21:33:06.361369 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:33:06.367012 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:33:06.367455 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:06.367860 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:33:06.381484 [debug] [MainThread]: SQL status: SELECT 0 in 0.013 seconds
[0m21:33:06.382924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c678ec0>]}
[0m21:33:06.383450 [debug] [MainThread]: On master: ROLLBACK
[0m21:33:06.383988 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:06.384326 [debug] [MainThread]: On master: BEGIN
[0m21:33:06.384922 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:33:06.385269 [debug] [MainThread]: On master: COMMIT
[0m21:33:06.385605 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:06.385925 [debug] [MainThread]: On master: COMMIT
[0m21:33:06.386378 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:33:06.408963 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:33:06.415033 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:33:06.419287 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:33:06.419981 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.03s]
[0m21:33:06.420584 [info ] [MainThread]: 
[0m21:33:06.421044 [debug] [MainThread]: On master: Close
[0m21:33:06.426480 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:33:06.427351 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:33:06.428069 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:33:06.428586 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:33:06.433308 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:33:06.434463 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:33:06.475482 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:33:06.476674 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:06.477078 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:33:06.477463 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:33:06.482924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:33:06.483399 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:06.483801 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:33:06.493544 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.009 seconds
[0m21:33:06.501342 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:06.501826 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp" rename to "bronze_eco2mix"
[0m21:33:06.502796 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:33:06.530131 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:06.530688 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."bronze_eco2mix" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:33:06.533584 [debug] [Thread-1 (]: SQL status: COMMENT in 0.002 seconds
[0m21:33:06.557751 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:06.558296 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'bronze_eco2mix'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:33:06.568272 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.009 seconds
[0m21:33:06.573456 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:06.573971 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:33:06.574683 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m21:33:06.578559 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:33:06.579422 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:33:06.600645 [debug] [Thread-1 (]: Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  'add_index' is undefined
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql). This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:33:06.604230 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '441014e4-1ebe-4e48-a32c-0ccabb3e9c2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a955810>]}
[0m21:33:06.605274 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.17s]
[0m21:33:06.606245 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:33:06.607083 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  'add_index' is undefined
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql). This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m21:33:06.611278 [info ] [MainThread]: 
[0m21:33:06.612279 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:06.613103 [debug] [MainThread]: On master: BEGIN
[0m21:33:06.613570 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:33:06.620320 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:33:06.620756 [debug] [MainThread]: On master: COMMIT
[0m21:33:06.621090 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:06.621399 [debug] [MainThread]: On master: COMMIT
[0m21:33:06.621850 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:33:06.653430 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:33:06.660641 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:33:06.690963 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:33:06.691987 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:33:06.692524 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:33:06.692925 [debug] [MainThread]: On master: Close
[0m21:33:06.693393 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:33:06.693698 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:33:06.693979 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:33:06.694353 [info ] [MainThread]: 
[0m21:33:06.694846 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m21:33:06.696337 [debug] [MainThread]: Command end result
[0m21:33:06.787045 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:33:06.789604 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:33:06.796462 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:33:06.796850 [info ] [MainThread]: 
[0m21:33:06.797377 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:33:06.797758 [info ] [MainThread]: 
[0m21:33:06.798209 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:33:06.798727 [error] [MainThread]:   Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  'add_index' is undefined
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql). This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:33:06.799243 [info ] [MainThread]: 
[0m21:33:06.799698 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:33:06.800124 [info ] [MainThread]: 
[0m21:33:06.800570 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:33:06.801227 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- DuplicateYAMLKeysDeprecation: 10 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m21:33:06.805602 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.615728, "process_in_blocks": "0", "process_kernel_time": 0.904379, "process_mem_max_rss": "139931648", "process_out_blocks": "0", "process_user_time": 8.06995}
[0m21:33:06.806218 [debug] [MainThread]: Command `dbt run` failed at 21:33:06.806094 after 6.62 seconds
[0m21:33:06.806666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc0db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd04c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6da2e0>]}
[0m21:33:06.807065 [debug] [MainThread]: Flushing usage events
[0m21:33:07.348103 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:33:50.429391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11094f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11204b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11204b4d0>]}


============================== 21:33:50.438303 | 7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81 ==============================
[0m21:33:50.438303 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:33:50.439218 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:33:50.659812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113c8510>]}
[0m21:33:50.734958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ecfdf0>]}
[0m21:33:50.736799 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:33:50.913824 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:33:51.375617 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:33:51.376701 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:33:51.981384 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m21:33:52.001295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11328e550>]}
[0m21:33:52.171726 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:33:52.175146 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:33:52.216071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fad400>]}
[0m21:33:52.216671 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1569 macros
[0m21:33:52.217059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135cdc50>]}
[0m21:33:52.219064 [info ] [MainThread]: 
[0m21:33:52.219453 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:33:52.219841 [info ] [MainThread]: 
[0m21:33:52.220454 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:33:52.221325 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:33:52.289798 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:33:52.290252 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:33:52.290592 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:33:52.320572 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.030 seconds
[0m21:33:52.322253 [debug] [ThreadPool]: On list_elsa: Close
[0m21:33:52.329769 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:33:52.337325 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:33:52.337964 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:33:52.340918 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:33:52.341354 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:33:52.341692 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:33:52.342013 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:33:52.342331 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:33:52.349168 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:33:52.349666 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:33:52.350066 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:33:52.350420 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:33:52.350778 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:33:52.351162 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:33:52.355914 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:33:52.356422 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m21:33:52.357731 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:33:52.358891 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:33:52.359479 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:33:52.359826 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:33:52.366756 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:52.367152 [debug] [MainThread]: On master: BEGIN
[0m21:33:52.367443 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:33:52.372796 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:33:52.373207 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:52.373612 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:33:52.384883 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m21:33:52.386210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113871230>]}
[0m21:33:52.386721 [debug] [MainThread]: On master: ROLLBACK
[0m21:33:52.387298 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:52.387647 [debug] [MainThread]: On master: BEGIN
[0m21:33:52.388232 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:33:52.388574 [debug] [MainThread]: On master: COMMIT
[0m21:33:52.388895 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:52.389193 [debug] [MainThread]: On master: COMMIT
[0m21:33:52.389657 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:33:52.428432 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:33:52.434544 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:33:52.438762 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:33:52.439476 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:33:52.439848 [info ] [MainThread]: 
[0m21:33:52.440341 [debug] [MainThread]: On master: Close
[0m21:33:52.446032 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:33:52.446904 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:33:52.447559 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:33:52.448278 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:33:52.454132 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:33:52.455008 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:33:52.494913 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:33:52.495788 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:52.496174 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:33:52.496523 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:33:52.501872 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:33:52.502399 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:52.502903 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:33:52.506659 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:33:52.518857 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:52.519324 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp" rename to "bronze_eco2mix"
[0m21:33:52.520208 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:33:52.542820 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:52.543299 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."bronze_eco2mix" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:33:52.544268 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:33:52.567927 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:52.568519 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'bronze_eco2mix'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:33:52.577185 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.008 seconds
[0m21:33:52.582375 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:33:52.582932 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:33:52.583837 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m21:33:52.588075 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:33:52.588915 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:33:52.603858 [debug] [Thread-1 (]: Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  'add_index' is undefined
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql). This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:33:52.606600 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cd65e31-88c3-4ee3-b7fc-a8e7d78f3f81', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135e6a50>]}
[0m21:33:52.607599 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.16s]
[0m21:33:52.608436 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:33:52.609127 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  'add_index' is undefined
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql). This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m21:33:52.612604 [info ] [MainThread]: 
[0m21:33:52.613302 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:52.614277 [debug] [MainThread]: On master: BEGIN
[0m21:33:52.614757 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:33:52.622471 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m21:33:52.622948 [debug] [MainThread]: On master: COMMIT
[0m21:33:52.623325 [debug] [MainThread]: Using postgres connection "master"
[0m21:33:52.623663 [debug] [MainThread]: On master: COMMIT
[0m21:33:52.624113 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:33:52.659878 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:33:52.666450 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:33:52.692046 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:33:52.692989 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:33:52.693511 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:33:52.693898 [debug] [MainThread]: On master: Close
[0m21:33:52.694364 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:33:52.694728 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:33:52.695085 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:33:52.695474 [info ] [MainThread]: 
[0m21:33:52.695829 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m21:33:52.697062 [debug] [MainThread]: Command end result
[0m21:33:52.779718 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:33:52.782398 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:33:52.789042 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:33:52.789583 [info ] [MainThread]: 
[0m21:33:52.790046 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:33:52.790437 [info ] [MainThread]: 
[0m21:33:52.790875 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:33:52.791306 [error] [MainThread]:   Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  'add_index' is undefined
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql). This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m21:33:52.791668 [info ] [MainThread]: 
[0m21:33:52.792100 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:33:52.792453 [info ] [MainThread]: 
[0m21:33:52.792817 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:33:52.797927 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.4757447, "process_in_blocks": "0", "process_kernel_time": 0.719592, "process_mem_max_rss": "141553664", "process_out_blocks": "0", "process_user_time": 3.967861}
[0m21:33:52.798706 [debug] [MainThread]: Command `dbt run` failed at 21:33:52.798527 after 2.48 seconds
[0m21:33:52.799337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137d7cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113603930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113603bb0>]}
[0m21:33:52.799945 [debug] [MainThread]: Flushing usage events
[0m21:33:53.202802 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:37:07.539844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e0f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113543610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135434d0>]}


============================== 21:37:07.548810 | b584fa71-99eb-4529-9767-f320916f61d4 ==============================
[0m21:37:07.548810 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:37:07.549748 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:37:07.880432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b584fa71-99eb-4529-9767-f320916f61d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11288c510>]}
[0m21:37:07.961011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b584fa71-99eb-4529-9767-f320916f61d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133bfdf0>]}
[0m21:37:07.962773 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:37:08.121405 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:37:08.649322 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m21:37:08.650162 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://macros/add_index.sql
[0m21:37:08.856810 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:37:08.875283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b584fa71-99eb-4529-9767-f320916f61d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114775350>]}
[0m21:37:09.045649 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:37:09.050346 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:37:09.100937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b584fa71-99eb-4529-9767-f320916f61d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133a2990>]}
[0m21:37:09.101557 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1570 macros
[0m21:37:09.101995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b584fa71-99eb-4529-9767-f320916f61d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11352e430>]}
[0m21:37:09.104272 [info ] [MainThread]: 
[0m21:37:09.104744 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:37:09.105132 [info ] [MainThread]: 
[0m21:37:09.105899 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:37:09.106956 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:37:09.186904 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:37:09.188031 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:37:09.188850 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:37:09.245200 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.056 seconds
[0m21:37:09.247336 [debug] [ThreadPool]: On list_elsa: Close
[0m21:37:09.256687 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:37:09.257443 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:37:09.267355 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:37:09.270318 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:37:09.270765 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:37:09.271157 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:37:09.271500 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:37:09.271826 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:37:09.279114 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:37:09.279597 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:37:09.279935 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:37:09.280276 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:37:09.280640 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:37:09.281034 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:37:09.288728 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m21:37:09.289215 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m21:37:09.290548 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:37:09.291733 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:37:09.292287 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:37:09.292884 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:37:09.300629 [debug] [MainThread]: Using postgres connection "master"
[0m21:37:09.301073 [debug] [MainThread]: On master: BEGIN
[0m21:37:09.301375 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:37:09.306736 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:37:09.307156 [debug] [MainThread]: Using postgres connection "master"
[0m21:37:09.307562 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:37:09.322156 [debug] [MainThread]: SQL status: SELECT 0 in 0.014 seconds
[0m21:37:09.323578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b584fa71-99eb-4529-9767-f320916f61d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141e8a10>]}
[0m21:37:09.324083 [debug] [MainThread]: On master: ROLLBACK
[0m21:37:09.324641 [debug] [MainThread]: Using postgres connection "master"
[0m21:37:09.325058 [debug] [MainThread]: On master: BEGIN
[0m21:37:09.325719 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:37:09.326051 [debug] [MainThread]: On master: COMMIT
[0m21:37:09.326365 [debug] [MainThread]: Using postgres connection "master"
[0m21:37:09.326660 [debug] [MainThread]: On master: COMMIT
[0m21:37:09.327078 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:37:09.364751 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:37:09.370546 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:37:09.374682 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:37:09.375400 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:37:09.375802 [info ] [MainThread]: 
[0m21:37:09.376243 [debug] [MainThread]: On master: Close
[0m21:37:09.382327 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:37:09.383206 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:37:09.383737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:37:09.384141 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:37:09.388324 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:37:09.389445 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:37:09.429612 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:37:09.431630 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:37:09.432224 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:37:09.432661 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:37:09.439108 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:37:09.439659 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:37:09.440135 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:37:09.444926 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m21:37:09.452757 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:37:09.453439 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp" rename to "bronze_eco2mix"
[0m21:37:09.454347 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:37:09.477436 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:37:09.477945 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."bronze_eco2mix" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:37:09.478885 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:37:09.502076 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:37:09.502653 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'bronze_eco2mix'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:37:09.514251 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.011 seconds
[0m21:37:09.519206 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:37:09.519814 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:37:09.520859 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m21:37:09.526170 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:37:09.527698 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:37:09.544055 [debug] [Thread-1 (]: Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_index' takes not more than 1 argument(s)
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql)
[0m21:37:09.547321 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b584fa71-99eb-4529-9767-f320916f61d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143da450>]}
[0m21:37:09.548520 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.16s]
[0m21:37:09.549496 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:37:09.550320 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_index' takes not more than 1 argument(s)
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql).
[0m21:37:09.555569 [info ] [MainThread]: 
[0m21:37:09.556161 [debug] [MainThread]: Using postgres connection "master"
[0m21:37:09.556543 [debug] [MainThread]: On master: BEGIN
[0m21:37:09.556901 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:37:09.563605 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:37:09.564111 [debug] [MainThread]: On master: COMMIT
[0m21:37:09.564456 [debug] [MainThread]: Using postgres connection "master"
[0m21:37:09.564776 [debug] [MainThread]: On master: COMMIT
[0m21:37:09.565475 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:37:09.602290 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:37:09.607563 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:37:09.633759 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:37:09.634728 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:37:09.635260 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:37:09.635662 [debug] [MainThread]: On master: Close
[0m21:37:09.636134 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:37:09.636440 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:37:09.636730 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:37:09.637115 [info ] [MainThread]: 
[0m21:37:09.637515 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.53 seconds (0.53s).
[0m21:37:09.638641 [debug] [MainThread]: Command end result
[0m21:37:09.723456 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:37:09.726076 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:37:09.733610 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:37:09.734123 [info ] [MainThread]: 
[0m21:37:09.734605 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:37:09.735035 [info ] [MainThread]: 
[0m21:37:09.735498 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:37:09.735949 [error] [MainThread]:   Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_index' takes not more than 1 argument(s)
  
  > in macro run_hooks (macros/materializations/hooks.sql)
  > called by macro materialization_view_default (macros/materializations/models/view.sql)
  > called by model daily_consumption (models/bronze/daily_consumption.sql)
[0m21:37:09.736312 [info ] [MainThread]: 
[0m21:37:09.736756 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:37:09.737127 [info ] [MainThread]: 
[0m21:37:09.737525 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:37:09.741465 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.3176284, "process_in_blocks": "0", "process_kernel_time": 0.881801, "process_mem_max_rss": "135315456", "process_out_blocks": "0", "process_user_time": 3.711478}
[0m21:37:09.742133 [debug] [MainThread]: Command `dbt run` failed at 21:37:09.741992 after 2.32 seconds
[0m21:37:09.742934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147ec890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b7c7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114b7ca50>]}
[0m21:37:09.743733 [debug] [MainThread]: Flushing usage events
[0m21:37:10.237892 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:38:28.228147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e15f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f893610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8934d0>]}


============================== 21:38:28.237976 | 2407f711-f02f-4a04-bcb6-689f4923dc7d ==============================
[0m21:38:28.237976 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:38:28.238915 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:38:28.489530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2407f711-f02f-4a04-bcb6-689f4923dc7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ebdc510>]}
[0m21:38:28.563713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2407f711-f02f-4a04-bcb6-689f4923dc7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f70fdf0>]}
[0m21:38:28.565761 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:38:28.727074 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:38:29.260201 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m21:38:29.261006 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://macros/add_primary_key_composite.sql
[0m21:38:29.261648 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:38:29.586919 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_primary_key_composite' takes not more than 1 argument(s)
[0m21:38:29.589833 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4662642, "process_in_blocks": "0", "process_kernel_time": 0.700961, "process_mem_max_rss": "124116992", "process_out_blocks": "0", "process_user_time": 3.144186}
[0m21:38:29.590406 [debug] [MainThread]: Command `dbt run` failed at 21:38:29.590279 after 1.47 seconds
[0m21:38:29.590872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f802750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f803350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110be56d0>]}
[0m21:38:29.591309 [debug] [MainThread]: Flushing usage events
[0m21:38:30.056200 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:39:28.865997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131b7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148af610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148af4d0>]}


============================== 21:39:28.877409 | 4bb98881-8221-413e-9814-c373fefcbe35 ==============================
[0m21:39:28.877409 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:39:28.878958 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:39:29.209210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4bb98881-8221-413e-9814-c373fefcbe35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c2c510>]}
[0m21:39:29.283366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4bb98881-8221-413e-9814-c373fefcbe35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114733df0>]}
[0m21:39:29.285077 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:39:29.446053 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:39:29.899251 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m21:39:29.900122 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://macros/add_primary_key_composite.sql
[0m21:39:29.900719 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:39:30.503442 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:39:30.522630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4bb98881-8221-413e-9814-c373fefcbe35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115b06250>]}
[0m21:39:30.705711 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:39:30.711106 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:39:30.757396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4bb98881-8221-413e-9814-c373fefcbe35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115811400>]}
[0m21:39:30.758012 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1571 macros
[0m21:39:30.758452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4bb98881-8221-413e-9814-c373fefcbe35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115e09b70>]}
[0m21:39:30.760715 [info ] [MainThread]: 
[0m21:39:30.761401 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:39:30.761868 [info ] [MainThread]: 
[0m21:39:30.762502 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:39:30.763492 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:39:30.835776 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:39:30.836286 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:39:30.836664 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:39:30.878445 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.042 seconds
[0m21:39:30.880220 [debug] [ThreadPool]: On list_elsa: Close
[0m21:39:30.886969 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:39:30.887667 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:39:30.894701 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:39:30.897737 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:39:30.898157 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:39:30.898477 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:39:30.898787 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:39:30.899091 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:39:30.905988 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:39:30.906418 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:39:30.906738 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:39:30.907061 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:39:30.907407 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:39:30.907776 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:39:30.911969 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:39:30.912398 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:39:30.913615 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:39:30.914735 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:39:30.915298 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:39:30.915851 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:39:30.922739 [debug] [MainThread]: Using postgres connection "master"
[0m21:39:30.923147 [debug] [MainThread]: On master: BEGIN
[0m21:39:30.923441 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:39:30.928803 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:39:30.929204 [debug] [MainThread]: Using postgres connection "master"
[0m21:39:30.929594 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:39:30.940543 [debug] [MainThread]: SQL status: SELECT 0 in 0.010 seconds
[0m21:39:30.941970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4bb98881-8221-413e-9814-c373fefcbe35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1160e1640>]}
[0m21:39:30.942487 [debug] [MainThread]: On master: ROLLBACK
[0m21:39:30.943018 [debug] [MainThread]: Using postgres connection "master"
[0m21:39:30.943350 [debug] [MainThread]: On master: BEGIN
[0m21:39:30.943991 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:39:30.944341 [debug] [MainThread]: On master: COMMIT
[0m21:39:30.944671 [debug] [MainThread]: Using postgres connection "master"
[0m21:39:30.944985 [debug] [MainThread]: On master: COMMIT
[0m21:39:30.945428 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:39:30.983734 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:39:30.989647 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:39:30.993405 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:39:30.994097 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:39:30.994546 [info ] [MainThread]: 
[0m21:39:30.995017 [debug] [MainThread]: On master: Close
[0m21:39:31.000344 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:39:31.001348 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:39:31.002141 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:39:31.002585 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:39:31.006694 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:39:31.007515 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:39:31.047756 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:39:31.048703 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:39:31.049111 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:39:31.049475 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:39:31.054957 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:39:31.055420 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:39:31.055813 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:39:31.059030 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:39:31.069692 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:39:31.070172 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp" rename to "bronze_eco2mix"
[0m21:39:31.071081 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:39:31.094510 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:39:31.095009 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."bronze_eco2mix" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:39:31.095993 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:39:31.119306 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:39:31.119830 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'bronze_eco2mix'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:39:31.128415 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.008 seconds
[0m21:39:31.133051 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:39:31.133545 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:39:31.134654 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:39:31.136751 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:39:31.137193 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."bronze_eco2mix"
ADD PRIMARY KEY IF NOT EXISTS (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:39:31.138284 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "IF"
LINE 10: ADD PRIMARY KEY IF NOT EXISTS (i, d, c, r, e, a, t, e, d, _,...
                         ^

[0m21:39:31.138728 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:39:31.139415 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:39:31.154794 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  syntax error at or near "IF"
  LINE 10: ADD PRIMARY KEY IF NOT EXISTS (i, d, c, r, e, a, t, e, d, _,...
                           ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:39:31.156813 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4bb98881-8221-413e-9814-c373fefcbe35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115e28950>]}
[0m21:39:31.157547 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.15s]
[0m21:39:31.158414 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:39:31.159182 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  syntax error at or near "IF"
  LINE 10: ADD PRIMARY KEY IF NOT EXISTS (i, d, c, r, e, a, t, e, d, _,...
                           ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:39:31.161635 [info ] [MainThread]: 
[0m21:39:31.162116 [debug] [MainThread]: Using postgres connection "master"
[0m21:39:31.162431 [debug] [MainThread]: On master: BEGIN
[0m21:39:31.162729 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:39:31.169728 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:39:31.170327 [debug] [MainThread]: On master: COMMIT
[0m21:39:31.170702 [debug] [MainThread]: Using postgres connection "master"
[0m21:39:31.171008 [debug] [MainThread]: On master: COMMIT
[0m21:39:31.171520 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:39:31.206750 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:39:31.212568 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:39:31.237920 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:39:31.239025 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:39:31.239616 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:39:31.240110 [debug] [MainThread]: On master: Close
[0m21:39:31.240680 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:39:31.240988 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:39:31.241275 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:39:31.241666 [info ] [MainThread]: 
[0m21:39:31.242039 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m21:39:31.243137 [debug] [MainThread]: Command end result
[0m21:39:31.326244 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:39:31.328808 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:39:31.335062 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:39:31.335708 [info ] [MainThread]: 
[0m21:39:31.336199 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:39:31.336807 [info ] [MainThread]: 
[0m21:39:31.337367 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:39:31.337914 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  syntax error at or near "IF"
  LINE 10: ADD PRIMARY KEY IF NOT EXISTS (i, d, c, r, e, a, t, e, d, _,...
                           ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:39:31.338340 [info ] [MainThread]: 
[0m21:39:31.338826 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:39:31.339193 [info ] [MainThread]: 
[0m21:39:31.339575 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:39:31.344609 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.582372, "process_in_blocks": "0", "process_kernel_time": 0.495996, "process_mem_max_rss": "141066240", "process_out_blocks": "0", "process_user_time": 3.466821}
[0m21:39:31.345335 [debug] [MainThread]: Command `dbt run` failed at 21:39:31.345187 after 2.58 seconds
[0m21:39:31.345784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116043cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115e77c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115e77b10>]}
[0m21:39:31.346332 [debug] [MainThread]: Flushing usage events
[0m21:39:31.848092 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:39:49.829307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105887770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fbf610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fbf4d0>]}


============================== 21:39:49.834201 | dfd71383-342b-480d-8b2f-58e5e48b5207 ==============================
[0m21:39:49.834201 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:39:49.834818 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:39:50.041603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dfd71383-342b-480d-8b2f-58e5e48b5207', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10630c510>]}
[0m21:39:50.116792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dfd71383-342b-480d-8b2f-58e5e48b5207', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e3fdf0>]}
[0m21:39:50.117782 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:39:50.244343 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:39:50.478689 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:39:50.479520 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:39:50.789932 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_primary_key_composite' takes not more than 1 argument(s)
[0m21:39:50.792642 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.047995, "process_in_blocks": "0", "process_kernel_time": 0.321448, "process_mem_max_rss": "123736064", "process_out_blocks": "0", "process_user_time": 2.365154}
[0m21:39:50.793191 [debug] [MainThread]: Command `dbt run` failed at 21:39:50.793074 after 1.05 seconds
[0m21:39:50.793609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f33850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f33c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10833d6d0>]}
[0m21:39:50.794007 [debug] [MainThread]: Flushing usage events
[0m21:39:51.251711 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:40:42.039696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104adb770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10620f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10620f4d0>]}


============================== 21:40:42.048275 | 43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4 ==============================
[0m21:40:42.048275 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:40:42.049421 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:40:42.309265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105558510>]}
[0m21:40:42.383693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10608bdf0>]}
[0m21:40:42.385185 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:40:42.580629 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:40:43.162117 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:40:43.163115 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://macros/add_primary_key_composite.sql
[0m21:40:43.757581 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:40:43.779799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107446250>]}
[0m21:40:43.943255 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:40:43.947827 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:40:43.996740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107161400>]}
[0m21:40:43.997344 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1571 macros
[0m21:40:43.997794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107726270>]}
[0m21:40:44.000055 [info ] [MainThread]: 
[0m21:40:44.000497 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:40:44.000885 [info ] [MainThread]: 
[0m21:40:44.001438 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:40:44.002284 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:40:44.078693 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:40:44.079174 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:40:44.079593 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:40:44.124235 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.045 seconds
[0m21:40:44.126041 [debug] [ThreadPool]: On list_elsa: Close
[0m21:40:44.134367 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_bronze)
[0m21:40:44.142198 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:40:44.142827 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m21:40:44.143179 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:40:44.146194 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:40:44.146670 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:40:44.147043 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:40:44.147609 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:40:44.153437 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:40:44.153870 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:40:44.154186 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:40:44.154514 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:40:44.154868 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:40:44.155247 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:40:44.159984 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:40:44.160428 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m21:40:44.161684 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:40:44.162919 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:40:44.163503 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:40:44.163869 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:40:44.170864 [debug] [MainThread]: Using postgres connection "master"
[0m21:40:44.171283 [debug] [MainThread]: On master: BEGIN
[0m21:40:44.171588 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:40:44.177022 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:40:44.177438 [debug] [MainThread]: Using postgres connection "master"
[0m21:40:44.177840 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:40:44.188788 [debug] [MainThread]: SQL status: SELECT 0 in 0.010 seconds
[0m21:40:44.190108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107af9640>]}
[0m21:40:44.190607 [debug] [MainThread]: On master: ROLLBACK
[0m21:40:44.191158 [debug] [MainThread]: Using postgres connection "master"
[0m21:40:44.191525 [debug] [MainThread]: On master: BEGIN
[0m21:40:44.192192 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:40:44.192584 [debug] [MainThread]: On master: COMMIT
[0m21:40:44.192914 [debug] [MainThread]: Using postgres connection "master"
[0m21:40:44.193219 [debug] [MainThread]: On master: COMMIT
[0m21:40:44.193674 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:40:44.232784 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:40:44.238683 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:40:44.242602 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:40:44.243263 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:40:44.243658 [info ] [MainThread]: 
[0m21:40:44.244092 [debug] [MainThread]: On master: Close
[0m21:40:44.249514 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:40:44.250258 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:40:44.251177 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_bronze, now model.dbt_elsa.daily_consumption)
[0m21:40:44.251628 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:40:44.256178 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:40:44.257430 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:40:44.302988 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:40:44.303986 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:40:44.304407 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:40:44.304769 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:40:44.310448 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:40:44.310917 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:40:44.311316 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:40:44.314727 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:40:44.322600 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:40:44.323097 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp" rename to "bronze_eco2mix"
[0m21:40:44.324017 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:40:44.346553 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:40:44.347064 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."bronze_eco2mix" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:40:44.348074 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:40:44.371958 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:40:44.372535 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'bronze_eco2mix'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:40:44.381661 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.008 seconds
[0m21:40:44.386633 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:40:44.387207 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:40:44.388324 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m21:40:44.390667 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:40:44.391146 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."bronze_eco2mix"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:40:44.391967 [debug] [Thread-1 (]: Postgres adapter: Postgres error: "bronze_eco2mix" is not a table or foreign table

[0m21:40:44.392402 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:40:44.393023 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:40:44.410501 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "bronze_eco2mix" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:40:44.414795 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43fc2ed4-591d-44f3-bafa-0cf0e68a3ef4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107096750>]}
[0m21:40:44.416284 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.16s]
[0m21:40:44.417703 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:40:44.418923 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "bronze_eco2mix" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:40:44.424546 [info ] [MainThread]: 
[0m21:40:44.425440 [debug] [MainThread]: Using postgres connection "master"
[0m21:40:44.426033 [debug] [MainThread]: On master: BEGIN
[0m21:40:44.426591 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:40:44.434072 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:40:44.434512 [debug] [MainThread]: On master: COMMIT
[0m21:40:44.434853 [debug] [MainThread]: Using postgres connection "master"
[0m21:40:44.435172 [debug] [MainThread]: On master: COMMIT
[0m21:40:44.435639 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:40:44.472632 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:40:44.478174 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:40:44.503566 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:40:44.504835 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:40:44.505485 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:40:44.505925 [debug] [MainThread]: On master: Close
[0m21:40:44.506522 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:40:44.506824 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:40:44.507095 [debug] [MainThread]: Connection 'list_elsa_bronze_tec_elsa' was properly closed.
[0m21:40:44.507452 [info ] [MainThread]: 
[0m21:40:44.507814 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m21:40:44.508933 [debug] [MainThread]: Command end result
[0m21:40:44.592683 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:40:44.595175 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:40:44.601681 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:40:44.602052 [info ] [MainThread]: 
[0m21:40:44.602446 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:40:44.602869 [info ] [MainThread]: 
[0m21:40:44.603411 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:40:44.603873 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "bronze_eco2mix" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:40:44.604382 [info ] [MainThread]: 
[0m21:40:44.604879 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:40:44.605254 [info ] [MainThread]: 
[0m21:40:44.605684 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:40:44.609979 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.671165, "process_in_blocks": "0", "process_kernel_time": 0.836104, "process_mem_max_rss": "141635584", "process_out_blocks": "0", "process_user_time": 4.053993}
[0m21:40:44.610821 [debug] [MainThread]: Command `dbt run` failed at 21:40:44.610634 after 2.67 seconds
[0m21:40:44.611310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078ebd80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079af570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079af930>]}
[0m21:40:44.611727 [debug] [MainThread]: Flushing usage events
[0m21:40:45.048513 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:43:57.024895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a13770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a14f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a14f4d0>]}


============================== 21:43:57.033552 | 930cc742-e3cb-4d96-be9e-8510e47dbe2a ==============================
[0m21:43:57.033552 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:43:57.034547 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:43:57.411207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '930cc742-e3cb-4d96-be9e-8510e47dbe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10949c510>]}
[0m21:43:57.490387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '930cc742-e3cb-4d96-be9e-8510e47dbe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fcfdf0>]}
[0m21:43:57.492161 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:43:57.649217 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:43:58.172074 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m21:43:58.172890 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/sources/_elsa_bronze__sources.yml
[0m21:43:58.483669 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m21:43:58.505252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '930cc742-e3cb-4d96-be9e-8510e47dbe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0c7650>]}
[0m21:43:58.671558 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:43:58.675278 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:43:58.715481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '930cc742-e3cb-4d96-be9e-8510e47dbe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fb2990>]}
[0m21:43:58.716728 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1571 macros
[0m21:43:58.717522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '930cc742-e3cb-4d96-be9e-8510e47dbe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b54f4d0>]}
[0m21:43:58.720281 [info ] [MainThread]: 
[0m21:43:58.720730 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:43:58.721108 [info ] [MainThread]: 
[0m21:43:58.721669 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:43:58.722672 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:43:58.793006 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:43:58.793458 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:43:58.793805 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:43:58.843677 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.050 seconds
[0m21:43:58.846683 [debug] [ThreadPool]: On list_elsa: Close
[0m21:43:58.857570 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:43:58.858471 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:43:58.867450 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:43:58.870688 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:43:58.871143 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:43:58.871525 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:43:58.871893 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:58.872345 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:43:58.880098 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:43:58.880561 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:43:58.880922 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:43:58.881363 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m21:43:58.881714 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:43:58.882076 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:43:58.885517 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:43:58.886019 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:43:58.887383 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:43:58.888595 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:43:58.889211 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:43:58.889621 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:43:58.897053 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:58.897459 [debug] [MainThread]: On master: BEGIN
[0m21:43:58.897756 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:43:58.903032 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:43:58.903434 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:58.903833 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:43:58.914794 [debug] [MainThread]: SQL status: SELECT 0 in 0.010 seconds
[0m21:43:58.916213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '930cc742-e3cb-4d96-be9e-8510e47dbe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adf5b20>]}
[0m21:43:58.916752 [debug] [MainThread]: On master: ROLLBACK
[0m21:43:58.917287 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:58.917619 [debug] [MainThread]: On master: BEGIN
[0m21:43:58.918220 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:43:58.918568 [debug] [MainThread]: On master: COMMIT
[0m21:43:58.918899 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:58.919216 [debug] [MainThread]: On master: COMMIT
[0m21:43:58.919648 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:43:58.957720 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:43:58.963373 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:43:58.967212 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:43:58.967883 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:43:58.968319 [info ] [MainThread]: 
[0m21:43:58.968786 [debug] [MainThread]: On master: Close
[0m21:43:58.974370 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:43:58.975356 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.bronze_eco2mix ....................... [RUN]
[0m21:43:58.976093 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:43:58.976505 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:43:58.984756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:43:58.985604 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:43:59.024994 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:43:59.025904 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:43:59.026300 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:43:59.026654 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:43:59.032075 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:43:59.032552 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:43:59.032950 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:43:59.036334 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:43:59.043802 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:43:59.044278 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."bronze_eco2mix__dbt_tmp" rename to "bronze_eco2mix"
[0m21:43:59.045161 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:43:59.068247 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:43:59.068726 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."bronze_eco2mix" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:43:59.069675 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:43:59.092632 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:43:59.093160 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'bronze_eco2mix'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:43:59.106327 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.013 seconds
[0m21:43:59.111426 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:43:59.111966 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."bronze_eco2mix".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:43:59.113031 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m21:43:59.116675 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:43:59.117123 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."bronze_eco2mix"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:43:59.118032 [debug] [Thread-1 (]: Postgres adapter: Postgres error: "bronze_eco2mix" is not a table or foreign table

[0m21:43:59.118449 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:43:59.119093 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:43:59.140026 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "bronze_eco2mix" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:43:59.142646 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '930cc742-e3cb-4d96-be9e-8510e47dbe2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b402b10>]}
[0m21:43:59.143554 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.bronze_eco2mix .............. [[31mERROR[0m in 0.16s]
[0m21:43:59.144358 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:43:59.144987 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "bronze_eco2mix" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:43:59.147738 [info ] [MainThread]: 
[0m21:43:59.148259 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:59.148596 [debug] [MainThread]: On master: BEGIN
[0m21:43:59.148907 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:43:59.155797 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:43:59.156373 [debug] [MainThread]: On master: COMMIT
[0m21:43:59.157461 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:59.158103 [debug] [MainThread]: On master: COMMIT
[0m21:43:59.158775 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:43:59.195765 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:43:59.201591 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:43:59.228540 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:43:59.229614 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:43:59.230352 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:43:59.230782 [debug] [MainThread]: On master: Close
[0m21:43:59.231291 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:43:59.231592 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:43:59.231865 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:43:59.232257 [info ] [MainThread]: 
[0m21:43:59.232614 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m21:43:59.233808 [debug] [MainThread]: Command end result
[0m21:43:59.323095 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:43:59.325859 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:43:59.333341 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:43:59.333872 [info ] [MainThread]: 
[0m21:43:59.334532 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:43:59.335006 [info ] [MainThread]: 
[0m21:43:59.335459 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:43:59.335885 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "bronze_eco2mix" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:43:59.336210 [info ] [MainThread]: 
[0m21:43:59.336600 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:43:59.336933 [info ] [MainThread]: 
[0m21:43:59.337306 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:43:59.342785 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.4239838, "process_in_blocks": "0", "process_kernel_time": 0.872569, "process_mem_max_rss": "136671232", "process_out_blocks": "0", "process_user_time": 3.790454}
[0m21:43:59.344123 [debug] [MainThread]: Command `dbt run` failed at 21:43:59.343585 after 2.43 seconds
[0m21:43:59.344770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5e3e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4a5c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4a5db0>]}
[0m21:43:59.345249 [debug] [MainThread]: Flushing usage events
[0m21:43:59.867056 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:44:43.019209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a303770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba3f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba3f4d0>]}


============================== 21:44:43.024207 | ca380576-a43a-42ea-a63b-6907b871fa40 ==============================
[0m21:44:43.024207 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:44:43.024977 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:44:43.234942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca380576-a43a-42ea-a63b-6907b871fa40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad8c510>]}
[0m21:44:43.307611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca380576-a43a-42ea-a63b-6907b871fa40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8bfdf0>]}
[0m21:44:43.308610 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:44:43.437322 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:44:43.684565 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:44:43.685537 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:44:44.271330 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m21:44:44.289885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca380576-a43a-42ea-a63b-6907b871fa40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc9a450>]}
[0m21:44:44.449777 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:44:44.452443 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:44:44.496317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca380576-a43a-42ea-a63b-6907b871fa40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9a5400>]}
[0m21:44:44.496885 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1571 macros
[0m21:44:44.497286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca380576-a43a-42ea-a63b-6907b871fa40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cfa19b0>]}
[0m21:44:44.499266 [info ] [MainThread]: 
[0m21:44:44.499663 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:44:44.499998 [info ] [MainThread]: 
[0m21:44:44.500563 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:44:44.501442 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:44:44.563581 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:44:44.564105 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:44:44.564523 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:44:44.595278 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.031 seconds
[0m21:44:44.597354 [debug] [ThreadPool]: On list_elsa: Close
[0m21:44:44.605588 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:44:44.606350 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:44:44.614266 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:44:44.617143 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:44:44.617568 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:44:44.617903 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:44:44.618222 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:44.618539 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:44:44.626305 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:44:44.626713 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:44:44.627080 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:44:44.627414 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:44:44.627772 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:44:44.628160 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:44:44.632314 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:44:44.633847 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:44:44.634285 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m21:44:44.635561 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:44:44.635931 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:44:44.636298 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:44:44.643462 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:44.643860 [debug] [MainThread]: On master: BEGIN
[0m21:44:44.644155 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:44:44.649533 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:44:44.649930 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:44.650327 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:44:44.661237 [debug] [MainThread]: SQL status: SELECT 0 in 0.010 seconds
[0m21:44:44.662662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca380576-a43a-42ea-a63b-6907b871fa40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2393d0>]}
[0m21:44:44.663286 [debug] [MainThread]: On master: ROLLBACK
[0m21:44:44.663876 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:44.664219 [debug] [MainThread]: On master: BEGIN
[0m21:44:44.664811 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:44:44.665155 [debug] [MainThread]: On master: COMMIT
[0m21:44:44.665478 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:44.665790 [debug] [MainThread]: On master: COMMIT
[0m21:44:44.666246 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:44:44.704158 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:44:44.711418 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:44:44.715383 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:44:44.715966 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:44:44.716311 [info ] [MainThread]: 
[0m21:44:44.716674 [debug] [MainThread]: On master: Close
[0m21:44:44.720928 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:44:44.721525 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.daily_consumption .................... [RUN]
[0m21:44:44.722299 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:44:44.723002 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:44:44.728052 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:44:44.728919 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:44:44.766444 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:44:44.767349 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:44:44.767734 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:44:44.768076 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:44:44.774614 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:44:44.775072 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:44:44.775458 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:44:44.778738 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:44:44.789647 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:44:44.790128 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m21:44:44.791087 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:44.813096 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:44:44.813671 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:44:44.814745 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:44:44.837701 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:44:44.838258 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:44:44.846471 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.008 seconds
[0m21:44:44.851469 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:44:44.852002 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:44:44.852912 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m21:44:44.855038 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:44:44.855473 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."daily_consumption"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:44:44.856366 [debug] [Thread-1 (]: Postgres adapter: Postgres error: "daily_consumption" is not a table or foreign table

[0m21:44:44.856821 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:44:44.857440 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:44:44.870494 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:44:44.872952 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca380576-a43a-42ea-a63b-6907b871fa40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccfec90>]}
[0m21:44:44.873720 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.daily_consumption ........... [[31mERROR[0m in 0.15s]
[0m21:44:44.874416 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:44:44.875015 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:44:44.877572 [info ] [MainThread]: 
[0m21:44:44.878035 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:44.878370 [debug] [MainThread]: On master: BEGIN
[0m21:44:44.878679 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:44:44.885065 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:44:44.885727 [debug] [MainThread]: On master: COMMIT
[0m21:44:44.886132 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:44.886457 [debug] [MainThread]: On master: COMMIT
[0m21:44:44.886996 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:44:44.922236 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:44:44.927890 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:44:44.953053 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:44:44.953997 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:44:44.954609 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:44:44.955046 [debug] [MainThread]: On master: Close
[0m21:44:44.955713 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:44:44.956025 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:44:44.956318 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:44:44.956718 [info ] [MainThread]: 
[0m21:44:44.957089 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m21:44:44.958265 [debug] [MainThread]: Command end result
[0m21:44:45.040471 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:44:45.043085 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:44:45.049482 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:44:45.049839 [info ] [MainThread]: 
[0m21:44:45.050378 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:44:45.050897 [info ] [MainThread]: 
[0m21:44:45.051470 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:44:45.051936 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:44:45.052300 [info ] [MainThread]: 
[0m21:44:45.052719 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:44:45.053089 [info ] [MainThread]: 
[0m21:44:45.053480 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:44:45.056906 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1238203, "process_in_blocks": "0", "process_kernel_time": 0.467735, "process_mem_max_rss": "141529088", "process_out_blocks": "0", "process_user_time": 3.404277}
[0m21:44:45.057985 [debug] [MainThread]: Command `dbt run` failed at 21:44:45.057727 after 2.13 seconds
[0m21:44:45.058472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1e7cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1102d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d110190>]}
[0m21:44:45.058876 [debug] [MainThread]: Flushing usage events
[0m21:44:45.471512 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:46:13.179259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c93770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053cb610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053cb4d0>]}


============================== 21:46:13.189504 | c912cc7a-1380-4a57-93c4-1df3fe4db460 ==============================
[0m21:46:13.189504 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:46:13.190486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m21:46:13.527026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c912cc7a-1380-4a57-93c4-1df3fe4db460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104718510>]}
[0m21:46:13.608317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c912cc7a-1380-4a57-93c4-1df3fe4db460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10524bdf0>]}
[0m21:46:13.610205 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:46:13.774134 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:46:14.228359 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:14.228836 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:14.236846 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m21:46:14.376296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c912cc7a-1380-4a57-93c4-1df3fe4db460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105343350>]}
[0m21:46:14.553552 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:46:14.558071 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:46:14.606083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c912cc7a-1380-4a57-93c4-1df3fe4db460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10522e990>]}
[0m21:46:14.606779 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1571 macros
[0m21:46:14.607244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c912cc7a-1380-4a57-93c4-1df3fe4db460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054c2970>]}
[0m21:46:14.609637 [info ] [MainThread]: 
[0m21:46:14.610101 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:46:14.610488 [info ] [MainThread]: 
[0m21:46:14.611236 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:46:14.612604 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:46:14.685973 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:46:14.686485 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:46:14.686871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:46:14.723894 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.037 seconds
[0m21:46:14.725449 [debug] [ThreadPool]: On list_elsa: Close
[0m21:46:14.731916 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:46:14.732591 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:46:14.739240 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:46:14.741971 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:46:14.742400 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:46:14.742800 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:46:14.743170 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:46:14.743506 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:46:14.750763 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:46:14.751164 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:46:14.751516 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:46:14.751842 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:46:14.752185 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:46:14.752567 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:46:14.756575 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:46:14.757013 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:46:14.758262 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:46:14.759393 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:46:14.759964 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:46:14.760317 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:46:14.767450 [debug] [MainThread]: Using postgres connection "master"
[0m21:46:14.767863 [debug] [MainThread]: On master: BEGIN
[0m21:46:14.768163 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:46:14.773353 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:46:14.773775 [debug] [MainThread]: Using postgres connection "master"
[0m21:46:14.774174 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:46:14.785503 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m21:46:14.786903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c912cc7a-1380-4a57-93c4-1df3fe4db460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106709570>]}
[0m21:46:14.787421 [debug] [MainThread]: On master: ROLLBACK
[0m21:46:14.787946 [debug] [MainThread]: Using postgres connection "master"
[0m21:46:14.788280 [debug] [MainThread]: On master: BEGIN
[0m21:46:14.788902 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:46:14.789290 [debug] [MainThread]: On master: COMMIT
[0m21:46:14.789601 [debug] [MainThread]: Using postgres connection "master"
[0m21:46:14.789890 [debug] [MainThread]: On master: COMMIT
[0m21:46:14.790404 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:46:14.829599 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:46:14.836133 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:46:14.840119 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:46:14.840731 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:46:14.841092 [info ] [MainThread]: 
[0m21:46:14.841476 [debug] [MainThread]: On master: Close
[0m21:46:14.845739 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:46:14.846799 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.daily_consumption .................... [RUN]
[0m21:46:14.847714 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:46:14.848318 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:46:14.853342 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:46:14.854591 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:46:14.898884 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:46:14.901081 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:46:14.901531 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:46:14.901895 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:46:14.908176 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:46:14.908644 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:46:14.909033 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:46:14.912256 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:46:14.920132 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:46:14.920617 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m21:46:14.921636 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:46:14.944814 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:46:14.945323 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:46:14.946248 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:46:14.979736 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:46:14.980375 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:46:14.988578 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.008 seconds
[0m21:46:14.993889 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:46:14.994491 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:46:14.995578 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:46:14.998996 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:46:14.999489 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."daily_consumption"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:46:15.000390 [debug] [Thread-1 (]: Postgres adapter: Postgres error: "daily_consumption" is not a table or foreign table

[0m21:46:15.000853 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:46:15.001477 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:46:15.017945 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:46:15.020940 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c912cc7a-1380-4a57-93c4-1df3fe4db460', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067cd310>]}
[0m21:46:15.021937 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.daily_consumption ........... [[31mERROR[0m in 0.17s]
[0m21:46:15.022973 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:46:15.023865 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:46:15.027772 [info ] [MainThread]: 
[0m21:46:15.028435 [debug] [MainThread]: Using postgres connection "master"
[0m21:46:15.029327 [debug] [MainThread]: On master: BEGIN
[0m21:46:15.029819 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:46:15.036449 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:46:15.036942 [debug] [MainThread]: On master: COMMIT
[0m21:46:15.037332 [debug] [MainThread]: Using postgres connection "master"
[0m21:46:15.037698 [debug] [MainThread]: On master: COMMIT
[0m21:46:15.038400 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:46:15.076092 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:46:15.081741 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:46:15.106853 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:46:15.107901 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:46:15.108495 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:46:15.108984 [debug] [MainThread]: On master: Close
[0m21:46:15.109536 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:46:15.109846 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:46:15.110116 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:46:15.110482 [info ] [MainThread]: 
[0m21:46:15.110847 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.50 seconds (0.50s).
[0m21:46:15.111947 [debug] [MainThread]: Command end result
[0m21:46:15.197917 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:46:15.200724 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:46:15.210261 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:46:15.210720 [info ] [MainThread]: 
[0m21:46:15.211279 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:46:15.211935 [info ] [MainThread]: 
[0m21:46:15.212513 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:46:15.213022 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:46:15.213377 [info ] [MainThread]: 
[0m21:46:15.213793 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:46:15.214147 [info ] [MainThread]: 
[0m21:46:15.214538 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:46:15.218665 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1545515, "process_in_blocks": "0", "process_kernel_time": 0.80705, "process_mem_max_rss": "130723840", "process_out_blocks": "0", "process_user_time": 3.616282}
[0m21:46:15.219693 [debug] [MainThread]: Command `dbt run` failed at 21:46:15.219507 after 2.16 seconds
[0m21:46:15.220187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f3cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667fbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667f390>]}
[0m21:46:15.220645 [debug] [MainThread]: Flushing usage events
[0m21:46:15.703846 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:51:22.062517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6e7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe17610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe174d0>]}


============================== 21:51:22.072814 | 6497020a-f6b0-4861-906c-0e948272aa58 ==============================
[0m21:51:22.072814 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:51:22.074225 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:51:22.296681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6497020a-f6b0-4861-906c-0e948272aa58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f16c510>]}
[0m21:51:22.487040 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-gaqa757g'
[0m21:51:22.487741 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m21:51:22.614888 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m21:51:22.616316 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m21:51:22.682460 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m21:51:22.691390 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m21:51:22.752913 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m21:51:22.761971 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m21:51:22.824038 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m21:51:22.839676 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m21:51:22.916417 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m21:51:22.924222 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m21:51:23.366953 [info ] [MainThread]: Installed from version 1.3.0
[0m21:51:23.367742 [info ] [MainThread]: Up to date!
[0m21:51:23.368492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6497020a-f6b0-4861-906c-0e948272aa58', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc9ebe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fff67a0>]}
[0m21:51:23.369263 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m21:51:24.941152 [info ] [MainThread]: Installed from version 0.10.9
[0m21:51:24.941834 [info ] [MainThread]: Up to date!
[0m21:51:24.942475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6497020a-f6b0-4861-906c-0e948272aa58', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11002cb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6f5220>]}
[0m21:51:24.942977 [info ] [MainThread]: Installing elementary-data/elementary
[0m21:51:25.433150 [info ] [MainThread]: Installed from version 0.19.0
[0m21:51:25.433762 [info ] [MainThread]: Updated version available: 0.19.1
[0m21:51:25.434174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6497020a-f6b0-4861-906c-0e948272aa58', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110058ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110058f30>]}
[0m21:51:25.434603 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m21:51:25.757953 [info ] [MainThread]: Installed from version 0.14.2
[0m21:51:25.758399 [info ] [MainThread]: Up to date!
[0m21:51:25.758817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6497020a-f6b0-4861-906c-0e948272aa58', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100210d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110021490>]}
[0m21:51:25.759233 [info ] [MainThread]: 
[0m21:51:25.759592 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m21:51:25.764258 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 3.808279, "process_in_blocks": "0", "process_kernel_time": 1.053203, "process_mem_max_rss": "114991104", "process_out_blocks": "0", "process_user_time": 2.838424}
[0m21:51:25.765121 [debug] [MainThread]: Command `dbt deps` succeeded at 21:51:25.764930 after 3.81 seconds
[0m21:51:25.765619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100503c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11004bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11004bc50>]}
[0m21:51:25.766061 [debug] [MainThread]: Flushing usage events
[0m21:51:26.258506 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:51:33.425125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de7b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5a7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5a74d0>]}


============================== 21:51:33.430326 | 88a5205f-5ba9-4e93-b5e4-364ea6d8741e ==============================
[0m21:51:33.430326 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:51:33.431088 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt parse', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:51:33.669278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '88a5205f-5ba9-4e93-b5e4-364ea6d8741e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8f8510>]}
[0m21:51:33.742945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '88a5205f-5ba9-4e93-b5e4-364ea6d8741e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f42bdf0>]}
[0m21:51:33.744585 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:51:33.882343 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:51:34.204617 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:51:34.205082 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:51:34.212542 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m21:51:34.341963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '88a5205f-5ba9-4e93-b5e4-364ea6d8741e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f51f250>]}
[0m21:51:34.345579 [info ] [MainThread]: Performance info: /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/perf_info.json
[0m21:51:34.515695 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:51:34.520342 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:51:34.523122 [debug] [MainThread]: Resource report: {"command_name": "parse", "command_success": true, "command_wall_clock_time": 1.1845063, "process_in_blocks": "0", "process_kernel_time": 0.353812, "process_mem_max_rss": "122515456", "process_out_blocks": "0", "process_user_time": 2.369887}
[0m21:51:34.523707 [debug] [MainThread]: Command `dbt parse` succeeded at 21:51:34.523571 after 1.19 seconds
[0m21:51:34.524175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5e6f30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f40e990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb87070>]}
[0m21:51:34.524618 [debug] [MainThread]: Flushing usage events
[0m21:51:34.930546 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:51:45.292325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2eb770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da27610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da274d0>]}


============================== 21:51:45.297106 | dcdd7d61-3fb5-4034-8c94-be44230deded ==============================
[0m21:51:45.297106 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:51:45.297921 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:51:45.501386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dcdd7d61-3fb5-4034-8c94-be44230deded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd74510>]}
[0m21:51:45.574050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dcdd7d61-3fb5-4034-8c94-be44230deded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8a7df0>]}
[0m21:51:45.575030 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:51:45.700063 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:51:45.946705 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:51:45.947179 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:51:45.955297 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m21:51:46.098229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dcdd7d61-3fb5-4034-8c94-be44230deded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d99b350>]}
[0m21:51:46.274329 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:51:46.277740 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:51:46.310278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dcdd7d61-3fb5-4034-8c94-be44230deded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d88a990>]}
[0m21:51:46.310906 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1571 macros
[0m21:51:46.311348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dcdd7d61-3fb5-4034-8c94-be44230deded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db1e970>]}
[0m21:51:46.313597 [info ] [MainThread]: 
[0m21:51:46.314050 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:51:46.314450 [info ] [MainThread]: 
[0m21:51:46.315137 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:51:46.316161 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:51:46.388899 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:51:46.389409 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:51:46.389791 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:51:46.427963 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.038 seconds
[0m21:51:46.429580 [debug] [ThreadPool]: On list_elsa: Close
[0m21:51:46.436180 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_bronze)
[0m21:51:46.436827 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m21:51:46.443823 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:51:46.446453 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:51:46.446909 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:51:46.447520 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:51:46.447903 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:51:46.448312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:51:46.454274 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:51:46.454695 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:51:46.455034 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:51:46.455413 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:51:46.455748 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:51:46.456084 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:51:46.459977 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:51:46.460460 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m21:51:46.461729 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:51:46.462846 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:51:46.463388 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:51:46.463720 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:51:46.470764 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:46.471174 [debug] [MainThread]: On master: BEGIN
[0m21:51:46.471470 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:51:46.476679 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:51:46.477088 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:46.477485 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:51:46.491107 [debug] [MainThread]: SQL status: SELECT 0 in 0.013 seconds
[0m21:51:46.492552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dcdd7d61-3fb5-4034-8c94-be44230deded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed65570>]}
[0m21:51:46.493074 [debug] [MainThread]: On master: ROLLBACK
[0m21:51:46.493640 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:46.493983 [debug] [MainThread]: On master: BEGIN
[0m21:51:46.494593 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:51:46.494939 [debug] [MainThread]: On master: COMMIT
[0m21:51:46.495268 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:46.495578 [debug] [MainThread]: On master: COMMIT
[0m21:51:46.496015 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:51:46.533821 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:51:46.539590 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:51:46.543775 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:51:46.544494 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:51:46.544887 [info ] [MainThread]: 
[0m21:51:46.545390 [debug] [MainThread]: On master: Close
[0m21:51:46.550588 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:51:46.551281 [info ] [Thread-1 (]: 1 of 1 START sql view model bronze_bronze.daily_consumption .................... [RUN]
[0m21:51:46.552157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_bronze, now model.dbt_elsa.daily_consumption)
[0m21:51:46.552579 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:51:46.557595 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:51:46.558828 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:51:46.602640 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:51:46.603985 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:51:46.604395 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:51:46.604748 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:51:46.610713 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:51:46.611198 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:51:46.611591 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  create view "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
    
    
  as (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
[0m21:51:46.618307 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m21:51:46.625772 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:51:46.626244 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m21:51:46.627113 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:51:46.649653 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:51:46.650125 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on view "elsa"."bronze_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m21:51:46.651143 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m21:51:46.674691 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:51:46.675235 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m21:51:46.689795 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.014 seconds
[0m21:51:46.696250 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:51:46.696933 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m21:51:46.700107 [debug] [Thread-1 (]: SQL status: COMMENT in 0.003 seconds
[0m21:51:46.704064 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:51:46.704588 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."daily_consumption"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:51:46.705478 [debug] [Thread-1 (]: Postgres adapter: Postgres error: "daily_consumption" is not a table or foreign table

[0m21:51:46.705944 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:51:46.706612 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:51:46.726144 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:51:46.728700 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dcdd7d61-3fb5-4034-8c94-be44230deded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee25310>]}
[0m21:51:46.729592 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model bronze_bronze.daily_consumption ........... [[31mERROR[0m in 0.17s]
[0m21:51:46.730328 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:51:46.730942 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:51:46.733461 [info ] [MainThread]: 
[0m21:51:46.734037 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:46.734398 [debug] [MainThread]: On master: BEGIN
[0m21:51:46.734710 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:51:46.741056 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:51:46.741503 [debug] [MainThread]: On master: COMMIT
[0m21:51:46.741835 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:46.742146 [debug] [MainThread]: On master: COMMIT
[0m21:51:46.742701 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:51:46.778443 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:51:46.784287 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:51:46.809427 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:51:46.810369 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:51:46.810965 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:51:46.811419 [debug] [MainThread]: On master: Close
[0m21:51:46.811925 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:51:46.812225 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:51:46.812491 [debug] [MainThread]: Connection 'list_elsa_bronze_tec_elsa' was properly closed.
[0m21:51:46.812844 [info ] [MainThread]: 
[0m21:51:46.813197 [info ] [MainThread]: Finished running 2 project hooks, 1 view model in 0 hours 0 minutes and 0.50 seconds (0.50s).
[0m21:51:46.814471 [debug] [MainThread]: Command end result
[0m21:51:46.897593 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:51:46.902297 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:51:46.914316 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:51:46.914822 [info ] [MainThread]: 
[0m21:51:46.915348 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:51:46.915829 [info ] [MainThread]: 
[0m21:51:46.916417 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:51:46.916992 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  "daily_consumption" is not a table or foreign table
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:51:46.917461 [info ] [MainThread]: 
[0m21:51:46.918011 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:51:46.918466 [info ] [MainThread]: 
[0m21:51:46.918971 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:51:46.923192 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.7174648, "process_in_blocks": "0", "process_kernel_time": 0.391694, "process_mem_max_rss": "130695168", "process_out_blocks": "0", "process_user_time": 2.848797}
[0m21:51:46.924177 [debug] [MainThread]: Command `dbt run` failed at 21:51:46.924001 after 1.72 seconds
[0m21:51:46.924671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed4fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ecdbbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ecdb390>]}
[0m21:51:46.925122 [debug] [MainThread]: Flushing usage events
[0m21:51:47.325761 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:52:04.945112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba43770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d177610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1774d0>]}


============================== 21:52:04.950343 | 4dbf5341-a95c-4188-add2-c4b008f77a27 ==============================
[0m21:52:04.950343 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:52:04.951089 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:52:05.156319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4c4510>]}
[0m21:52:05.258935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cff7df0>]}
[0m21:52:05.260159 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:52:05.385413 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:52:05.592426 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:52:05.593220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3d0550>]}
[0m21:52:11.025419 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:52:11.039737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3df980>]}
[0m21:52:11.199335 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:52:11.202246 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:52:11.222534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e520830>]}
[0m21:52:11.223068 [info ] [MainThread]: Found 31 models, 2 operations, 1 test, 1 source, 1571 macros
[0m21:52:11.223507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e655f30>]}
[0m21:52:11.225753 [info ] [MainThread]: 
[0m21:52:11.226322 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:52:11.226803 [info ] [MainThread]: 
[0m21:52:11.227424 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:52:11.228313 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:52:11.286311 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:52:11.286821 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:52:11.287147 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:52:11.309639 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.022 seconds
[0m21:52:11.311081 [debug] [ThreadPool]: On list_elsa: Close
[0m21:52:11.317403 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:52:11.318014 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:52:11.330471 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:52:11.330125 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:52:11.331346 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:52:11.331672 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:52:11.331988 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:52:11.332318 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:52:11.338228 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:52:11.338654 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:52:11.338984 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:52:11.339320 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:52:11.339664 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:52:11.340038 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:52:11.344061 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:52:11.344531 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:52:11.345766 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:52:11.346884 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:52:11.347424 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:52:11.347797 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:52:11.354875 [debug] [MainThread]: Using postgres connection "master"
[0m21:52:11.355273 [debug] [MainThread]: On master: BEGIN
[0m21:52:11.355566 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:52:11.360935 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:52:11.361345 [debug] [MainThread]: Using postgres connection "master"
[0m21:52:11.361745 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:52:11.373585 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m21:52:11.374993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e499190>]}
[0m21:52:11.375492 [debug] [MainThread]: On master: ROLLBACK
[0m21:52:11.376043 [debug] [MainThread]: Using postgres connection "master"
[0m21:52:11.376385 [debug] [MainThread]: On master: BEGIN
[0m21:52:11.376973 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:52:11.377320 [debug] [MainThread]: On master: COMMIT
[0m21:52:11.377647 [debug] [MainThread]: Using postgres connection "master"
[0m21:52:11.377959 [debug] [MainThread]: On master: COMMIT
[0m21:52:11.378395 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:52:11.399822 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:52:11.405483 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:52:11.409324 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:52:11.410085 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.03s]
[0m21:52:11.410502 [info ] [MainThread]: 
[0m21:52:11.411041 [debug] [MainThread]: On master: Close
[0m21:52:11.415529 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:52:11.416569 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze_bronze.daily_consumption ................... [RUN]
[0m21:52:11.417318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:52:11.418210 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:52:11.423089 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:52:11.423927 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:52:11.467526 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:52:11.468431 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:52:11.468814 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:52:11.469179 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:52:11.474542 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:52:11.475008 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:52:11.475406 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m21:52:11.482113 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.006 seconds
[0m21:52:11.493432 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:52:11.493911 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m21:52:11.494901 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:52:11.496823 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:52:11.497229 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."daily_consumption"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:52:11.499011 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "e" appears twice in primary key constraint
LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
             ^

[0m21:52:11.499466 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:52:11.500052 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:52:11.506986 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:52:11.508736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dbf5341-a95c-4188-add2-c4b008f77a27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e68ad00>]}
[0m21:52:11.509418 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze_bronze.daily_consumption .......... [[31mERROR[0m in 0.09s]
[0m21:52:11.510075 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:52:11.510646 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:52:11.513071 [info ] [MainThread]: 
[0m21:52:11.513533 [debug] [MainThread]: Using postgres connection "master"
[0m21:52:11.513892 [debug] [MainThread]: On master: BEGIN
[0m21:52:11.514200 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:52:11.524103 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m21:52:11.524720 [debug] [MainThread]: On master: COMMIT
[0m21:52:11.525144 [debug] [MainThread]: Using postgres connection "master"
[0m21:52:11.525458 [debug] [MainThread]: On master: COMMIT
[0m21:52:11.525970 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:52:11.550293 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:52:11.555673 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:52:11.581467 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:52:11.582419 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:52:11.583010 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.06s]
[0m21:52:11.583497 [debug] [MainThread]: On master: Close
[0m21:52:11.584013 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:52:11.584321 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:52:11.584590 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:52:11.584950 [info ] [MainThread]: 
[0m21:52:11.585309 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.36 seconds (0.36s).
[0m21:52:11.586419 [debug] [MainThread]: Command end result
[0m21:52:11.670545 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:52:11.673024 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:52:11.679217 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:52:11.679602 [info ] [MainThread]: 
[0m21:52:11.679993 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:52:11.680499 [info ] [MainThread]: 
[0m21:52:11.680992 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:52:11.681441 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:52:11.681838 [info ] [MainThread]: 
[0m21:52:11.682267 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:52:11.682609 [info ] [MainThread]: 
[0m21:52:11.683019 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:52:11.685895 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.826618, "process_in_blocks": "0", "process_kernel_time": 0.444321, "process_mem_max_rss": "141979648", "process_out_blocks": "0", "process_user_time": 7.926114}
[0m21:52:11.686766 [debug] [MainThread]: Command `dbt run` failed at 21:52:11.686512 after 6.83 seconds
[0m21:52:11.687360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6f9630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e44e060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba3e250>]}
[0m21:52:11.688030 [debug] [MainThread]: Flushing usage events
[0m21:52:12.089192 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:52:41.139872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111e3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112917610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129174d0>]}


============================== 21:52:41.144936 | 06ec9971-d1d5-43ee-9a08-21db30bcb766 ==============================
[0m21:52:41.144936 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:52:41.145597 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:52:41.349385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '06ec9971-d1d5-43ee-9a08-21db30bcb766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c64510>]}
[0m21:52:41.421512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '06ec9971-d1d5-43ee-9a08-21db30bcb766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112797df0>]}
[0m21:52:41.422453 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:52:41.548575 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:52:41.787073 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:52:41.787989 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:52:42.096773 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_primary_key_composite' takes not more than 1 argument(s)
[0m21:52:42.100158 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0478991, "process_in_blocks": "0", "process_kernel_time": 0.298305, "process_mem_max_rss": "124235776", "process_out_blocks": "0", "process_user_time": 2.352508}
[0m21:52:42.100847 [debug] [MainThread]: Command `dbt run` failed at 21:52:42.100701 after 1.05 seconds
[0m21:52:42.101632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11288e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11288f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c8d4f0>]}
[0m21:52:42.102369 [debug] [MainThread]: Flushing usage events
[0m21:52:42.504375 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:52:55.748595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11002b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11175f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11175f4d0>]}


============================== 21:52:55.753640 | c0115264-9577-4524-9764-5da573672f95 ==============================
[0m21:52:55.753640 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:52:55.754296 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:52:55.960856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c0115264-9577-4524-9764-5da573672f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110aac510>]}
[0m21:52:56.037394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c0115264-9577-4524-9764-5da573672f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115dfdf0>]}
[0m21:52:56.038367 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:52:56.166486 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:52:56.412202 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:52:56.413029 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:52:56.710531 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  unexpected char '#' at 32
    line 3
      # "{{ add_primary_key_composite('id', 'created_at') }}",
[0m21:52:56.713356 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.051161, "process_in_blocks": "0", "process_kernel_time": 0.305109, "process_mem_max_rss": "123797504", "process_out_blocks": "0", "process_user_time": 2.398314}
[0m21:52:56.713935 [debug] [MainThread]: Command `dbt run` failed at 21:52:56.713816 after 1.05 seconds
[0m21:52:56.714484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d2750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ad9130>]}
[0m21:52:56.715016 [debug] [MainThread]: Flushing usage events
[0m21:52:57.151829 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:53:56.511586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063ef770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b23610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b234d0>]}


============================== 21:53:56.516669 | 83a23d4a-4998-49cd-80e6-79130da0f792 ==============================
[0m21:53:56.516669 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:53:56.517321 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:53:56.726893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '83a23d4a-4998-49cd-80e6-79130da0f792', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e6c510>]}
[0m21:53:56.801712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '83a23d4a-4998-49cd-80e6-79130da0f792', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10799fdf0>]}
[0m21:53:56.802700 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:53:56.932435 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:53:57.185240 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:53:57.186189 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:53:57.186683 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m21:53:57.187025 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:53:57.492821 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  unexpected char '#' at 32
    line 3
      # "{{ add_primary_key_composite('id', 'created_at') }}",
[0m21:53:57.495355 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0715916, "process_in_blocks": "0", "process_kernel_time": 0.338552, "process_mem_max_rss": "123772928", "process_out_blocks": "0", "process_user_time": 2.406053}
[0m21:53:57.496016 [debug] [MainThread]: Command `dbt run` failed at 21:53:57.495862 after 1.07 seconds
[0m21:53:57.496528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a93850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a92750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e81040>]}
[0m21:53:57.497000 [debug] [MainThread]: Flushing usage events
[0m21:53:57.925331 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:54:11.804401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9c3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9c34d0>]}


============================== 21:54:11.809941 | 42c214e2-cc7b-4737-895a-d5abbec88784 ==============================
[0m21:54:11.809941 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:54:11.810673 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m21:54:12.015347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '42c214e2-cc7b-4737-895a-d5abbec88784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d0c510>]}
[0m21:54:12.088023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '42c214e2-cc7b-4737-895a-d5abbec88784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a83fdf0>]}
[0m21:54:12.089215 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:54:12.215161 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:54:12.453613 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:54:12.454529 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:54:12.454970 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m21:54:12.455302 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:54:13.032485 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:54:13.049796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42c214e2-cc7b-4737-895a-d5abbec88784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf9f50>]}
[0m21:54:13.212460 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:54:13.215556 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:54:13.235708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42c214e2-cc7b-4737-895a-d5abbec88784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9154f0>]}
[0m21:54:13.236242 [info ] [MainThread]: Found 31 models, 2 operations, 2 data tests, 1 source, 1571 macros
[0m21:54:13.236621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '42c214e2-cc7b-4737-895a-d5abbec88784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bee1fd0>]}
[0m21:54:13.238588 [info ] [MainThread]: 
[0m21:54:13.238994 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:54:13.239319 [info ] [MainThread]: 
[0m21:54:13.239831 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:54:13.240645 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:54:13.296710 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:54:13.297137 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:54:13.297462 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:54:13.319795 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.022 seconds
[0m21:54:13.321235 [debug] [ThreadPool]: On list_elsa: Close
[0m21:54:13.327626 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m21:54:13.328256 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m21:54:13.335051 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:54:13.337670 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:54:13.338042 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:54:13.338360 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:54:13.338668 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:54:13.338976 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:54:13.344829 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:54:13.345262 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:54:13.345579 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:54:13.345898 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:54:13.346247 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:54:13.346616 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:54:13.350603 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:54:13.351036 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:54:13.352300 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:54:13.353425 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:54:13.353910 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:54:13.354262 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:54:13.361181 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:13.361580 [debug] [MainThread]: On master: BEGIN
[0m21:54:13.361873 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:54:13.367100 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:54:13.367513 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:13.367909 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:54:13.379489 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m21:54:13.380890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '42c214e2-cc7b-4737-895a-d5abbec88784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c20d4a0>]}
[0m21:54:13.381441 [debug] [MainThread]: On master: ROLLBACK
[0m21:54:13.382048 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:13.382403 [debug] [MainThread]: On master: BEGIN
[0m21:54:13.383027 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:54:13.383373 [debug] [MainThread]: On master: COMMIT
[0m21:54:13.383699 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:13.384010 [debug] [MainThread]: On master: COMMIT
[0m21:54:13.384455 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:54:13.421562 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:54:13.427288 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:54:13.431044 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:54:13.431882 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:54:13.432368 [info ] [MainThread]: 
[0m21:54:13.432889 [debug] [MainThread]: On master: Close
[0m21:54:13.437530 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:54:13.438366 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze_bronze.daily_consumption ................... [RUN]
[0m21:54:13.439457 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m21:54:13.440043 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:54:13.445124 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:54:13.445970 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:54:13.488890 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:54:13.489785 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:13.490167 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:54:13.490523 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:54:13.496352 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m21:54:13.496967 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:13.497561 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m21:54:13.502618 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.005 seconds
[0m21:54:13.517259 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:13.517743 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m21:54:13.518751 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:54:13.520614 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:13.521032 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."daily_consumption"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:54:13.522594 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "e" appears twice in primary key constraint
LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
             ^

[0m21:54:13.523009 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:54:13.523581 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:54:13.530347 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:54:13.532322 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42c214e2-cc7b-4737-895a-d5abbec88784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bee6690>]}
[0m21:54:13.533095 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze_bronze.daily_consumption .......... [[31mERROR[0m in 0.09s]
[0m21:54:13.533764 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:54:13.534329 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:54:13.536647 [info ] [MainThread]: 
[0m21:54:13.537150 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:13.537474 [debug] [MainThread]: On master: BEGIN
[0m21:54:13.537772 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:54:13.544421 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:54:13.544846 [debug] [MainThread]: On master: COMMIT
[0m21:54:13.545171 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:13.545486 [debug] [MainThread]: On master: COMMIT
[0m21:54:13.546095 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:54:13.583490 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:54:13.588975 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:54:13.614592 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:54:13.615630 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:54:13.616218 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:54:13.616645 [debug] [MainThread]: On master: Close
[0m21:54:13.617156 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:54:13.617480 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:54:13.617755 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m21:54:13.618123 [info ] [MainThread]: 
[0m21:54:13.618494 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.38 seconds (0.38s).
[0m21:54:13.619577 [debug] [MainThread]: Command end result
[0m21:54:13.702072 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:54:13.704476 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:54:13.710594 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:54:13.710948 [info ] [MainThread]: 
[0m21:54:13.711325 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:54:13.711824 [info ] [MainThread]: 
[0m21:54:13.712389 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:54:13.712820 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:54:13.713166 [info ] [MainThread]: 
[0m21:54:13.713670 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:54:13.714124 [info ] [MainThread]: 
[0m21:54:13.714615 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:54:13.717651 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.00398, "process_in_blocks": "0", "process_kernel_time": 0.357402, "process_mem_max_rss": "141103104", "process_out_blocks": "0", "process_user_time": 3.22165}
[0m21:54:13.718424 [debug] [MainThread]: Command `dbt run` failed at 21:54:13.718192 after 2.00 seconds
[0m21:54:13.718998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8e7cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf5d270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf5cf50>]}
[0m21:54:13.719735 [debug] [MainThread]: Flushing usage events
[0m21:54:14.113047 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:54:35.185508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10461f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d53610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d534d0>]}


============================== 21:54:35.190445 | 7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba ==============================
[0m21:54:35.190445 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:54:35.191243 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:54:35.396841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10509c510>]}
[0m21:54:35.479602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bcfdf0>]}
[0m21:54:35.480562 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:54:35.605230 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:54:35.843187 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:54:35.844055 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:54:36.420444 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m21:54:36.438453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8a450>]}
[0m21:54:36.598856 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:54:36.601502 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:54:36.619936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ca54f0>]}
[0m21:54:36.620474 [info ] [MainThread]: Found 31 models, 2 operations, 2 data tests, 1 source, 1571 macros
[0m21:54:36.620883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107275ef0>]}
[0m21:54:36.622922 [info ] [MainThread]: 
[0m21:54:36.623351 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m21:54:36.623743 [info ] [MainThread]: 
[0m21:54:36.624356 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:54:36.625319 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m21:54:36.676853 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m21:54:36.677274 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m21:54:36.677581 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:54:36.700024 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.022 seconds
[0m21:54:36.701457 [debug] [ThreadPool]: On list_elsa: Close
[0m21:54:36.707715 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_bronze)
[0m21:54:36.708431 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m21:54:36.715346 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:54:36.718108 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:54:36.718488 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m21:54:36.718806 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m21:54:36.719114 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:54:36.719418 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:54:36.726149 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:54:36.726559 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m21:54:36.726898 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m21:54:36.727282 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m21:54:36.727614 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m21:54:36.727945 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m21:54:36.730694 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:54:36.732067 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m21:54:36.732524 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:54:36.733667 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m21:54:36.734020 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m21:54:36.734551 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m21:54:36.741775 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:36.742196 [debug] [MainThread]: On master: BEGIN
[0m21:54:36.742500 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:54:36.747842 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:54:36.748252 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:36.748641 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:54:36.760296 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m21:54:36.761745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075a13d0>]}
[0m21:54:36.762276 [debug] [MainThread]: On master: ROLLBACK
[0m21:54:36.762808 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:36.763135 [debug] [MainThread]: On master: BEGIN
[0m21:54:36.763763 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:54:36.764108 [debug] [MainThread]: On master: COMMIT
[0m21:54:36.764435 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:36.764752 [debug] [MainThread]: On master: COMMIT
[0m21:54:36.765252 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:54:36.803379 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m21:54:36.808955 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m21:54:36.812861 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m21:54:36.813601 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m21:54:36.814081 [info ] [MainThread]: 
[0m21:54:36.814625 [debug] [MainThread]: On master: Close
[0m21:54:36.819096 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m21:54:36.819739 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze_bronze.daily_consumption ................... [RUN]
[0m21:54:36.820877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_bronze, now model.dbt_elsa.daily_consumption)
[0m21:54:36.821383 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m21:54:36.825764 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m21:54:36.827093 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m21:54:36.870306 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m21:54:36.871187 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:36.871571 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m21:54:36.871923 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:54:36.877477 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m21:54:36.878384 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:36.878920 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    /*

*/

SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m21:54:36.884020 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.005 seconds
[0m21:54:36.899042 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:36.899540 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m21:54:36.900625 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:54:36.902485 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m21:54:36.902891 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

        -- This macro generates the SQL to add a composite primary key to a table.
-- Parameters:
--   table_name: The name of the table where the primary key will be added.
--   columns: A list of column names to be used as the composite primary key.

-- Generate the SQL statement
ALTER TABLE "elsa"."bronze_bronze"."daily_consumption"
ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
      
[0m21:54:36.904440 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "e" appears twice in primary key constraint
LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
             ^

[0m21:54:36.904851 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: ROLLBACK
[0m21:54:36.905435 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m21:54:36.912157 [debug] [Thread-1 (]: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:54:36.913900 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7dd1ad6f-8c1b-4b9b-aaee-6bd5971be6ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d3e5d0>]}
[0m21:54:36.914599 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze_bronze.daily_consumption .......... [[31mERROR[0m in 0.09s]
[0m21:54:36.915262 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m21:54:36.915943 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.daily_consumption' to be skipped because of status 'error'.  Reason: Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql.
[0m21:54:36.918341 [info ] [MainThread]: 
[0m21:54:36.918774 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:36.919089 [debug] [MainThread]: On master: BEGIN
[0m21:54:36.919382 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:54:36.925034 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:54:36.925463 [debug] [MainThread]: On master: COMMIT
[0m21:54:36.925788 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:36.926090 [debug] [MainThread]: On master: COMMIT
[0m21:54:36.926484 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:54:36.962051 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m21:54:36.967321 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m21:54:36.992536 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m21:54:36.993496 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m21:54:36.994141 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m21:54:36.994576 [debug] [MainThread]: On master: Close
[0m21:54:36.995141 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:54:36.995447 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m21:54:36.995721 [debug] [MainThread]: Connection 'list_elsa_bronze_tec_elsa' was properly closed.
[0m21:54:36.996078 [info ] [MainThread]: 
[0m21:54:36.996443 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m21:54:36.997612 [debug] [MainThread]: Command end result
[0m21:54:37.078248 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m21:54:37.080576 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m21:54:37.086901 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m21:54:37.087258 [info ] [MainThread]: 
[0m21:54:37.087692 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:54:37.088202 [info ] [MainThread]: 
[0m21:54:37.088726 [error] [MainThread]: [31mFailure in model daily_consumption (models/bronze/daily_consumption.sql)[0m
[0m21:54:37.089197 [error] [MainThread]:   Database Error in model daily_consumption (models/bronze/daily_consumption.sql)
  column "e" appears twice in primary key constraint
  LINE 10: ADD PRIMARY KEY (i, d, c, r, e, a, t, e, d, _, a, t);
               ^
  compiled code at target/run/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:54:37.089550 [info ] [MainThread]: 
[0m21:54:37.090005 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/daily_consumption.sql
[0m21:54:37.090415 [info ] [MainThread]: 
[0m21:54:37.090859 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m21:54:37.094502 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.9942254, "process_in_blocks": "0", "process_kernel_time": 0.345683, "process_mem_max_rss": "140886016", "process_out_blocks": "0", "process_user_time": 3.177136}
[0m21:54:37.095654 [debug] [MainThread]: Command `dbt run` failed at 21:54:37.095515 after 2.00 seconds
[0m21:54:37.096069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f7cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072f8910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072f85f0>]}
[0m21:54:37.096457 [debug] [MainThread]: Flushing usage events
[0m21:54:37.527107 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:55:33.266291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10354f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c87610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c874d0>]}


============================== 21:55:33.272253 | 10d014cd-b6fa-484a-9552-0e1cf5a022bc ==============================
[0m21:55:33.272253 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:55:33.273129 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:55:33.483285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10d014cd-b6fa-484a-9552-0e1cf5a022bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fd0510>]}
[0m21:55:33.559068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10d014cd-b6fa-484a-9552-0e1cf5a022bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b03df0>]}
[0m21:55:33.559971 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:55:33.689542 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:55:33.939142 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:55:33.939906 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:55:34.251276 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_primary_key_composite' takes not more than 1 argument(s)
[0m21:55:34.253881 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0772805, "process_in_blocks": "0", "process_kernel_time": 0.328657, "process_mem_max_rss": "123666432", "process_out_blocks": "0", "process_user_time": 2.363714}
[0m21:55:34.254405 [debug] [MainThread]: Command `dbt run` failed at 21:55:34.254281 after 1.08 seconds
[0m21:55:34.254822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bfa750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bfb850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fd56d0>]}
[0m21:55:34.255215 [debug] [MainThread]: Flushing usage events
[0m21:55:34.658762 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:57:39.547090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1033ab770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104adf610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104adf4d0>]}


============================== 21:57:39.552050 | 198eb1d4-c49d-4afa-a2c3-5b5e4cac07e6 ==============================
[0m21:57:39.552050 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:57:39.552712 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:57:39.765335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '198eb1d4-c49d-4afa-a2c3-5b5e4cac07e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103e2c510>]}
[0m21:57:39.840140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '198eb1d4-c49d-4afa-a2c3-5b5e4cac07e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10495fdf0>]}
[0m21:57:39.841180 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:57:39.970546 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:57:40.223113 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:57:40.224248 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:57:40.224845 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m21:57:40.225309 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:57:40.540199 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_primary_key_composite' takes not more than 1 argument(s)
[0m21:57:40.542856 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0839319, "process_in_blocks": "0", "process_kernel_time": 0.334015, "process_mem_max_rss": "124063744", "process_out_blocks": "0", "process_user_time": 2.404838}
[0m21:57:40.543476 [debug] [MainThread]: Command `dbt run` failed at 21:57:40.543306 after 1.08 seconds
[0m21:57:40.543976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a56750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a57850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e5d4f0>]}
[0m21:57:40.544394 [debug] [MainThread]: Flushing usage events
[0m21:57:41.672895 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:58:25.329302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11185b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f97610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f974d0>]}


============================== 21:58:25.334755 | 4b6c869f-6f7a-467b-a3e0-c19edc332f4d ==============================
[0m21:58:25.334755 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:58:25.335523 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:58:25.540745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b6c869f-6f7a-467b-a3e0-c19edc332f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122e4510>]}
[0m21:58:25.617938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4b6c869f-6f7a-467b-a3e0-c19edc332f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e17df0>]}
[0m21:58:25.618922 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:58:25.747926 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:58:25.997537 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:58:25.998461 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:58:25.998833 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:58:25.999385 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m21:58:26.312830 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  expected token ',', got 'created_at'
    line 1
      {{ add_primary_key_composite(id created_at) }}
[0m21:58:26.315550 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0723913, "process_in_blocks": "0", "process_kernel_time": 0.328968, "process_mem_max_rss": "124096512", "process_out_blocks": "0", "process_user_time": 2.377811}
[0m21:58:26.316322 [debug] [MainThread]: Command `dbt run` failed at 21:58:26.316123 after 1.07 seconds
[0m21:58:26.316744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f0a750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f0b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143154f0>]}
[0m21:58:26.317141 [debug] [MainThread]: Flushing usage events
[0m21:58:26.709232 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:58:41.392269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d75b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee8f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee8f4d0>]}


============================== 21:58:41.397148 | bc537250-6197-4fc5-b022-f0d699c8e7dc ==============================
[0m21:58:41.397148 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:58:41.397893 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:58:41.602372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bc537250-6197-4fc5-b022-f0d699c8e7dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1d8510>]}
[0m21:58:41.675101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bc537250-6197-4fc5-b022-f0d699c8e7dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed0bdf0>]}
[0m21:58:41.676158 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:58:41.801321 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:58:42.044388 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:58:42.045603 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:58:42.046106 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m21:58:42.046464 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:58:42.354701 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_primary_key_composite' takes not more than 1 argument(s)
[0m21:58:42.357386 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0497512, "process_in_blocks": "0", "process_kernel_time": 0.297705, "process_mem_max_rss": "124682240", "process_out_blocks": "0", "process_user_time": 2.36547}
[0m21:58:42.357919 [debug] [MainThread]: Command `dbt run` failed at 21:58:42.357805 after 1.05 seconds
[0m21:58:42.358321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10edfe750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10edff850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101e54f0>]}
[0m21:58:42.358708 [debug] [MainThread]: Flushing usage events
[0m21:58:42.758005 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:58:57.346403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10937f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa7b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa7b4d0>]}


============================== 21:58:57.351571 | efae9d7f-eac7-450a-9932-4abf2ca5f453 ==============================
[0m21:58:57.351571 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:58:57.352252 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:58:57.557847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'efae9d7f-eac7-450a-9932-4abf2ca5f453', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109df8510>]}
[0m21:58:57.634294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'efae9d7f-eac7-450a-9932-4abf2ca5f453', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8ffdf0>]}
[0m21:58:57.635292 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:58:57.763935 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:58:58.001467 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:58:58.002417 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:58:58.002866 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m21:58:58.003322 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:58:58.307981 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  No filter named 'created_at'.
    line 1
      {{ add_primary_key_composite(id | created_at) }}
[0m21:58:58.311014 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0513827, "process_in_blocks": "0", "process_kernel_time": 0.294966, "process_mem_max_rss": "123576320", "process_out_blocks": "0", "process_user_time": 2.358451}
[0m21:58:58.311578 [debug] [MainThread]: Command `dbt run` failed at 21:58:58.311463 after 1.05 seconds
[0m21:58:58.311983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9ee750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9ef850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdf1310>]}
[0m21:58:58.312363 [debug] [MainThread]: Flushing usage events
[0m21:58:58.787019 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:59:55.041812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e18f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8cb610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8cb4d0>]}


============================== 21:59:55.050372 | d32b28e9-7bde-4ba7-b081-4ca0697a2894 ==============================
[0m21:59:55.050372 [info ] [MainThread]: Running with dbt=1.10.4
[0m21:59:55.051324 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:59:55.368990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd32b28e9-7bde-4ba7-b081-4ca0697a2894', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec14510>]}
[0m21:59:55.447677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd32b28e9-7bde-4ba7-b081-4ca0697a2894', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f747df0>]}
[0m21:59:55.449536 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:59:55.618139 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m21:59:56.077471 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:59:56.078620 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m21:59:56.079392 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m21:59:56.079948 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m21:59:56.396176 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  macro 'dbt_macro__add_primary_key_composite' takes not more than 1 argument(s)
[0m21:59:56.399778 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.463974, "process_in_blocks": "0", "process_kernel_time": 0.740818, "process_mem_max_rss": "123514880", "process_out_blocks": "0", "process_user_time": 3.072094}
[0m21:59:56.400378 [debug] [MainThread]: Command `dbt run` failed at 21:59:56.400256 after 1.46 seconds
[0m21:59:56.400811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f83a750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f83b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c214f0>]}
[0m21:59:56.401223 [debug] [MainThread]: Flushing usage events
[0m21:59:56.814434 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:01:26.865075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2f3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea27610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea274d0>]}


============================== 22:01:26.874594 | f13eb1fa-18b4-4110-a332-b51056d3526c ==============================
[0m22:01:26.874594 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:01:26.875503 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m22:01:27.183976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f13eb1fa-18b4-4110-a332-b51056d3526c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd70510>]}
[0m22:01:27.262609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f13eb1fa-18b4-4110-a332-b51056d3526c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8a3df0>]}
[0m22:01:27.264237 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:01:27.453845 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:01:28.028258 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m22:01:28.029365 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m22:01:28.029915 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m22:01:28.030346 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m22:01:28.641208 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.silver
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m22:01:28.659129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f13eb1fa-18b4-4110-a332-b51056d3526c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc5df50>]}
[0m22:01:28.832315 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:01:28.836339 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:01:28.875931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f13eb1fa-18b4-4110-a332-b51056d3526c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f979310>]}
[0m22:01:28.876668 [info ] [MainThread]: Found 31 models, 2 operations, 4 data tests, 1 source, 1571 macros
[0m22:01:28.877117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f13eb1fa-18b4-4110-a332-b51056d3526c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff2dfd0>]}
[0m22:01:28.879300 [info ] [MainThread]: 
[0m22:01:28.879780 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m22:01:28.880127 [info ] [MainThread]: 
[0m22:01:28.880683 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:01:28.881592 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m22:01:28.958816 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m22:01:28.959562 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m22:01:28.960167 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:01:29.027513 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.067 seconds
[0m22:01:29.029617 [debug] [ThreadPool]: On list_elsa: Close
[0m22:01:29.037891 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m22:01:29.038648 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_bronze'
[0m22:01:29.051870 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:01:29.052478 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m22:01:29.052821 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m22:01:29.053167 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m22:01:29.053497 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:01:29.053819 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:01:29.062966 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m22:01:29.063401 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m22:01:29.063904 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m22:01:29.064323 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:01:29.064729 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m22:01:29.065143 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m22:01:29.071375 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m22:01:29.071974 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m22:01:29.073267 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m22:01:29.074452 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m22:01:29.075025 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m22:01:29.075372 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m22:01:29.082277 [debug] [MainThread]: Using postgres connection "master"
[0m22:01:29.082673 [debug] [MainThread]: On master: BEGIN
[0m22:01:29.082970 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:01:29.088179 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:01:29.088611 [debug] [MainThread]: Using postgres connection "master"
[0m22:01:29.089031 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:01:29.104265 [debug] [MainThread]: SQL status: SELECT 0 in 0.015 seconds
[0m22:01:29.105778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f13eb1fa-18b4-4110-a332-b51056d3526c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11025d090>]}
[0m22:01:29.106332 [debug] [MainThread]: On master: ROLLBACK
[0m22:01:29.106940 [debug] [MainThread]: Using postgres connection "master"
[0m22:01:29.107325 [debug] [MainThread]: On master: BEGIN
[0m22:01:29.107963 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:01:29.108362 [debug] [MainThread]: On master: COMMIT
[0m22:01:29.108695 [debug] [MainThread]: Using postgres connection "master"
[0m22:01:29.109013 [debug] [MainThread]: On master: COMMIT
[0m22:01:29.109457 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:01:29.147389 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m22:01:29.153576 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:01:29.157547 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:01:29.158285 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m22:01:29.158744 [info ] [MainThread]: 
[0m22:01:29.159164 [debug] [MainThread]: On master: Close
[0m22:01:29.163655 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m22:01:29.164365 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze_bronze.daily_consumption ................... [RUN]
[0m22:01:29.165466 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m22:01:29.166264 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m22:01:29.171281 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m22:01:29.172152 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m22:01:29.215712 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m22:01:29.217724 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.218713 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m22:01:29.219529 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:01:29.226960 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m22:01:29.227605 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.228726 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m22:01:29.238835 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.009 seconds
[0m22:01:29.254886 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.255388 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m22:01:29.257503 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:01:29.281091 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.281573 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on table "elsa"."bronze_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m22:01:29.282643 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:01:29.305549 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.306106 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m22:01:29.322351 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.016 seconds
[0m22:01:29.328807 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.329421 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m22:01:29.330460 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m22:01:29.331938 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:01:29.332403 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.332837 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:01:29.334365 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m22:01:29.342697 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze_bronze"."daily_consumption__dbt_backup"
[0m22:01:29.348435 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:01:29.348925 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
drop table if exists "elsa"."bronze_bronze"."daily_consumption__dbt_backup" cascade
[0m22:01:29.349805 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:01:29.352894 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m22:01:29.355249 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f13eb1fa-18b4-4110-a332-b51056d3526c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffa6810>]}
[0m22:01:29.355991 [info ] [Thread-1 (]: 1 of 1 OK created sql table model bronze_bronze.daily_consumption .............. [[32mSELECT 96[0m in 0.19s]
[0m22:01:29.356939 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m22:01:29.360081 [info ] [MainThread]: 
[0m22:01:29.360747 [debug] [MainThread]: Using postgres connection "master"
[0m22:01:29.361167 [debug] [MainThread]: On master: BEGIN
[0m22:01:29.361481 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:01:29.367127 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:01:29.367652 [debug] [MainThread]: On master: COMMIT
[0m22:01:29.368523 [debug] [MainThread]: Using postgres connection "master"
[0m22:01:29.369094 [debug] [MainThread]: On master: COMMIT
[0m22:01:29.369719 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:01:29.405637 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:01:29.411317 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m22:01:29.436465 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:01:29.437478 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m22:01:29.438095 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m22:01:29.438550 [debug] [MainThread]: On master: Close
[0m22:01:29.439057 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:01:29.439361 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m22:01:29.439646 [debug] [MainThread]: Connection 'list_elsa_bronze_bronze' was properly closed.
[0m22:01:29.440008 [info ] [MainThread]: 
[0m22:01:29.440351 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m22:01:29.441407 [debug] [MainThread]: Command end result
[0m22:01:29.525042 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:01:29.527420 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:01:29.534975 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m22:01:29.535613 [info ] [MainThread]: 
[0m22:01:29.536173 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:01:29.536596 [info ] [MainThread]: 
[0m22:01:29.537058 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m22:01:29.540872 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.7962582, "process_in_blocks": "0", "process_kernel_time": 0.899577, "process_mem_max_rss": "143327232", "process_out_blocks": "0", "process_user_time": 4.174561}
[0m22:01:29.541515 [debug] [MainThread]: Command `dbt run` succeeded at 22:01:29.541384 after 2.80 seconds
[0m22:01:29.541952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9a7e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffd4230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffd4cd0>]}
[0m22:01:29.542365 [debug] [MainThread]: Flushing usage events
[0m22:01:30.022807 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:06:02.904652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110143770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11183f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11183f4d0>]}


============================== 22:06:02.912850 | 4534b776-0426-4f16-910e-bde527f3a3b5 ==============================
[0m22:06:02.912850 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:06:02.913764 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:06:03.234062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4534b776-0426-4f16-910e-bde527f3a3b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bbc510>]}
[0m22:06:03.318629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4534b776-0426-4f16-910e-bde527f3a3b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c3df0>]}
[0m22:06:03.320753 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:06:03.490487 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:06:03.945977 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 1 files changed.
[0m22:06:03.946846 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/bronze/_elsa_bronze__sources.yml
[0m22:06:03.947516 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m22:06:04.248909 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  unexpected '}', expected ')'
    line 16
      FROM {{ source('bronze', rte_eco2mix }}
[0m22:06:04.253256 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.454536, "process_in_blocks": "0", "process_kernel_time": 0.77911, "process_mem_max_rss": "123363328", "process_out_blocks": "0", "process_user_time": 3.117278}
[0m22:06:04.253933 [debug] [MainThread]: Command `dbt run` failed at 22:06:04.253794 after 1.46 seconds
[0m22:06:04.254420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117b3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117b3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bb8c80>]}
[0m22:06:04.255641 [debug] [MainThread]: Flushing usage events
[0m22:06:04.778822 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:06:14.869566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108057610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080574d0>]}


============================== 22:06:14.874608 | 862d5710-cb61-43b5-9596-19319dbf9f0f ==============================
[0m22:06:14.874608 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:06:14.875398 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:06:15.077861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '862d5710-cb61-43b5-9596-19319dbf9f0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073d4510>]}
[0m22:06:15.150543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '862d5710-cb61-43b5-9596-19319dbf9f0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107edbdf0>]}
[0m22:06:15.151693 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:06:15.286719 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:06:15.524113 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 1 files changed.
[0m22:06:15.524844 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/bronze/_elsa_bronze__sources.yml
[0m22:06:15.525395 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m22:06:15.811216 [error] [MainThread]: Encountered an error:
Compilation Error in model daily_consumption (models/bronze/daily_consumption.sql)
  unexpected '}', expected ')'
    line 16
      FROM {{ source('bronze', 'rte_eco2mix' }}
[0m22:06:15.813849 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0320823, "process_in_blocks": "0", "process_kernel_time": 0.300966, "process_mem_max_rss": "123686912", "process_out_blocks": "0", "process_user_time": 2.330175}
[0m22:06:15.814374 [debug] [MainThread]: Command `dbt run` failed at 22:06:15.814261 after 1.03 seconds
[0m22:06:15.814839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fcb850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fca750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093c9220>]}
[0m22:06:15.815239 [debug] [MainThread]: Flushing usage events
[0m22:06:16.206484 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:06:24.609550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2b7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9ef610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9ef4d0>]}


============================== 22:06:24.614710 | 7cd2bc97-0eef-457d-aeab-d69c46fd1feb ==============================
[0m22:06:24.614710 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:06:24.615456 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:06:24.828945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7cd2bc97-0eef-457d-aeab-d69c46fd1feb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd3c510>]}
[0m22:06:24.900647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7cd2bc97-0eef-457d-aeab-d69c46fd1feb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e86fdf0>]}
[0m22:06:24.901832 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:06:25.029297 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:06:25.283886 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 1 files changed.
[0m22:06:25.284654 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/bronze/_elsa_bronze__sources.yml
[0m22:06:25.285274 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/daily_consumption.sql
[0m22:06:25.977019 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m22:06:25.995789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7cd2bc97-0eef-457d-aeab-d69c46fd1feb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc78d50>]}
[0m22:06:26.161272 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:06:26.168243 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:06:26.239988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7cd2bc97-0eef-457d-aeab-d69c46fd1feb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f95d130>]}
[0m22:06:26.240711 [info ] [MainThread]: Found 31 models, 2 operations, 4 data tests, 1 source, 1571 macros
[0m22:06:26.241261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cd2bc97-0eef-457d-aeab-d69c46fd1feb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8db310>]}
[0m22:06:26.244247 [info ] [MainThread]: 
[0m22:06:26.244832 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m22:06:26.245305 [info ] [MainThread]: 
[0m22:06:26.246004 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:06:26.247060 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m22:06:26.326420 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m22:06:26.327161 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m22:06:26.327848 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:06:26.389218 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.061 seconds
[0m22:06:26.391896 [debug] [ThreadPool]: On list_elsa: Close
[0m22:06:26.402049 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_bronze)
[0m22:06:26.402916 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m22:06:26.412116 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m22:06:26.415344 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:06:26.415798 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m22:06:26.416237 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m22:06:26.416625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:26.416987 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:06:26.424378 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:06:26.424837 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:06:26.425215 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m22:06:26.425540 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:06:26.425888 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m22:06:26.426262 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m22:06:26.431658 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m22:06:26.432112 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m22:06:26.433464 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m22:06:26.434764 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m22:06:26.435352 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m22:06:26.435727 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m22:06:26.443447 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:26.443892 [debug] [MainThread]: On master: BEGIN
[0m22:06:26.444208 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:06:26.449914 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:06:26.450334 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:26.450737 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:06:26.465032 [debug] [MainThread]: SQL status: SELECT 0 in 0.014 seconds
[0m22:06:26.466489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cd2bc97-0eef-457d-aeab-d69c46fd1feb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11013a4e0>]}
[0m22:06:26.467010 [debug] [MainThread]: On master: ROLLBACK
[0m22:06:26.467567 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:26.467914 [debug] [MainThread]: On master: BEGIN
[0m22:06:26.468571 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:06:26.468933 [debug] [MainThread]: On master: COMMIT
[0m22:06:26.469270 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:26.469581 [debug] [MainThread]: On master: COMMIT
[0m22:06:26.470039 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:06:26.509136 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m22:06:26.515037 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:06:26.519259 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:06:26.519959 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m22:06:26.520342 [info ] [MainThread]: 
[0m22:06:26.520765 [debug] [MainThread]: On master: Close
[0m22:06:26.526114 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m22:06:26.527035 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze_bronze.daily_consumption ................... [RUN]
[0m22:06:26.527981 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_bronze, now model.dbt_elsa.daily_consumption)
[0m22:06:26.528532 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m22:06:26.532938 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m22:06:26.533762 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m22:06:26.583609 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m22:06:26.585025 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.585471 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m22:06:26.585855 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:06:26.591780 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m22:06:26.592260 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.592679 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m22:06:26.600533 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.007 seconds
[0m22:06:26.611649 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.612135 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption" rename to "daily_consumption__dbt_backup"
[0m22:06:26.613070 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:26.616808 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.617221 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m22:06:26.618197 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:26.643019 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.643511 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on table "elsa"."bronze_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m22:06:26.644550 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:06:26.667360 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.667876 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m22:06:26.681139 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.013 seconds
[0m22:06:26.686459 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.687021 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m22:06:26.688028 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:06:26.689330 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:06:26.689735 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.690115 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:06:26.691175 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m22:06:26.699217 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze_bronze"."daily_consumption__dbt_backup"
[0m22:06:26.704847 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:06:26.705332 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
drop table if exists "elsa"."bronze_bronze"."daily_consumption__dbt_backup" cascade
[0m22:06:26.710510 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:06:26.713519 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m22:06:26.715953 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cd2bc97-0eef-457d-aeab-d69c46fd1feb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8af290>]}
[0m22:06:26.716827 [info ] [Thread-1 (]: 1 of 1 OK created sql table model bronze_bronze.daily_consumption .............. [[32mSELECT 96[0m in 0.19s]
[0m22:06:26.717571 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m22:06:26.719538 [info ] [MainThread]: 
[0m22:06:26.719993 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:26.720334 [debug] [MainThread]: On master: BEGIN
[0m22:06:26.720651 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:06:26.726374 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:06:26.726815 [debug] [MainThread]: On master: COMMIT
[0m22:06:26.727154 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:26.727472 [debug] [MainThread]: On master: COMMIT
[0m22:06:26.727891 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:06:26.764104 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:06:26.769831 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m22:06:26.795129 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:06:26.796087 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m22:06:26.796727 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.07s]
[0m22:06:26.797208 [debug] [MainThread]: On master: Close
[0m22:06:26.797749 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:06:26.798054 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m22:06:26.798324 [debug] [MainThread]: Connection 'list_elsa_bronze_tec_elsa' was properly closed.
[0m22:06:26.798682 [info ] [MainThread]: 
[0m22:06:26.799130 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.55 seconds (0.55s).
[0m22:06:26.800459 [debug] [MainThread]: Command end result
[0m22:06:26.884705 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:06:26.887363 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:06:26.894689 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m22:06:26.895225 [info ] [MainThread]: 
[0m22:06:26.895679 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:06:26.896084 [info ] [MainThread]: 
[0m22:06:26.896528 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m22:06:26.899213 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.3754456, "process_in_blocks": "0", "process_kernel_time": 0.396217, "process_mem_max_rss": "141422592", "process_out_blocks": "0", "process_user_time": 3.452184}
[0m22:06:26.899758 [debug] [MainThread]: Command `dbt run` succeeded at 22:06:26.899634 after 2.38 seconds
[0m22:06:26.900175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110075c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110495c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110495450>]}
[0m22:06:26.900576 [debug] [MainThread]: Flushing usage events
[0m22:06:27.293598 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:14:47.959618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d17770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a44b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a44b4d0>]}


============================== 22:14:47.971232 | e7d13726-fbb6-455f-b030-11c7856c8c8e ==============================
[0m22:14:47.971232 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:14:47.972405 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m22:14:48.296745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109798510>]}
[0m22:14:48.378830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2cbdf0>]}
[0m22:14:48.380034 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:14:48.544806 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:14:48.985298 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:14:48.985774 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:14:48.993682 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m22:14:49.129556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3bf350>]}
[0m22:14:49.309326 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:14:49.312849 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:14:49.348937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2ae990>]}
[0m22:14:49.349573 [info ] [MainThread]: Found 31 models, 2 operations, 4 data tests, 1 source, 1571 macros
[0m22:14:49.350026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a544050>]}
[0m22:14:49.353666 [info ] [MainThread]: 
[0m22:14:49.354170 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m22:14:49.354603 [info ] [MainThread]: 
[0m22:14:49.355596 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:14:49.363004 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m22:14:49.363674 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m22:14:49.441929 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m22:14:49.442466 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m22:14:49.442869 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m22:14:49.443295 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m22:14:49.443690 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:14:49.444075 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:14:49.491379 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.048 seconds
[0m22:14:49.491874 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.048 seconds
[0m22:14:49.493608 [debug] [ThreadPool]: On list_elsa: Close
[0m22:14:49.495030 [debug] [ThreadPool]: On list_elsa: Close
[0m22:14:49.496122 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa_bronze_tec_elsa)
[0m22:14:49.497193 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "bronze_tec_elsa"
"
[0m22:14:49.504622 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_tec_elsa"
[0m22:14:49.505052 [debug] [ThreadPool]: On create_elsa_bronze_tec_elsa: BEGIN
[0m22:14:49.505370 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:49.511525 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:14:49.511957 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_tec_elsa"
[0m22:14:49.512298 [debug] [ThreadPool]: On create_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "create_elsa_bronze_tec_elsa"} */
create schema if not exists "bronze_tec_elsa"
[0m22:14:49.513241 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m22:14:49.514264 [debug] [ThreadPool]: On create_elsa_bronze_tec_elsa: COMMIT
[0m22:14:49.514622 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_tec_elsa"
[0m22:14:49.514950 [debug] [ThreadPool]: On create_elsa_bronze_tec_elsa: COMMIT
[0m22:14:49.516130 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m22:14:49.516507 [debug] [ThreadPool]: On create_elsa_bronze_tec_elsa: Close
[0m22:14:49.520158 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa_bronze_tec_elsa, now list_elsa_bronze_bronze)
[0m22:14:49.520932 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m22:14:49.527907 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m22:14:49.530574 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:14:49.531012 [debug] [ThreadPool]: On list_elsa_bronze_bronze: BEGIN
[0m22:14:49.531374 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m22:14:49.531948 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:49.532254 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:49.538083 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:14:49.538491 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:14:49.538815 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_bronze"
[0m22:14:49.539152 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:14:49.539529 [debug] [ThreadPool]: On list_elsa_bronze_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_bronze'
  
[0m22:14:49.539905 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m22:14:49.545546 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m22:14:49.546064 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m22:14:49.547426 [debug] [ThreadPool]: On list_elsa_bronze_bronze: ROLLBACK
[0m22:14:49.548611 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m22:14:49.549228 [debug] [ThreadPool]: On list_elsa_bronze_bronze: Close
[0m22:14:49.549578 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m22:14:49.556903 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:49.557307 [debug] [MainThread]: On master: BEGIN
[0m22:14:49.557604 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:14:49.562948 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:14:49.563374 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:49.563770 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:14:49.578572 [debug] [MainThread]: SQL status: SELECT 0 in 0.014 seconds
[0m22:14:49.580114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b78e0d0>]}
[0m22:14:49.580664 [debug] [MainThread]: On master: ROLLBACK
[0m22:14:49.581245 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:49.581597 [debug] [MainThread]: On master: BEGIN
[0m22:14:49.582230 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:14:49.582590 [debug] [MainThread]: On master: COMMIT
[0m22:14:49.582919 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:49.583233 [debug] [MainThread]: On master: COMMIT
[0m22:14:49.583680 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:14:49.626324 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m22:14:49.632682 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:14:49.636956 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:14:49.637848 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m22:14:49.638275 [info ] [MainThread]: 
[0m22:14:49.638714 [debug] [MainThread]: On master: Close
[0m22:14:49.644160 [debug] [Thread-16 ]: Began running node model.elementary.metadata
[0m22:14:49.645058 [debug] [Thread-4 (]: Began running node model.elementary.dbt_exposures
[0m22:14:49.645828 [debug] [Thread-3 (]: Began running node model.elementary.dbt_columns
[0m22:14:49.646259 [debug] [Thread-5 (]: Began running node model.elementary.dbt_groups
[0m22:14:49.646658 [debug] [Thread-7 (]: Began running node model.elementary.dbt_metrics
[0m22:14:49.647225 [debug] [Thread-8 (]: Began running node model.elementary.dbt_models
[0m22:14:49.648180 [debug] [Thread-6 (]: Began running node model.elementary.dbt_invocations
[0m22:14:49.648751 [debug] [Thread-10 ]: Began running node model.elementary.dbt_seeds
[0m22:14:49.649253 [debug] [Thread-11 ]: Began running node model.elementary.dbt_snapshots
[0m22:14:49.650156 [debug] [Thread-14 ]: Began running node model.elementary.dbt_tests
[0m22:14:49.650574 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m22:14:49.650987 [debug] [Thread-9 (]: Began running node model.elementary.dbt_run_results
[0m22:14:49.651366 [debug] [Thread-12 ]: Began running node model.elementary.dbt_source_freshness_results
[0m22:14:49.651740 [debug] [Thread-15 ]: Began running node model.elementary.elementary_test_results
[0m22:14:49.652267 [info ] [Thread-16 ]: 16 of 31 START sql table model bronze_tec_elsa.metadata ........................ [RUN]
[0m22:14:49.652703 [debug] [Thread-13 ]: Began running node model.elementary.dbt_sources
[0m22:14:49.653125 [debug] [Thread-2 (]: Began running node model.elementary.data_monitoring_metrics
[0m22:14:49.653614 [info ] [Thread-4 (]: 4 of 31 START sql incremental model bronze_tec_elsa.dbt_exposures .............. [RUN]
[0m22:14:49.654135 [info ] [Thread-3 (]: 3 of 31 START sql incremental model bronze_tec_elsa.dbt_columns ................ [RUN]
[0m22:14:49.654648 [info ] [Thread-5 (]: 5 of 31 START sql incremental model bronze_tec_elsa.dbt_groups ................. [RUN]
[0m22:14:49.655238 [info ] [Thread-7 (]: 7 of 31 START sql incremental model bronze_tec_elsa.dbt_metrics ................ [RUN]
[0m22:14:49.655984 [info ] [Thread-8 (]: 8 of 31 START sql incremental model bronze_tec_elsa.dbt_models ................. [RUN]
[0m22:14:49.656851 [info ] [Thread-6 (]: 6 of 31 START sql incremental model bronze_tec_elsa.dbt_invocations ............ [RUN]
[0m22:14:49.657575 [info ] [Thread-10 ]: 10 of 31 START sql incremental model bronze_tec_elsa.dbt_seeds ................. [RUN]
[0m22:14:49.658668 [info ] [Thread-11 ]: 11 of 31 START sql incremental model bronze_tec_elsa.dbt_snapshots ............. [RUN]
[0m22:14:49.660140 [info ] [Thread-14 ]: 14 of 31 START sql incremental model bronze_tec_elsa.dbt_tests ................. [RUN]
[0m22:14:49.660836 [info ] [Thread-1 (]: 1 of 31 START sql table model bronze_bronze.daily_consumption .................. [RUN]
[0m22:14:49.661458 [info ] [Thread-9 (]: 9 of 31 START sql incremental model bronze_tec_elsa.dbt_run_results ............ [RUN]
[0m22:14:49.662056 [info ] [Thread-12 ]: 12 of 31 START sql incremental model bronze_tec_elsa.dbt_source_freshness_results  [RUN]
[0m22:14:49.662691 [info ] [Thread-15 ]: 15 of 31 START sql incremental model bronze_tec_elsa.elementary_test_results ... [RUN]
[0m22:14:49.663365 [debug] [Thread-16 ]: Acquiring new postgres connection 'model.elementary.metadata'
[0m22:14:49.663929 [info ] [Thread-13 ]: 13 of 31 START sql incremental model bronze_tec_elsa.dbt_sources ............... [RUN]
[0m22:14:49.664945 [info ] [Thread-2 (]: 2 of 31 START sql incremental model bronze_tec_elsa.data_monitoring_metrics .... [RUN]
[0m22:14:49.665703 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.elementary.dbt_exposures'
[0m22:14:49.666240 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.elementary.dbt_columns'
[0m22:14:49.666764 [debug] [Thread-5 (]: Acquiring new postgres connection 'model.elementary.dbt_groups'
[0m22:14:49.667277 [debug] [Thread-7 (]: Acquiring new postgres connection 'model.elementary.dbt_metrics'
[0m22:14:49.667781 [debug] [Thread-8 (]: Acquiring new postgres connection 'model.elementary.dbt_models'
[0m22:14:49.668284 [debug] [Thread-6 (]: Acquiring new postgres connection 'model.elementary.dbt_invocations'
[0m22:14:49.668769 [debug] [Thread-10 ]: Acquiring new postgres connection 'model.elementary.dbt_seeds'
[0m22:14:49.669313 [debug] [Thread-11 ]: Acquiring new postgres connection 'model.elementary.dbt_snapshots'
[0m22:14:49.669844 [debug] [Thread-14 ]: Acquiring new postgres connection 'model.elementary.dbt_tests'
[0m22:14:49.670287 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_bronze, now model.dbt_elsa.daily_consumption)
[0m22:14:49.670824 [debug] [Thread-9 (]: Acquiring new postgres connection 'model.elementary.dbt_run_results'
[0m22:14:49.671432 [debug] [Thread-12 ]: Acquiring new postgres connection 'model.elementary.dbt_source_freshness_results'
[0m22:14:49.672338 [debug] [Thread-15 ]: Acquiring new postgres connection 'model.elementary.elementary_test_results'
[0m22:14:49.672779 [debug] [Thread-16 ]: Began compiling node model.elementary.metadata
[0m22:14:49.673301 [debug] [Thread-13 ]: Acquiring new postgres connection 'model.elementary.dbt_sources'
[0m22:14:49.673739 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.elementary.data_monitoring_metrics)
[0m22:14:49.674158 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_exposures
[0m22:14:49.674549 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_columns
[0m22:14:49.674986 [debug] [Thread-5 (]: Began compiling node model.elementary.dbt_groups
[0m22:14:49.675399 [debug] [Thread-7 (]: Began compiling node model.elementary.dbt_metrics
[0m22:14:49.675835 [debug] [Thread-8 (]: Began compiling node model.elementary.dbt_models
[0m22:14:49.676365 [debug] [Thread-6 (]: Began compiling node model.elementary.dbt_invocations
[0m22:14:49.676884 [debug] [Thread-10 ]: Began compiling node model.elementary.dbt_seeds
[0m22:14:49.677316 [debug] [Thread-11 ]: Began compiling node model.elementary.dbt_snapshots
[0m22:14:49.677790 [debug] [Thread-14 ]: Began compiling node model.elementary.dbt_tests
[0m22:14:49.678218 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m22:14:49.678635 [debug] [Thread-9 (]: Began compiling node model.elementary.dbt_run_results
[0m22:14:49.679027 [debug] [Thread-12 ]: Began compiling node model.elementary.dbt_source_freshness_results
[0m22:14:49.679546 [debug] [Thread-15 ]: Began compiling node model.elementary.elementary_test_results
[0m22:14:49.686095 [debug] [Thread-16 ]: Writing injected SQL for node "model.elementary.metadata"
[0m22:14:49.686660 [debug] [Thread-13 ]: Began compiling node model.elementary.dbt_sources
[0m22:14:49.687063 [debug] [Thread-2 (]: Began compiling node model.elementary.data_monitoring_metrics
[0m22:14:49.746378 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_columns"
[0m22:14:49.759900 [debug] [Thread-5 (]: Writing injected SQL for node "model.elementary.dbt_groups"
[0m22:14:49.761342 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_exposures"
[0m22:14:49.770092 [debug] [Thread-7 (]: Writing injected SQL for node "model.elementary.dbt_metrics"
[0m22:14:49.817765 [debug] [Thread-10 ]: Writing injected SQL for node "model.elementary.dbt_seeds"
[0m22:14:49.825752 [debug] [Thread-8 (]: Writing injected SQL for node "model.elementary.dbt_models"
[0m22:14:49.831717 [debug] [Thread-6 (]: Writing injected SQL for node "model.elementary.dbt_invocations"
[0m22:14:49.841210 [debug] [Thread-11 ]: Writing injected SQL for node "model.elementary.dbt_snapshots"
[0m22:14:49.856306 [debug] [Thread-14 ]: Writing injected SQL for node "model.elementary.dbt_tests"
[0m22:14:49.859976 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m22:14:49.889557 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.dbt_source_freshness_results"
[0m22:14:49.894387 [debug] [Thread-9 (]: Writing injected SQL for node "model.elementary.dbt_run_results"
[0m22:14:49.911937 [debug] [Thread-15 ]: Writing injected SQL for node "model.elementary.elementary_test_results"
[0m22:14:49.926108 [debug] [Thread-13 ]: Writing injected SQL for node "model.elementary.dbt_sources"
[0m22:14:49.940267 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.data_monitoring_metrics"
[0m22:14:49.940957 [debug] [Thread-16 ]: Began executing node model.elementary.metadata
[0m22:14:49.942243 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_exposures
[0m22:14:49.942684 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_columns
[0m22:14:49.943144 [debug] [Thread-7 (]: Began executing node model.elementary.dbt_metrics
[0m22:14:49.943506 [debug] [Thread-5 (]: Began executing node model.elementary.dbt_groups
[0m22:14:49.943905 [debug] [Thread-8 (]: Began executing node model.elementary.dbt_models
[0m22:14:49.944372 [debug] [Thread-10 ]: Began executing node model.elementary.dbt_seeds
[0m22:14:49.944958 [debug] [Thread-6 (]: Began executing node model.elementary.dbt_invocations
[0m22:14:49.946544 [debug] [Thread-12 ]: Began executing node model.elementary.dbt_source_freshness_results
[0m22:14:49.947044 [debug] [Thread-9 (]: Began executing node model.elementary.dbt_run_results
[0m22:14:49.947600 [debug] [Thread-11 ]: Began executing node model.elementary.dbt_snapshots
[0m22:14:49.953590 [debug] [Thread-15 ]: Began executing node model.elementary.elementary_test_results
[0m22:14:49.954373 [debug] [Thread-14 ]: Began executing node model.elementary.dbt_tests
[0m22:14:49.960089 [debug] [Thread-13 ]: Began executing node model.elementary.dbt_sources
[0m22:14:49.960613 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m22:14:50.029219 [debug] [Thread-16 ]: Writing runtime sql for node "model.elementary.metadata"
[0m22:14:50.033953 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_columns"
[0m22:14:50.040020 [debug] [Thread-7 (]: Writing runtime sql for node "model.elementary.dbt_metrics"
[0m22:14:50.041329 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_exposures"
[0m22:14:50.046431 [debug] [Thread-5 (]: Writing runtime sql for node "model.elementary.dbt_groups"
[0m22:14:50.046938 [debug] [Thread-2 (]: Began executing node model.elementary.data_monitoring_metrics
[0m22:14:50.055029 [debug] [Thread-8 (]: Writing runtime sql for node "model.elementary.dbt_models"
[0m22:14:50.059549 [debug] [Thread-10 ]: Writing runtime sql for node "model.elementary.dbt_seeds"
[0m22:14:50.064093 [debug] [Thread-6 (]: Writing runtime sql for node "model.elementary.dbt_invocations"
[0m22:14:50.068776 [debug] [Thread-12 ]: Writing runtime sql for node "model.elementary.dbt_source_freshness_results"
[0m22:14:50.073513 [debug] [Thread-9 (]: Writing runtime sql for node "model.elementary.dbt_run_results"
[0m22:14:50.078824 [debug] [Thread-11 ]: Writing runtime sql for node "model.elementary.dbt_snapshots"
[0m22:14:50.083568 [debug] [Thread-15 ]: Writing runtime sql for node "model.elementary.elementary_test_results"
[0m22:14:50.088638 [debug] [Thread-14 ]: Writing runtime sql for node "model.elementary.dbt_tests"
[0m22:14:50.093186 [debug] [Thread-13 ]: Writing runtime sql for node "model.elementary.dbt_sources"
[0m22:14:50.096985 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m22:14:50.105537 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.data_monitoring_metrics"
[0m22:14:50.106589 [debug] [Thread-16 ]: Using postgres connection "model.elementary.metadata"
[0m22:14:50.107683 [debug] [Thread-5 (]: Using postgres connection "model.elementary.dbt_groups"
[0m22:14:50.108523 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:50.109353 [debug] [Thread-7 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m22:14:50.110423 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m22:14:50.112018 [debug] [Thread-6 (]: Using postgres connection "model.elementary.dbt_invocations"
[0m22:14:50.113065 [debug] [Thread-10 ]: Using postgres connection "model.elementary.dbt_seeds"
[0m22:14:50.113848 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:50.115719 [debug] [Thread-9 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m22:14:50.117098 [debug] [Thread-12 ]: Using postgres connection "model.elementary.dbt_source_freshness_results"
[0m22:14:50.118229 [debug] [Thread-16 ]: On model.elementary.metadata: BEGIN
[0m22:14:50.119110 [debug] [Thread-15 ]: Using postgres connection "model.elementary.elementary_test_results"
[0m22:14:50.119968 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:50.120840 [debug] [Thread-11 ]: Using postgres connection "model.elementary.dbt_snapshots"
[0m22:14:50.121702 [debug] [Thread-5 (]: On model.elementary.dbt_groups: BEGIN
[0m22:14:50.122616 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:50.123587 [debug] [Thread-3 (]: On model.elementary.dbt_columns: BEGIN
[0m22:14:50.124411 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:50.125119 [debug] [Thread-7 (]: On model.elementary.dbt_metrics: BEGIN
[0m22:14:50.125897 [debug] [Thread-2 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m22:14:50.126584 [debug] [Thread-4 (]: On model.elementary.dbt_exposures: BEGIN
[0m22:14:50.127349 [debug] [Thread-6 (]: On model.elementary.dbt_invocations: BEGIN
[0m22:14:50.128113 [debug] [Thread-10 ]: On model.elementary.dbt_seeds: BEGIN
[0m22:14:50.128819 [debug] [Thread-8 (]: On model.elementary.dbt_models: BEGIN
[0m22:14:50.129648 [debug] [Thread-9 (]: On model.elementary.dbt_run_results: BEGIN
[0m22:14:50.130470 [debug] [Thread-12 ]: On model.elementary.dbt_source_freshness_results: BEGIN
[0m22:14:50.131265 [debug] [Thread-16 ]: Opening a new connection, currently in state init
[0m22:14:50.132106 [debug] [Thread-15 ]: On model.elementary.elementary_test_results: BEGIN
[0m22:14:50.132875 [debug] [Thread-13 ]: On model.elementary.dbt_sources: BEGIN
[0m22:14:50.133571 [debug] [Thread-11 ]: On model.elementary.dbt_snapshots: BEGIN
[0m22:14:50.134244 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m22:14:50.134977 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m22:14:50.135752 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m22:14:50.136492 [debug] [Thread-14 ]: On model.elementary.dbt_tests: BEGIN
[0m22:14:50.137182 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m22:14:50.137899 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: BEGIN
[0m22:14:50.138628 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m22:14:50.139374 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m22:14:50.140109 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m22:14:50.140825 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m22:14:50.141667 [debug] [Thread-9 (]: Opening a new connection, currently in state init
[0m22:14:50.142471 [debug] [Thread-12 ]: Opening a new connection, currently in state init
[0m22:14:50.143549 [debug] [Thread-15 ]: Opening a new connection, currently in state init
[0m22:14:50.144433 [debug] [Thread-13 ]: Opening a new connection, currently in state init
[0m22:14:50.145215 [debug] [Thread-11 ]: Opening a new connection, currently in state init
[0m22:14:50.146276 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:14:50.147316 [debug] [Thread-14 ]: Opening a new connection, currently in state init
[0m22:14:50.148373 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:14:50.161008 [debug] [Thread-16 ]: SQL status: BEGIN in 0.030 seconds
[0m22:14:50.161703 [debug] [Thread-16 ]: Using postgres connection "model.elementary.metadata"
[0m22:14:50.162365 [debug] [Thread-5 (]: SQL status: BEGIN in 0.028 seconds
[0m22:14:50.163011 [debug] [Thread-16 ]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.metadata"} */

  
    

  create  table "elsa"."bronze_tec_elsa"."metadata__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    '0.19.0' as dbt_pkg_version
  );
  
[0m22:14:50.163816 [debug] [Thread-5 (]: Using postgres connection "model.elementary.dbt_groups"
[0m22:14:50.164512 [debug] [Thread-3 (]: SQL status: BEGIN in 0.029 seconds
[0m22:14:50.165364 [debug] [Thread-5 (]: On model.elementary.dbt_groups: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_groups"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_groups"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as owner_email

,
                
        cast('dummy_string' as varchar(4096)) as owner_name

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.166322 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:50.167221 [debug] [Thread-3 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_columns"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_columns"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as parent_unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as data_type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as table_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as resource_type

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.168035 [debug] [Thread-7 (]: SQL status: BEGIN in 0.031 seconds
[0m22:14:50.168810 [debug] [Thread-7 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m22:14:50.169726 [debug] [Thread-7 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_metrics"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_metrics"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as label

,
                
        cast('dummy_string' as varchar(4096)) as model

,
                
        cast('dummy_string' as varchar(4096)) as type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as sql

,
                
        cast('dummy_string' as varchar(4096)) as timestamp

,
                
        cast('this_is_just_a_long_dummy_string' as text) as filters

,
                
        cast('this_is_just_a_long_dummy_string' as text) as time_grains

,
                
        cast('this_is_just_a_long_dummy_string' as text) as dimensions

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.170622 [debug] [Thread-4 (]: SQL status: BEGIN in 0.032 seconds
[0m22:14:50.171310 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m22:14:50.172111 [debug] [Thread-4 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_exposures"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_exposures"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as maturity

,
                
        cast('dummy_string' as varchar(4096)) as type

,
                
        cast('dummy_string' as varchar(4096)) as owner_email

,
                
        cast('dummy_string' as varchar(4096)) as owner_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as url

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_columns

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as label

,
                
        cast('this_is_just_a_long_dummy_string' as text) as raw_queries


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.174203 [debug] [Thread-10 ]: SQL status: BEGIN in 0.034 seconds
[0m22:14:50.174999 [debug] [Thread-10 ]: Using postgres connection "model.elementary.dbt_seeds"
[0m22:14:50.175794 [debug] [Thread-10 ]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_seeds"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_seeds"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as checksum

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.176600 [debug] [Thread-16 ]: SQL status: SELECT 1 in 0.011 seconds
[0m22:14:50.184884 [debug] [Thread-7 (]: SQL status: SELECT 0 in 0.014 seconds
[0m22:14:50.185679 [debug] [Thread-6 (]: SQL status: BEGIN in 0.046 seconds
[0m22:14:50.186303 [debug] [Thread-15 ]: SQL status: BEGIN in 0.043 seconds
[0m22:14:50.186907 [debug] [Thread-5 (]: SQL status: SELECT 0 in 0.020 seconds
[0m22:14:50.187670 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.019 seconds
[0m22:14:50.195394 [debug] [Thread-12 ]: SQL status: BEGIN in 0.053 seconds
[0m22:14:50.201272 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.028 seconds
[0m22:14:50.201971 [debug] [Thread-10 ]: SQL status: SELECT 0 in 0.025 seconds
[0m22:14:50.212352 [debug] [Thread-13 ]: SQL status: BEGIN in 0.068 seconds
[0m22:14:50.213101 [debug] [Thread-9 (]: SQL status: BEGIN in 0.071 seconds
[0m22:14:50.213718 [debug] [Thread-8 (]: SQL status: BEGIN in 0.073 seconds
[0m22:14:50.222606 [debug] [Thread-16 ]: Using postgres connection "model.elementary.metadata"
[0m22:14:50.229360 [debug] [Thread-1 (]: SQL status: BEGIN in 0.083 seconds
[0m22:14:50.230078 [debug] [Thread-11 ]: SQL status: BEGIN in 0.085 seconds
[0m22:14:50.241484 [debug] [Thread-14 ]: SQL status: BEGIN in 0.094 seconds
[0m22:14:50.242049 [debug] [Thread-2 (]: SQL status: BEGIN in 0.094 seconds
[0m22:14:50.254061 [debug] [Thread-6 (]: Using postgres connection "model.elementary.dbt_invocations"
[0m22:14:50.265247 [debug] [Thread-15 ]: Using postgres connection "model.elementary.elementary_test_results"
[0m22:14:50.320895 [debug] [Thread-12 ]: Using postgres connection "model.elementary.dbt_source_freshness_results"
[0m22:14:50.327236 [debug] [Thread-3 (]: Elementary: [dbt_columns] Flattening the artifacts.
[0m22:14:50.328421 [debug] [Thread-7 (]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m22:14:50.333844 [debug] [Thread-5 (]: Elementary: [dbt_groups] Flattening the artifacts.
[0m22:14:50.339444 [debug] [Thread-4 (]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m22:14:50.344983 [debug] [Thread-10 ]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m22:14:50.345473 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:50.345907 [debug] [Thread-9 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m22:14:50.346288 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:50.346673 [debug] [Thread-16 ]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.metadata"} */
alter table "elsa"."bronze_tec_elsa"."metadata__dbt_tmp" rename to "metadata"
[0m22:14:50.347055 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:50.347427 [debug] [Thread-11 ]: Using postgres connection "model.elementary.dbt_snapshots"
[0m22:14:50.347826 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:50.348231 [debug] [Thread-2 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m22:14:50.348750 [debug] [Thread-6 (]: On model.elementary.dbt_invocations: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_invocations"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_invocations"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as invocation_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as job_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as job_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as job_run_id

,
                
        cast('dummy_string' as varchar(4096)) as run_started_at

,
                
        cast('dummy_string' as varchar(4096)) as run_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast('dummy_string' as varchar(4096)) as command

,
                
        cast('dummy_string' as varchar(4096)) as dbt_version

,
                
        cast('dummy_string' as varchar(4096)) as elementary_version

,
                
        cast (True as boolean) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as text) as invocation_vars

,
                
        cast('this_is_just_a_long_dummy_string' as text) as vars

,
                
        cast('dummy_string' as varchar(4096)) as target_name

,
                
        cast('dummy_string' as varchar(4096)) as target_database

,
                
        cast('dummy_string' as varchar(4096)) as target_schema

,
                
        cast('dummy_string' as varchar(4096)) as target_profile_name

,
                
        cast(123456789 as integer) as threads

,
                
        cast('this_is_just_a_long_dummy_string' as text) as selected

,
                
        cast('this_is_just_a_long_dummy_string' as text) as yaml_selector

,
                
        cast('dummy_string' as varchar(4096)) as project_id

,
                
        cast('dummy_string' as varchar(4096)) as project_name

,
                
        cast('dummy_string' as varchar(4096)) as env

,
                
        cast('dummy_string' as varchar(4096)) as env_id

,
                
        cast('dummy_string' as varchar(4096)) as cause_category

,
                
        cast('this_is_just_a_long_dummy_string' as text) as cause

,
                
        cast('dummy_string' as varchar(4096)) as pull_request_id

,
                
        cast('dummy_string' as varchar(4096)) as git_sha

,
                
        cast('dummy_string' as varchar(4096)) as orchestrator

,
                
        cast('dummy_string' as varchar(4096)) as dbt_user

,
                
        cast('dummy_string' as varchar(4096)) as job_url

,
                
        cast('dummy_string' as varchar(4096)) as job_run_url

,
                
        cast('dummy_string' as varchar(4096)) as account_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as target_adapter_specific_fields


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.349375 [debug] [Thread-15 ]: On model.elementary.elementary_test_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.elementary_test_results"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."elementary_test_results"
  
  
    as
  
  (
    


    select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as id

,
                
        cast('dummy_string' as varchar(4096)) as data_issue_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as model_unique_id

,
                
        cast('dummy_string' as varchar(4096)) as invocation_id

,
                cast('2091-02-17' as timestamp) as detected_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as table_name

,
                
        cast('dummy_string' as varchar(4096)) as column_name

,
                
        cast('dummy_string' as varchar(4096)) as test_type

,
                
        cast('dummy_string' as varchar(4096)) as test_sub_type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_results_description

,
                
        cast('dummy_string' as varchar(4096)) as owners

,
                
        cast('dummy_string' as varchar(4096)) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_results_query

,
                
        cast('dummy_string' as varchar(4096)) as other

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_params

,
                
        cast('dummy_string' as varchar(4096)) as severity

,
                
        cast('dummy_string' as varchar(4096)) as status

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as varchar(4096)) as test_short_name

,
                
        cast('dummy_string' as varchar(4096)) as test_alias

,
                
        cast('this_is_just_a_long_dummy_string' as text) as result_rows

,
                
        cast(31474836478 as bigint) as failed_row_count


        ) as empty_table
        where 1 = 0

  );
  
  
[0m22:14:50.349943 [debug] [Thread-12 ]: On model.elementary.dbt_source_freshness_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_source_freshness_results"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_source_freshness_results"
  
  
    as
  
  (
    


    select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as source_freshness_execution_id

,
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as max_loaded_at

,
                
        cast('dummy_string' as varchar(4096)) as snapshotted_at

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast(123456789.99 as float) as max_loaded_at_time_ago_in_s

,
                
        cast('dummy_string' as varchar(4096)) as status

,
                
        cast('dummy_string' as varchar(4096)) as error

,
                
        cast('dummy_string' as varchar(4096)) as compile_started_at

,
                
        cast('dummy_string' as varchar(4096)) as compile_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as execute_started_at

,
                
        cast('dummy_string' as varchar(4096)) as execute_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as invocation_id

,
                
        cast('dummy_string' as varchar(4096)) as warn_after

,
                
        cast('dummy_string' as varchar(4096)) as error_after

,
                
        cast('this_is_just_a_long_dummy_string' as text) as filter


        ) as empty_table
        where 1 = 0

  );
  
  
[0m22:14:50.413854 [debug] [Thread-7 (]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m22:14:50.418704 [debug] [Thread-5 (]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m22:14:50.433285 [debug] [Thread-4 (]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m22:14:50.448893 [debug] [Thread-10 ]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m22:14:50.465674 [debug] [Thread-13 ]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_sources"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_sources"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as source_name

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as identifier

,
                
        cast('dummy_string' as varchar(4096)) as loaded_at_field

,
                
        cast('dummy_string' as varchar(4096)) as freshness_warn_after

,
                
        cast('dummy_string' as varchar(4096)) as freshness_error_after

,
                
        cast('this_is_just_a_long_dummy_string' as text) as freshness_filter

,
                
        cast('this_is_just_a_long_dummy_string' as text) as freshness_description

,
                
        cast('dummy_string' as varchar(4096)) as relation_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('this_is_just_a_long_dummy_string' as text) as source_description

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.483582 [debug] [Thread-9 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_run_results"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_run_results"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as model_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as invocation_id

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast('this_is_just_a_long_dummy_string' as text) as name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as message

,
                
        cast('dummy_string' as varchar(4096)) as status

,
                
        cast('dummy_string' as varchar(4096)) as resource_type

,
                
        cast(123456789.99 as float) as execution_time

,
                
        cast('dummy_string' as varchar(4096)) as execute_started_at

,
                
        cast('dummy_string' as varchar(4096)) as execute_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as compile_started_at

,
                
        cast('dummy_string' as varchar(4096)) as compile_completed_at

,
                
        cast(31474836478 as bigint) as rows_affected

,
                
        cast (True as boolean) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as text) as compiled_code

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as varchar(4096)) as query_id

,
                
        cast('dummy_string' as varchar(4096)) as thread_id

,
                
        cast('dummy_string' as varchar(4096)) as materialization

,
                
        cast('dummy_string' as varchar(4096)) as adapter_response

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.500523 [debug] [Thread-8 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_models"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_models"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as checksum

,
                
        cast('dummy_string' as varchar(4096)) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as patch_path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as unique_key

,
                
        cast('dummy_string' as varchar(4096)) as incremental_strategy

,
                
        cast('dummy_string' as varchar(4096)) as group_name

,
                
        cast('dummy_string' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.525037 [debug] [Thread-16 ]: SQL status: ALTER TABLE in 0.006 seconds
[0m22:14:50.541691 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m22:14:50.553829 [debug] [Thread-11 ]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_snapshots"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_snapshots"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as checksum

,
                
        cast('dummy_string' as varchar(4096)) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as patch_path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as unique_key

,
                
        cast('dummy_string' as varchar(4096)) as incremental_strategy

,
                
        cast('dummy_string' as varchar(4096)) as group_name

,
                
        cast('dummy_string' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.558454 [debug] [Thread-3 (]: Elementary: [dbt_columns] Flattened 83 artifacts.
[0m22:14:50.558984 [debug] [Thread-14 ]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_tests"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."dbt_tests"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as short_name

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as test_column_name

,
                
        cast('dummy_string' as varchar(4096)) as severity

,
                
        cast('dummy_string' as varchar(4096)) as warn_if

,
                
        cast('dummy_string' as varchar(4096)) as error_if

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_params

,
                
        cast('dummy_string' as varchar(4096)) as test_namespace

,
                
        cast('dummy_string' as varchar(4096)) as test_original_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as model_tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as model_owners

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('dummy_string' as varchar(4096)) as parent_model_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('dummy_string' as varchar(4096)) as type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as quality_dimension

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:50.559543 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.data_monitoring_metrics"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."data_monitoring_metrics"
  
  
    as
  
  (
    


    
    
        
    
    select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as id

,
                
        cast('dummy_string' as varchar(4096)) as full_table_name

,
                
        cast('dummy_string' as varchar(4096)) as column_name

,
                
        cast('dummy_string' as varchar(4096)) as metric_name

,
                
        cast('dummy_string' as varchar(4096)) as metric_type

,
                
        cast(123456789.99 as float) as metric_value

,
                
        cast('dummy_string' as varchar(4096)) as source_value

,
                cast('2091-02-17' as timestamp) as bucket_start

,
                cast('2091-02-17' as timestamp) as bucket_end

,
                
        cast(123456789 as integer) as bucket_duration_hours

,
                cast('2091-02-17' as timestamp) as updated_at

,
                
        cast('dummy_string' as varchar(4096)) as dimension

,
                
        cast('dummy_string' as varchar(4096)) as dimension_value

,
                
        cast('dummy_string' as varchar(4096)) as metric_properties

,
                cast('2091-02-17' as timestamp) as created_at


        ) as empty_table
        where 1 = 0

  );
  
  
[0m22:14:50.565477 [debug] [Thread-12 ]: SQL status: SELECT 0 in 0.005 seconds
[0m22:14:50.571976 [debug] [Thread-6 (]: SQL status: SELECT 0 in 0.012 seconds
[0m22:14:50.587163 [debug] [Thread-5 (]: Using postgres connection "model.elementary.dbt_groups"
[0m22:14:50.587733 [debug] [Thread-15 ]: SQL status: SELECT 0 in 0.028 seconds
[0m22:14:50.588588 [debug] [Thread-7 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m22:14:50.590004 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m22:14:50.591433 [debug] [Thread-10 ]: Using postgres connection "model.elementary.dbt_seeds"
[0m22:14:50.593114 [debug] [Thread-16 ]: On model.elementary.metadata: COMMIT
[0m22:14:50.594853 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:50.597396 [debug] [Thread-12 ]: On model.elementary.dbt_source_freshness_results: COMMIT
[0m22:14:50.600117 [debug] [Thread-6 (]: On model.elementary.dbt_invocations: COMMIT
[0m22:14:50.600849 [debug] [Thread-13 ]: SQL status: SELECT 0 in 0.009 seconds
[0m22:14:50.601272 [debug] [Thread-11 ]: SQL status: SELECT 0 in 0.008 seconds
[0m22:14:50.601654 [debug] [Thread-8 (]: SQL status: SELECT 0 in 0.010 seconds
[0m22:14:50.602029 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.008 seconds
[0m22:14:50.602565 [debug] [Thread-5 (]: On model.elementary.dbt_groups: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_groups"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_groups"
    order by metadata_hash
    
  
[0m22:14:50.602999 [debug] [Thread-14 ]: SQL status: SELECT 0 in 0.007 seconds
[0m22:14:50.603559 [debug] [Thread-9 (]: SQL status: SELECT 0 in 0.012 seconds
[0m22:14:50.603964 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.008 seconds
[0m22:14:50.605838 [debug] [Thread-15 ]: On model.elementary.elementary_test_results: COMMIT
[0m22:14:50.606420 [debug] [Thread-7 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_metrics"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_metrics"
    order by metadata_hash
    
  
[0m22:14:50.606916 [debug] [Thread-4 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_exposures"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_exposures"
    order by metadata_hash
    
  
[0m22:14:50.607381 [debug] [Thread-10 ]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_seeds"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_seeds"
    order by metadata_hash
    
  
[0m22:14:50.607823 [debug] [Thread-16 ]: Using postgres connection "model.elementary.metadata"
[0m22:14:50.608413 [debug] [Thread-3 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_columns"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_columns"
    order by metadata_hash
    
  
[0m22:14:50.608941 [debug] [Thread-12 ]: Using postgres connection "model.elementary.dbt_source_freshness_results"
[0m22:14:50.609375 [debug] [Thread-6 (]: Using postgres connection "model.elementary.dbt_invocations"
[0m22:14:50.615457 [debug] [Thread-13 ]: Elementary: [dbt_sources] Flattening the artifacts.
[0m22:14:50.620875 [debug] [Thread-11 ]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m22:14:50.626274 [debug] [Thread-8 (]: Elementary: [dbt_models] Flattening the artifacts.
[0m22:14:50.630580 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:50.637012 [debug] [Thread-5 (]: SQL status: SELECT 0 in 0.006 seconds
[0m22:14:50.637710 [debug] [Thread-14 ]: Elementary: [dbt_tests] Flattening the artifacts.
[0m22:14:50.647829 [debug] [Thread-9 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m22:14:50.649410 [debug] [Thread-2 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m22:14:50.649888 [debug] [Thread-15 ]: Using postgres connection "model.elementary.elementary_test_results"
[0m22:14:50.650648 [debug] [Thread-16 ]: On model.elementary.metadata: COMMIT
[0m22:14:50.651219 [debug] [Thread-12 ]: On model.elementary.dbt_source_freshness_results: COMMIT
[0m22:14:50.651713 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.001 seconds
[0m22:14:50.652102 [debug] [Thread-6 (]: On model.elementary.dbt_invocations: COMMIT
[0m22:14:50.652479 [debug] [Thread-10 ]: SQL status: SELECT 0 in 0.002 seconds
[0m22:14:50.652850 [debug] [Thread-7 (]: SQL status: SELECT 0 in 0.003 seconds
[0m22:14:50.659640 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.008 seconds
[0m22:14:50.667905 [debug] [Thread-11 ]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m22:14:50.673391 [debug] [Thread-13 ]: Elementary: [dbt_sources] Flattened 1 artifacts.
[0m22:14:50.679344 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption" rename to "daily_consumption__dbt_backup"
[0m22:14:50.705428 [debug] [Thread-5 (]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m22:14:50.721354 [debug] [Thread-8 (]: Elementary: [dbt_models] Flattened 31 artifacts.
[0m22:14:50.734019 [debug] [Thread-9 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_run_results"} */

    create  index if not exists
  "daeb49c7c4c7c0efa0f5b1021c120da4"
  on "elsa"."bronze_tec_elsa"."dbt_run_results" 
  (unique_id)
  
[0m22:14:50.751221 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.data_monitoring_metrics"} */

    create  index if not exists
  "b20fde3c19e5f7052cda898e1f5ac597"
  on "elsa"."bronze_tec_elsa"."data_monitoring_metrics" 
  (full_table_name, column_name, metric_name)
  
[0m22:14:50.767863 [debug] [Thread-15 ]: On model.elementary.elementary_test_results: COMMIT
[0m22:14:50.788324 [debug] [Thread-16 ]: SQL status: COMMIT in 0.008 seconds
[0m22:14:50.790121 [debug] [Thread-4 (]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m22:14:50.806787 [debug] [Thread-12 ]: SQL status: COMMIT in 0.019 seconds
[0m22:14:50.825142 [debug] [Thread-6 (]: SQL status: COMMIT in 0.006 seconds
[0m22:14:50.832990 [debug] [Thread-10 ]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m22:14:50.846457 [debug] [Thread-14 ]: Elementary: [dbt_tests] Flattened 4 artifacts.
[0m22:14:50.847956 [debug] [Thread-7 (]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m22:14:50.849441 [debug] [Thread-3 (]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m22:14:50.850890 [debug] [Thread-11 ]: Using postgres connection "model.elementary.dbt_snapshots"
[0m22:14:50.852167 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:50.853041 [debug] [Thread-5 (]: Elementary: [dbt_groups] Artifacts did not change.
[0m22:14:50.854787 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:50.855180 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m22:14:50.862243 [debug] [Thread-9 (]: SQL status: CREATE INDEX in 0.007 seconds
[0m22:14:50.862719 [debug] [Thread-15 ]: SQL status: COMMIT in 0.007 seconds
[0m22:14:50.864159 [debug] [Thread-16 ]: Applying DROP to: "elsa"."bronze_tec_elsa"."metadata__dbt_backup"
[0m22:14:50.864897 [debug] [Thread-4 (]: Elementary: [dbt_exposures] Artifacts did not change.
[0m22:14:50.865312 [debug] [Thread-2 (]: SQL status: CREATE INDEX in 0.010 seconds
[0m22:14:50.867309 [debug] [Thread-12 ]: On model.elementary.dbt_source_freshness_results: Close
[0m22:14:50.868191 [debug] [Thread-6 (]: On model.elementary.dbt_invocations: Close
[0m22:14:50.869000 [debug] [Thread-10 ]: Elementary: [dbt_seeds] Artifacts did not change.
[0m22:14:50.870311 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:50.871045 [debug] [Thread-7 (]: Elementary: [dbt_metrics] Artifacts did not change.
[0m22:14:50.871872 [debug] [Thread-3 (]: Elementary: [dbt_columns] Artifacts changed.
[0m22:14:50.872312 [debug] [Thread-11 ]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_snapshots"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_snapshots"
    order by metadata_hash
    
  
[0m22:14:50.872746 [debug] [Thread-13 ]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_sources"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_sources"
    order by metadata_hash
    
  
[0m22:14:50.873892 [debug] [Thread-5 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m22:14:50.874355 [debug] [Thread-8 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_models"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_models"
    order by metadata_hash
    
  
[0m22:14:50.878167 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:50.879770 [debug] [Thread-9 (]: On model.elementary.dbt_run_results: COMMIT
[0m22:14:50.880550 [debug] [Thread-15 ]: On model.elementary.elementary_test_results: Close
[0m22:14:50.886092 [debug] [Thread-16 ]: Using postgres connection "model.elementary.metadata"
[0m22:14:50.887364 [debug] [Thread-4 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m22:14:50.888955 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: COMMIT
[0m22:14:50.892052 [debug] [Thread-10 ]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m22:14:50.892909 [debug] [Thread-14 ]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_tests"} */

    
    select metadata_hash 
    from "elsa"."bronze_tec_elsa"."dbt_tests"
    order by metadata_hash
    
  
[0m22:14:50.894673 [debug] [Thread-7 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m22:14:50.903386 [debug] [Thread-3 (]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m22:14:50.904036 [debug] [Thread-12 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b81eed0>]}
[0m22:14:50.904531 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b752af0>]}
[0m22:14:50.905168 [debug] [Thread-11 ]: SQL status: SELECT 0 in 0.001 seconds
[0m22:14:50.906165 [debug] [Thread-5 (]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.037179 (1 runs)
[0m22:14:50.906832 [debug] [Thread-13 ]: SQL status: SELECT 0 in 0.002 seconds
[0m22:14:50.907482 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m22:14:50.908001 [debug] [Thread-9 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m22:14:50.908466 [debug] [Thread-8 (]: SQL status: SELECT 0 in 0.001 seconds
[0m22:14:50.909056 [debug] [Thread-15 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b752990>]}
[0m22:14:50.909473 [debug] [Thread-16 ]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.metadata"} */
drop table if exists "elsa"."bronze_tec_elsa"."metadata__dbt_backup" cascade
[0m22:14:50.910300 [debug] [Thread-4 (]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.034023 (1 runs)
[0m22:14:50.910727 [debug] [Thread-2 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m22:14:50.911507 [debug] [Thread-10 ]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000415 (1 runs)
[0m22:14:50.912365 [debug] [Thread-7 (]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.050649 (1 runs)
[0m22:14:50.925189 [debug] [Thread-14 ]: SQL status: SELECT 0 in 0.013 seconds
[0m22:14:50.931755 [info ] [Thread-12 ]: 12 of 31 OK created sql incremental model bronze_tec_elsa.dbt_source_freshness_results  [[32mSELECT 0[0m in 1.22s]
[0m22:14:50.936821 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:50.937559 [info ] [Thread-6 (]: 6 of 31 OK created sql incremental model bronze_tec_elsa.dbt_invocations ....... [[32mSELECT 0[0m in 1.22s]
[0m22:14:50.941897 [debug] [Thread-11 ]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m22:14:50.943012 [debug] [Thread-5 (]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.540049 (1 runs)
[0m22:14:50.944519 [debug] [Thread-13 ]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m22:14:50.945144 [debug] [Thread-9 (]: On model.elementary.dbt_run_results: COMMIT
[0m22:14:50.946666 [debug] [Thread-8 (]: Elementary: [dbt_models] Comparing the artifacts state.
[0m22:14:50.947058 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:14:50.947707 [info ] [Thread-15 ]: 15 of 31 OK created sql incremental model bronze_tec_elsa.elementary_test_results  [[32mSELECT 0[0m in 1.24s]
[0m22:14:50.948722 [debug] [Thread-4 (]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.547894 (1 runs)
[0m22:14:50.949151 [debug] [Thread-16 ]: SQL status: DROP TABLE in 0.001 seconds
[0m22:14:50.949530 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: COMMIT
[0m22:14:50.950292 [debug] [Thread-10 ]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.547001 (1 runs)
[0m22:14:50.951415 [debug] [Thread-7 (]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.566202 (1 runs)
[0m22:14:50.953069 [debug] [Thread-14 ]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m22:14:50.953701 [debug] [Thread-12 ]: Finished running node model.elementary.dbt_source_freshness_results
[0m22:14:50.954108 [debug] [Thread-3 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_columns"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718201450923355221450928711"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m22:14:50.954704 [debug] [Thread-6 (]: Finished running node model.elementary.dbt_invocations
[0m22:14:50.955659 [debug] [Thread-11 ]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m22:14:50.956485 [debug] [Thread-5 (]: On model.elementary.dbt_groups: COMMIT
[0m22:14:50.957233 [debug] [Thread-13 ]: Elementary: [dbt_sources] Artifacts changed.
[0m22:14:50.958274 [debug] [Thread-8 (]: Elementary: [dbt_models] Artifacts changed.
[0m22:14:50.965349 [debug] [Thread-9 (]: SQL status: COMMIT in 0.008 seconds
[0m22:14:50.970365 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:50.971099 [debug] [Thread-15 ]: Finished running node model.elementary.elementary_test_results
[0m22:14:50.971892 [debug] [Thread-4 (]: On model.elementary.dbt_exposures: COMMIT
[0m22:14:50.973346 [debug] [Thread-16 ]: On model.elementary.metadata: Close
[0m22:14:50.974290 [debug] [Thread-10 ]: On model.elementary.dbt_seeds: COMMIT
[0m22:14:50.974761 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:50.975569 [debug] [Thread-7 (]: On model.elementary.dbt_metrics: COMMIT
[0m22:14:50.976401 [debug] [Thread-14 ]: Elementary: [dbt_tests] Artifacts changed.
[0m22:14:50.976917 [debug] [Thread-12 ]: Began running node model.elementary.schema_columns_snapshot
[0m22:14:50.978736 [debug] [Thread-11 ]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m22:14:50.979720 [debug] [Thread-6 (]: Began running node model.elementary.job_run_results
[0m22:14:50.980331 [debug] [Thread-5 (]: Using postgres connection "model.elementary.dbt_groups"
[0m22:14:50.980854 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.003 seconds
[0m22:14:50.981964 [debug] [Thread-13 ]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_sources"
[0m22:14:50.982828 [debug] [Thread-8 (]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m22:14:50.983756 [debug] [Thread-9 (]: On model.elementary.dbt_run_results: Close
[0m22:14:50.984276 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on table "elsa"."bronze_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m22:14:50.985253 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m22:14:50.985717 [debug] [Thread-15 ]: Began running node model.elementary.alerts_anomaly_detection
[0m22:14:50.986208 [debug] [Thread-10 ]: Using postgres connection "model.elementary.dbt_seeds"
[0m22:14:50.986731 [debug] [Thread-16 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11022cf50>]}
[0m22:14:50.987589 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: Close
[0m22:14:50.988016 [debug] [Thread-7 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m22:14:50.988875 [debug] [Thread-14 ]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m22:14:50.989465 [info ] [Thread-12 ]: 17 of 31 START sql incremental model bronze_tec_elsa.schema_columns_snapshot ... [RUN]
[0m22:14:50.990362 [debug] [Thread-11 ]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000863 (1 runs)
[0m22:14:50.990893 [info ] [Thread-6 (]: 18 of 31 START sql view model bronze_tec_elsa.job_run_results .................. [RUN]
[0m22:14:50.991365 [debug] [Thread-5 (]: On model.elementary.dbt_groups: COMMIT
[0m22:14:51.004852 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:51.032513 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:51.034681 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:51.035396 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11022cdd0>]}
[0m22:14:51.035917 [debug] [Thread-4 (]: On model.elementary.dbt_exposures: COMMIT
[0m22:14:51.036348 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:14:51.036908 [info ] [Thread-15 ]: 19 of 31 START sql view model bronze_tec_elsa.alerts_anomaly_detection ......... [RUN]
[0m22:14:51.037388 [debug] [Thread-10 ]: On model.elementary.dbt_seeds: COMMIT
[0m22:14:51.038036 [info ] [Thread-16 ]: 16 of 31 OK created sql table model bronze_tec_elsa.metadata ................... [[32mSELECT 1[0m in 1.32s]
[0m22:14:51.038564 [debug] [Thread-7 (]: On model.elementary.dbt_metrics: COMMIT
[0m22:14:51.039073 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bac7000>]}
[0m22:14:51.041351 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:51.041844 [debug] [Thread-12 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_source_freshness_results, now model.elementary.schema_columns_snapshot)
[0m22:14:51.042632 [debug] [Thread-11 ]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.357748 (1 runs)
[0m22:14:51.043034 [debug] [Thread-6 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_invocations, now model.elementary.job_run_results)
[0m22:14:51.043569 [debug] [Thread-13 ]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_sources"} */

    
  
    

  create temporary table "dbt_sources__tmp_20250718201451003421221451003779"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_sources"
        WHERE 1 = 0
    
  );
  
  
[0m22:14:51.044816 [debug] [Thread-5 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:51.046019 [debug] [Thread-3 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_columns"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718201450923355221450928711'
        
      order by ordinal_position

  
[0m22:14:51.046740 [debug] [Thread-8 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_models"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718201451033347221451033673"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m22:14:51.047574 [info ] [Thread-9 (]: 9 of 31 OK created sql incremental model bronze_tec_elsa.dbt_run_results ....... [[32mSELECT 0[0m in 1.36s]
[0m22:14:51.054659 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m22:14:51.058099 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:51.058648 [debug] [Thread-15 ]: Re-using an available connection from the pool (formerly model.elementary.elementary_test_results, now model.elementary.alerts_anomaly_detection)
[0m22:14:51.059377 [debug] [Thread-16 ]: Finished running node model.elementary.metadata
[0m22:14:51.059839 [debug] [Thread-10 ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:51.060714 [debug] [Thread-7 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:51.061363 [info ] [Thread-2 (]: 2 of 31 OK created sql incremental model bronze_tec_elsa.data_monitoring_metrics  [[32mSELECT 0[0m in 1.37s]
[0m22:14:51.061855 [debug] [Thread-14 ]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_tests"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718201451039974221451040308"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m22:14:51.062294 [debug] [Thread-12 ]: Began compiling node model.elementary.schema_columns_snapshot
[0m22:14:51.063115 [debug] [Thread-11 ]: On model.elementary.dbt_snapshots: COMMIT
[0m22:14:51.063522 [debug] [Thread-6 (]: Began compiling node model.elementary.job_run_results
[0m22:14:51.064661 [debug] [Thread-5 (]: On model.elementary.dbt_groups: Close
[0m22:14:51.065661 [debug] [Thread-9 (]: Finished running node model.elementary.dbt_run_results
[0m22:14:51.066724 [debug] [Thread-4 (]: On model.elementary.dbt_exposures: Close
[0m22:14:51.067210 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'bronze_bronze'
        
      order by ordinal_position

  
[0m22:14:51.067647 [debug] [Thread-13 ]: SQL status: SELECT 0 in 0.004 seconds
[0m22:14:51.068260 [debug] [Thread-8 (]: SQL status: SELECT 0 in 0.003 seconds
[0m22:14:51.068704 [debug] [Thread-15 ]: Began compiling node model.elementary.alerts_anomaly_detection
[0m22:14:51.069174 [debug] [Thread-16 ]: Began running node model.elementary.alerts_dbt_tests
[0m22:14:51.070135 [debug] [Thread-10 ]: On model.elementary.dbt_seeds: Close
[0m22:14:51.071218 [debug] [Thread-7 (]: On model.elementary.dbt_metrics: Close
[0m22:14:51.072312 [debug] [Thread-2 (]: Finished running node model.elementary.data_monitoring_metrics
[0m22:14:51.078296 [debug] [Thread-14 ]: SQL status: SELECT 0 in 0.005 seconds
[0m22:14:51.078820 [debug] [Thread-3 (]: SQL status: SELECT 13 in 0.014 seconds
[0m22:14:51.079295 [debug] [Thread-11 ]: Using postgres connection "model.elementary.dbt_snapshots"
[0m22:14:51.084309 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.schema_columns_snapshot"
[0m22:14:51.109128 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11015e7b0>]}
[0m22:14:51.109628 [debug] [Thread-9 (]: Began running node model.elementary.alerts_schema_changes
[0m22:14:51.112030 [debug] [Thread-6 (]: Writing injected SQL for node "model.elementary.job_run_results"
[0m22:14:51.112891 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb7c0b0>]}
[0m22:14:51.118219 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:51.123373 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:51.123862 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.011 seconds
[0m22:14:51.129670 [debug] [Thread-15 ]: Writing injected SQL for node "model.elementary.alerts_anomaly_detection"
[0m22:14:51.130264 [info ] [Thread-16 ]: 20 of 31 START sql view model bronze_tec_elsa.alerts_dbt_tests ................. [RUN]
[0m22:14:51.130924 [debug] [Thread-2 (]: Began running node model.elementary.test_result_rows
[0m22:14:51.131445 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100d7650>]}
[0m22:14:51.132080 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100d5bb0>]}
[0m22:14:51.137100 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:51.142050 [debug] [Thread-3 (]: Elementary: Inserting 83 rows to table "dbt_columns__tmp_20250718201450923355221450928711"
[0m22:14:51.142537 [debug] [Thread-11 ]: On model.elementary.dbt_snapshots: COMMIT
[0m22:14:51.143456 [info ] [Thread-5 (]: 5 of 31 OK created sql incremental model bronze_tec_elsa.dbt_groups ............ [[32mSELECT 0[0m in 1.44s]
[0m22:14:51.144077 [info ] [Thread-9 (]: 21 of 31 START sql view model bronze_tec_elsa.alerts_schema_changes ............ [RUN]
[0m22:14:51.144698 [debug] [Thread-12 ]: Began executing node model.elementary.schema_columns_snapshot
[0m22:14:51.145354 [info ] [Thread-4 (]: 4 of 31 OK created sql incremental model bronze_tec_elsa.dbt_exposures ......... [[32mSELECT 0[0m in 1.45s]
[0m22:14:51.145881 [debug] [Thread-13 ]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_sources"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_sources__tmp_20250718201451003421221451003779'
        
      order by ordinal_position

  
[0m22:14:51.146319 [debug] [Thread-8 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_models"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718201451033347221451033673'
        
      order by ordinal_position

  
[0m22:14:51.148760 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:51.149171 [debug] [Thread-6 (]: Began executing node model.elementary.job_run_results
[0m22:14:51.149827 [debug] [Thread-16 ]: Re-using an available connection from the pool (formerly model.elementary.metadata, now model.elementary.alerts_dbt_tests)
[0m22:14:51.150513 [info ] [Thread-2 (]: 22 of 31 START sql incremental model bronze_tec_elsa.test_result_rows .......... [RUN]
[0m22:14:51.151268 [info ] [Thread-10 ]: 10 of 31 OK created sql incremental model bronze_tec_elsa.dbt_seeds ............ [[32mSELECT 0[0m in 1.46s]
[0m22:14:51.151846 [debug] [Thread-15 ]: Began executing node model.elementary.alerts_anomaly_detection
[0m22:14:51.152283 [debug] [Thread-14 ]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_tests"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718201451039974221451040308'
        
      order by ordinal_position

  
[0m22:14:51.152810 [info ] [Thread-7 (]: 7 of 31 OK created sql incremental model bronze_tec_elsa.dbt_metrics ........... [[32mSELECT 0[0m in 1.46s]
[0m22:14:51.178006 [debug] [Thread-5 (]: Finished running node model.elementary.dbt_groups
[0m22:14:51.178418 [debug] [Thread-11 ]: SQL status: COMMIT in 0.014 seconds
[0m22:14:51.185251 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_run_results, now model.elementary.alerts_schema_changes)
[0m22:14:51.308349 [debug] [Thread-12 ]: Writing runtime sql for node "model.elementary.schema_columns_snapshot"
[0m22:14:51.320653 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_exposures
[0m22:14:51.344141 [debug] [Thread-13 ]: SQL status: SELECT 22 in 0.012 seconds
[0m22:14:51.378662 [debug] [Thread-8 (]: SQL status: SELECT 23 in 0.010 seconds
[0m22:14:51.397909 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m22:14:51.433592 [debug] [Thread-16 ]: Began compiling node model.elementary.alerts_dbt_tests
[0m22:14:51.459968 [debug] [Thread-6 (]: Writing runtime sql for node "model.elementary.job_run_results"
[0m22:14:51.465908 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.data_monitoring_metrics, now model.elementary.test_result_rows)
[0m22:14:51.484730 [debug] [Thread-10 ]: Finished running node model.elementary.dbt_seeds
[0m22:14:51.507914 [debug] [Thread-15 ]: Writing runtime sql for node "model.elementary.alerts_anomaly_detection"
[0m22:14:51.534801 [debug] [Thread-14 ]: SQL status: SELECT 29 in 0.012 seconds
[0m22:14:51.558943 [debug] [Thread-7 (]: Finished running node model.elementary.dbt_metrics
[0m22:14:51.581896 [debug] [Thread-5 (]: Began running node model.elementary.metrics_anomaly_score
[0m22:14:51.599349 [debug] [Thread-11 ]: On model.elementary.dbt_snapshots: Close
[0m22:14:51.618125 [debug] [Thread-9 (]: Began compiling node model.elementary.alerts_schema_changes
[0m22:14:51.641511 [debug] [Thread-4 (]: Began running node model.elementary.monitors_runs
[0m22:14:51.655837 [debug] [Thread-13 ]: Elementary: Inserting 1 rows to table "dbt_sources__tmp_20250718201451003421221451003779"
[0m22:14:51.684636 [debug] [Thread-8 (]: Elementary: Inserting 31 rows to table "dbt_models__tmp_20250718201451033347221451033673"
[0m22:14:51.697976 [debug] [Thread-1 (]: SQL status: COMMENT in 0.006 seconds
[0m22:14:51.703770 [debug] [Thread-12 ]: Using postgres connection "model.elementary.schema_columns_snapshot"
[0m22:14:51.715824 [debug] [Thread-16 ]: Writing injected SQL for node "model.elementary.alerts_dbt_tests"
[0m22:14:51.736198 [debug] [Thread-2 (]: Began compiling node model.elementary.test_result_rows
[0m22:14:51.753587 [debug] [Thread-6 (]: Using postgres connection "model.elementary.job_run_results"
[0m22:14:51.756379 [debug] [Thread-14 ]: Elementary: Inserting 4 rows to table "dbt_tests__tmp_20250718201451039974221451040308"
[0m22:14:51.756840 [debug] [Thread-10 ]: Began running node model.elementary.seed_run_results
[0m22:14:51.780216 [debug] [Thread-3 (]: Elementary: [1/1] Running insert query.
[0m22:14:51.780945 [info ] [Thread-5 (]: 23 of 31 START sql view model bronze_tec_elsa.metrics_anomaly_score ............ [RUN]
[0m22:14:51.781891 [debug] [Thread-11 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcfb650>]}
[0m22:14:51.788618 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m22:14:51.788191 [debug] [Thread-9 (]: Writing injected SQL for node "model.elementary.alerts_schema_changes"
[0m22:14:51.789698 [info ] [Thread-4 (]: 24 of 31 START sql view model bronze_tec_elsa.monitors_runs .................... [RUN]
[0m22:14:51.812953 [debug] [Thread-13 ]: Elementary: [1/1] Running insert query.
[0m22:14:51.822003 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:14:51.837804 [debug] [Thread-12 ]: On model.elementary.schema_columns_snapshot: BEGIN
[0m22:14:51.870421 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.test_result_rows"
[0m22:14:51.870979 [debug] [Thread-6 (]: On model.elementary.job_run_results: BEGIN
[0m22:14:51.889111 [debug] [Thread-16 ]: Began executing node model.elementary.alerts_dbt_tests
[0m22:14:51.920735 [info ] [Thread-10 ]: 25 of 31 START sql view model bronze_tec_elsa.seed_run_results ................. [RUN]
[0m22:14:51.949886 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:51.972684 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_groups, now model.elementary.metrics_anomaly_score)
[0m22:14:52.021642 [debug] [Thread-14 ]: Elementary: [1/1] Running insert query.
[0m22:14:52.022277 [info ] [Thread-11 ]: 11 of 31 OK created sql incremental model bronze_tec_elsa.dbt_snapshots ........ [[32mSELECT 0[0m in 2.11s]
[0m22:14:52.022711 [debug] [Thread-15 ]: On model.elementary.alerts_anomaly_detection: BEGIN
[0m22:14:52.040089 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_exposures, now model.elementary.monitors_runs)
[0m22:14:52.052294 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:52.061693 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:52.073915 [debug] [Thread-9 (]: Began executing node model.elementary.alerts_schema_changes
[0m22:14:52.080869 [debug] [Thread-12 ]: Opening a new connection, currently in state closed
[0m22:14:52.132204 [debug] [Thread-6 (]: Opening a new connection, currently in state closed
[0m22:14:52.143334 [debug] [Thread-2 (]: Began executing node model.elementary.test_result_rows
[0m22:14:52.153272 [debug] [Thread-16 ]: Writing runtime sql for node "model.elementary.alerts_dbt_tests"
[0m22:14:52.172980 [debug] [Thread-10 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_seeds, now model.elementary.seed_run_results)
[0m22:14:52.186218 [debug] [Thread-3 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_columns"} */

    
       insert into "dbt_columns__tmp_20250718201450923355221450928711"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.elementary.dbt_tests.unique_id','model.elementary.dbt_tests','unique_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_tests','The unique id of the test.','model','2025-07-18 20:14:50','d25619fda5221df4c6efc32e9844059a'),('column.model.elementary.dbt_tests.database_name','model.elementary.dbt_tests','database_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_tests','The tested model database name.','model','2025-07-18 20:14:50','aae1365cc64ffac6fcbcf0ad31bc1f71'),('column.model.elementary.dbt_tests.schema_name','model.elementary.dbt_tests','schema_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_tests','The tested model schema name.','model','2025-07-18 20:14:50','fb6e7a2e3e9f4f805b90e89d6f22a35d'),('column.model.elementary.dbt_tests.name','model.elementary.dbt_tests','name','string','[]','{}','elsa','bronze_tec_elsa','dbt_tests','The test name.','model','2025-07-18 20:14:50','208dd254c51e342ae76423cdd5640c03'),('column.model.elementary.dbt_tests.test_column_name','model.elementary.dbt_tests','test_column_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_tests','The name of the tested column.','model','2025-07-18 20:14:50','4bb3c72c4a177ebc2b02080ffc84f4a5'),('column.model.elementary.dbt_models.unique_id','model.elementary.dbt_models','unique_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','The unique id of the model.','model','2025-07-18 20:14:50','7739dcacb4551fbd6c4f07e606571899'),('column.model.elementary.dbt_models.checksum','model.elementary.dbt_models','checksum','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Model file checksum.','model','2025-07-18 20:14:50','99c2552bd5b201fe6dd7e5f23a28fc3d'),('column.model.elementary.dbt_models.materialization','model.elementary.dbt_models','materialization','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','The model materialization config.','model','2025-07-18 20:14:50','f7d097ee2384111dd5f5905b3f9c7af5'),('column.model.elementary.dbt_models.tags','model.elementary.dbt_models','tags','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Model tags property.','model','2025-07-18 20:14:50','302eccc5e55ef7140733bee5633ff0a7'),('column.model.elementary.dbt_models.meta','model.elementary.dbt_models','meta','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','The content of ''meta'' property key.','model','2025-07-18 20:14:50','4572c035cdc7488e5d1e20677dba8189'),('column.model.elementary.dbt_models.owner','model.elementary.dbt_models','owner','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Model owner property (configured under ''meta'' key).','model','2025-07-18 20:14:50','36c691f1087ab68c16247d063c5d4fc0'),('column.model.elementary.dbt_models.database_name','model.elementary.dbt_models','database_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','The model database name.','model','2025-07-18 20:14:50','8d7aa28946ed28507d46724a82142e89'),('column.model.elementary.dbt_models.schema_name','model.elementary.dbt_models','schema_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','The model schema name.','model','2025-07-18 20:14:50','afd8f0d605da372eeba94beb42dd4b8b'),('column.model.elementary.dbt_models.depends_on_macros','model.elementary.dbt_models','depends_on_macros','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','The macros the model directly depends on.','model','2025-07-18 20:14:50','af856face8c5e1ab5aa4609e4aeb7d0b'),('column.model.elementary.dbt_models.depends_on_nodes','model.elementary.dbt_models','depends_on_nodes','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','The nodes the model directly depends on.','model','2025-07-18 20:14:50','be52bcb8c1a189dfd2c41a8bb82cb66f'),('column.model.elementary.dbt_models.description','model.elementary.dbt_models','description','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Model description.','model','2025-07-18 20:14:50','07542df4eebf9570956990c128b2ec2c'),('column.model.elementary.dbt_models.name','model.elementary.dbt_models','name','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Model name.','model','2025-07-18 20:14:50','6e132e5445cc91823a1cba37250977a1'),('column.model.elementary.dbt_models.package_name','model.elementary.dbt_models','package_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Package name of the model.','model','2025-07-18 20:14:50','b0e236d2f767826e54181294b4ea2d23'),('column.model.elementary.dbt_models.original_path','model.elementary.dbt_models','original_path','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Full path of the model file.','model','2025-07-18 20:14:50','a7ad49272b0acc6c697a189276261f80'),('column.model.elementary.dbt_models.path','model.elementary.dbt_models','path','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Short path of the model file.','model','2025-07-18 20:14:50','3d69ca275496cb8c4c60e6b4e2400e27'),('column.model.elementary.dbt_models.generated_at','model.elementary.dbt_models','generated_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_models','Update time of the table.','model','2025-07-18 20:14:50','56f1239e1e1718e9208af933a52622f3'),('column.model.elementary.dbt_invocations.invocation_id','model.elementary.dbt_invocations','invocation_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Primary key of this table.','model','2025-07-18 20:14:50','8ac32ec0f48a8440649e6ca1b3a89f7a'),('column.model.elementary.dbt_invocations.run_started_at','model.elementary.dbt_invocations','run_started_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Timestamp the invocation was started.','model','2025-07-18 20:14:50','6ec97d5168d56de3d4945a3777652a68'),('column.model.elementary.dbt_invocations.run_completed_at','model.elementary.dbt_invocations','run_completed_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Timestamp the invocation was completed','model','2025-07-18 20:14:50','3e9efc6c035297b9fbc1d25e283994ba'),('column.model.elementary.dbt_invocations.generated_at','model.elementary.dbt_invocations','generated_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The time this invocation was uploaded to the database.','model','2025-07-18 20:14:50','b734590693963d5d73379f68ddcf5cc2'),('column.model.elementary.dbt_invocations.command','model.elementary.dbt_invocations','command','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','dbt command that was used. For example, run.','model','2025-07-18 20:14:50','503096ddbc7432ffefe73b14bdd951cb'),('column.model.elementary.dbt_invocations.dbt_version','model.elementary.dbt_invocations','dbt_version','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Version of dbt that was used in this invocation.','model','2025-07-18 20:14:50','4848768adaf185d26c70df696aacaf18'),('column.model.elementary.dbt_invocations.elementary_version','model.elementary.dbt_invocations','elementary_version','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Version of the elementary package that was used in this invocation.','model','2025-07-18 20:14:50','8d187e80ba5e920252951b30736b8bb7'),('column.model.elementary.dbt_invocations.full_refresh','model.elementary.dbt_invocations','full_refresh','boolean','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Whether or not this invocation was executed as a full-refresh.','model','2025-07-18 20:14:50','09043361f1ed104e648345cb58609261'),('column.model.elementary.dbt_invocations.invocation_vars','model.elementary.dbt_invocations','invocation_vars','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Dictionary of the variables (and values) that were declared in the invocation.','model','2025-07-18 20:14:50','8c25f3b15989c0b9f26c05f2a3a9b99d'),('column.model.elementary.dbt_invocations.vars','model.elementary.dbt_invocations','vars','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Dictionary of all variables (and values) in the dbt project. If none were declared at runtime, these are the variables declared in dbt_project yml','model','2025-07-18 20:14:50','f971d6944294ad11b7538b377a2f3d93'),('column.model.elementary.dbt_invocations.target_name','model.elementary.dbt_invocations','target_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Name of the target used in this invocation.','model','2025-07-18 20:14:50','a55ad8717e5816332360048602b79f21'),('column.model.elementary.dbt_invocations.target_database','model.elementary.dbt_invocations','target_database','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Name of the target database that was used in this invocation.','model','2025-07-18 20:14:50','93ff8231237f067d716ffdfd716d2955'),('column.model.elementary.dbt_invocations.target_schema','model.elementary.dbt_invocations','target_schema','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Name of the target schema that was used in this invocation.','model','2025-07-18 20:14:50','40cdb8173bb5aac9442a662ddf5f77cd'),('column.model.elementary.dbt_invocations.target_profile_name','model.elementary.dbt_invocations','target_profile_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Name of the dbt profile that was used in this invocation.','model','2025-07-18 20:14:50','9daae6d7071b3e42215d2079bcff3454'),('column.model.elementary.dbt_invocations.threads','model.elementary.dbt_invocations','threads','integer','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','Number of threads that were used to run this dbt invocation. (This number could impact the performance of a dbt invocation).','model','2025-07-18 20:14:50','633421b8b96a59de044b46255a809976'),('column.model.elementary.dbt_invocations.selected','model.elementary.dbt_invocations','selected','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The selected resources in the dbt command. While this is a string in the database, this can easily be converted to an array.','model','2025-07-18 20:14:50','de294d4642bc126bf192c9ac8507f299'),('column.model.elementary.dbt_invocations.yaml_selector','model.elementary.dbt_invocations','yaml_selector','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The yaml selector that was passed in this invocation.','model','2025-07-18 20:14:50','e77a65f1fff2383591e64cf394c2fed7'),('column.model.elementary.dbt_invocations.job_id','model.elementary.dbt_invocations','job_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The ID of a job, defined in the `job_id` var or in the `JOB_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-18 20:14:50','b907a47b51493552d96fe672cd12f14d'),('column.model.elementary.dbt_invocations.job_name','model.elementary.dbt_invocations','job_name','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The name of a job, defined in the `job_name` var or in the `JOB_NAME` env var.','model','2025-07-18 20:14:50','7e0d14a85df98158ad9cb8d7b83cdb91'),('column.model.elementary.dbt_invocations.job_run_id','model.elementary.dbt_invocations','job_run_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The run ID of a job, defined in the `job_run_id` var or in the `DBT_JOB_RUN_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-18 20:14:50','121824f0fd41e46c31dcc3d92455f242'),('column.model.elementary.dbt_invocations.env','model.elementary.dbt_invocations','env','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The environment''s name, defined in the `DBT_ENV` env var.','model','2025-07-18 20:14:50','1c1e90faa8f67df2ad3b497da4a634e0'),('column.model.elementary.dbt_invocations.env_id','model.elementary.dbt_invocations','env_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The ID of an environment, defined in the `DBT_ENV_ID` env var.','model','2025-07-18 20:14:50','760050490f59a2e53c429e0813312b0b'),('column.model.elementary.dbt_invocations.project_id','model.elementary.dbt_invocations','project_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The ID of a project, defined in the `DBT_PROJECT_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-18 20:14:50','7299cb5b9a2c655c5527db36aaae6b0a'),('column.model.elementary.dbt_invocations.cause_category','model.elementary.dbt_invocations','cause_category','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The category of the cause of the invocation. For example, if the invocation was triggered by a schedule, the cause category would be schedule.
Defined in the `DBT_CAUSE_CATEGORY` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).
','model','2025-07-18 20:14:50','cdb19eb63bdc2fee43f8a5902d35550c'),('column.model.elementary.dbt_invocations.cause','model.elementary.dbt_invocations','cause','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The cause of the invocation. For example, if the invocation was triggered by a manual run, the cause would be _"Kicked off by Joe."_.
Defined in the `DBT_CAUSE` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).
','model','2025-07-18 20:14:50','0c758903acc47a4416ecf14ab66259da'),('column.model.elementary.dbt_invocations.pull_request_id','model.elementary.dbt_invocations','pull_request_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The ID of a pull request, defined in the `DBT_PULL_REQUEST_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-18 20:14:50','aee6fe127e16827676f202ded1e7a208'),('column.model.elementary.dbt_invocations.git_sha','model.elementary.dbt_invocations','git_sha','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The git SHA of the commit that was used in this invocation, defined in the `DBT_GIT_SHA` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-18 20:14:50','eb39fc2815ac40d8092d40e5638a9e79'),('column.model.elementary.dbt_invocations.orchestrator','model.elementary.dbt_invocations','orchestrator','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The orchestrator that was used to run this invocation, defined in the `orchestrator` var or in the `ORCHESTRATOR` env var or by the orchestrator env vars. For example, dbt Cloud, GitHub Actions, etc.','model','2025-07-18 20:14:50','e9cbf11d1f422e00fb476e5aa1a75ef7'),('column.model.elementary.dbt_invocations.job_url','model.elementary.dbt_invocations','job_url','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The name of a job, defined in the `job_url` var or in the `JOB_URL` env var or by the orchestrator. For GitHub Actions orchestrator, the value is calculated.','model','2025-07-18 20:14:50','db9ed66c1bc2bcd9b8ff4ef1e2c147de'),('column.model.elementary.dbt_invocations.account_id','model.elementary.dbt_invocations','account_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_invocations','The ID of the account, defined in the `account_id` var or in the `ACCOUNT_ID` env var or by the orchestrator.','model','2025-07-18 20:14:50','4ef2848fac4804f4744d9bbf0ee0453c'),('column.model.elementary.dbt_run_results.model_execution_id','model.elementary.dbt_run_results','model_execution_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Execution id generated by joining the unique_id of the resource and the invocation_id. This is the unique key of each row in this model.','model','2025-07-18 20:14:50','4581d2ecca510f64a57b71f09e77feb3'),('column.model.elementary.dbt_run_results.unique_id','model.elementary.dbt_run_results','unique_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','The unique id of the resource (would be similar for all executions of the same resource).','model','2025-07-18 20:14:50','3ba2c6a6709bf561899e7c7494206d62'),('column.model.elementary.dbt_run_results.invocation_id','model.elementary.dbt_run_results','invocation_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','The unique id of the invocation (would be similar for all resources executed on the same invocation). FK to dbt_invocations.','model','2025-07-18 20:14:50','5e3ea3f8fd93f3619054a8eebebb9b1b'),('column.model.elementary.dbt_run_results.name','model.elementary.dbt_run_results','name','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Resource name.','model','2025-07-18 20:14:50','d54eba517c1089789f16df42fac2f9c0'),('column.model.elementary.dbt_run_results.message','model.elementary.dbt_run_results','message','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Execution results message returned by dbt.','model','2025-07-18 20:14:50','d1e14d97411f022781214ea57328a93e'),('column.model.elementary.dbt_run_results.status','model.elementary.dbt_run_results','status','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Execution result status (success, error, pass, fail)','model','2025-07-18 20:14:50','4120e38b63acd929b559e86f032a15f6'),('column.model.elementary.dbt_run_results.resource_type','model.elementary.dbt_run_results','resource_type','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Resource type (model, test, snapshot, seed, etc)','model','2025-07-18 20:14:50','d457d90491534e7af2b2b31a1b982b8e'),('column.model.elementary.dbt_run_results.execution_time','model.elementary.dbt_run_results','execution_time','float','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Resource execution duration in seconds.','model','2025-07-18 20:14:50','967b24a62083e1fa3ed223ec5ef03cfb'),('column.model.elementary.dbt_run_results.execute_started_at','model.elementary.dbt_run_results','execute_started_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Start time of the execution.','model','2025-07-18 20:14:50','b8338c335914f0c304139447a90495db'),('column.model.elementary.dbt_run_results.execute_completed_at','model.elementary.dbt_run_results','execute_completed_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','End time of the execution.','model','2025-07-18 20:14:50','f89f4906eb6d45e401b969148a1cfeb5'),('column.model.elementary.dbt_run_results.compile_started_at','model.elementary.dbt_run_results','compile_started_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Start time of resource compile action.','model','2025-07-18 20:14:50','247c874b6cc52af97ebd1ec7ac5e757f'),('column.model.elementary.dbt_run_results.compile_completed_at','model.elementary.dbt_run_results','compile_completed_at','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','End time of resource compile action.','model','2025-07-18 20:14:50','3f3db1a83714dc274e726575a2e5ea5d'),('column.model.elementary.dbt_run_results.full_refresh','model.elementary.dbt_run_results','full_refresh','boolean','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Was this a full refresh execution.','model','2025-07-18 20:14:50','3fdfbba8b7d20ed51a95ba01a819771d'),('column.model.elementary.dbt_run_results.compiled_code','model.elementary.dbt_run_results','compiled_code','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','The compiled code (SQL / Python) executed against the database.','model','2025-07-18 20:14:50','4153e166e67d936b221e1805cb424a88'),('column.model.elementary.dbt_run_results.failures','model.elementary.dbt_run_results','failures','int','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Number of failures in this run.','model','2025-07-18 20:14:50','66ff9a47e96baee5f93bf6f2e3bc0ec4'),('column.model.elementary.dbt_run_results.query_id','model.elementary.dbt_run_results','query_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Query ID in the data warehouse, if returned by the adapter (currently only supported in Snowflake, is null for any other adapter).','model','2025-07-18 20:14:50','802bc83a4bbca46d7b2b45db5dec1bd0'),('column.model.elementary.dbt_run_results.thread_id','model.elementary.dbt_run_results','thread_id','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Id of the thread of this resource run.','model','2025-07-18 20:14:50','7963f5b9013c6d81f9b747d862722651'),('column.model.elementary.dbt_run_results.adapter_response','model.elementary.dbt_run_results','adapter_response','string','[]','{}','elsa','bronze_tec_elsa','dbt_run_results','Response returned by the adapter (Fields will be different for each adapters).','model','2025-07-18 20:14:50','899f3e597283ed87597f768c0af3882e'),('column.model.dbt_elsa.daily_consumption.id','model.dbt_elsa.daily_consumption','id','integer','[]','{}','elsa','bronze_bronze','daily_consumption','ID','model','2025-07-18 20:14:50','19309b8221a3b7c2cb225c039f26002f'),('column.model.dbt_elsa.daily_consumption.created_at','model.dbt_elsa.daily_consumption','created_at','datetime','[]','{}','elsa','bronze_bronze','daily_consumption','datetime','model','2025-07-18 20:14:50','589019d67d5fef5065f2e6cb0aa3658f'),('column.model.dbt_elsa.daily_consumption.date','model.dbt_elsa.daily_consumption','date','date','[]','{}','elsa','bronze_bronze','daily_consumption','date','model','2025-07-18 20:14:50','ddb0ec5e50fbf25a992026f099a24b68'),('column.model.dbt_elsa.daily_consumption.time','model.dbt_elsa.daily_consumption','time','time','[]','{}','elsa','bronze_bronze','daily_consumption','time','model','2025-07-18 20:14:50','76030b988eff440e8b70060002b07af7'),('column.model.dbt_elsa.daily_consumption.gaz','model.dbt_elsa.daily_consumption','gaz','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for gaz energy in TWH','model','2025-07-18 20:14:50','f06577f58280a4e77e3907ef3b20d651'),('column.model.dbt_elsa.daily_consumption.nucleaire','model.dbt_elsa.daily_consumption','nucleaire','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for nuclear energy in TWH','model','2025-07-18 20:14:50','d8aad2d83629892631476fa1d923cf19'),('column.model.dbt_elsa.daily_consumption.charbon','model.dbt_elsa.daily_consumption','charbon','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for coal energy in TWH','model','2025-07-18 20:14:50','1570cf802c1386727a33c36a034be5e6'),('column.model.dbt_elsa.daily_consumption.solaire','model.dbt_elsa.daily_consumption','solaire','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for solar energy in TWH','model','2025-07-18 20:14:50','1fbc3373398a87c1eb7f19bf5a7266e3'),('column.model.dbt_elsa.daily_consumption.eolien','model.dbt_elsa.daily_consumption','eolien','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for eolian energy in TWH','model','2025-07-18 20:14:50','4121a63d20ab40b8a3d7e41aedc55303'),('column.model.dbt_elsa.daily_consumption.hydraulique','model.dbt_elsa.daily_consumption','hydraulique','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for hydrolic energy in TWH','model','2025-07-18 20:14:50','9c08034f02e761a9e6697e54c6c6683d'),('column.model.dbt_elsa.daily_consumption.bioenergies','model.dbt_elsa.daily_consumption','bioenergies','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for bioenergy energy in TWH','model','2025-07-18 20:14:50','161ebd245783f3919192a2762cf66698'),('column.model.dbt_elsa.daily_consumption.autres','model.dbt_elsa.daily_consumption','autres','float','[]','{}','elsa','bronze_bronze','daily_consumption','Production for other energy in TWH','model','2025-07-18 20:14:50','2793cf3c09a607a2cfe92b7360bd1582'),('column.model.dbt_elsa.daily_consumption.prevision_j','model.dbt_elsa.daily_consumption','prevision_j','float','[]','{}','elsa','bronze_bronze','daily_consumption','Pprevision_j','model','2025-07-18 20:14:50','710c196bcb851ff219af0d705545f9da'),('column.model.dbt_elsa.daily_consumption.prevision_j1','model.dbt_elsa.daily_consumption','prevision_j1','float','[]','{}','elsa','bronze_bronze','daily_consumption','prevision_j1','model','2025-07-18 20:14:50','03e0094d8e04313bb2fe1af7afc71d20')
  
[0m22:14:52.197829 [debug] [Thread-5 (]: Began compiling node model.elementary.metrics_anomaly_score
[0m22:14:52.216665 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:52.234144 [debug] [Thread-11 ]: Finished running node model.elementary.dbt_snapshots
[0m22:14:52.251574 [debug] [Thread-15 ]: Opening a new connection, currently in state closed
[0m22:14:52.268411 [debug] [Thread-4 (]: Began compiling node model.elementary.monitors_runs
[0m22:14:52.274469 [debug] [Thread-8 (]: Elementary: [1/1] Running insert query.
[0m22:14:52.275032 [debug] [Thread-13 ]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_sources"} */

    
       insert into "dbt_sources__tmp_20250718201451003421221451003779"
         (unique_id,database_name,schema_name,source_name,name,identifier,loaded_at_field,freshness_warn_after,freshness_error_after,freshness_filter,freshness_description,relation_name,tags,meta,owner,package_name,original_path,path,source_description,description,generated_at,metadata_hash) values
    ('source.dbt_elsa.bronze.rte_eco2mix','elsa','bronze','bronze','rte_eco2mix','rte_eco2mix','created_at','{"count": null, "period": null}','{"count": null, "period": null}',NULL,'Source freshness validates if the time elapsed between the test execution to the latest record is above an acceptable SLA threshold.','"elsa"."bronze"."rte_eco2mix"','[]','{}','[]','dbt_elsa','models/bronze/_elsa_bronze__sources.yml','models/bronze/_elsa_bronze__sources.yml','','Source JSON loadée dans le champ data','2025-07-18 20:14:50','f4b31759d8110599123fad1e18fd43ac')
  
[0m22:14:52.275606 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:14:52.280120 [debug] [Thread-9 (]: Writing runtime sql for node "model.elementary.alerts_schema_changes"
[0m22:14:52.286149 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.test_result_rows"
[0m22:14:52.286891 [debug] [Thread-10 ]: Began compiling node model.elementary.seed_run_results
[0m22:14:52.287379 [debug] [Thread-12 ]: SQL status: BEGIN in 0.207 seconds
[0m22:14:52.287747 [debug] [Thread-6 (]: SQL status: BEGIN in 0.156 seconds
[0m22:14:52.288333 [debug] [Thread-16 ]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m22:14:52.295069 [debug] [Thread-3 (]: SQL status: INSERT 0 83 in 0.007 seconds
[0m22:14:52.317364 [debug] [Thread-14 ]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_tests"} */

    
       insert into "dbt_tests__tmp_20250718201451039974221451040308"
         (unique_id,database_name,schema_name,name,short_name,alias,test_column_name,severity,warn_if,error_if,test_params,test_namespace,test_original_name,tags,model_tags,model_owners,meta,depends_on_macros,depends_on_nodes,parent_model_unique_id,description,package_name,type,original_path,path,generated_at,metadata_hash,quality_dimension,group_name) values
    ('test.dbt_elsa.not_null_daily_consumption_id.9183981eb4','elsa','bronze_bronze','not_null_daily_consumption_id','not_null','not_null_daily_consumption_id','id','ERROR','!= 0','!= 0','{"column_name": "id", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_id.sql','2025-07-18 20:14:50','62a6af057d124e81e5fd5edc21b478e4','completeness',NULL),('test.dbt_elsa.not_null_daily_consumption_created_at.d60c851a3a','elsa','bronze_bronze','not_null_daily_consumption_created_at','not_null','not_null_daily_consumption_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_created_at.sql','2025-07-18 20:14:50','3ef2c7669dbe501432b678b81b93d3ca','completeness',NULL),('test.dbt_elsa.not_null_daily_consumption_date.c78a11ccee','elsa','bronze_bronze','not_null_daily_consumption_date','not_null','not_null_daily_consumption_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_date.sql','2025-07-18 20:14:50','741e080242dfaa710f406bddddda19ec','completeness',NULL),('test.dbt_elsa.not_null_daily_consumption_time.ab08545457','elsa','bronze_bronze','not_null_daily_consumption_time','not_null','not_null_daily_consumption_time','time','ERROR','!= 0','!= 0','{"column_name": "time", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_time.sql','2025-07-18 20:14:50','b992aa3a13dcf1a233ac68ebee7bd040','completeness',NULL)
  
[0m22:14:52.317835 [debug] [Thread-5 (]: Writing injected SQL for node "model.elementary.metrics_anomaly_score"
[0m22:14:52.324040 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.monitors_runs"
[0m22:14:52.324522 [debug] [Thread-7 (]: Began running node model.elementary.snapshot_run_results
[0m22:14:52.326014 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:52.326467 [debug] [Thread-15 ]: SQL status: BEGIN in 0.075 seconds
[0m22:14:52.331252 [debug] [Thread-10 ]: Writing injected SQL for node "model.elementary.seed_run_results"
[0m22:14:52.331774 [debug] [Thread-13 ]: SQL status: INSERT 0 1 in 0.005 seconds
[0m22:14:52.332308 [debug] [Thread-12 ]: Using postgres connection "model.elementary.schema_columns_snapshot"
[0m22:14:52.332678 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:14:52.333108 [debug] [Thread-6 (]: Using postgres connection "model.elementary.job_run_results"
[0m22:14:52.333627 [debug] [Thread-2 (]: Using postgres connection "model.elementary.test_result_rows"
[0m22:14:52.334019 [debug] [Thread-9 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m22:14:52.334372 [debug] [Thread-16 ]: On model.elementary.alerts_dbt_tests: BEGIN
[0m22:14:52.342504 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:52.343514 [info ] [Thread-7 (]: 26 of 31 START sql view model bronze_tec_elsa.snapshot_run_results ............. [RUN]
[0m22:14:52.344120 [debug] [Thread-14 ]: SQL status: INSERT 0 4 in 0.001 seconds
[0m22:14:52.345468 [debug] [Thread-8 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_models"} */

    
       insert into "dbt_models__tmp_20250718201451033347221451033673"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.elementary.snapshot_run_results','snapshot_run_results','eb2ce3c6a48f39b5654308c6ee10dce649e156abefe4d95a89402f497061f908','view','[]','{}','[]','elsa','bronze_tec_elsa','[]','["model.elementary.dbt_run_results", "model.elementary.dbt_snapshots"]','Run results of dbt snapshots, enriched with snapshots metadata. Each row is the result of a single snapshot. This is a view that joins data from `dbt_run_results` and `dbt_snapshots`.
','snapshot_run_results','elementary','models/edr/run_results/snapshot_run_results.sql','edr/run_results/snapshot_run_results.sql','elementary://models/run_results.yml','2025-07-18 20:14:50','b0394d368578e3b87b4b887f5d91d352',NULL,NULL,NULL,'protected'),('model.elementary.job_run_results','job_run_results','70fa0f75184f074237575d1146a8caf3048d0d0300a5da5013b7a88f137bc810','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.timediff"]','["model.elementary.dbt_invocations"]','Run results of dbt invocations, enriched with jobs metadata. Each row is the result of a single job. This is a view on `dbt_invocations`.','job_run_results','elementary','models/edr/run_results/job_run_results.sql','edr/run_results/job_run_results.sql','elementary://models/run_results.yml','2025-07-18 20:14:50','d8a2c1a6ae1346579079794c88872b58',NULL,NULL,NULL,'protected'),('model.elementary.model_run_results','model_run_results','437b57b32630844cde2f23de66531b56757f9ee23c0ffbbb7bec945823c50636','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.edr_time_trunc"]','["model.elementary.dbt_models", "model.elementary.dbt_run_results"]','Run results of dbt models, enriched with models metadata. Each row is the result of a single model. This is a view that joins data from `dbt_run_results` and `dbt_models`.
','model_run_results','elementary','models/edr/run_results/model_run_results.sql','edr/run_results/model_run_results.sql','elementary://models/run_results.yml','2025-07-18 20:14:50','2689c6606d31e694f9c740c1bd2084e9',NULL,NULL,NULL,'protected'),('model.elementary.test_result_rows','test_result_rows','30fb69b16af56c55748fcb347c94ff46981dc4bf76b9b6aa272aa5194aa32f96','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "detected_at"}','[]','elsa','bronze_tec_elsa','["macro.elementary.empty_table", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','["model.elementary.elementary_test_results"]','','test_result_rows','elementary','models/edr/run_results/test_result_rows.sql','edr/run_results/test_result_rows.sql',NULL,'2025-07-18 20:14:50','01307066c290c38d4b25b85d4e2622bf','elementary_test_results_id',NULL,NULL,'protected'),('model.elementary.seed_run_results','seed_run_results','7f1ce3a11e8f228f1bdd1d9b73a525881b52bd93712575ab43a1c56c41d0f15c','view','[]','{}','[]','elsa','bronze_tec_elsa','[]','["model.elementary.dbt_run_results", "model.elementary.dbt_seeds"]','','seed_run_results','elementary','models/edr/run_results/seed_run_results.sql','edr/run_results/seed_run_results.sql',NULL,'2025-07-18 20:14:50','d7fbdab6d35bd2c9eadb7f03cfcdc5cc',NULL,NULL,NULL,'protected'),('model.elementary.elementary_test_results','elementary_test_results','df74ce864e711c45b8f20af4d3246257f95ef0735e17d83dce220bdd80bde93a','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "detected_at"}','[]','elsa','bronze_tec_elsa','["macro.elementary.empty_elementary_test_results", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Run results of all dbt tests, with fields and metadata needed to produce the Elementary report UI. Each row is the result of a single test, including native dbt tests, packages tests and elementary tests. New data is loaded to this model on an on-run-end hook named `elementary.handle_tests_results`.
','elementary_test_results','elementary','models/edr/run_results/elementary_test_results.sql','edr/run_results/elementary_test_results.sql','elementary://models/run_results.yml','2025-07-18 20:14:50','e73f740621c0fb02ae9c06332efc078a','id',NULL,NULL,'protected'),('model.elementary.dbt_source_freshness_results','dbt_source_freshness_results','fb063c8eb524356395464854c25d33038742ce2e0c3d4b3936ce8919a0ee27d6','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "generated_at"}','[]','elsa','bronze_tec_elsa','["macro.elementary.empty_dbt_source_freshness_results", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','','dbt_source_freshness_results','elementary','models/edr/run_results/dbt_source_freshness_results.sql','edr/run_results/dbt_source_freshness_results.sql',NULL,'2025-07-18 20:14:50','baf6b9b550ca534ad45378a804384fd0','source_freshness_execution_id',NULL,NULL,'protected'),('model.elementary.alerts_dbt_tests','alerts_dbt_tests','d15f2b4a7ade165ad09b2b9f6d143d9d47ab0f080b2de5dce1c6fae9e30375ba','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate dbt tests alerts, including all the fields the alert will include such as owner, tags, error message, etc. This view includes data about all dbt tests except elementary tests. It filters alerts according to configuration.
','alerts_dbt_tests','elementary','models/edr/alerts/alerts_dbt_tests.sql','edr/alerts/alerts_dbt_tests.sql','elementary://models/alerts_views.yml','2025-07-18 20:14:50','8ad796e4d5bd6f9a744fb39003979a63',NULL,NULL,NULL,'protected'),('model.elementary.alerts_schema_changes','alerts_schema_changes','bad7007c54d8885efe0496bd6289998cfed84a250ada4899fb8e53765236db0b','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on schema changes detected using elementary tests. The view filters alerts according to configuration.','alerts_schema_changes','elementary','models/edr/alerts/alerts_schema_changes.sql','edr/alerts/alerts_schema_changes.sql','elementary://models/alerts_views.yml','2025-07-18 20:14:50','06e16ad5c7186ba1c3d8daa21140fd2c',NULL,NULL,NULL,'protected'),('model.elementary.alerts_dbt_source_freshness','alerts_dbt_source_freshness','59b6900cf93ce1ac9e61f07c3358a21aecda80b7980e55e4387c80ea3463f012','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.get_config_var"]','["model.elementary.dbt_source_freshness_results", "model.elementary.dbt_sources"]','','alerts_dbt_source_freshness','elementary','models/edr/alerts/alerts_dbt_source_freshness.sql','edr/alerts/alerts_dbt_source_freshness.sql',NULL,'2025-07-18 20:14:50','f70bc78a6a35599a387c025d6fa65bd9',NULL,NULL,NULL,'protected'),('model.elementary.alerts_anomaly_detection','alerts_anomaly_detection','0d2bb9c33ded81e6501643abeeacde1b21695f406b861f748923e4bd9ce0c4c8','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on data anomalies detected using the elementary anomaly detection tests. The view filters alerts according to configuration.
','alerts_anomaly_detection','elementary','models/edr/alerts/alerts_anomaly_detection.sql','edr/alerts/alerts_anomaly_detection.sql','elementary://models/alerts_views.yml','2025-07-18 20:14:50','a48551845b4057af06147e3cb53f49ac',NULL,NULL,NULL,'protected'),('model.elementary.alerts_dbt_models','alerts_dbt_models','6b76b9a7b5f40ef4f9ff316fe90b4d48451442cafac243dc5abf0ac10b4c67eb','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.get_config_var"]','["model.elementary.model_run_results", "model.elementary.snapshot_run_results"]','A view that is used by the Elementary CLI to generate models alerts, including all the fields the alert will include such as owner, tags, error message, etc. It joins data about models and snapshots run results, and filters alerts according to configuration.
','alerts_dbt_models','elementary','models/edr/alerts/alerts_dbt_models.sql','edr/alerts/alerts_dbt_models.sql','elementary://models/alerts_views.yml','2025-07-18 20:14:50','6920145e3d3f2683a0caf6c45917832a',NULL,NULL,NULL,'protected'),('model.elementary.monitors_runs','monitors_runs','3720e206635d4f2f95c193835727b0d533ec1a5fa56e5dec79331418d07e934f','view','[]','{}','[]','elsa','bronze_tec_elsa','[]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that is used to determine when a specific anomaly detection test was last executed. Each anomaly detection test queries this view to decide on a start time for collecting metrics.
','monitors_runs','elementary','models/edr/system/monitors_runs.sql','edr/system/monitors_runs.sql','elementary://models/elementary_tests.yml','2025-07-18 20:14:50','bb24d1a36068f312d7532495810677e7',NULL,NULL,NULL,'protected'),('model.elementary.metadata','metadata','7d06c726499b330d51c340d2dc2774ac95f958fd6824c09711b3881b39b76a84','table','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_elementary_package_version"]','[]','','metadata','elementary','models/edr/system/metadata.sql','edr/system/metadata.sql',NULL,'2025-07-18 20:14:50','7f4bc079125d094e040038edbc8536ec',NULL,NULL,NULL,'protected'),('model.elementary.dbt_tests','dbt_tests','e3e387b5d7f7df8bdfdc358f4458dd69b8311803d989c7a0a571314bb1f1dfc2','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_tests_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_tests"]','[]','Metadata about tests in the project, including configuration and properties from the dbt graph. Each row contains information about a single test. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_tests','elementary','models/edr/dbt_artifacts/dbt_tests.sql','edr/dbt_artifacts/dbt_tests.sql','elementary://models/dbt_artifacts.yml','2025-07-18 20:14:50','fd9a20f536ec961ed62372884cfde7f6','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_models','dbt_models','3b137ff6fc5007c98c2cce8c57010d5a8386ed4f9d217b08506e9106ab9168fd','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_models"]','[]','Metadata about models in the project, including configuration and properties from the dbt graph. Each row contains information about a single model. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_models','elementary','models/edr/dbt_artifacts/dbt_models.sql','edr/dbt_artifacts/dbt_models.sql','elementary://models/dbt_artifacts.yml','2025-07-18 20:14:50','da26b63e33bd043b081cce90be1a27fa','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_sources','dbt_sources','1abd5241398ed596cf8fcf85b84a45835ae0a3e67069f00d7b519757b009cbb3','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_sources_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_sources"]','[]','Metadata about sources in the project, including configuration and properties from the dbt graph. Each row contains information about a single source. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_sources','elementary','models/edr/dbt_artifacts/dbt_sources.sql','edr/dbt_artifacts/dbt_sources.sql','elementary://models/dbt_artifacts.yml','2025-07-18 20:14:50','7dc7239b3c9b5a4673b5ba080554bfc6','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_snapshots','dbt_snapshots','84129810bfd9a5181f3d1552ba85143966cd16d64b9fc9169c1b089eab0c6ac2','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_snapshots"]','[]','Metadata about snapshots in the project, including configuration and properties from the dbt graph. Each row contains information about a single snapshot. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_snapshots','elementary','models/edr/dbt_artifacts/dbt_snapshots.sql','edr/dbt_artifacts/dbt_snapshots.sql','elementary://models/dbt_artifacts.yml','2025-07-18 20:14:50','494789acc9268badb4c57968b93a9f78','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_columns','dbt_columns','b8a1cdacc7886a9dc3c8595a28fe850e1c39090ca6da04e3431b6549b986dc99','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_columns_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_columns"]','[]','','dbt_columns','elementary','models/edr/dbt_artifacts/dbt_columns.sql','edr/dbt_artifacts/dbt_columns.sql',NULL,'2025-07-18 20:14:50','c5f436ec2ee260df07035c33da24ac43','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_invocations','dbt_invocations','6ec0cb09a0a3991db91ebd8a52625cc508faa4aac958138022aeaa3abb960755','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "generated_at"}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_invocations_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Attributes associated with each dbt invocation. Inserted at the end of each invocation.
','dbt_invocations','elementary','models/edr/dbt_artifacts/dbt_invocations.sql','edr/dbt_artifacts/dbt_invocations.sql','elementary://models/run_results.yml','2025-07-18 20:14:50','73bae85b486649d9450f4acbcbf016ae','invocation_id',NULL,NULL,'protected'),('model.elementary.dbt_metrics','dbt_metrics','86136f6682874137b3f9277098edf419c918548c440e1cd03c29f930d13d6dca','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_metrics_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_metrics"]','[]','Metadata about metrics in the project, including configuration and properties from the dbt graph. Each row contains information about a single metric. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_metrics','elementary','models/edr/dbt_artifacts/dbt_metrics.sql','edr/dbt_artifacts/dbt_metrics.sql','elementary://models/dbt_artifacts.yml','2025-07-18 20:14:50','a44563b9ac05bc325928119074dd7aec','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_seeds','dbt_seeds','e768cbfb8ca753297d627bc51d661b4d4278e48650f9479d6a64431cb291a551','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_seeds_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_seeds"]','[]','','dbt_seeds','elementary','models/edr/dbt_artifacts/dbt_seeds.sql','edr/dbt_artifacts/dbt_seeds.sql',NULL,'2025-07-18 20:14:50','9e92a45e72d4bbfac7d201181266e634','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_artifacts_hashes','dbt_artifacts_hashes','ac875e63f33b65509c9c0a5bacb9ddf19955c4c395562a5d4424fc380f76e98f','view','[]','{}','[]','elsa','bronze_tec_elsa','[]','["model.elementary.dbt_columns", "model.elementary.dbt_exposures", "model.elementary.dbt_groups", "model.elementary.dbt_metrics", "model.elementary.dbt_models", "model.elementary.dbt_seeds", "model.elementary.dbt_snapshots", "model.elementary.dbt_sources", "model.elementary.dbt_tests"]','','dbt_artifacts_hashes','elementary','models/edr/dbt_artifacts/dbt_artifacts_hashes.sql','edr/dbt_artifacts/dbt_artifacts_hashes.sql',NULL,'2025-07-18 20:14:50','dc6663bbc43629eea274c5b5b2029aa0',NULL,NULL,NULL,'protected'),('model.elementary.dbt_run_results','dbt_run_results','997ce0c97d01170814d63bc24012c41911aa1666dd62b68c298adb156584ac65','incremental','[]','{"deprecated_columns": [{"name": "compiled_sql", "data_type": "string", "description": "The compiled SQL executed against the database."}], "dedup_by_column": "model_execution_id", "timestamp_column": "created_at", "prev_timestamp_column": "generated_at"}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_run_results_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Run results of dbt invocations, inserted at the end of each invocation. Each row is the invocation result of a single resource (model, test, snapshot, etc). New data is loaded to this model on an on-run-end hook named ''elementary.upload_run_results'' from each invocation that produces a result object. This is an incremental model.
','dbt_run_results','elementary','models/edr/dbt_artifacts/dbt_run_results.sql','edr/dbt_artifacts/dbt_run_results.sql','elementary://models/run_results.yml','2025-07-18 20:14:50','ef60f4d5e2bea77b979e90c21d213f40','model_execution_id',NULL,NULL,'protected'),('model.elementary.dbt_groups','dbt_groups','b2cbce8ffc59730649cc06cac4b70b4fb6fe36adf58ae162031c451b75ca908f','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_groups_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_groups"]','[]','','dbt_groups','elementary','models/edr/dbt_artifacts/dbt_groups.sql','edr/dbt_artifacts/dbt_groups.sql',NULL,'2025-07-18 20:14:50','b53313956c972af67044f20d9f36f443','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_exposures','dbt_exposures','11693171043651333132be14894b4b7acad2ce7f09dea0ae0f722cf7d2417bb0','incremental','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_exposures_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_exposures"]','[]','Metadata about exposures in the project, including configuration and properties from the dbt graph. Each row contains information about a single exposure. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_exposures','elementary','models/edr/dbt_artifacts/dbt_exposures.sql','edr/dbt_artifacts/dbt_exposures.sql','elementary://models/dbt_artifacts.yml','2025-07-18 20:14:50','8ef1e577fc7276e742e78848728ccf28','unique_id',NULL,NULL,'protected'),('model.elementary.metrics_anomaly_score','metrics_anomaly_score','081d8b024e9c3ee037a2b149ddf564350743575027240ed019deee27ae94b004','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.dbt_utils.group_by", "macro.elementary.edr_current_timestamp", "macro.elementary.edr_date_trunc", "macro.elementary.edr_timeadd", "macro.elementary.get_config_var", "macro.elementary.standard_deviation"]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that runs the same query the anomaly detection tests run to calculate anomaly scores. The purpose of this view is to provide visibility to the results of anomaly detection tests.
','metrics_anomaly_score','elementary','models/edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','elementary://models/elementary_tests.yml','2025-07-18 20:14:50','2432a2560e447069b2764ba926f98efa',NULL,NULL,NULL,'protected'),('model.elementary.anomaly_threshold_sensitivity','anomaly_threshold_sensitivity','b0e4310abc62902b98a6ad6fd465713d5aeb5e884b52594e8a1b2ff6429b1b2d','view','[]','{}','[]','elsa','bronze_tec_elsa','["macro.elementary.edr_quote_column"]','["model.elementary.metrics_anomaly_score"]','This is a view on `metrics_anomaly_score` that calculates if values of metrics from latest runs would have been considered anomalies in different anomaly scores. This can help you decide if there is a need to adjust the `anomaly_score_threshold`.
','anomaly_threshold_sensitivity','elementary','models/edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','elementary://models/elementary_tests.yml','2025-07-18 20:14:50','b489be50f1bf820a54933459efb6d491',NULL,NULL,NULL,'protected'),('model.elementary.schema_columns_snapshot','schema_columns_snapshot','91a98d3190bef02e47f763520b5443197e120ceb132a86b1d90608ca30c33374','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "detected_at"}','[]','elsa','bronze_tec_elsa','["macro.elementary.empty_schema_columns_snapshot", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Stores the schema details for tables that are monitored with elementary schema changes test. In order to compare current schema to previous state, we must store the previous state. The data is from a view that queries the data warehouse information schema. This is an incremental table.','schema_columns_snapshot','elementary','models/edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','elementary://models/elementary_tests.yml','2025-07-18 20:14:50','6b7c4a6cc6bf96e0ca4912994fdac24f','column_state_id',NULL,NULL,'protected'),('model.elementary.data_monitoring_metrics','data_monitoring_metrics','39b2ef4821634e188a273316d5ad0ae780c42b5429b7313dcd385d4db64d613b','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "updated_at"}','[]','elsa','bronze_tec_elsa','["macro.elementary.empty_data_monitoring_metrics", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Elementary anomaly detection tests monitor metrics such as volume, freshness and data quality metrics. This incremental table is used to store the metrics over time. On each anomaly detection test, the test queries this table for historical metrics, and compares to the latest values. The table is updated with new metrics on the on-run-end named handle_test_results that is executed at the end of dbt test invocations.
','data_monitoring_metrics','elementary','models/edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','elementary://models/elementary_tests.yml','2025-07-18 20:14:50','3b6ff9fb2cf3bc77f9d326116a80cfa7','id',NULL,NULL,'protected'),('model.dbt_elsa.daily_consumption','daily_consumption','fa1c4ca81ba141cb831969824ce43dcc19b625a3d7e5a49ba6f95e16f6e8fd41','table','[]','{}','[]','elsa','bronze_bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','The aim of this table is to track daily energy production
','daily_consumption','dbt_elsa','models/bronze/daily_consumption.sql','bronze/daily_consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-18 20:14:50','30f900f85d7e2651e6d2ce2083057529',NULL,NULL,NULL,'protected')
  
[0m22:14:52.346929 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m22:14:52.347299 [debug] [Thread-4 (]: Began executing node model.elementary.monitors_runs
[0m22:14:52.347786 [debug] [Thread-5 (]: Began executing node model.elementary.metrics_anomaly_score
[0m22:14:52.351967 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:52.352576 [debug] [Thread-12 ]: On model.elementary.schema_columns_snapshot: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.schema_columns_snapshot"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."schema_columns_snapshot"
  
  
    as
  
  (
    


    select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as column_state_id

,
                
        cast('dummy_string' as varchar(4096)) as full_column_name

,
                
        cast('dummy_string' as varchar(4096)) as full_table_name

,
                
        cast('dummy_string' as varchar(4096)) as column_name

,
                
        cast('dummy_string' as varchar(4096)) as data_type

,
                
        cast (True as boolean) as is_new

,
                cast('2091-02-17' as timestamp) as detected_at

,
                cast('2091-02-17' as timestamp) as created_at


        ) as empty_table
        where 1 = 0

  );
  
  
[0m22:14:52.356397 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze_bronze"."daily_consumption__dbt_backup"
[0m22:14:52.356877 [debug] [Thread-10 ]: Began executing node model.elementary.seed_run_results
[0m22:14:52.357308 [debug] [Thread-6 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.job_run_results"} */

  create view "elsa"."bronze_tec_elsa"."job_run_results__dbt_tmp"
    
    
  as (
    





with jobs as (
  select
    job_name,
    job_id,
    job_run_id,
    
min(cast(run_started_at as timestamp))
 as job_run_started_at,
    
max(cast(run_completed_at as timestamp))
 as job_run_completed_at,
    
    
        (
        (
        (
        ((
max(cast(run_completed_at as timestamp))
)::date - (
min(cast(run_started_at as timestamp))
)::date)
     * 24 + date_part('hour', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part('hour', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + date_part('minute', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part('minute', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + floor(date_part('second', (
max(cast(run_completed_at as timestamp))
)::timestamp)) - floor(date_part('second', (
min(cast(run_started_at as timestamp))
)::timestamp)))
    
 as job_run_execution_time
  from "elsa"."bronze_tec_elsa"."dbt_invocations"
  where job_id is not null
  group by job_name, job_id, job_run_id
)

select
  job_name as name,
  job_id as id,
  job_run_id as run_id,
  job_run_started_at as run_started_at,
  job_run_completed_at as run_completed_at,
  job_run_execution_time as run_execution_time
from jobs
  );
[0m22:14:52.357758 [debug] [Thread-2 (]: On model.elementary.test_result_rows: BEGIN
[0m22:14:52.358136 [debug] [Thread-9 (]: On model.elementary.alerts_schema_changes: BEGIN
[0m22:14:52.358625 [debug] [Thread-16 ]: Opening a new connection, currently in state closed
[0m22:14:52.359248 [debug] [Thread-3 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_columns"} */

    
        begin transaction;
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250718201450923355221450928711";
        
        commit;
    
  
[0m22:14:52.360088 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_metrics, now model.elementary.snapshot_run_results)
[0m22:14:52.363715 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:52.364418 [debug] [Thread-15 ]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_anomaly_detection"} */

  create view "elsa"."bronze_tec_elsa"."alerts_anomaly_detection__dbt_tmp"
    
    
  as (
    

with elementary_test_results as (
    select * from "elsa"."bronze_tec_elsa"."elementary_test_results"
),

alerts_anomaly_detection as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'anomaly_detection'
)

select * from alerts_anomaly_detection
  );
[0m22:14:52.369128 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.monitors_runs"
[0m22:14:52.369621 [debug] [Thread-8 (]: SQL status: INSERT 0 31 in 0.005 seconds
[0m22:14:52.373900 [debug] [Thread-5 (]: Writing runtime sql for node "model.elementary.metrics_anomaly_score"
[0m22:14:52.374469 [debug] [Thread-13 ]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_sources"} */

    
        begin transaction;
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_sources" select * from "dbt_sources__tmp_20250718201451003421221451003779";
        
        commit;
    
  
[0m22:14:52.375301 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:14:52.380119 [debug] [Thread-10 ]: Writing runtime sql for node "model.elementary.seed_run_results"
[0m22:14:52.380793 [debug] [Thread-12 ]: SQL status: SELECT 0 in 0.006 seconds
[0m22:14:52.381255 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:14:52.381684 [debug] [Thread-9 (]: Opening a new connection, currently in state closed
[0m22:14:52.382519 [debug] [Thread-7 (]: Began compiling node model.elementary.snapshot_run_results
[0m22:14:52.383250 [debug] [Thread-14 ]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_tests"} */

    
        begin transaction;
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_tests" select * from "dbt_tests__tmp_20250718201451039974221451040308";
        
        commit;
    
  
[0m22:14:52.387979 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:52.388656 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m22:14:52.389638 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m22:14:52.390152 [debug] [Thread-16 ]: SQL status: BEGIN in 0.032 seconds
[0m22:14:52.390581 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
drop table if exists "elsa"."bronze_bronze"."daily_consumption__dbt_backup" cascade
[0m22:14:52.391322 [debug] [Thread-13 ]: SQL status: COMMIT in 0.002 seconds
[0m22:14:52.391883 [debug] [Thread-15 ]: SQL status: CREATE VIEW in 0.008 seconds
[0m22:14:52.392367 [debug] [Thread-6 (]: SQL status: CREATE VIEW in 0.012 seconds
[0m22:14:52.392904 [debug] [Thread-5 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m22:14:52.394816 [debug] [Thread-12 ]: On model.elementary.schema_columns_snapshot: COMMIT
[0m22:14:52.395222 [debug] [Thread-10 ]: Using postgres connection "model.elementary.seed_run_results"
[0m22:14:52.402921 [debug] [Thread-7 (]: Writing injected SQL for node "model.elementary.snapshot_run_results"
[0m22:14:52.404005 [debug] [Thread-8 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_models"} */

    
        begin transaction;
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718201451033347221451033673";
        
        commit;
    
  
[0m22:14:52.404816 [debug] [Thread-9 (]: SQL status: BEGIN in 0.023 seconds
[0m22:14:52.410386 [debug] [Thread-3 (]: Applying DROP to: "dbt_columns__tmp_20250718201450923355221450928711"
[0m22:14:52.410873 [debug] [Thread-2 (]: SQL status: BEGIN in 0.030 seconds
[0m22:14:52.411381 [debug] [Thread-14 ]: SQL status: COMMIT in 0.008 seconds
[0m22:14:52.411853 [debug] [Thread-4 (]: On model.elementary.monitors_runs: BEGIN
[0m22:14:52.412246 [debug] [Thread-16 ]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m22:14:52.417146 [debug] [Thread-13 ]: Applying DROP to: "dbt_sources__tmp_20250718201451003421221451003779"
[0m22:14:52.417649 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:14:52.421618 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m22:14:52.425402 [debug] [Thread-6 (]: Using postgres connection "model.elementary.job_run_results"
[0m22:14:52.425874 [debug] [Thread-5 (]: On model.elementary.metrics_anomaly_score: BEGIN
[0m22:14:52.426315 [debug] [Thread-12 ]: Using postgres connection "model.elementary.schema_columns_snapshot"
[0m22:14:52.426723 [debug] [Thread-10 ]: On model.elementary.seed_run_results: BEGIN
[0m22:14:52.427474 [debug] [Thread-9 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m22:14:52.428387 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:52.429811 [debug] [Thread-7 (]: Began executing node model.elementary.snapshot_run_results
[0m22:14:52.430552 [debug] [Thread-8 (]: SQL status: COMMIT in 0.003 seconds
[0m22:14:52.431074 [debug] [Thread-2 (]: Using postgres connection "model.elementary.test_result_rows"
[0m22:14:52.435425 [debug] [Thread-14 ]: Applying DROP to: "dbt_tests__tmp_20250718201451039974221451040308"
[0m22:14:52.435912 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:14:52.436459 [debug] [Thread-16 ]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_tests"} */

  create view "elsa"."bronze_tec_elsa"."alerts_dbt_tests__dbt_tmp"
    
    
  as (
    

with elementary_test_results as (
    select * from "elsa"."bronze_tec_elsa"."elementary_test_results"
),

alerts_dbt_tests as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'   and lower(status) != 'skipped'  and test_type = 'dbt_test'
)

select * from alerts_dbt_tests
  );
[0m22:14:52.437416 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:52.440042 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m22:14:52.440603 [debug] [Thread-15 ]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_anomaly_detection"} */
alter table "elsa"."bronze_tec_elsa"."alerts_anomaly_detection__dbt_tmp" rename to "alerts_anomaly_detection"
[0m22:14:52.441096 [debug] [Thread-6 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.job_run_results"} */
alter table "elsa"."bronze_tec_elsa"."job_run_results__dbt_tmp" rename to "job_run_results"
[0m22:14:52.441505 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m22:14:52.441921 [debug] [Thread-12 ]: On model.elementary.schema_columns_snapshot: COMMIT
[0m22:14:52.442324 [debug] [Thread-10 ]: Opening a new connection, currently in state closed
[0m22:14:52.442762 [debug] [Thread-9 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_schema_changes"} */

  create view "elsa"."bronze_tec_elsa"."alerts_schema_changes__dbt_tmp"
    
    
  as (
    


with elementary_test_results as (
    select * from "elsa"."bronze_tec_elsa"."elementary_test_results"
),

alerts_schema_changes as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'schema_change'
)

select * from alerts_schema_changes
  );
[0m22:14:52.443247 [debug] [Thread-3 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_columns"} */
drop table if exists "dbt_columns__tmp_20250718201450923355221450928711" cascade
[0m22:14:52.453790 [debug] [Thread-8 (]: Applying DROP to: "dbt_models__tmp_20250718201451033347221451033673"
[0m22:14:52.456225 [debug] [Thread-7 (]: Writing runtime sql for node "model.elementary.snapshot_run_results"
[0m22:14:52.456692 [debug] [Thread-2 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.test_result_rows"} */

      
  
    

  create  table "elsa"."bronze_tec_elsa"."test_result_rows"
  
  
    as
  
  (
    -- indexes are not supported in all warehouses, relevant to postgres only


-- depends_on: "elsa"."bronze_tec_elsa"."elementary_test_results"
select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as elementary_test_results_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as result_row

,
                cast('2091-02-17' as timestamp) as detected_at

,
                cast('2091-02-17' as timestamp) as created_at


        ) as empty_table
        where 1 = 0
  );
  
  
[0m22:14:52.457386 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:52.459075 [debug] [Thread-13 ]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_sources"} */
drop table if exists "dbt_sources__tmp_20250718201451003421221451003779" cascade
[0m22:14:52.461005 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7a9250>]}
[0m22:14:52.462871 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:52.465430 [debug] [Thread-15 ]: SQL status: ALTER TABLE in 0.004 seconds
[0m22:14:52.466007 [debug] [Thread-6 (]: SQL status: ALTER TABLE in 0.004 seconds
[0m22:14:52.466717 [debug] [Thread-12 ]: SQL status: COMMIT in 0.005 seconds
[0m22:14:52.467302 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:14:52.468662 [debug] [Thread-4 (]: SQL status: BEGIN in 0.033 seconds
[0m22:14:52.469431 [debug] [Thread-16 ]: SQL status: CREATE VIEW in 0.010 seconds
[0m22:14:52.469909 [debug] [Thread-14 ]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_tests"} */
drop table if exists "dbt_tests__tmp_20250718201451039974221451040308" cascade
[0m22:14:52.471221 [debug] [Thread-9 (]: SQL status: CREATE VIEW in 0.009 seconds
[0m22:14:52.471670 [debug] [Thread-10 ]: SQL status: BEGIN in 0.029 seconds
[0m22:14:52.472150 [debug] [Thread-5 (]: SQL status: BEGIN in 0.031 seconds
[0m22:14:52.472926 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.004 seconds
[0m22:14:52.473465 [debug] [Thread-7 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m22:14:52.474032 [debug] [Thread-8 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_models"} */
drop table if exists "dbt_models__tmp_20250718201451033347221451033673" cascade
[0m22:14:52.475999 [info ] [Thread-1 (]: 1 of 31 OK created sql table model bronze_bronze.daily_consumption ............. [[32mSELECT 96[0m in 2.79s]
[0m22:14:52.476789 [debug] [Thread-13 ]: SQL status: DROP TABLE in 0.005 seconds
[0m22:14:52.479785 [debug] [Thread-15 ]: On model.elementary.alerts_anomaly_detection: COMMIT
[0m22:14:52.481410 [debug] [Thread-6 (]: On model.elementary.job_run_results: COMMIT
[0m22:14:52.482857 [debug] [Thread-12 ]: On model.elementary.schema_columns_snapshot: Close
[0m22:14:52.484809 [debug] [Thread-3 (]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m22:14:52.485475 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m22:14:52.490134 [debug] [Thread-16 ]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m22:14:52.494776 [debug] [Thread-9 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m22:14:52.495290 [debug] [Thread-14 ]: SQL status: DROP TABLE in 0.005 seconds
[0m22:14:52.496577 [debug] [Thread-10 ]: Using postgres connection "model.elementary.seed_run_results"
[0m22:14:52.496992 [debug] [Thread-5 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m22:14:52.498782 [debug] [Thread-2 (]: Using postgres connection "model.elementary.test_result_rows"
[0m22:14:52.499252 [debug] [Thread-7 (]: On model.elementary.snapshot_run_results: BEGIN
[0m22:14:52.500019 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m22:14:52.501333 [debug] [Thread-13 ]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_sources"
[0m22:14:52.501833 [debug] [Thread-8 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:52.503237 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m22:14:52.503706 [debug] [Thread-6 (]: Using postgres connection "model.elementary.job_run_results"
[0m22:14:52.505196 [debug] [Thread-3 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m22:14:52.505770 [debug] [Thread-12 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b5070>]}
[0m22:14:52.506247 [debug] [Thread-4 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.monitors_runs"} */

  create view "elsa"."bronze_tec_elsa"."monitors_runs__dbt_tmp"
    
    
  as (
    

with data_monitoring_metrics as (

    select * from "elsa"."bronze_tec_elsa"."data_monitoring_metrics"

),

max_bucket_end as (

    select full_table_name,
           column_name,
           metric_name,
           metric_properties,
           max(bucket_end) as last_bucket_end,
           min(bucket_end) as first_bucket_end
    from data_monitoring_metrics
    group by 1,2,3,4

)

select * from max_bucket_end
  );
[0m22:14:52.506723 [debug] [Thread-16 ]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_tests"} */
alter table "elsa"."bronze_tec_elsa"."alerts_dbt_tests__dbt_tmp" rename to "alerts_dbt_tests"
[0m22:14:52.507160 [debug] [Thread-9 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_schema_changes"} */
alter table "elsa"."bronze_tec_elsa"."alerts_schema_changes__dbt_tmp" rename to "alerts_schema_changes"
[0m22:14:52.508512 [debug] [Thread-14 ]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m22:14:52.509062 [debug] [Thread-10 ]: On model.elementary.seed_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.seed_run_results"} */

  create view "elsa"."bronze_tec_elsa"."seed_run_results__dbt_tmp"
    
    
  as (
    

with dbt_run_results as (
    select * from "elsa"."bronze_tec_elsa"."dbt_run_results"
),

dbt_seeds as (
    select * from "elsa"."bronze_tec_elsa"."dbt_seeds"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    seeds.database_name,
    seeds.schema_name,
    run_results.materialization,
    seeds.tags,
    seeds.package_name,
    seeds.path,
    seeds.original_path,
    seeds.owner,
    seeds.alias
FROM dbt_run_results run_results
JOIN dbt_seeds seeds ON run_results.unique_id = seeds.unique_id
  );
[0m22:14:52.509666 [debug] [Thread-5 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.metrics_anomaly_score"} */

  create view "elsa"."bronze_tec_elsa"."metrics_anomaly_score__dbt_tmp"
    
    
  as (
    

with data_monitoring_metrics as (

    select * from "elsa"."bronze_tec_elsa"."data_monitoring_metrics"

),

time_window_aggregation as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        metric_value,
        source_value,
        bucket_start,
        bucket_end,
        bucket_duration_hours,
        updated_at,
        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,
        stddev(cast(metric_value as float)) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,
        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,
        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,
        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start
    from data_monitoring_metrics
    group by 1,2,3,4,5,6,7,8,9,10,11,12
),

metrics_anomaly_score as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        case
            when training_stddev is null then null
            when training_stddev = 0 then 0
            else (metric_value - training_avg) / (training_stddev)
        end as anomaly_score,
        metric_value as latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        max(updated_at) as updated_at
    from time_window_aggregation
        where
            metric_value is not null
            and training_avg is not null
            and bucket_end >= 
    cast(date_trunc('day', 
    current_timestamp::timestamp
) as timestamp) + cast(-7 as integer) * INTERVAL '1 day'

    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    order by bucket_end desc


),

final as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        anomaly_score,
        latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        updated_at,
        case
            when abs(anomaly_score) > 3 then true
            else false end
        as is_anomaly
    from metrics_anomaly_score
)

select * from final
  );
[0m22:14:52.510207 [debug] [Thread-2 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.test_result_rows"} */

    create  index if not exists
  "c03c545b27c5819dca7f48b56afd1641"
  on "elsa"."bronze_tec_elsa"."test_result_rows" 
  (created_at)
  
[0m22:14:52.510600 [debug] [Thread-7 (]: Opening a new connection, currently in state closed
[0m22:14:52.512201 [debug] [Thread-13 ]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m22:14:52.513455 [debug] [Thread-8 (]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m22:14:52.513903 [debug] [Thread-15 ]: On model.elementary.alerts_anomaly_detection: COMMIT
[0m22:14:52.514292 [debug] [Thread-6 (]: On model.elementary.job_run_results: COMMIT
[0m22:14:52.515091 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.207090 (1 runs)
[0m22:14:52.515752 [info ] [Thread-12 ]: 17 of 31 OK created sql incremental model bronze_tec_elsa.schema_columns_snapshot  [[32mSELECT 0[0m in 1.46s]
[0m22:14:52.517866 [debug] [Thread-14 ]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m22:14:52.518348 [debug] [Thread-16 ]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:14:52.518787 [debug] [Thread-9 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:14:52.520311 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019508 (1 runs)
[0m22:14:52.522731 [debug] [Thread-8 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m22:14:52.523494 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m22:14:52.524035 [debug] [Thread-2 (]: SQL status: CREATE INDEX in 0.005 seconds
[0m22:14:52.525329 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.123692 (1 runs)
[0m22:14:52.525852 [debug] [Thread-6 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.526652 [debug] [Thread-15 ]: SQL status: COMMIT in 0.002 seconds
[0m22:14:52.527398 [debug] [Thread-12 ]: Finished running node model.elementary.schema_columns_snapshot
[0m22:14:52.527814 [debug] [Thread-10 ]: SQL status: CREATE VIEW in 0.009 seconds
[0m22:14:52.528688 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.123712 (1 runs)
[0m22:14:52.529110 [debug] [Thread-7 (]: SQL status: BEGIN in 0.018 seconds
[0m22:14:52.530487 [debug] [Thread-16 ]: On model.elementary.alerts_dbt_tests: COMMIT
[0m22:14:52.531738 [debug] [Thread-9 (]: On model.elementary.alerts_schema_changes: COMMIT
[0m22:14:52.532104 [debug] [Thread-5 (]: SQL status: CREATE VIEW in 0.013 seconds
[0m22:14:52.532912 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_columns_in_relation: 0:00:00.540188 (1 runs)
[0m22:14:52.533744 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.046832 (1 runs)
[0m22:14:52.537853 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m22:14:52.539600 [debug] [Thread-2 (]: Using postgres connection "model.elementary.test_result_rows"
[0m22:14:52.540422 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000610 (1 runs)
[0m22:14:52.543711 [debug] [Thread-6 (]: Applying DROP to: "elsa"."bronze_tec_elsa"."job_run_results__dbt_backup"
[0m22:14:52.546659 [debug] [Thread-15 ]: Applying DROP to: "elsa"."bronze_tec_elsa"."alerts_anomaly_detection__dbt_backup"
[0m22:14:52.550523 [debug] [Thread-10 ]: Using postgres connection "model.elementary.seed_run_results"
[0m22:14:52.551388 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.621677 (1 runs)
[0m22:14:52.551793 [debug] [Thread-7 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m22:14:52.552184 [debug] [Thread-16 ]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m22:14:52.552566 [debug] [Thread-9 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m22:14:52.556165 [debug] [Thread-5 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m22:14:52.556995 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001101 (1 runs)
[0m22:14:52.557760 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.563804 (1 runs)
[0m22:14:52.558164 [debug] [Thread-4 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.monitors_runs"} */
alter table "elsa"."bronze_tec_elsa"."monitors_runs__dbt_tmp" rename to "monitors_runs"
[0m22:14:52.558632 [debug] [Thread-2 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.test_result_rows"} */

    create  index if not exists
  "81efed8633d6a5d517ca5e58a00eebd5"
  on "elsa"."bronze_tec_elsa"."test_result_rows" 
  (elementary_test_results_id)
  
[0m22:14:52.559411 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.564636 (83 runs)
[0m22:14:52.562415 [debug] [Thread-6 (]: Using postgres connection "model.elementary.job_run_results"
[0m22:14:52.563056 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m22:14:52.563462 [debug] [Thread-10 ]: On model.elementary.seed_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.seed_run_results"} */
alter table "elsa"."bronze_tec_elsa"."seed_run_results__dbt_tmp" rename to "seed_run_results"
[0m22:14:52.564238 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000528 (1 runs)
[0m22:14:52.564693 [debug] [Thread-7 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.snapshot_run_results"} */

  create view "elsa"."bronze_tec_elsa"."snapshot_run_results__dbt_tmp"
    
    
  as (
    

with dbt_run_results as (
    select * from "elsa"."bronze_tec_elsa"."dbt_run_results"
),

dbt_snapshots as (
    select * from "elsa"."bronze_tec_elsa"."dbt_snapshots"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    snapshots.database_name,
    snapshots.schema_name,
    coalesce(run_results.materialization, snapshots.materialization) as materialization,
    snapshots.tags,
    snapshots.package_name,
    snapshots.path,
    snapshots.original_path,
    snapshots.owner,
    snapshots.alias
FROM dbt_run_results run_results
JOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id
  );
[0m22:14:52.565136 [debug] [Thread-16 ]: On model.elementary.alerts_dbt_tests: COMMIT
[0m22:14:52.565515 [debug] [Thread-9 (]: On model.elementary.alerts_schema_changes: COMMIT
[0m22:14:52.565911 [debug] [Thread-5 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.metrics_anomaly_score"} */
alter table "elsa"."bronze_tec_elsa"."metrics_anomaly_score__dbt_tmp" rename to "metrics_anomaly_score"
[0m22:14:52.566694 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.018877 (1 runs)
[0m22:14:52.567451 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000505 (1 runs)
[0m22:14:52.568439 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.608143 (1 runs)
[0m22:14:52.568895 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:52.569286 [debug] [Thread-6 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.job_run_results"} */
drop view if exists "elsa"."bronze_tec_elsa"."job_run_results__dbt_backup" cascade
[0m22:14:52.569655 [debug] [Thread-2 (]: SQL status: CREATE INDEX in 0.002 seconds
[0m22:14:52.570044 [debug] [Thread-15 ]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_anomaly_detection"} */
drop view if exists "elsa"."bronze_tec_elsa"."alerts_anomaly_detection__dbt_backup" cascade
[0m22:14:52.570914 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.128466 (4 runs)
[0m22:14:52.571344 [debug] [Thread-10 ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:52.572503 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries: 0:00:00.021836 (1 runs)
[0m22:14:52.572954 [debug] [Thread-16 ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.574141 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.444488 (31 runs)
[0m22:14:52.574574 [debug] [Thread-5 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m22:14:52.575021 [debug] [Thread-9 (]: SQL status: COMMIT in 0.003 seconds
[0m22:14:52.575843 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.386747 (1 runs)
[0m22:14:52.576304 [debug] [Thread-7 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m22:14:52.577652 [debug] [Thread-4 (]: On model.elementary.monitors_runs: COMMIT
[0m22:14:52.579281 [debug] [Thread-2 (]: On model.elementary.test_result_rows: COMMIT
[0m22:14:52.579739 [debug] [Thread-6 (]: SQL status: DROP VIEW in 0.002 seconds
[0m22:14:52.580595 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.137952 (1 runs)
[0m22:14:52.581893 [debug] [Thread-10 ]: On model.elementary.seed_run_results: COMMIT
[0m22:14:52.582281 [debug] [Thread-15 ]: SQL status: DROP VIEW in 0.002 seconds
[0m22:14:52.583070 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.run_insert_rows_query: 0:00:00.297967 (1 runs)
[0m22:14:52.586296 [debug] [Thread-16 ]: Applying DROP to: "elsa"."bronze_tec_elsa"."alerts_dbt_tests__dbt_backup"
[0m22:14:52.587075 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.470895 (1 runs)
[0m22:14:52.588359 [debug] [Thread-5 (]: On model.elementary.metrics_anomaly_score: COMMIT
[0m22:14:52.595155 [debug] [Thread-9 (]: Applying DROP to: "elsa"."bronze_tec_elsa"."alerts_schema_changes__dbt_backup"
[0m22:14:52.596125 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:01.319415 (1 runs)
[0m22:14:52.599976 [debug] [Thread-7 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m22:14:52.600450 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m22:14:52.600855 [debug] [Thread-2 (]: Using postgres connection "model.elementary.test_result_rows"
[0m22:14:52.602253 [debug] [Thread-6 (]: On model.elementary.job_run_results: Close
[0m22:14:52.603054 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.145949 (1 runs)
[0m22:14:52.603471 [debug] [Thread-10 ]: Using postgres connection "model.elementary.seed_run_results"
[0m22:14:52.604830 [debug] [Thread-15 ]: On model.elementary.alerts_anomaly_detection: Close
[0m22:14:52.605636 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows: 0:00:01.235628 (1 runs)
[0m22:14:52.606417 [debug] [Thread-16 ]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m22:14:52.607425 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.060694 (1 runs)
[0m22:14:52.607925 [debug] [Thread-5 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m22:14:52.608581 [debug] [Thread-9 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m22:14:52.609483 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:02.177776 (1 runs)
[0m22:14:52.609919 [debug] [Thread-7 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.snapshot_run_results"} */
alter table "elsa"."bronze_tec_elsa"."snapshot_run_results__dbt_tmp" rename to "snapshot_run_results"
[0m22:14:52.610326 [debug] [Thread-4 (]: On model.elementary.monitors_runs: COMMIT
[0m22:14:52.610716 [debug] [Thread-2 (]: On model.elementary.test_result_rows: COMMIT
[0m22:14:52.611578 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:01.228916 (1 runs)
[0m22:14:52.612150 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa10530>]}
[0m22:14:52.612605 [debug] [Thread-10 ]: On model.elementary.seed_run_results: COMMIT
[0m22:14:52.613519 [debug] [Thread-13 ]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:01.896564 (1 runs)
[0m22:14:52.614065 [debug] [Thread-15 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110069790>]}
[0m22:14:52.614468 [debug] [Thread-16 ]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_tests"} */
drop view if exists "elsa"."bronze_tec_elsa"."alerts_dbt_tests__dbt_backup" cascade
[0m22:14:52.615550 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:01.266921 (1 runs)
[0m22:14:52.616033 [debug] [Thread-5 (]: On model.elementary.metrics_anomaly_score: COMMIT
[0m22:14:52.616478 [debug] [Thread-9 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_schema_changes"} */
drop view if exists "elsa"."bronze_tec_elsa"."alerts_schema_changes__dbt_backup" cascade
[0m22:14:52.617377 [debug] [Thread-3 (]: On model.elementary.dbt_columns: COMMIT
[0m22:14:52.618522 [debug] [Thread-14 ]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:01.879534 (1 runs)
[0m22:14:52.618992 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.619635 [info ] [Thread-6 (]: 18 of 31 OK created sql view model bronze_tec_elsa.job_run_results ............. [[32mCREATE VIEW[0m in 1.57s]
[0m22:14:52.620104 [debug] [Thread-7 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:14:52.620494 [debug] [Thread-2 (]: SQL status: COMMIT in 0.003 seconds
[0m22:14:52.621377 [debug] [Thread-13 ]: On model.elementary.dbt_sources: COMMIT
[0m22:14:52.621801 [debug] [Thread-10 ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.622468 [info ] [Thread-15 ]: 19 of 31 OK created sql view model bronze_tec_elsa.alerts_anomaly_detection .... [[32mCREATE VIEW[0m in 1.56s]
[0m22:14:52.623419 [debug] [Thread-8 (]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:01.895937 (1 runs)
[0m22:14:52.623868 [debug] [Thread-16 ]: SQL status: DROP VIEW in 0.001 seconds
[0m22:14:52.624449 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_columns"
[0m22:14:52.625705 [debug] [Thread-14 ]: On model.elementary.dbt_tests: COMMIT
[0m22:14:52.626151 [debug] [Thread-9 (]: SQL status: DROP VIEW in 0.002 seconds
[0m22:14:52.626591 [debug] [Thread-5 (]: SQL status: COMMIT in 0.002 seconds
[0m22:14:52.630502 [debug] [Thread-4 (]: Applying DROP to: "elsa"."bronze_tec_elsa"."monitors_runs__dbt_backup"
[0m22:14:52.631553 [debug] [Thread-6 (]: Finished running node model.elementary.job_run_results
[0m22:14:52.633222 [debug] [Thread-7 (]: On model.elementary.snapshot_run_results: COMMIT
[0m22:14:52.634141 [debug] [Thread-2 (]: On model.elementary.test_result_rows: Close
[0m22:14:52.634620 [debug] [Thread-13 ]: Using postgres connection "model.elementary.dbt_sources"
[0m22:14:52.637797 [debug] [Thread-10 ]: Applying DROP to: "elsa"."bronze_tec_elsa"."seed_run_results__dbt_backup"
[0m22:14:52.638465 [debug] [Thread-15 ]: Finished running node model.elementary.alerts_anomaly_detection
[0m22:14:52.639351 [debug] [Thread-8 (]: On model.elementary.dbt_models: COMMIT
[0m22:14:52.640755 [debug] [Thread-16 ]: On model.elementary.alerts_dbt_tests: Close
[0m22:14:52.641157 [debug] [Thread-3 (]: On model.elementary.dbt_columns: COMMIT
[0m22:14:52.641563 [debug] [Thread-14 ]: Using postgres connection "model.elementary.dbt_tests"
[0m22:14:52.642849 [debug] [Thread-9 (]: On model.elementary.alerts_schema_changes: Close
[0m22:14:52.646456 [debug] [Thread-5 (]: Applying DROP to: "elsa"."bronze_tec_elsa"."metrics_anomaly_score__dbt_backup"
[0m22:14:52.647252 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m22:14:52.647918 [debug] [Thread-7 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m22:14:52.648616 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7a9e50>]}
[0m22:14:52.649073 [debug] [Thread-13 ]: On model.elementary.dbt_sources: COMMIT
[0m22:14:52.649755 [debug] [Thread-10 ]: Using postgres connection "model.elementary.seed_run_results"
[0m22:14:52.650382 [debug] [Thread-8 (]: Using postgres connection "model.elementary.dbt_models"
[0m22:14:52.651033 [debug] [Thread-16 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7abc50>]}
[0m22:14:52.651492 [debug] [Thread-14 ]: On model.elementary.dbt_tests: COMMIT
[0m22:14:52.651961 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.652599 [debug] [Thread-5 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m22:14:52.653099 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be2e570>]}
[0m22:14:52.653529 [debug] [Thread-4 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.monitors_runs"} */
drop view if exists "elsa"."bronze_tec_elsa"."monitors_runs__dbt_backup" cascade
[0m22:14:52.653928 [debug] [Thread-7 (]: On model.elementary.snapshot_run_results: COMMIT
[0m22:14:52.654802 [info ] [Thread-2 (]: 22 of 31 OK created sql incremental model bronze_tec_elsa.test_result_rows ..... [[32mSELECT 0[0m in 1.18s]
[0m22:14:52.655305 [debug] [Thread-13 ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.655689 [debug] [Thread-10 ]: On model.elementary.seed_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.seed_run_results"} */
drop view if exists "elsa"."bronze_tec_elsa"."seed_run_results__dbt_backup" cascade
[0m22:14:52.656113 [debug] [Thread-8 (]: On model.elementary.dbt_models: COMMIT
[0m22:14:52.656764 [info ] [Thread-16 ]: 20 of 31 OK created sql view model bronze_tec_elsa.alerts_dbt_tests ............ [[32mCREATE VIEW[0m in 1.50s]
[0m22:14:52.657805 [debug] [Thread-3 (]: On model.elementary.dbt_columns: Close
[0m22:14:52.658225 [debug] [Thread-5 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.metrics_anomaly_score"} */
drop view if exists "elsa"."bronze_tec_elsa"."metrics_anomaly_score__dbt_backup" cascade
[0m22:14:52.658631 [debug] [Thread-14 ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.659263 [info ] [Thread-9 (]: 21 of 31 OK created sql view model bronze_tec_elsa.alerts_schema_changes ....... [[32mCREATE VIEW[0m in 1.47s]
[0m22:14:52.660409 [debug] [Thread-2 (]: Finished running node model.elementary.test_result_rows
[0m22:14:52.660846 [debug] [Thread-7 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.661677 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.002 seconds
[0m22:14:52.662822 [debug] [Thread-13 ]: On model.elementary.dbt_sources: Close
[0m22:14:52.663636 [debug] [Thread-16 ]: Finished running node model.elementary.alerts_dbt_tests
[0m22:14:52.664105 [debug] [Thread-10 ]: SQL status: DROP VIEW in 0.001 seconds
[0m22:14:52.664658 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be2c8f0>]}
[0m22:14:52.665061 [debug] [Thread-8 (]: SQL status: COMMIT in 0.002 seconds
[0m22:14:52.666026 [debug] [Thread-14 ]: On model.elementary.dbt_tests: Close
[0m22:14:52.666493 [debug] [Thread-5 (]: SQL status: DROP VIEW in 0.001 seconds
[0m22:14:52.667099 [debug] [Thread-9 (]: Finished running node model.elementary.alerts_schema_changes
[0m22:14:52.670215 [debug] [Thread-7 (]: Applying DROP to: "elsa"."bronze_tec_elsa"."snapshot_run_results__dbt_backup"
[0m22:14:52.671791 [debug] [Thread-4 (]: On model.elementary.monitors_runs: Close
[0m22:14:52.672391 [debug] [Thread-13 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcfbb90>]}
[0m22:14:52.674005 [debug] [Thread-10 ]: On model.elementary.seed_run_results: Close
[0m22:14:52.675112 [debug] [Thread-8 (]: On model.elementary.dbt_models: Close
[0m22:14:52.675713 [info ] [Thread-3 (]: 3 of 31 OK created sql incremental model bronze_tec_elsa.dbt_columns ........... [[32mSELECT 0[0m in 3.00s]
[0m22:14:52.676396 [debug] [Thread-14 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be2f6b0>]}
[0m22:14:52.678117 [debug] [Thread-5 (]: On model.elementary.metrics_anomaly_score: Close
[0m22:14:52.679085 [debug] [Thread-7 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m22:14:52.679799 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcf9eb0>]}
[0m22:14:52.680461 [info ] [Thread-13 ]: 13 of 31 OK created sql incremental model bronze_tec_elsa.dbt_sources .......... [[32mSELECT 0[0m in 3.00s]
[0m22:14:52.681622 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcf8a70>]}
[0m22:14:52.682342 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcfba70>]}
[0m22:14:52.682979 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_columns
[0m22:14:52.683683 [info ] [Thread-14 ]: 14 of 31 OK created sql incremental model bronze_tec_elsa.dbt_tests ............ [[32mSELECT 0[0m in 3.01s]
[0m22:14:52.684392 [debug] [Thread-7 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.snapshot_run_results"} */
drop view if exists "elsa"."bronze_tec_elsa"."snapshot_run_results__dbt_backup" cascade
[0m22:14:52.684941 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcf95b0>]}
[0m22:14:52.685580 [info ] [Thread-4 (]: 24 of 31 OK created sql view model bronze_tec_elsa.monitors_runs ............... [[32mCREATE VIEW[0m in 0.64s]
[0m22:14:52.686400 [debug] [Thread-13 ]: Finished running node model.elementary.dbt_sources
[0m22:14:52.688356 [debug] [Thread-14 ]: Finished running node model.elementary.dbt_tests
[0m22:14:52.689321 [debug] [Thread-4 (]: Finished running node model.elementary.monitors_runs
[0m22:14:52.690147 [debug] [Thread-7 (]: SQL status: DROP VIEW in 0.001 seconds
[0m22:14:52.692209 [debug] [Thread-11 ]: Began running node model.elementary.alerts_dbt_source_freshness
[0m22:14:52.693870 [debug] [Thread-7 (]: On model.elementary.snapshot_run_results: Close
[0m22:14:52.694866 [info ] [Thread-11 ]: 27 of 31 START sql view model bronze_tec_elsa.alerts_dbt_source_freshness ...... [RUN]
[0m22:14:52.696994 [debug] [Thread-11 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_snapshots, now model.elementary.alerts_dbt_source_freshness)
[0m22:14:52.697895 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcfaa50>]}
[0m22:14:52.698467 [debug] [Thread-11 ]: Began compiling node model.elementary.alerts_dbt_source_freshness
[0m22:14:52.705151 [debug] [Thread-11 ]: Writing injected SQL for node "model.elementary.alerts_dbt_source_freshness"
[0m22:14:52.705908 [debug] [Thread-11 ]: Began executing node model.elementary.alerts_dbt_source_freshness
[0m22:14:52.710754 [debug] [Thread-11 ]: Writing runtime sql for node "model.elementary.alerts_dbt_source_freshness"
[0m22:14:52.711689 [debug] [Thread-11 ]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m22:14:52.712177 [debug] [Thread-11 ]: On model.elementary.alerts_dbt_source_freshness: BEGIN
[0m22:14:52.712600 [debug] [Thread-11 ]: Opening a new connection, currently in state closed
[0m22:14:52.717934 [debug] [Thread-11 ]: SQL status: BEGIN in 0.005 seconds
[0m22:14:52.718384 [debug] [Thread-11 ]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m22:14:52.718821 [debug] [Thread-11 ]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_source_freshness"} */

  create view "elsa"."bronze_tec_elsa"."alerts_dbt_source_freshness__dbt_tmp"
    
    
  as (
    

with results as (
  select * from "elsa"."bronze_tec_elsa"."dbt_source_freshness_results"
),

sources as (
  select * from "elsa"."bronze_tec_elsa"."dbt_sources"
)

select
  results.source_freshness_execution_id as alert_id,
  results.max_loaded_at,
  results.snapshotted_at,
  cast(results.generated_at as timestamp) as detected_at,
  results.max_loaded_at_time_ago_in_s,
  results.status,
  results.error,
  results.warn_after,
  results.error_after,
  results.filter,
  sources.unique_id,
  sources.database_name,
  sources.schema_name,
  sources.source_name,
  sources.identifier,
  sources.tags,
  sources.meta,
  sources.owner,
  sources.package_name,
  sources.path,
  -- These columns below are deprecated. We add them since this view
  -- was used to be loaded into an incremental model with those columns, their names were later changed
  -- and Databricks doesn't respect `on_schema_change = 'append_new_columns'` properly, as described here -
  -- https://docs.databricks.com/en/delta/update-schema.html#automatic-schema-evolution-for-delta-lake-merge
  results.error_after as freshness_error_after,
  results.warn_after as freshness_warn_after,
  results.filter as freshness_filter
from results
join sources on results.unique_id = sources.unique_id
where True and lower(status) != 'pass'
  );
[0m22:14:52.724485 [debug] [Thread-11 ]: SQL status: CREATE VIEW in 0.005 seconds
[0m22:14:52.734115 [debug] [Thread-11 ]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m22:14:52.734679 [debug] [Thread-11 ]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_source_freshness"} */
alter table "elsa"."bronze_tec_elsa"."alerts_dbt_source_freshness__dbt_tmp" rename to "alerts_dbt_source_freshness"
[0m22:14:52.735977 [debug] [Thread-11 ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:52.737757 [debug] [Thread-11 ]: On model.elementary.alerts_dbt_source_freshness: COMMIT
[0m22:14:52.738655 [debug] [Thread-11 ]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m22:14:52.739062 [debug] [Thread-11 ]: On model.elementary.alerts_dbt_source_freshness: COMMIT
[0m22:14:52.740170 [debug] [Thread-11 ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:52.743952 [debug] [Thread-11 ]: Applying DROP to: "elsa"."bronze_tec_elsa"."alerts_dbt_source_freshness__dbt_backup"
[0m22:14:52.744606 [debug] [Thread-11 ]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m22:14:52.744992 [debug] [Thread-11 ]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_source_freshness"} */
drop view if exists "elsa"."bronze_tec_elsa"."alerts_dbt_source_freshness__dbt_backup" cascade
[0m22:14:52.745906 [debug] [Thread-11 ]: SQL status: DROP VIEW in 0.000 seconds
[0m22:14:52.747353 [debug] [Thread-11 ]: On model.elementary.alerts_dbt_source_freshness: Close
[0m22:14:52.748030 [debug] [Thread-11 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7ab770>]}
[0m22:14:53.318744 [debug] [Thread-10 ]: An error was encountered while trying to send an event
[0m22:14:53.320531 [info ] [Thread-8 (]: 8 of 31 OK created sql incremental model bronze_tec_elsa.dbt_models ............ [[32mSELECT 0[0m in 3.01s]
[0m22:14:53.323067 [info ] [Thread-5 (]: 23 of 31 OK created sql view model bronze_tec_elsa.metrics_anomaly_score ....... [[32mCREATE VIEW[0m in 0.71s]
[0m22:14:53.327754 [debug] [Thread-8 (]: Finished running node model.elementary.dbt_models
[0m22:14:53.325407 [info ] [Thread-10 ]: 25 of 31 OK created sql view model bronze_tec_elsa.seed_run_results ............ [[32mCREATE VIEW[0m in 0.51s]
[0m22:14:53.334722 [debug] [Thread-5 (]: Finished running node model.elementary.metrics_anomaly_score
[0m22:14:53.329641 [info ] [Thread-7 (]: 26 of 31 OK created sql view model bronze_tec_elsa.snapshot_run_results ........ [[32mCREATE VIEW[0m in 0.34s]
[0m22:14:53.332495 [info ] [Thread-11 ]: 27 of 31 OK created sql view model bronze_tec_elsa.alerts_dbt_source_freshness . [[32mCREATE VIEW[0m in 0.05s]
[0m22:14:53.337283 [debug] [Thread-10 ]: Finished running node model.elementary.seed_run_results
[0m22:14:53.338341 [debug] [Thread-12 ]: Began running node model.elementary.model_run_results
[0m22:14:53.339153 [debug] [Thread-1 (]: Began running node model.elementary.dbt_artifacts_hashes
[0m22:14:53.340930 [debug] [Thread-7 (]: Finished running node model.elementary.snapshot_run_results
[0m22:14:53.341782 [debug] [Thread-6 (]: Began running node model.elementary.anomaly_threshold_sensitivity
[0m22:14:53.342821 [debug] [Thread-11 ]: Finished running node model.elementary.alerts_dbt_source_freshness
[0m22:14:53.343811 [info ] [Thread-12 ]: 29 of 31 START sql view model bronze_tec_elsa.model_run_results ................ [RUN]
[0m22:14:53.344701 [info ] [Thread-1 (]: 28 of 31 START sql view model bronze_tec_elsa.dbt_artifacts_hashes ............. [RUN]
[0m22:14:53.345914 [info ] [Thread-6 (]: 30 of 31 START sql view model bronze_tec_elsa.anomaly_threshold_sensitivity .... [RUN]
[0m22:14:53.347544 [debug] [Thread-12 ]: Re-using an available connection from the pool (formerly model.elementary.schema_columns_snapshot, now model.elementary.model_run_results)
[0m22:14:53.348536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_elsa.daily_consumption, now model.elementary.dbt_artifacts_hashes)
[0m22:14:53.349447 [debug] [Thread-6 (]: Re-using an available connection from the pool (formerly model.elementary.job_run_results, now model.elementary.anomaly_threshold_sensitivity)
[0m22:14:53.350256 [debug] [Thread-12 ]: Began compiling node model.elementary.model_run_results
[0m22:14:53.350823 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_artifacts_hashes
[0m22:14:53.351340 [debug] [Thread-6 (]: Began compiling node model.elementary.anomaly_threshold_sensitivity
[0m22:14:53.362372 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.model_run_results"
[0m22:14:53.377128 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_artifacts_hashes"
[0m22:14:53.380251 [debug] [Thread-6 (]: Writing injected SQL for node "model.elementary.anomaly_threshold_sensitivity"
[0m22:14:53.381480 [debug] [Thread-12 ]: Began executing node model.elementary.model_run_results
[0m22:14:53.392173 [debug] [Thread-12 ]: Writing runtime sql for node "model.elementary.model_run_results"
[0m22:14:53.393067 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_artifacts_hashes
[0m22:14:53.393525 [debug] [Thread-6 (]: Began executing node model.elementary.anomaly_threshold_sensitivity
[0m22:14:53.398594 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_artifacts_hashes"
[0m22:14:53.404094 [debug] [Thread-6 (]: Writing runtime sql for node "model.elementary.anomaly_threshold_sensitivity"
[0m22:14:53.404721 [debug] [Thread-12 ]: Using postgres connection "model.elementary.model_run_results"
[0m22:14:53.405377 [debug] [Thread-12 ]: On model.elementary.model_run_results: BEGIN
[0m22:14:53.405770 [debug] [Thread-12 ]: Opening a new connection, currently in state closed
[0m22:14:53.406639 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m22:14:53.407205 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: BEGIN
[0m22:14:53.407770 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:14:53.408390 [debug] [Thread-6 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m22:14:53.409395 [debug] [Thread-6 (]: On model.elementary.anomaly_threshold_sensitivity: BEGIN
[0m22:14:53.410000 [debug] [Thread-6 (]: Opening a new connection, currently in state closed
[0m22:14:53.412637 [debug] [Thread-12 ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:53.413156 [debug] [Thread-12 ]: Using postgres connection "model.elementary.model_run_results"
[0m22:14:53.413662 [debug] [Thread-12 ]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.model_run_results"} */

  create view "elsa"."bronze_tec_elsa"."model_run_results__dbt_tmp"
    
    
  as (
    

with dbt_run_results as (
    select * from "elsa"."bronze_tec_elsa"."dbt_run_results"
),

dbt_models as (
    select * from "elsa"."bronze_tec_elsa"."dbt_models"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    models.database_name,
    models.schema_name,
    coalesce(run_results.materialization, models.materialization) as materialization,
    models.tags,
    models.package_name,
    models.path,
    models.original_path,
    models.owner,
    models.alias,
    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,
    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc('day', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_first_invocation_of_the_day,
    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc('day', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_last_invocation_of_the_day
    
FROM dbt_run_results run_results
JOIN dbt_models models ON run_results.unique_id = models.unique_id
  );
[0m22:14:53.415182 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m22:14:53.415942 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m22:14:53.416597 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_artifacts_hashes"} */

  create view "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes__dbt_tmp"
    
    
  as (
    




select
  'dbt_models' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_models"
 union all 

select
  'dbt_tests' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_tests"
 union all 

select
  'dbt_sources' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_sources"
 union all 

select
  'dbt_snapshots' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_snapshots"
 union all 

select
  'dbt_metrics' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_metrics"
 union all 

select
  'dbt_exposures' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_exposures"
 union all 

select
  'dbt_seeds' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_seeds"
 union all 

select
  'dbt_columns' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_columns"
 union all 

select
  'dbt_groups' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_groups"


order by metadata_hash
  );
[0m22:14:53.417108 [debug] [Thread-6 (]: SQL status: BEGIN in 0.007 seconds
[0m22:14:53.417592 [debug] [Thread-6 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m22:14:53.418065 [debug] [Thread-6 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */

  create view "elsa"."bronze_tec_elsa"."anomaly_threshold_sensitivity__dbt_tmp"
    
    
  as (
    

with metrics_anomaly_score as (

    select * from "elsa"."bronze_tec_elsa"."metrics_anomaly_score"

),

score_sensitivity as (

    select
        full_table_name,
        column_name,
        metric_name,
        latest_metric_value,
        training_avg as metric_avg,
        training_stddev as metric_stddev,
        anomaly_score,
        case when abs(anomaly_score) >= 1.5 then true else false end as "is_anomaly_1_5",
        case when abs(anomaly_score) >= 2 then true else false end as "is_anomaly_2",
        case when abs(anomaly_score) >= 2.5 then true else false end as "is_anomaly_2_5",
        case when abs(anomaly_score) >= 3 then true else false end as "is_anomaly_3",
        case when abs(anomaly_score) >= 3.5 then true else false end as "is_anomaly_3_5",
        case when abs(anomaly_score) >= 4 then true else false end as "is_anomaly_4",
        case when abs(anomaly_score) >= 4.5 then true else false end as "is_anomaly_4_5"
    from metrics_anomaly_score
    where abs(anomaly_score) >= 1.5

)

select * from score_sensitivity
  );
[0m22:14:53.421229 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m22:14:53.421733 [debug] [Thread-12 ]: SQL status: CREATE VIEW in 0.008 seconds
[0m22:14:53.425947 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m22:14:53.426435 [debug] [Thread-6 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m22:14:53.430401 [debug] [Thread-12 ]: Using postgres connection "model.elementary.model_run_results"
[0m22:14:53.430893 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_artifacts_hashes"} */
alter table "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes__dbt_tmp" rename to "dbt_artifacts_hashes"
[0m22:14:53.435067 [debug] [Thread-6 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m22:14:53.435569 [debug] [Thread-12 ]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.model_run_results"} */
alter table "elsa"."bronze_tec_elsa"."model_run_results__dbt_tmp" rename to "model_run_results"
[0m22:14:53.436100 [debug] [Thread-6 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */
alter table "elsa"."bronze_tec_elsa"."anomaly_threshold_sensitivity__dbt_tmp" rename to "anomaly_threshold_sensitivity"
[0m22:14:53.436687 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:53.437114 [debug] [Thread-6 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m22:14:53.438471 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: COMMIT
[0m22:14:53.438867 [debug] [Thread-12 ]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:14:53.440162 [debug] [Thread-6 (]: On model.elementary.anomaly_threshold_sensitivity: COMMIT
[0m22:14:53.440589 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m22:14:53.441898 [debug] [Thread-12 ]: On model.elementary.model_run_results: COMMIT
[0m22:14:53.442423 [debug] [Thread-6 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m22:14:53.442833 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: COMMIT
[0m22:14:53.443228 [debug] [Thread-12 ]: Using postgres connection "model.elementary.model_run_results"
[0m22:14:53.443632 [debug] [Thread-6 (]: On model.elementary.anomaly_threshold_sensitivity: COMMIT
[0m22:14:53.444157 [debug] [Thread-12 ]: On model.elementary.model_run_results: COMMIT
[0m22:14:53.444699 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:53.445216 [debug] [Thread-6 (]: SQL status: COMMIT in 0.001 seconds
[0m22:14:53.448479 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes__dbt_backup"
[0m22:14:53.448980 [debug] [Thread-12 ]: SQL status: COMMIT in 0.004 seconds
[0m22:14:53.452071 [debug] [Thread-6 (]: Applying DROP to: "elsa"."bronze_tec_elsa"."anomaly_threshold_sensitivity__dbt_backup"
[0m22:14:53.452717 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m22:14:53.455482 [debug] [Thread-12 ]: Applying DROP to: "elsa"."bronze_tec_elsa"."model_run_results__dbt_backup"
[0m22:14:53.456070 [debug] [Thread-6 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m22:14:53.456464 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.dbt_artifacts_hashes"} */
drop view if exists "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes__dbt_backup" cascade
[0m22:14:53.457037 [debug] [Thread-12 ]: Using postgres connection "model.elementary.model_run_results"
[0m22:14:53.457429 [debug] [Thread-6 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */
drop view if exists "elsa"."bronze_tec_elsa"."anomaly_threshold_sensitivity__dbt_backup" cascade
[0m22:14:53.457913 [debug] [Thread-12 ]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.model_run_results"} */
drop view if exists "elsa"."bronze_tec_elsa"."model_run_results__dbt_backup" cascade
[0m22:14:53.458396 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m22:14:53.458815 [debug] [Thread-6 (]: SQL status: DROP VIEW in 0.000 seconds
[0m22:14:53.460261 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: Close
[0m22:14:53.461538 [debug] [Thread-6 (]: On model.elementary.anomaly_threshold_sensitivity: Close
[0m22:14:53.461894 [debug] [Thread-12 ]: SQL status: DROP VIEW in 0.003 seconds
[0m22:14:53.462454 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7ab830>]}
[0m22:14:53.463909 [debug] [Thread-12 ]: On model.elementary.model_run_results: Close
[0m22:14:53.464536 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7abc50>]}
[0m22:14:53.465269 [info ] [Thread-1 (]: 28 of 31 OK created sql view model bronze_tec_elsa.dbt_artifacts_hashes ........ [[32mCREATE VIEW[0m in 0.11s]
[0m22:14:53.466057 [debug] [Thread-12 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7ab830>]}
[0m22:14:53.466896 [info ] [Thread-6 (]: 30 of 31 OK created sql view model bronze_tec_elsa.anomaly_threshold_sensitivity  [[32mCREATE VIEW[0m in 0.12s]
[0m22:14:53.467610 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_artifacts_hashes
[0m22:14:53.468413 [info ] [Thread-12 ]: 29 of 31 OK created sql view model bronze_tec_elsa.model_run_results ........... [[32mCREATE VIEW[0m in 0.12s]
[0m22:14:53.469105 [debug] [Thread-6 (]: Finished running node model.elementary.anomaly_threshold_sensitivity
[0m22:14:53.469821 [debug] [Thread-12 ]: Finished running node model.elementary.model_run_results
[0m22:14:53.470590 [debug] [Thread-15 ]: Began running node model.elementary.alerts_dbt_models
[0m22:14:53.471078 [info ] [Thread-15 ]: 31 of 31 START sql view model bronze_tec_elsa.alerts_dbt_models ................ [RUN]
[0m22:14:53.471761 [debug] [Thread-15 ]: Re-using an available connection from the pool (formerly model.elementary.alerts_anomaly_detection, now model.elementary.alerts_dbt_models)
[0m22:14:53.472388 [debug] [Thread-15 ]: Began compiling node model.elementary.alerts_dbt_models
[0m22:14:53.479153 [debug] [Thread-15 ]: Writing injected SQL for node "model.elementary.alerts_dbt_models"
[0m22:14:53.479958 [debug] [Thread-15 ]: Began executing node model.elementary.alerts_dbt_models
[0m22:14:53.485199 [debug] [Thread-15 ]: Writing runtime sql for node "model.elementary.alerts_dbt_models"
[0m22:14:53.486085 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m22:14:53.486474 [debug] [Thread-15 ]: On model.elementary.alerts_dbt_models: BEGIN
[0m22:14:53.486825 [debug] [Thread-15 ]: Opening a new connection, currently in state closed
[0m22:14:53.492091 [debug] [Thread-15 ]: SQL status: BEGIN in 0.005 seconds
[0m22:14:53.492664 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m22:14:53.493262 [debug] [Thread-15 ]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_models"} */

  create view "elsa"."bronze_tec_elsa"."alerts_dbt_models__dbt_tmp"
    
    
  as (
    

with error_models as (
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias 
    from "elsa"."bronze_tec_elsa"."model_run_results"
  
    union all
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias  
  from "elsa"."bronze_tec_elsa"."snapshot_run_results"
)


select model_execution_id as alert_id,
       unique_id,
       cast(generated_at as timestamp) as detected_at,
       database_name,
       materialization,
       path,
       original_path,
       schema_name,
       message,
       owner as owners,
       tags,
       alias,
       status,
       full_refresh
from error_models
where True and lower(status) != 'success'and lower(status) != 'skipped'
  );
[0m22:14:53.498274 [debug] [Thread-15 ]: SQL status: CREATE VIEW in 0.005 seconds
[0m22:14:53.502428 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m22:14:53.502860 [debug] [Thread-15 ]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_models"} */
alter table "elsa"."bronze_tec_elsa"."alerts_dbt_models__dbt_tmp" rename to "alerts_dbt_models"
[0m22:14:53.503904 [debug] [Thread-15 ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:53.505202 [debug] [Thread-15 ]: On model.elementary.alerts_dbt_models: COMMIT
[0m22:14:53.505591 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m22:14:53.505949 [debug] [Thread-15 ]: On model.elementary.alerts_dbt_models: COMMIT
[0m22:14:53.506759 [debug] [Thread-15 ]: SQL status: COMMIT in 0.000 seconds
[0m22:14:53.514292 [debug] [Thread-15 ]: Applying DROP to: "elsa"."bronze_tec_elsa"."alerts_dbt_models__dbt_backup"
[0m22:14:53.515004 [debug] [Thread-15 ]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m22:14:53.515395 [debug] [Thread-15 ]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.elementary.alerts_dbt_models"} */
drop view if exists "elsa"."bronze_tec_elsa"."alerts_dbt_models__dbt_backup" cascade
[0m22:14:53.516301 [debug] [Thread-15 ]: SQL status: DROP VIEW in 0.000 seconds
[0m22:14:53.517941 [debug] [Thread-15 ]: On model.elementary.alerts_dbt_models: Close
[0m22:14:53.518515 [debug] [Thread-15 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7d13726-fbb6-455f-b030-11c7856c8c8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcf8ef0>]}
[0m22:14:53.519146 [info ] [Thread-15 ]: 31 of 31 OK created sql view model bronze_tec_elsa.alerts_dbt_models ........... [[32mCREATE VIEW[0m in 0.05s]
[0m22:14:53.519776 [debug] [Thread-15 ]: Finished running node model.elementary.alerts_dbt_models
[0m22:14:53.521913 [info ] [MainThread]: 
[0m22:14:53.522366 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:53.522680 [debug] [MainThread]: On master: BEGIN
[0m22:14:53.522970 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:14:53.528385 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:14:53.528810 [debug] [MainThread]: On master: COMMIT
[0m22:14:53.529133 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:53.529435 [debug] [MainThread]: On master: COMMIT
[0m22:14:53.529832 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:14:53.557175 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:53.557692 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m22:14:53.560940 [debug] [MainThread]: SQL status: SELECT 119 in 0.003 seconds
[0m22:14:53.564382 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:14:53.569040 [debug] [MainThread]: Elementary: [dbt_models] Artifacts already ran.
[0m22:14:53.569973 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts already ran.
[0m22:14:53.570778 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts already ran.
[0m22:14:53.571543 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts already ran.
[0m22:14:53.572298 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts already ran.
[0m22:14:53.573051 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts already ran.
[0m22:14:53.574240 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts already ran.
[0m22:14:53.575001 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts already ran.
[0m22:14:53.575947 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts already ran.
[0m22:14:53.576652 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m22:14:53.580861 [debug] [MainThread]: Elementary: Uploading run results.
[0m22:14:53.581813 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m22:14:53.629169 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 31 artifacts.
[0m22:14:53.633623 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:53.634089 [debug] [MainThread]: On master: BEGIN
[0m22:14:53.634769 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:14:53.635213 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:53.635692 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m22:14:53.644699 [debug] [MainThread]: SQL status: SELECT 23 in 0.009 seconds
[0m22:14:53.647377 [debug] [MainThread]: Elementary: Inserting 31 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m22:14:54.179422 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:14:54.181513 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:54.184609 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_source_freshness_results','model.elementary.dbt_source_freshness_results','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_source_freshness_results','SELECT 0','success','model',1.218369960784912,'2025-07-18T20:14:50.064426Z','2025-07-18T20:14:50.867140Z','2025-07-18T20:14:49.878466Z','2025-07-18T20:14:49.946330Z',0,False,'


    select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as source_freshness_execution_id

,
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as max_loaded_at

,
                
        cast(''dummy_string'' as varchar(4096)) as snapshotted_at

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(123456789.99 as float) as max_loaded_at_time_ago_in_s

,
                
        cast(''dummy_string'' as varchar(4096)) as status

,
                
        cast(''dummy_string'' as varchar(4096)) as error

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as invocation_id

,
                
        cast(''dummy_string'' as varchar(4096)) as warn_after

,
                
        cast(''dummy_string'' as varchar(4096)) as error_after

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as filter


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-12 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_invocations','model.elementary.dbt_invocations','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_invocations','SELECT 0','success','model',1.2243928909301758,'2025-07-18T20:14:50.059883Z','2025-07-18T20:14:50.868052Z','2025-07-18T20:14:49.776774Z','2025-07-18T20:14:49.944814Z',0,False,'

select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as invocation_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as job_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as job_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as job_run_id

,
                
        cast(''dummy_string'' as varchar(4096)) as run_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as run_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(''dummy_string'' as varchar(4096)) as command

,
                
        cast(''dummy_string'' as varchar(4096)) as dbt_version

,
                
        cast(''dummy_string'' as varchar(4096)) as elementary_version

,
                
        cast (True as boolean) as full_refresh

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as invocation_vars

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as vars

,
                
        cast(''dummy_string'' as varchar(4096)) as target_name

,
                
        cast(''dummy_string'' as varchar(4096)) as target_database

,
                
        cast(''dummy_string'' as varchar(4096)) as target_schema

,
                
        cast(''dummy_string'' as varchar(4096)) as target_profile_name

,
                
        cast(123456789 as integer) as threads

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as selected

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as yaml_selector

,
                
        cast(''dummy_string'' as varchar(4096)) as project_id

,
                
        cast(''dummy_string'' as varchar(4096)) as project_name

,
                
        cast(''dummy_string'' as varchar(4096)) as env

,
                
        cast(''dummy_string'' as varchar(4096)) as env_id

,
                
        cast(''dummy_string'' as varchar(4096)) as cause_category

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as cause

,
                
        cast(''dummy_string'' as varchar(4096)) as pull_request_id

,
                
        cast(''dummy_string'' as varchar(4096)) as git_sha

,
                
        cast(''dummy_string'' as varchar(4096)) as orchestrator

,
                
        cast(''dummy_string'' as varchar(4096)) as dbt_user

,
                
        cast(''dummy_string'' as varchar(4096)) as job_url

,
                
        cast(''dummy_string'' as varchar(4096)) as job_run_url

,
                
        cast(''dummy_string'' as varchar(4096)) as account_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as target_adapter_specific_fields


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-6 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.elementary_test_results','model.elementary.elementary_test_results','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'elementary_test_results','SELECT 0','success','model',1.2368550300598145,'2025-07-18T20:14:50.079215Z','2025-07-18T20:14:50.880416Z','2025-07-18T20:14:49.894698Z','2025-07-18T20:14:49.953294Z',0,False,'


    select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as id

,
                
        cast(''dummy_string'' as varchar(4096)) as data_issue_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_execution_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_unique_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as invocation_id

,
                cast(''2091-02-17'' as timestamp) as detected_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as table_name

,
                
        cast(''dummy_string'' as varchar(4096)) as column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as test_type

,
                
        cast(''dummy_string'' as varchar(4096)) as test_sub_type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_results_description

,
                
        cast(''dummy_string'' as varchar(4096)) as owners

,
                
        cast(''dummy_string'' as varchar(4096)) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_results_query

,
                
        cast(''dummy_string'' as varchar(4096)) as other

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_params

,
                
        cast(''dummy_string'' as varchar(4096)) as severity

,
                
        cast(''dummy_string'' as varchar(4096)) as status

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast(''dummy_string'' as varchar(4096)) as test_short_name

,
                
        cast(''dummy_string'' as varchar(4096)) as test_alias

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as result_rows

,
                
        cast(31474836478 as bigint) as failed_row_count


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-15 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.metadata','model.elementary.metadata','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'metadata','SELECT 1','success','model',1.3235182762145996,'2025-07-18T20:14:49.948064Z','2025-07-18T20:14:50.973214Z','2025-07-18T20:14:49.679853Z','2025-07-18T20:14:49.940799Z',1,False,'

SELECT
    ''0.19.0'' as dbt_pkg_version',NULL,NULL,'Thread-16 (worker)','table','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_run_results','model.elementary.dbt_run_results','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_run_results','SELECT 0','success','model',1.3646330833435059,'2025-07-18T20:14:50.069189Z','2025-07-18T20:14:50.983593Z','2025-07-18T20:14:49.860320Z','2025-07-18T20:14:49.946875Z',0,False,'

select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_execution_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as invocation_id

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as message

,
                
        cast(''dummy_string'' as varchar(4096)) as status

,
                
        cast(''dummy_string'' as varchar(4096)) as resource_type

,
                
        cast(123456789.99 as float) as execution_time

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_completed_at

,
                
        cast(31474836478 as bigint) as rows_affected

,
                
        cast (True as boolean) as full_refresh

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as compiled_code

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast(''dummy_string'' as varchar(4096)) as query_id

,
                
        cast(''dummy_string'' as varchar(4096)) as thread_id

,
                
        cast(''dummy_string'' as varchar(4096)) as materialization

,
                
        cast(''dummy_string'' as varchar(4096)) as adapter_response

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-9 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.data_monitoring_metrics','model.elementary.data_monitoring_metrics','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'data_monitoring_metrics','SELECT 0','success','model',1.365346908569336,'2025-07-18T20:14:50.098520Z','2025-07-18T20:14:50.987444Z','2025-07-18T20:14:49.926566Z','2025-07-18T20:14:50.046777Z',0,False,'


    
    
        
    
    select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as id

,
                
        cast(''dummy_string'' as varchar(4096)) as full_table_name

,
                
        cast(''dummy_string'' as varchar(4096)) as column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as metric_name

,
                
        cast(''dummy_string'' as varchar(4096)) as metric_type

,
                
        cast(123456789.99 as float) as metric_value

,
                
        cast(''dummy_string'' as varchar(4096)) as source_value

,
                cast(''2091-02-17'' as timestamp) as bucket_start

,
                cast(''2091-02-17'' as timestamp) as bucket_end

,
                
        cast(123456789 as integer) as bucket_duration_hours

,
                cast(''2091-02-17'' as timestamp) as updated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as dimension

,
                
        cast(''dummy_string'' as varchar(4096)) as dimension_value

,
                
        cast(''dummy_string'' as varchar(4096)) as metric_properties

,
                cast(''2091-02-17'' as timestamp) as created_at


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-2 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_groups','model.elementary.dbt_groups','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_groups','SELECT 0','success','model',1.44240403175354,'2025-07-18T20:14:50.041672Z','2025-07-18T20:14:51.064440Z','2025-07-18T20:14:49.723596Z','2025-07-18T20:14:49.943388Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_email

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_name

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-5 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_exposures','model.elementary.dbt_exposures','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_exposures','SELECT 0','success','model',1.4473357200622559,'2025-07-18T20:14:49.960895Z','2025-07-18T20:14:51.066580Z','2025-07-18T20:14:49.687334Z','2025-07-18T20:14:49.942066Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as maturity

,
                
        cast(''dummy_string'' as varchar(4096)) as type

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_email

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as url

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_columns

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as label

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as raw_queries


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-4 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_seeds','model.elementary.dbt_seeds','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_seeds','SELECT 0','success','model',1.462745189666748,'2025-07-18T20:14:50.055353Z','2025-07-18T20:14:51.069991Z','2025-07-18T20:14:49.800108Z','2025-07-18T20:14:49.944232Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as checksum

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-10 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_metrics','model.elementary.dbt_metrics','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_metrics','SELECT 0','success','model',1.4648668766021729,'2025-07-18T20:14:50.034513Z','2025-07-18T20:14:51.070966Z','2025-07-18T20:14:49.746713Z','2025-07-18T20:14:49.943011Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as label

,
                
        cast(''dummy_string'' as varchar(4096)) as model

,
                
        cast(''dummy_string'' as varchar(4096)) as type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as sql

,
                
        cast(''dummy_string'' as varchar(4096)) as timestamp

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as filters

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as time_grains

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as dimensions

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-7 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_snapshots','model.elementary.dbt_snapshots','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_snapshots','SELECT 0','success','model',2.112600088119507,'2025-07-18T20:14:50.074054Z','2025-07-18T20:14:51.599201Z','2025-07-18T20:14:49.832062Z','2025-07-18T20:14:49.947398Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as checksum

,
                
        cast(''dummy_string'' as varchar(4096)) as materialization

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as patch_path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as unique_key

,
                
        cast(''dummy_string'' as varchar(4096)) as incremental_strategy

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name

,
                
        cast(''dummy_string'' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-11 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.dbt_elsa.daily_consumption','model.dbt_elsa.daily_consumption','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'daily_consumption','SELECT 96','success','model',2.7906651496887207,'2025-07-18T20:14:50.093506Z','2025-07-18T20:14:52.439892Z','2025-07-18T20:14:49.856644Z','2025-07-18T20:14:49.960476Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    data->>''gaz'' AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.schema_columns_snapshot','model.elementary.schema_columns_snapshot','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'schema_columns_snapshot','SELECT 0','success','model',1.4639298915863037,'2025-07-18T20:14:51.203719Z','2025-07-18T20:14:52.482640Z','2025-07-18T20:14:51.072830Z','2025-07-18T20:14:51.144543Z',0,False,'


    select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as column_state_id

,
                
        cast(''dummy_string'' as varchar(4096)) as full_column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as full_table_name

,
                
        cast(''dummy_string'' as varchar(4096)) as column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as data_type

,
                
        cast (True as boolean) as is_new

,
                cast(''2091-02-17'' as timestamp) as detected_at

,
                cast(''2091-02-17'' as timestamp) as created_at


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-12 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.job_run_results','model.elementary.job_run_results','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'job_run_results','CREATE VIEW','success','model',1.5690789222717285,'2025-07-18T20:14:51.414576Z','2025-07-18T20:14:52.602120Z','2025-07-18T20:14:51.084693Z','2025-07-18T20:14:51.149041Z',-1,False,'





with jobs as (
  select
    job_name,
    job_id,
    job_run_id,
    
min(cast(run_started_at as timestamp))
 as job_run_started_at,
    
max(cast(run_completed_at as timestamp))
 as job_run_completed_at,
    
    
        (
        (
        (
        ((
max(cast(run_completed_at as timestamp))
)::date - (
min(cast(run_started_at as timestamp))
)::date)
     * 24 + date_part(''hour'', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part(''hour'', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + date_part(''minute'', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part(''minute'', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + floor(date_part(''second'', (
max(cast(run_completed_at as timestamp))
)::timestamp)) - floor(date_part(''second'', (
min(cast(run_started_at as timestamp))
)::timestamp)))
    
 as job_run_execution_time
  from "elsa"."bronze_tec_elsa"."dbt_invocations"
  where job_id is not null
  group by job_name, job_id, job_run_id
)

select
  job_name as name,
  job_id as id,
  job_run_id as run_id,
  job_run_started_at as run_started_at,
  job_run_completed_at as run_completed_at,
  job_run_execution_time as run_execution_time
from jobs',NULL,NULL,'Thread-6 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.alerts_anomaly_detection','model.elementary.alerts_anomaly_detection','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'alerts_anomaly_detection','CREATE VIEW','success','model',1.5554330348968506,'2025-07-18T20:14:51.503233Z','2025-07-18T20:14:52.604700Z','2025-07-18T20:14:51.124146Z','2025-07-18T20:14:51.151700Z',-1,False,'

with elementary_test_results as (
    select * from "elsa"."bronze_tec_elsa"."elementary_test_results"
),

alerts_anomaly_detection as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != ''pass''and lower(status) != ''skipped''and test_type = ''anomaly_detection''
)

select * from alerts_anomaly_detection',NULL,NULL,'Thread-15 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.test_result_rows','model.elementary.test_result_rows','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'test_result_rows','SELECT 0','success','model',1.182732105255127,'2025-07-18T20:14:52.280873Z','2025-07-18T20:14:52.633997Z','2025-07-18T20:14:51.856640Z','2025-07-18T20:14:52.143146Z',0,False,'-- indexes are not supported in all warehouses, relevant to postgres only


-- depends_on: "elsa"."bronze_tec_elsa"."elementary_test_results"
select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as elementary_test_results_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as result_row

,
                cast(''2091-02-17'' as timestamp) as detected_at

,
                cast(''2091-02-17'' as timestamp) as created_at


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-2 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.alerts_dbt_tests','model.elementary.alerts_dbt_tests','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'alerts_dbt_tests','CREATE VIEW','success','model',1.501309871673584,'2025-07-18T20:14:52.148903Z','2025-07-18T20:14:52.640627Z','2025-07-18T20:14:51.704130Z','2025-07-18T20:14:51.888927Z',-1,False,'

with elementary_test_results as (
    select * from "elsa"."bronze_tec_elsa"."elementary_test_results"
),

alerts_dbt_tests as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != ''pass''   and lower(status) != ''skipped''  and test_type = ''dbt_test''
)

select * from alerts_dbt_tests',NULL,NULL,'Thread-16 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.alerts_schema_changes','model.elementary.alerts_schema_changes','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'alerts_schema_changes','CREATE VIEW','success','model',1.4679100513458252,'2025-07-18T20:14:52.275973Z','2025-07-18T20:14:52.642726Z','2025-07-18T20:14:51.782223Z','2025-07-18T20:14:52.073714Z',-1,False,'


with elementary_test_results as (
    select * from "elsa"."bronze_tec_elsa"."elementary_test_results"
),

alerts_schema_changes as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != ''pass''and lower(status) != ''skipped''and test_type = ''schema_change''
)

select * from alerts_schema_changes',NULL,NULL,'Thread-9 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_columns','model.elementary.dbt_columns','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_columns','SELECT 0','success','model',2.9985060691833496,'2025-07-18T20:14:50.012787Z','2025-07-18T20:14:52.657667Z','2025-07-18T20:14:49.699553Z','2025-07-18T20:14:49.942549Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as parent_unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as data_type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as table_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as resource_type

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-3 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_sources','model.elementary.dbt_sources','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_sources','SELECT 0','success','model',2.9991939067840576,'2025-07-18T20:14:50.089012Z','2025-07-18T20:14:52.662680Z','2025-07-18T20:14:49.912298Z','2025-07-18T20:14:49.959880Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as source_name

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as identifier

,
                
        cast(''dummy_string'' as varchar(4096)) as loaded_at_field

,
                
        cast(''dummy_string'' as varchar(4096)) as freshness_warn_after

,
                
        cast(''dummy_string'' as varchar(4096)) as freshness_error_after

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as freshness_filter

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as freshness_description

,
                
        cast(''dummy_string'' as varchar(4096)) as relation_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as source_description

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-13 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_tests','model.elementary.dbt_tests','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_tests','SELECT 0','success','model',3.0066418647766113,'2025-07-18T20:14:50.083936Z','2025-07-18T20:14:52.665888Z','2025-07-18T20:14:49.841610Z','2025-07-18T20:14:49.954131Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as short_name

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as test_column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as severity

,
                
        cast(''dummy_string'' as varchar(4096)) as warn_if

,
                
        cast(''dummy_string'' as varchar(4096)) as error_if

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_params

,
                
        cast(''dummy_string'' as varchar(4096)) as test_namespace

,
                
        cast(''dummy_string'' as varchar(4096)) as test_original_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_owners

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''dummy_string'' as varchar(4096)) as parent_model_unique_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''dummy_string'' as varchar(4096)) as type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as quality_dimension

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-14 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.monitors_runs','model.elementary.monitors_runs','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'monitors_runs','CREATE VIEW','success','model',0.6397497653961182,'2025-07-18T20:14:52.364798Z','2025-07-18T20:14:52.671652Z','2025-07-18T20:14:52.318530Z','2025-07-18T20:14:52.347172Z',-1,False,'

with data_monitoring_metrics as (

    select * from "elsa"."bronze_tec_elsa"."data_monitoring_metrics"

),

max_bucket_end as (

    select full_table_name,
           column_name,
           metric_name,
           metric_properties,
           max(bucket_end) as last_bucket_end,
           min(bucket_end) as first_bucket_end
    from data_monitoring_metrics
    group by 1,2,3,4

)

select * from max_bucket_end',NULL,NULL,'Thread-4 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_models','model.elementary.dbt_models','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_models','SELECT 0','success','model',3.0146420001983643,'2025-07-18T20:14:50.047199Z','2025-07-18T20:14:52.674907Z','2025-07-18T20:14:49.770446Z','2025-07-18T20:14:49.943774Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as checksum

,
                
        cast(''dummy_string'' as varchar(4096)) as materialization

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as patch_path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as unique_key

,
                
        cast(''dummy_string'' as varchar(4096)) as incremental_strategy

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name

,
                
        cast(''dummy_string'' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-8 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.metrics_anomaly_score','model.elementary.metrics_anomaly_score','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'metrics_anomaly_score','CREATE VIEW','success','model',0.7122879028320312,'2025-07-18T20:14:52.369883Z','2025-07-18T20:14:52.677870Z','2025-07-18T20:14:52.288593Z','2025-07-18T20:14:52.347607Z',-1,False,'

with data_monitoring_metrics as (

    select * from "elsa"."bronze_tec_elsa"."data_monitoring_metrics"

),

time_window_aggregation as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        metric_value,
        source_value,
        bucket_start,
        bucket_end,
        bucket_duration_hours,
        updated_at,
        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,
        stddev(cast(metric_value as float)) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,
        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,
        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,
        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start
    from data_monitoring_metrics
    group by 1,2,3,4,5,6,7,8,9,10,11,12
),

metrics_anomaly_score as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        case
            when training_stddev is null then null
            when training_stddev = 0 then 0
            else (metric_value - training_avg) / (training_stddev)
        end as anomaly_score,
        metric_value as latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        max(updated_at) as updated_at
    from time_window_aggregation
        where
            metric_value is not null
            and training_avg is not null
            and bucket_end >= 
    cast(date_trunc(''day'', 
    current_timestamp::timestamp
) as timestamp) + cast(-7 as integer) * INTERVAL ''1 day''

    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    order by bucket_end desc


),

final as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        anomaly_score,
        latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        updated_at,
        case
            when abs(anomaly_score) > 3 then true
            else false end
        as is_anomaly
    from metrics_anomaly_score
)

select * from final',NULL,NULL,'Thread-5 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.seed_run_results','model.elementary.seed_run_results','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'seed_run_results','CREATE VIEW','success','model',0.5086159706115723,'2025-07-18T20:14:52.375624Z','2025-07-18T20:14:52.673869Z','2025-07-18T20:14:52.327098Z','2025-07-18T20:14:52.356736Z',-1,False,'

with dbt_run_results as (
    select * from "elsa"."bronze_tec_elsa"."dbt_run_results"
),

dbt_seeds as (
    select * from "elsa"."bronze_tec_elsa"."dbt_seeds"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    seeds.database_name,
    seeds.schema_name,
    run_results.materialization,
    seeds.tags,
    seeds.package_name,
    seeds.path,
    seeds.original_path,
    seeds.owner,
    seeds.alias
FROM dbt_run_results run_results
JOIN dbt_seeds seeds ON run_results.unique_id = seeds.unique_id',NULL,NULL,'Thread-10 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.snapshot_run_results','model.elementary.snapshot_run_results','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'snapshot_run_results','CREATE VIEW','success','model',0.33790111541748047,'2025-07-18T20:14:52.444459Z','2025-07-18T20:14:52.693721Z','2025-07-18T20:14:52.395900Z','2025-07-18T20:14:52.429612Z',-1,False,'

with dbt_run_results as (
    select * from "elsa"."bronze_tec_elsa"."dbt_run_results"
),

dbt_snapshots as (
    select * from "elsa"."bronze_tec_elsa"."dbt_snapshots"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    snapshots.database_name,
    snapshots.schema_name,
    coalesce(run_results.materialization, snapshots.materialization) as materialization,
    snapshots.tags,
    snapshots.package_name,
    snapshots.path,
    snapshots.original_path,
    snapshots.owner,
    snapshots.alias
FROM dbt_run_results run_results
JOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id',NULL,NULL,'Thread-7 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.alerts_dbt_source_freshness','model.elementary.alerts_dbt_source_freshness','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'alerts_dbt_source_freshness','CREATE VIEW','success','model',0.0512700080871582,'2025-07-18T20:14:52.706253Z','2025-07-18T20:14:52.747218Z','2025-07-18T20:14:52.698942Z','2025-07-18T20:14:52.705758Z',-1,False,'

with results as (
  select * from "elsa"."bronze_tec_elsa"."dbt_source_freshness_results"
),

sources as (
  select * from "elsa"."bronze_tec_elsa"."dbt_sources"
)

select
  results.source_freshness_execution_id as alert_id,
  results.max_loaded_at,
  results.snapshotted_at,
  cast(results.generated_at as timestamp) as detected_at,
  results.max_loaded_at_time_ago_in_s,
  results.status,
  results.error,
  results.warn_after,
  results.error_after,
  results.filter,
  sources.unique_id,
  sources.database_name,
  sources.schema_name,
  sources.source_name,
  sources.identifier,
  sources.tags,
  sources.meta,
  sources.owner,
  sources.package_name,
  sources.path,
  -- These columns below are deprecated. We add them since this view
  -- was used to be loaded into an incremental model with those columns, their names were later changed
  -- and Databricks doesn''t respect `on_schema_change = ''append_new_columns''` properly, as described here -
  -- https://docs.databricks.com/en/delta/update-schema.html#automatic-schema-evolution-for-delta-lake-merge
  results.error_after as freshness_error_after,
  results.warn_after as freshness_warn_after,
  results.filter as freshness_filter
from results
join sources on results.unique_id = sources.unique_id
where True and lower(status) != ''pass''',NULL,NULL,'Thread-11 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.dbt_artifacts_hashes','model.elementary.dbt_artifacts_hashes','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'dbt_artifacts_hashes','CREATE VIEW','success','model',0.1142570972442627,'2025-07-18T20:14:53.393778Z','2025-07-18T20:14:53.460128Z','2025-07-18T20:14:53.362815Z','2025-07-18T20:14:53.392875Z',-1,False,'




select
  ''dbt_models'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_models"
 union all 

select
  ''dbt_tests'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_tests"
 union all 

select
  ''dbt_sources'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_sources"
 union all 

select
  ''dbt_snapshots'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_snapshots"
 union all 

select
  ''dbt_metrics'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_metrics"
 union all 

select
  ''dbt_exposures'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_exposures"
 union all 

select
  ''dbt_seeds'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_seeds"
 union all 

select
  ''dbt_columns'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_columns"
 union all 

select
  ''dbt_groups'' as artifacts_model,
   metadata_hash
from "elsa"."bronze_tec_elsa"."dbt_groups"


order by metadata_hash',NULL,NULL,'Thread-1 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.anomaly_threshold_sensitivity','model.elementary.anomaly_threshold_sensitivity','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'anomaly_threshold_sensitivity','CREATE VIEW','success','model',0.11531686782836914,'2025-07-18T20:14:53.399438Z','2025-07-18T20:14:53.461412Z','2025-07-18T20:14:53.367963Z','2025-07-18T20:14:53.393390Z',-1,False,'

with metrics_anomaly_score as (

    select * from "elsa"."bronze_tec_elsa"."metrics_anomaly_score"

),

score_sensitivity as (

    select
        full_table_name,
        column_name,
        metric_name,
        latest_metric_value,
        training_avg as metric_avg,
        training_stddev as metric_stddev,
        anomaly_score,
        case when abs(anomaly_score) >= 1.5 then true else false end as "is_anomaly_1_5",
        case when abs(anomaly_score) >= 2 then true else false end as "is_anomaly_2",
        case when abs(anomaly_score) >= 2.5 then true else false end as "is_anomaly_2_5",
        case when abs(anomaly_score) >= 3 then true else false end as "is_anomaly_3",
        case when abs(anomaly_score) >= 3.5 then true else false end as "is_anomaly_3_5",
        case when abs(anomaly_score) >= 4 then true else false end as "is_anomaly_4",
        case when abs(anomaly_score) >= 4.5 then true else false end as "is_anomaly_4_5"
    from metrics_anomaly_score
    where abs(anomaly_score) >= 1.5

)

select * from score_sensitivity',NULL,NULL,'Thread-6 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.model_run_results','model.elementary.model_run_results','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'model_run_results','CREATE VIEW','success','model',0.11853313446044922,'2025-07-18T20:14:53.381898Z','2025-07-18T20:14:53.463769Z','2025-07-18T20:14:53.351697Z','2025-07-18T20:14:53.381245Z',-1,False,'

with dbt_run_results as (
    select * from "elsa"."bronze_tec_elsa"."dbt_run_results"
),

dbt_models as (
    select * from "elsa"."bronze_tec_elsa"."dbt_models"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    models.database_name,
    models.schema_name,
    coalesce(run_results.materialization, models.materialization) as materialization,
    models.tags,
    models.package_name,
    models.path,
    models.original_path,
    models.owner,
    models.alias,
    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,
    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc(''day'', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_first_invocation_of_the_day,
    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc(''day'', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_last_invocation_of_the_day
    
FROM dbt_run_results run_results
JOIN dbt_models models ON run_results.unique_id = models.unique_id',NULL,NULL,'Thread-12 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('e7d13726-fbb6-455f-b030-11c7856c8c8e.model.elementary.alerts_dbt_models','model.elementary.alerts_dbt_models','e7d13726-fbb6-455f-b030-11c7856c8c8e','2025-07-18 20:14:53',
    current_timestamp::timestamp
,'alerts_dbt_models','CREATE VIEW','success','model',0.04698514938354492,'2025-07-18T20:14:53.480222Z','2025-07-18T20:14:53.517799Z','2025-07-18T20:14:53.472684Z','2025-07-18T20:14:53.479814Z',-1,False,'

with error_models as (
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias 
    from "elsa"."bronze_tec_elsa"."model_run_results"
  
    union all
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias  
  from "elsa"."bronze_tec_elsa"."snapshot_run_results"
)


select model_execution_id as alert_id,
       unique_id,
       cast(generated_at as timestamp) as detected_at,
       database_name,
       materialization,
       path,
       original_path,
       schema_name,
       message,
       owner as owners,
       tags,
       alias,
       status,
       full_refresh
from error_models
where True and lower(status) != ''success''and lower(status) != ''skipped''',NULL,NULL,'Thread-15 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL)
  
[0m22:14:54.192152 [debug] [MainThread]: SQL status: INSERT 0 31 in 0.004 seconds
[0m22:14:54.194462 [debug] [MainThread]: On master: COMMIT
[0m22:14:54.194876 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:54.195236 [debug] [MainThread]: On master: COMMIT
[0m22:14:54.196397 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:14:54.199478 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m22:14:54.200323 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.046355 (1 runs)
[0m22:14:54.201194 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.016685 (1 runs)
[0m22:14:54.201991 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000673 (1 runs)
[0m22:14:54.202749 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.514112 (31 runs)
[0m22:14:54.203516 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.530169 (1 runs)
[0m22:14:54.204231 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.013082 (1 runs)
[0m22:14:54.204940 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003072 (1 runs)
[0m22:14:54.205653 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.567745 (1 runs)
[0m22:14:54.206457 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.617389 (1 runs)
[0m22:14:54.207287 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m22:14:54.244871 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m22:14:54.338247 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:54.338736 [debug] [MainThread]: On master: BEGIN
[0m22:14:54.339554 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:14:54.340082 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:54.340838 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m22:14:54.345420 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m22:14:54.348350 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m22:14:54.367898 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:14:54.369184 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:54.369758 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('e7d13726-fbb6-455f-b030-11c7856c8c8e',NULL,NULL,NULL,'2025-07-18 20:14:47','2025-07-18 20:14:54','2025-07-18 20:14:54',
    current_timestamp::timestamp
,'run','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'[]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m22:14:54.371031 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m22:14:54.373562 [debug] [MainThread]: On master: COMMIT
[0m22:14:54.373978 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:54.374397 [debug] [MainThread]: On master: COMMIT
[0m22:14:54.375328 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:14:54.376922 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m22:14:54.384046 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:14:54.385063 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m22:14:54.385612 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.86s]
[0m22:14:54.386045 [debug] [MainThread]: On master: Close
[0m22:14:54.386568 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:14:54.386872 [debug] [MainThread]: Connection 'model.elementary.dbt_artifacts_hashes' was properly closed.
[0m22:14:54.387147 [debug] [MainThread]: Connection 'model.elementary.test_result_rows' was properly closed.
[0m22:14:54.387417 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_tests' was properly closed.
[0m22:14:54.387687 [debug] [MainThread]: Connection 'model.elementary.monitors_runs' was properly closed.
[0m22:14:54.387952 [debug] [MainThread]: Connection 'model.elementary.dbt_columns' was properly closed.
[0m22:14:54.388222 [debug] [MainThread]: Connection 'model.elementary.metrics_anomaly_score' was properly closed.
[0m22:14:54.388486 [debug] [MainThread]: Connection 'model.elementary.snapshot_run_results' was properly closed.
[0m22:14:54.388749 [debug] [MainThread]: Connection 'model.elementary.dbt_models' was properly closed.
[0m22:14:54.389027 [debug] [MainThread]: Connection 'model.elementary.anomaly_threshold_sensitivity' was properly closed.
[0m22:14:54.389381 [debug] [MainThread]: Connection 'model.elementary.seed_run_results' was properly closed.
[0m22:14:54.389668 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_source_freshness' was properly closed.
[0m22:14:54.389938 [debug] [MainThread]: Connection 'model.elementary.dbt_tests' was properly closed.
[0m22:14:54.390202 [debug] [MainThread]: Connection 'model.elementary.alerts_schema_changes' was properly closed.
[0m22:14:54.390471 [debug] [MainThread]: Connection 'model.elementary.model_run_results' was properly closed.
[0m22:14:54.390737 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_models' was properly closed.
[0m22:14:54.391069 [debug] [MainThread]: Connection 'model.elementary.dbt_sources' was properly closed.
[0m22:14:54.391876 [info ] [MainThread]: 
[0m22:14:54.392324 [info ] [MainThread]: Finished running 16 incremental models, 2 project hooks, 2 table models, 13 view models in 0 hours 0 minutes and 5.04 seconds (5.04s).
[0m22:14:54.399533 [debug] [MainThread]: Command end result
[0m22:14:54.545444 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:14:54.548089 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:14:54.557284 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m22:14:54.557692 [info ] [MainThread]: 
[0m22:14:54.558242 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:14:54.559065 [info ] [MainThread]: 
[0m22:14:54.559512 [info ] [MainThread]: Done. PASS=33 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=33
[0m22:14:54.563417 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.7136493, "process_in_blocks": "0", "process_kernel_time": 0.922201, "process_mem_max_rss": "145719296", "process_out_blocks": "0", "process_user_time": 6.882916}
[0m22:14:54.564409 [debug] [MainThread]: Command `dbt run` succeeded at 22:14:54.564112 after 6.71 seconds
[0m22:14:54.565019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10965e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11015d970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11015d3d0>]}
[0m22:14:54.565760 [debug] [MainThread]: Flushing usage events
[0m22:14:54.947023 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:16:15.209294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11299f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140d7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140d74d0>]}


============================== 22:16:15.214443 | 21285c92-d8df-495b-8b47-fd5b240c6070 ==============================
[0m22:16:15.214443 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:16:15.215109 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:16:15.275951 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "dbt_elsa", target "dev_live" invalid: 'schema' is a required property
[0m22:16:15.278766 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.15640251, "process_in_blocks": "0", "process_kernel_time": 0.336714, "process_mem_max_rss": "104271872", "process_out_blocks": "0", "process_user_time": 1.851058}
[0m22:16:15.279416 [debug] [MainThread]: Command `dbt run` failed at 22:16:15.279289 after 0.16 seconds
[0m22:16:15.279817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11414eea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11454d370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f57ce0>]}
[0m22:16:15.280225 [debug] [MainThread]: Flushing usage events
[0m22:16:15.737371 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:16:26.606289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109593770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acc7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acc74d0>]}


============================== 22:16:26.611675 | 23249273-fddb-4c65-bb4a-7f9f9922957f ==============================
[0m22:16:26.611675 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:16:26.612416 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m22:16:26.822280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a010510>]}
[0m22:16:26.896859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab43df0>]}
[0m22:16:26.897782 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:16:27.026839 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:16:27.185341 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m22:16:27.186015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf30450>]}
[0m22:16:32.030979 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m22:16:32.044667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0237a0>]}
[0m22:16:32.209480 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:16:32.212790 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:16:32.232742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0367b0>]}
[0m22:16:32.233343 [info ] [MainThread]: Found 31 models, 2 operations, 4 data tests, 1 source, 1571 macros
[0m22:16:32.233735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c393e10>]}
[0m22:16:32.235728 [info ] [MainThread]: 
[0m22:16:32.236107 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m22:16:32.236431 [info ] [MainThread]: 
[0m22:16:32.236941 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:16:32.237747 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m22:16:32.295133 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m22:16:32.295698 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m22:16:32.296042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:32.318192 [debug] [ThreadPool]: SQL status: SELECT 17 in 0.022 seconds
[0m22:16:32.319639 [debug] [ThreadPool]: On list_elsa: Close
[0m22:16:32.320336 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa__bronze)
[0m22:16:32.320813 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "_bronze"
"
[0m22:16:32.328820 [debug] [ThreadPool]: Using postgres connection "create_elsa__bronze"
[0m22:16:32.329254 [debug] [ThreadPool]: On create_elsa__bronze: BEGIN
[0m22:16:32.329558 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:32.334985 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:16:32.335398 [debug] [ThreadPool]: Using postgres connection "create_elsa__bronze"
[0m22:16:32.335713 [debug] [ThreadPool]: On create_elsa__bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "create_elsa__bronze"} */
create schema if not exists "_bronze"
[0m22:16:32.336606 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m22:16:32.337574 [debug] [ThreadPool]: On create_elsa__bronze: COMMIT
[0m22:16:32.337910 [debug] [ThreadPool]: Using postgres connection "create_elsa__bronze"
[0m22:16:32.338218 [debug] [ThreadPool]: On create_elsa__bronze: COMMIT
[0m22:16:32.339245 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m22:16:32.339589 [debug] [ThreadPool]: On create_elsa__bronze: Close
[0m22:16:32.346375 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa__bronze, now list_elsa__bronze)
[0m22:16:32.347000 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa__tec_elsa'
[0m22:16:32.353805 [debug] [ThreadPool]: Using postgres connection "list_elsa__bronze"
[0m22:16:32.356447 [debug] [ThreadPool]: Using postgres connection "list_elsa__tec_elsa"
[0m22:16:32.356810 [debug] [ThreadPool]: On list_elsa__bronze: BEGIN
[0m22:16:32.357128 [debug] [ThreadPool]: On list_elsa__tec_elsa: BEGIN
[0m22:16:32.357438 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:32.357742 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:32.363531 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:16:32.363949 [debug] [ThreadPool]: Using postgres connection "list_elsa__tec_elsa"
[0m22:16:32.364292 [debug] [ThreadPool]: On list_elsa__tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa__tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike '_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike '_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike '_tec_elsa'
  
[0m22:16:32.364672 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:16:32.364993 [debug] [ThreadPool]: Using postgres connection "list_elsa__bronze"
[0m22:16:32.365326 [debug] [ThreadPool]: On list_elsa__bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa__bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike '_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike '_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike '_bronze'
  
[0m22:16:32.368290 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m22:16:32.369638 [debug] [ThreadPool]: On list_elsa__tec_elsa: ROLLBACK
[0m22:16:32.370039 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m22:16:32.371204 [debug] [ThreadPool]: On list_elsa__bronze: ROLLBACK
[0m22:16:32.371553 [debug] [ThreadPool]: On list_elsa__tec_elsa: Close
[0m22:16:32.371906 [debug] [ThreadPool]: On list_elsa__bronze: Close
[0m22:16:32.378911 [debug] [MainThread]: Using postgres connection "master"
[0m22:16:32.379314 [debug] [MainThread]: On master: BEGIN
[0m22:16:32.379608 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:16:32.385102 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:16:32.385508 [debug] [MainThread]: Using postgres connection "master"
[0m22:16:32.385902 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:16:32.425318 [debug] [MainThread]: SQL status: SELECT 26 in 0.039 seconds
[0m22:16:32.427224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bff0e90>]}
[0m22:16:32.427706 [debug] [MainThread]: On master: ROLLBACK
[0m22:16:32.428337 [debug] [MainThread]: Using postgres connection "master"
[0m22:16:32.428722 [debug] [MainThread]: On master: BEGIN
[0m22:16:32.429568 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:16:32.429878 [debug] [MainThread]: On master: COMMIT
[0m22:16:32.430176 [debug] [MainThread]: Using postgres connection "master"
[0m22:16:32.430458 [debug] [MainThread]: On master: COMMIT
[0m22:16:32.430945 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:16:32.453741 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m22:16:32.459452 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:16:32.463404 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:16:32.464112 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.03s]
[0m22:16:32.464507 [info ] [MainThread]: 
[0m22:16:32.464953 [debug] [MainThread]: On master: Close
[0m22:16:32.469239 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m22:16:32.470042 [info ] [Thread-1 (]: 1 of 1 START sql table model _bronze.daily_consumption ......................... [RUN]
[0m22:16:32.470766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa__bronze, now model.dbt_elsa.daily_consumption)
[0m22:16:32.471215 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m22:16:32.476093 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m22:16:32.476988 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m22:16:32.519758 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m22:16:32.520646 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.521029 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m22:16:32.521383 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:16:32.526885 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m22:16:32.527351 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.527746 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m22:16:32.533505 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.005 seconds
[0m22:16:32.545220 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.545720 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m22:16:32.546670 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:16:32.569368 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.569857 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on table "elsa"."_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m22:16:32.570730 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m22:16:32.594834 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.595410 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = '_bronze'
        
      order by ordinal_position

  
[0m22:16:32.603927 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.008 seconds
[0m22:16:32.609013 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.609567 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m22:16:32.610602 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:16:32.611950 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:16:32.612372 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.612760 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:16:32.614752 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m22:16:32.622905 [debug] [Thread-1 (]: Applying DROP to: "elsa"."_bronze"."daily_consumption__dbt_backup"
[0m22:16:32.628331 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:16:32.628826 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
drop table if exists "elsa"."_bronze"."daily_consumption__dbt_backup" cascade
[0m22:16:32.629610 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:16:32.632221 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m22:16:32.634277 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23249273-fddb-4c65-bb4a-7f9f9922957f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0f6ba0>]}
[0m22:16:32.635124 [info ] [Thread-1 (]: 1 of 1 OK created sql table model _bronze.daily_consumption .................... [[32mSELECT 96[0m in 0.16s]
[0m22:16:32.635825 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m22:16:32.637747 [info ] [MainThread]: 
[0m22:16:32.638195 [debug] [MainThread]: Using postgres connection "master"
[0m22:16:32.638513 [debug] [MainThread]: On master: BEGIN
[0m22:16:32.638812 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:16:32.644204 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:16:32.644653 [debug] [MainThread]: On master: COMMIT
[0m22:16:32.644984 [debug] [MainThread]: Using postgres connection "master"
[0m22:16:32.645385 [debug] [MainThread]: On master: COMMIT
[0m22:16:32.645889 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:16:32.670495 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:16:32.680417 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m22:16:32.705966 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:16:32.706919 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m22:16:32.707630 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.06s]
[0m22:16:32.708112 [debug] [MainThread]: On master: Close
[0m22:16:32.708688 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:16:32.708997 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m22:16:32.709291 [debug] [MainThread]: Connection 'list_elsa__tec_elsa' was properly closed.
[0m22:16:32.709654 [info ] [MainThread]: 
[0m22:16:32.710018 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.47 seconds (0.47s).
[0m22:16:32.711288 [debug] [MainThread]: Command end result
[0m22:16:32.795717 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:16:32.798408 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:16:32.806022 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m22:16:32.806451 [info ] [MainThread]: 
[0m22:16:32.806907 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:16:32.807337 [info ] [MainThread]: 
[0m22:16:32.807734 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m22:16:32.810486 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.2931833, "process_in_blocks": "0", "process_kernel_time": 0.409269, "process_mem_max_rss": "140632064", "process_out_blocks": "0", "process_user_time": 7.397653}
[0m22:16:32.811112 [debug] [MainThread]: Command `dbt run` succeeded at 22:16:32.810981 after 6.29 seconds
[0m22:16:32.811541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b26c870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfe5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acc9750>]}
[0m22:16:32.811952 [debug] [MainThread]: Flushing usage events
[0m22:16:33.221419 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:22:07.588771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b407770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb3f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb3f4d0>]}


============================== 22:22:07.595386 | 41c250fd-745a-4381-8a06-6eaf526fddcd ==============================
[0m22:22:07.595386 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:22:07.596081 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:22:07.786709 [error] [MainThread]: Encountered an error:
Runtime Error
  at path []: Additional properties are not allowed ('generate_schema_name' was unexpected)

Error encountered in /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/dbt_project.yml
[0m22:22:07.791474 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.308118, "process_in_blocks": "0", "process_kernel_time": 0.581985, "process_mem_max_rss": "106037248", "process_out_blocks": "0", "process_user_time": 2.37499}
[0m22:22:07.792159 [debug] [MainThread]: Command `dbt run` failed at 22:22:07.792022 after 0.31 seconds
[0m22:22:07.792586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d05e060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d061910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9bb130>]}
[0m22:22:07.793047 [debug] [MainThread]: Flushing usage events
[0m22:22:08.253963 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:23:54.820188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10852f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c63610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c634d0>]}


============================== 22:23:54.828799 | 2b2a9fd6-670e-40d8-9002-0ce658f722b7 ==============================
[0m22:23:54.828799 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:23:54.829644 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:23:55.131195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fb0510>]}
[0m22:23:55.205740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ae3df0>]}
[0m22:23:55.207388 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:23:55.369520 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:23:55.530553 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m22:23:55.531160 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m22:23:55.531630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aef0450>]}
[0m22:24:00.506284 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m22:24:00.521541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa977a0>]}
[0m22:24:00.689066 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:24:00.695755 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:24:00.742478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab127b0>]}
[0m22:24:00.743031 [info ] [MainThread]: Found 31 models, 2 operations, 4 data tests, 1 source, 1571 macros
[0m22:24:00.743431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aaffe10>]}
[0m22:24:00.745530 [info ] [MainThread]: 
[0m22:24:00.745924 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m22:24:00.746270 [info ] [MainThread]: 
[0m22:24:00.746832 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:24:00.747718 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m22:24:00.819268 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m22:24:00.819773 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m22:24:00.820157 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:24:00.863964 [debug] [ThreadPool]: SQL status: SELECT 17 in 0.044 seconds
[0m22:24:00.865914 [debug] [ThreadPool]: On list_elsa: Close
[0m22:24:00.866835 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa_sandbox_bronze)
[0m22:24:00.867436 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "sandbox_bronze"
"
[0m22:24:00.876564 [debug] [ThreadPool]: Using postgres connection "create_elsa_sandbox_bronze"
[0m22:24:00.877041 [debug] [ThreadPool]: On create_elsa_sandbox_bronze: BEGIN
[0m22:24:00.877365 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:24:00.885030 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:24:00.885529 [debug] [ThreadPool]: Using postgres connection "create_elsa_sandbox_bronze"
[0m22:24:00.885920 [debug] [ThreadPool]: On create_elsa_sandbox_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "create_elsa_sandbox_bronze"} */
create schema if not exists "sandbox_bronze"
[0m22:24:00.887007 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m22:24:00.888031 [debug] [ThreadPool]: On create_elsa_sandbox_bronze: COMMIT
[0m22:24:00.888393 [debug] [ThreadPool]: Using postgres connection "create_elsa_sandbox_bronze"
[0m22:24:00.888721 [debug] [ThreadPool]: On create_elsa_sandbox_bronze: COMMIT
[0m22:24:00.890445 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m22:24:00.890987 [debug] [ThreadPool]: On create_elsa_sandbox_bronze: Close
[0m22:24:00.897575 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa_sandbox_bronze, now list_elsa_sandbox_tec_elsa)
[0m22:24:00.898199 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_sandbox_bronze'
[0m22:24:00.904999 [debug] [ThreadPool]: Using postgres connection "list_elsa_sandbox_tec_elsa"
[0m22:24:00.907672 [debug] [ThreadPool]: Using postgres connection "list_elsa_sandbox_bronze"
[0m22:24:00.908046 [debug] [ThreadPool]: On list_elsa_sandbox_tec_elsa: BEGIN
[0m22:24:00.908362 [debug] [ThreadPool]: On list_elsa_sandbox_bronze: BEGIN
[0m22:24:00.908668 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:24:00.909025 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:24:00.915910 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:24:00.916338 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:24:00.916676 [debug] [ThreadPool]: Using postgres connection "list_elsa_sandbox_tec_elsa"
[0m22:24:00.916988 [debug] [ThreadPool]: Using postgres connection "list_elsa_sandbox_bronze"
[0m22:24:00.917320 [debug] [ThreadPool]: On list_elsa_sandbox_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_sandbox_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sandbox_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sandbox_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'sandbox_tec_elsa'
  
[0m22:24:00.917680 [debug] [ThreadPool]: On list_elsa_sandbox_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_sandbox_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sandbox_bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sandbox_bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'sandbox_bronze'
  
[0m22:24:00.923871 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m22:24:00.924328 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m22:24:00.925606 [debug] [ThreadPool]: On list_elsa_sandbox_tec_elsa: ROLLBACK
[0m22:24:00.926790 [debug] [ThreadPool]: On list_elsa_sandbox_bronze: ROLLBACK
[0m22:24:00.927324 [debug] [ThreadPool]: On list_elsa_sandbox_tec_elsa: Close
[0m22:24:00.927690 [debug] [ThreadPool]: On list_elsa_sandbox_bronze: Close
[0m22:24:00.935051 [debug] [MainThread]: Using postgres connection "master"
[0m22:24:00.935462 [debug] [MainThread]: On master: BEGIN
[0m22:24:00.935767 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:24:00.941155 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:24:00.941551 [debug] [MainThread]: Using postgres connection "master"
[0m22:24:00.941941 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:24:00.984214 [debug] [MainThread]: SQL status: SELECT 26 in 0.042 seconds
[0m22:24:00.986144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a981190>]}
[0m22:24:00.986663 [debug] [MainThread]: On master: ROLLBACK
[0m22:24:00.987223 [debug] [MainThread]: Using postgres connection "master"
[0m22:24:00.987569 [debug] [MainThread]: On master: BEGIN
[0m22:24:00.988175 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:24:00.988519 [debug] [MainThread]: On master: COMMIT
[0m22:24:00.988847 [debug] [MainThread]: Using postgres connection "master"
[0m22:24:00.989158 [debug] [MainThread]: On master: COMMIT
[0m22:24:00.989590 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:24:01.011194 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m22:24:01.017470 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:24:01.021448 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:24:01.022105 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.03s]
[0m22:24:01.022500 [info ] [MainThread]: 
[0m22:24:01.022974 [debug] [MainThread]: On master: Close
[0m22:24:01.028354 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m22:24:01.029025 [info ] [Thread-1 (]: 1 of 1 START sql table model sandbox_bronze.daily_consumption .................. [RUN]
[0m22:24:01.029926 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_sandbox_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m22:24:01.030434 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m22:24:01.034980 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m22:24:01.036169 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m22:24:01.078987 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m22:24:01.080127 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.080643 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m22:24:01.081038 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:24:01.087423 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m22:24:01.087940 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.088390 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."sandbox_bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m22:24:01.095633 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.007 seconds
[0m22:24:01.107099 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.107580 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."sandbox_bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m22:24:01.108560 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:24:01.131064 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.131533 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on table "elsa"."sandbox_bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m22:24:01.132487 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:24:01.155506 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.156049 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'sandbox_bronze'
        
      order by ordinal_position

  
[0m22:24:01.171417 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.015 seconds
[0m22:24:01.178107 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.178838 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."sandbox_bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m22:24:01.179995 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:24:01.181497 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:24:01.181985 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.182417 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:24:01.183701 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m22:24:01.192410 [debug] [Thread-1 (]: Applying DROP to: "elsa"."sandbox_bronze"."daily_consumption__dbt_backup"
[0m22:24:01.197914 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:24:01.198392 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
drop table if exists "elsa"."sandbox_bronze"."daily_consumption__dbt_backup" cascade
[0m22:24:01.199172 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:24:01.201803 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m22:24:01.203952 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b2a9fd6-670e-40d8-9002-0ce658f722b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abfeba0>]}
[0m22:24:01.204803 [info ] [Thread-1 (]: 1 of 1 OK created sql table model sandbox_bronze.daily_consumption ............. [[32mSELECT 96[0m in 0.17s]
[0m22:24:01.205593 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m22:24:01.208753 [info ] [MainThread]: 
[0m22:24:01.209309 [debug] [MainThread]: Using postgres connection "master"
[0m22:24:01.209646 [debug] [MainThread]: On master: BEGIN
[0m22:24:01.209958 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:24:01.216373 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:24:01.216902 [debug] [MainThread]: On master: COMMIT
[0m22:24:01.217271 [debug] [MainThread]: Using postgres connection "master"
[0m22:24:01.217790 [debug] [MainThread]: On master: COMMIT
[0m22:24:01.218372 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:24:01.243884 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:24:01.253587 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m22:24:01.279374 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:24:01.280324 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m22:24:01.281055 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.06s]
[0m22:24:01.281544 [debug] [MainThread]: On master: Close
[0m22:24:01.282032 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:24:01.282347 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m22:24:01.282617 [debug] [MainThread]: Connection 'list_elsa_sandbox_bronze' was properly closed.
[0m22:24:01.282972 [info ] [MainThread]: 
[0m22:24:01.283330 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.54 seconds (0.54s).
[0m22:24:01.284424 [debug] [MainThread]: Command end result
[0m22:24:01.373289 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:24:01.378106 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:24:01.390647 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m22:24:01.391238 [info ] [MainThread]: 
[0m22:24:01.391820 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:24:01.392349 [info ] [MainThread]: 
[0m22:24:01.393112 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m22:24:01.397875 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.6820407, "process_in_blocks": "0", "process_kernel_time": 0.820866, "process_mem_max_rss": "142716928", "process_out_blocks": "0", "process_user_time": 8.041456}
[0m22:24:01.399184 [debug] [MainThread]: Command `dbt run` succeeded at 22:24:01.398896 after 6.68 seconds
[0m22:24:01.400185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1f4af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9e9d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c672d0>]}
[0m22:24:01.401027 [debug] [MainThread]: Flushing usage events
[0m22:24:01.923455 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:43:57.316623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b9f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10929b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10929b4d0>]}


============================== 22:43:57.324684 | 7f6c930c-1281-4055-99b6-02d96ac15e68 ==============================
[0m22:43:57.324684 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:43:57.325383 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:43:57.644312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108618510>]}
[0m22:43:57.726788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10911fdf0>]}
[0m22:43:57.728481 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:43:57.882020 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:43:58.080633 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m22:43:58.081201 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m22:43:58.081687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a51c450>]}
[0m22:44:03.111838 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m22:44:03.126386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a61b7a0>]}
[0m22:44:03.293226 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:44:03.300212 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:44:03.364015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6267b0>]}
[0m22:44:03.364747 [info ] [MainThread]: Found 31 models, 2 operations, 4 data tests, 1 source, 1571 macros
[0m22:44:03.365384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a133e10>]}
[0m22:44:03.367827 [info ] [MainThread]: 
[0m22:44:03.368280 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m22:44:03.368674 [info ] [MainThread]: 
[0m22:44:03.369304 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:44:03.370612 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m22:44:03.447474 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m22:44:03.447928 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m22:44:03.448268 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:44:03.482606 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.034 seconds
[0m22:44:03.484239 [debug] [ThreadPool]: On list_elsa: Close
[0m22:44:03.491163 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m22:44:03.491938 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m22:44:03.501299 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:44:03.504209 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m22:44:03.504616 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m22:44:03.504936 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m22:44:03.505242 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:44:03.505541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:44:03.512478 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:44:03.512892 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:44:03.513210 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m22:44:03.513535 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:44:03.513875 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m22:44:03.514244 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m22:44:03.518879 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m22:44:03.519393 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.005 seconds
[0m22:44:03.521062 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m22:44:03.522298 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m22:44:03.522811 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m22:44:03.523159 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m22:44:03.536169 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:03.536607 [debug] [MainThread]: On master: BEGIN
[0m22:44:03.536910 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:44:03.542532 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:44:03.542992 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:03.543423 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:44:03.584776 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m22:44:03.591857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a005490>]}
[0m22:44:03.592364 [debug] [MainThread]: On master: ROLLBACK
[0m22:44:03.592962 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:03.593325 [debug] [MainThread]: On master: BEGIN
[0m22:44:03.593950 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:44:03.594301 [debug] [MainThread]: On master: COMMIT
[0m22:44:03.594633 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:03.594947 [debug] [MainThread]: On master: COMMIT
[0m22:44:03.595392 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:44:03.616786 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m22:44:03.623061 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:44:03.627206 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:44:03.627943 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.03s]
[0m22:44:03.628455 [info ] [MainThread]: 
[0m22:44:03.629002 [debug] [MainThread]: On master: Close
[0m22:44:03.634831 [debug] [Thread-1 (]: Began running node model.dbt_elsa.daily_consumption
[0m22:44:03.635596 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.daily_consumption .......................... [RUN]
[0m22:44:03.636451 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.daily_consumption)
[0m22:44:03.637232 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.daily_consumption
[0m22:44:03.643215 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.daily_consumption"
[0m22:44:03.644412 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.daily_consumption
[0m22:44:03.690246 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.daily_consumption"
[0m22:44:03.691676 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.692172 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: BEGIN
[0m22:44:03.692546 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:44:03.698230 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m22:44:03.698693 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.699213 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

  
    

  create  table "elsa"."bronze"."daily_consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m22:44:03.705351 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.006 seconds
[0m22:44:03.716979 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.717467 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze"."daily_consumption" rename to "daily_consumption__dbt_backup"
[0m22:44:03.718351 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m22:44:03.722263 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.722690 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
alter table "elsa"."bronze"."daily_consumption__dbt_tmp" rename to "daily_consumption"
[0m22:44:03.723658 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:44:03.749176 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.749694 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  comment on table "elsa"."bronze"."daily_consumption" is $dbt_comment_literal_block$The aim of this table is to track daily energy production
$dbt_comment_literal_block$;

  
[0m22:44:03.750779 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:44:03.773880 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.774432 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'daily_consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m22:44:03.787474 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.012 seconds
[0m22:44:03.794320 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.795089 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."daily_consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m22:44:03.796362 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m22:44:03.797944 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:44:03.798453 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.798953 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: COMMIT
[0m22:44:03.800090 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m22:44:03.809141 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."daily_consumption__dbt_backup"
[0m22:44:03.815147 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.daily_consumption"
[0m22:44:03.815659 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.daily_consumption"} */
drop table if exists "elsa"."bronze"."daily_consumption__dbt_backup" cascade
[0m22:44:03.818521 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:44:03.821253 [debug] [Thread-1 (]: On model.dbt_elsa.daily_consumption: Close
[0m22:44:03.823537 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f6c930c-1281-4055-99b6-02d96ac15e68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac14680>]}
[0m22:44:03.824335 [info ] [Thread-1 (]: 1 of 1 OK created sql table model bronze.daily_consumption ..................... [[32mSELECT 96[0m in 0.19s]
[0m22:44:03.825031 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.daily_consumption
[0m22:44:03.826961 [info ] [MainThread]: 
[0m22:44:03.827412 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:03.827745 [debug] [MainThread]: On master: BEGIN
[0m22:44:03.828065 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:44:03.833943 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:44:03.834421 [debug] [MainThread]: On master: COMMIT
[0m22:44:03.834781 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:03.835135 [debug] [MainThread]: On master: COMMIT
[0m22:44:03.835945 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:44:03.864824 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:03.865448 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m22:44:03.871068 [debug] [MainThread]: SQL status: SELECT 119 in 0.005 seconds
[0m22:44:03.878034 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:44:03.911217 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m22:44:03.987293 [debug] [MainThread]: Elementary: [dbt_models] Flattened 31 artifacts.
[0m22:44:03.994872 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m22:44:03.995828 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m22:44:04.005264 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m22:44:04.035508 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.036025 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718204404020279224404028525"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m22:44:04.040431 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m22:44:04.059540 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.060054 [debug] [MainThread]: On master: BEGIN
[0m22:44:04.060760 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:44:04.061159 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.061558 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718204404020279224404028525'
        
      order by ordinal_position

  
[0m22:44:04.068489 [debug] [MainThread]: SQL status: SELECT 1 in 0.006 seconds
[0m22:44:04.070844 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718204404020279224404028525"
[0m22:44:04.114154 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:04.115513 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.115981 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718204404020279224404028525"
         (metadata_hash) values
    ('30f900f85d7e2651e6d2ce2083057529')
  
[0m22:44:04.117003 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m22:44:04.120806 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.121203 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718204404119592224404119843"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m22:44:04.123294 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m22:44:04.128440 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.129147 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718204404119592224404119843'
        
      order by ordinal_position

  
[0m22:44:04.133232 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m22:44:04.136812 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718204404119592224404119843"
[0m22:44:04.148405 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:04.149768 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.150186 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718204404119592224404119843"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.daily_consumption','daily_consumption','fa1c4ca81ba141cb831969824ce43dcc19b625a3d7e5a49ba6f95e16f6e8fd41','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','The aim of this table is to track daily energy production
','daily_consumption','dbt_elsa','models/bronze/daily_consumption.sql','bronze/daily_consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-18 20:44:03','dd8e8ba547b55216c77b725dba89d622',NULL,NULL,NULL,'protected')
  
[0m22:44:04.151235 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m22:44:04.158823 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.159378 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718204404020279224404028525");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718204404119592224404119843";
        
        commit;
    
  
[0m22:44:04.162697 [debug] [MainThread]: SQL status: COMMIT in 0.003 seconds
[0m22:44:04.167572 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718204404020279224404028525"
[0m22:44:04.168280 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.168680 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718204404020279224404028525" cascade
[0m22:44:04.171019 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m22:44:04.175116 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718204404119592224404119843"
[0m22:44:04.175774 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.176188 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718204404119592224404119843" cascade
[0m22:44:04.177855 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m22:44:04.179146 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m22:44:04.180847 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m22:44:04.181818 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.074879 (1 runs)
[0m22:44:04.182706 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.024960 (2 runs)
[0m22:44:04.183582 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000946 (2 runs)
[0m22:44:04.184462 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.030126 (2 runs)
[0m22:44:04.185340 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.038969 (2 runs)
[0m22:44:04.186228 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.007022 (2 runs)
[0m22:44:04.187110 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.090997 (2 runs)
[0m22:44:04.187985 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.269333 (1 runs)
[0m22:44:04.190181 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m22:44:04.303535 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 4 artifacts.
[0m22:44:04.304833 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m22:44:04.305574 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts changed.
[0m22:44:04.306390 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m22:44:04.308491 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.308870 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718204404307189224404307507"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m22:44:04.311891 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m22:44:04.317083 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.317534 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718204404307189224404307507'
        
      order by ordinal_position

  
[0m22:44:04.320677 [debug] [MainThread]: SQL status: SELECT 1 in 0.003 seconds
[0m22:44:04.322821 [debug] [MainThread]: Elementary: Inserting 4 rows to table "dbt_tests__tmp_20250718204404307189224404307507"
[0m22:44:04.329259 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:04.330673 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.331139 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250718204404307189224404307507"
         (metadata_hash) values
    ('3ef2c7669dbe501432b678b81b93d3ca'),('62a6af057d124e81e5fd5edc21b478e4'),('741e080242dfaa710f406bddddda19ec'),('b992aa3a13dcf1a233ac68ebee7bd040')
  
[0m22:44:04.332087 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m22:44:04.335841 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.336254 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718204404334615224404334852"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m22:44:04.338934 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m22:44:04.344090 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.344559 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718204404334615224404334852'
        
      order by ordinal_position

  
[0m22:44:04.348112 [debug] [MainThread]: SQL status: SELECT 29 in 0.003 seconds
[0m22:44:04.350682 [debug] [MainThread]: Elementary: Inserting 4 rows to table "dbt_tests__tmp_20250718204404334615224404334852"
[0m22:44:04.393527 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:04.394824 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.395483 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250718204404334615224404334852"
         (unique_id,database_name,schema_name,name,short_name,alias,test_column_name,severity,warn_if,error_if,test_params,test_namespace,test_original_name,tags,model_tags,model_owners,meta,depends_on_macros,depends_on_nodes,parent_model_unique_id,description,package_name,type,original_path,path,generated_at,metadata_hash,quality_dimension,group_name) values
    ('test.dbt_elsa.not_null_daily_consumption_id.9183981eb4','elsa','bronze','not_null_daily_consumption_id','not_null','not_null_daily_consumption_id','id','ERROR','!= 0','!= 0','{"column_name": "id", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_id.sql','2025-07-18 20:44:04','a2b3139930021b90abaeba8bb5050171','completeness',NULL),('test.dbt_elsa.not_null_daily_consumption_created_at.d60c851a3a','elsa','bronze','not_null_daily_consumption_created_at','not_null','not_null_daily_consumption_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_created_at.sql','2025-07-18 20:44:04','8a067ec9013321f49ce92fc705584768','completeness',NULL),('test.dbt_elsa.not_null_daily_consumption_date.c78a11ccee','elsa','bronze','not_null_daily_consumption_date','not_null','not_null_daily_consumption_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_date.sql','2025-07-18 20:44:04','ce9efa3ee5baf94e522c80c502b5b9ed','completeness',NULL),('test.dbt_elsa.not_null_daily_consumption_time.ab08545457','elsa','bronze','not_null_daily_consumption_time','not_null','not_null_daily_consumption_time','time','ERROR','!= 0','!= 0','{"column_name": "time", "model": "{{ get_where_subquery(ref(''daily_consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.daily_consumption"]','model.dbt_elsa.daily_consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_daily_consumption_time.sql','2025-07-18 20:44:04','50d0c441c7d860d924f1fef55d19e132','completeness',NULL)
  
[0m22:44:04.397105 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m22:44:04.400967 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.401705 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_tests"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_tests__tmp_20250718204404307189224404307507");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_tests" select * from "dbt_tests__tmp_20250718204404334615224404334852";
        
        commit;
    
  
[0m22:44:04.403773 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m22:44:04.407843 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250718204404307189224404307507"
[0m22:44:04.408780 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.409183 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250718204404307189224404307507" cascade
[0m22:44:04.410743 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m22:44:04.414487 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250718204404334615224404334852"
[0m22:44:04.415154 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.415606 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250718204404334615224404334852" cascade
[0m22:44:04.417292 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m22:44:04.418666 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m22:44:04.421213 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m22:44:04.422220 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.112372 (1 runs)
[0m22:44:04.423120 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.017625 (2 runs)
[0m22:44:04.424003 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001206 (2 runs)
[0m22:44:04.424883 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.042034 (8 runs)
[0m22:44:04.425774 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.046918 (2 runs)
[0m22:44:04.426677 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.008427 (2 runs)
[0m22:44:04.427565 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:00.079664 (2 runs)
[0m22:44:04.428444 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.230613 (1 runs)
[0m22:44:04.430327 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m22:44:04.450791 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 1 artifacts.
[0m22:44:04.452088 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m22:44:04.452877 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m22:44:04.454021 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m22:44:04.454842 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019423 (1 runs)
[0m22:44:04.455656 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.023631 (1 runs)
[0m22:44:04.457287 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m22:44:04.458864 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m22:44:04.460257 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m22:44:04.460975 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m22:44:04.462081 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m22:44:04.462872 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000706 (1 runs)
[0m22:44:04.463654 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.004710 (1 runs)
[0m22:44:04.465388 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m22:44:04.466631 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m22:44:04.467759 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m22:44:04.468763 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m22:44:04.469993 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m22:44:04.470791 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000331 (1 runs)
[0m22:44:04.471573 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004526 (1 runs)
[0m22:44:04.473133 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m22:44:04.474382 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m22:44:04.475507 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m22:44:04.476474 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m22:44:04.477606 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m22:44:04.478723 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000368 (1 runs)
[0m22:44:04.479514 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004386 (1 runs)
[0m22:44:04.481092 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m22:44:04.482494 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m22:44:04.483625 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m22:44:04.484323 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m22:44:04.485492 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m22:44:04.486380 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000457 (1 runs)
[0m22:44:04.487178 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004250 (1 runs)
[0m22:44:04.489120 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m22:44:04.490349 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m22:44:04.491486 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m22:44:04.492202 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m22:44:04.493559 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m22:44:04.494392 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000330 (1 runs)
[0m22:44:04.495200 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004352 (1 runs)
[0m22:44:04.496814 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m22:44:04.651338 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 83 artifacts.
[0m22:44:04.652653 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m22:44:04.653661 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts changed.
[0m22:44:04.656419 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m22:44:04.658548 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.658952 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718204404657306224404657555"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m22:44:04.661521 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m22:44:04.666722 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.667217 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718204404657306224404657555'
        
      order by ordinal_position

  
[0m22:44:04.670046 [debug] [MainThread]: SQL status: SELECT 1 in 0.002 seconds
[0m22:44:04.672399 [debug] [MainThread]: Elementary: Inserting 14 rows to table "dbt_columns__tmp_20250718204404657306224404657555"
[0m22:44:04.688551 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:04.689695 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.690100 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718204404657306224404657555"
         (metadata_hash) values
    ('03e0094d8e04313bb2fe1af7afc71d20'),('1570cf802c1386727a33c36a034be5e6'),('161ebd245783f3919192a2762cf66698'),('19309b8221a3b7c2cb225c039f26002f'),('1fbc3373398a87c1eb7f19bf5a7266e3'),('2793cf3c09a607a2cfe92b7360bd1582'),('4121a63d20ab40b8a3d7e41aedc55303'),('589019d67d5fef5065f2e6cb0aa3658f'),('710c196bcb851ff219af0d705545f9da'),('76030b988eff440e8b70060002b07af7'),('9c08034f02e761a9e6697e54c6c6683d'),('d8aad2d83629892631476fa1d923cf19'),('ddb0ec5e50fbf25a992026f099a24b68'),('f06577f58280a4e77e3907ef3b20d651')
  
[0m22:44:04.691228 [debug] [MainThread]: SQL status: INSERT 0 14 in 0.001 seconds
[0m22:44:04.696502 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.696988 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718204404695191224404695442"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m22:44:04.699276 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m22:44:04.704656 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.705218 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718204404695191224404695442'
        
      order by ordinal_position

  
[0m22:44:04.709119 [debug] [MainThread]: SQL status: SELECT 13 in 0.003 seconds
[0m22:44:04.711727 [debug] [MainThread]: Elementary: Inserting 14 rows to table "dbt_columns__tmp_20250718204404695191224404695442"
[0m22:44:04.778917 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:04.780001 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.780501 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718204404695191224404695442"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.dbt_elsa.daily_consumption.id','model.dbt_elsa.daily_consumption','id','integer','[]','{}','elsa','bronze','daily_consumption','ID','model','2025-07-18 20:44:04','374bd67e774675f19f28cde7c6bda29a'),('column.model.dbt_elsa.daily_consumption.created_at','model.dbt_elsa.daily_consumption','created_at','datetime','[]','{}','elsa','bronze','daily_consumption','datetime','model','2025-07-18 20:44:04','22c40f93a6414d60245a7536e5608785'),('column.model.dbt_elsa.daily_consumption.date','model.dbt_elsa.daily_consumption','date','date','[]','{}','elsa','bronze','daily_consumption','date','model','2025-07-18 20:44:04','b6fe1ea8e16a5c21257cb5f6e611d14b'),('column.model.dbt_elsa.daily_consumption.time','model.dbt_elsa.daily_consumption','time','time','[]','{}','elsa','bronze','daily_consumption','time','model','2025-07-18 20:44:04','8f044a91afbea79bc342f32a805d9bdd'),('column.model.dbt_elsa.daily_consumption.gaz','model.dbt_elsa.daily_consumption','gaz','float','[]','{}','elsa','bronze','daily_consumption','Production for gaz energy in TWH','model','2025-07-18 20:44:04','c16c2c65425e41a6d8dc6cfe1a49169e'),('column.model.dbt_elsa.daily_consumption.nucleaire','model.dbt_elsa.daily_consumption','nucleaire','float','[]','{}','elsa','bronze','daily_consumption','Production for nuclear energy in TWH','model','2025-07-18 20:44:04','fd67e4ad540602ffd4b4e3741871bd5e'),('column.model.dbt_elsa.daily_consumption.charbon','model.dbt_elsa.daily_consumption','charbon','float','[]','{}','elsa','bronze','daily_consumption','Production for coal energy in TWH','model','2025-07-18 20:44:04','7ab14ad5a82cf844237c79796ea76a4d'),('column.model.dbt_elsa.daily_consumption.solaire','model.dbt_elsa.daily_consumption','solaire','float','[]','{}','elsa','bronze','daily_consumption','Production for solar energy in TWH','model','2025-07-18 20:44:04','f8c5d217d3d31b9919cbc73644d37265'),('column.model.dbt_elsa.daily_consumption.eolien','model.dbt_elsa.daily_consumption','eolien','float','[]','{}','elsa','bronze','daily_consumption','Production for eolian energy in TWH','model','2025-07-18 20:44:04','dac2f8348537266668cd4c8850f0a0ad'),('column.model.dbt_elsa.daily_consumption.hydraulique','model.dbt_elsa.daily_consumption','hydraulique','float','[]','{}','elsa','bronze','daily_consumption','Production for hydrolic energy in TWH','model','2025-07-18 20:44:04','d290a08dfab4e1855a9893ca12f95784'),('column.model.dbt_elsa.daily_consumption.bioenergies','model.dbt_elsa.daily_consumption','bioenergies','float','[]','{}','elsa','bronze','daily_consumption','Production for bioenergy energy in TWH','model','2025-07-18 20:44:04','572c4c651fed95c173ad7a463718c51a'),('column.model.dbt_elsa.daily_consumption.autres','model.dbt_elsa.daily_consumption','autres','float','[]','{}','elsa','bronze','daily_consumption','Production for other energy in TWH','model','2025-07-18 20:44:04','9f4a0fa51ccd9d73d9ed989c1bed32a2'),('column.model.dbt_elsa.daily_consumption.prevision_j','model.dbt_elsa.daily_consumption','prevision_j','float','[]','{}','elsa','bronze','daily_consumption','Pprevision_j','model','2025-07-18 20:44:04','8a0f0a86271b42de2ee1ac75b0d922b6'),('column.model.dbt_elsa.daily_consumption.prevision_j1','model.dbt_elsa.daily_consumption','prevision_j1','float','[]','{}','elsa','bronze','daily_consumption','prevision_j1','model','2025-07-18 20:44:04','57bfd15cd8de45edae4068a74ccffdca')
  
[0m22:44:04.782008 [debug] [MainThread]: SQL status: INSERT 0 14 in 0.001 seconds
[0m22:44:04.784975 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.785358 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_columns"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_columns__tmp_20250718204404657306224404657555");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250718204404695191224404695442";
        
        commit;
    
  
[0m22:44:04.787672 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m22:44:04.792023 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718204404657306224404657555"
[0m22:44:04.793005 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.793430 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718204404657306224404657555" cascade
[0m22:44:04.795006 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m22:44:04.798722 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718204404695191224404695442"
[0m22:44:04.799357 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.799718 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718204404695191224404695442" cascade
[0m22:44:04.801165 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m22:44:04.802345 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m22:44:04.804510 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m22:44:04.805418 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.153546 (1 runs)
[0m22:44:04.806508 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.018189 (2 runs)
[0m22:44:04.807335 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001213 (2 runs)
[0m22:44:04.808225 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.071156 (28 runs)
[0m22:44:04.809041 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.080715 (2 runs)
[0m22:44:04.810072 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.009189 (2 runs)
[0m22:44:04.810891 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.114432 (2 runs)
[0m22:44:04.811708 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.307449 (1 runs)
[0m22:44:04.812569 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m22:44:04.816598 [debug] [MainThread]: Elementary: Uploading run results.
[0m22:44:04.817462 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m22:44:04.844255 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 1 artifacts.
[0m22:44:04.848539 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.849010 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m22:44:04.854445 [debug] [MainThread]: SQL status: SELECT 23 in 0.005 seconds
[0m22:44:04.857133 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m22:44:04.874051 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:04.875585 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.876485 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('7f6c930c-1281-4055-99b6-02d96ac15e68.model.dbt_elsa.daily_consumption','model.dbt_elsa.daily_consumption','7f6c930c-1281-4055-99b6-02d96ac15e68','2025-07-18 20:44:04',
    current_timestamp::timestamp
,'daily_consumption','SELECT 96','success','model',0.1856062412261963,'2025-07-18T20:44:03.644730Z','2025-07-18T20:44:03.821098Z','2025-07-18T20:44:03.637743Z','2025-07-18T20:44:03.644226Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    data->>''gaz'' AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL)
  
[0m22:44:04.878274 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m22:44:04.880960 [debug] [MainThread]: On master: COMMIT
[0m22:44:04.881509 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.882311 [debug] [MainThread]: On master: COMMIT
[0m22:44:04.883946 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:44:04.888621 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m22:44:04.889454 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025826 (1 runs)
[0m22:44:04.890200 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.011305 (1 runs)
[0m22:44:04.890923 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000742 (1 runs)
[0m22:44:04.891631 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.013255 (1 runs)
[0m22:44:04.892337 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.015500 (1 runs)
[0m22:44:04.893047 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005468 (1 runs)
[0m22:44:04.893757 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.004600 (1 runs)
[0m22:44:04.894465 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.042260 (1 runs)
[0m22:44:04.895175 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.070894 (1 runs)
[0m22:44:04.895945 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m22:44:04.912159 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m22:44:04.975392 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.976000 [debug] [MainThread]: On master: BEGIN
[0m22:44:04.976880 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m22:44:04.977324 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:04.977817 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m22:44:04.981889 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m22:44:04.984737 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m22:44:05.005549 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:44:05.006723 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:05.007386 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('7f6c930c-1281-4055-99b6-02d96ac15e68',NULL,NULL,NULL,'2025-07-18 20:43:57','2025-07-18 20:44:04','2025-07-18 20:44:04',
    current_timestamp::timestamp
,'run','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m22:44:05.008597 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m22:44:05.011451 [debug] [MainThread]: On master: COMMIT
[0m22:44:05.011911 [debug] [MainThread]: Using postgres connection "master"
[0m22:44:05.012269 [debug] [MainThread]: On master: COMMIT
[0m22:44:05.013592 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:44:05.015912 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m22:44:05.022248 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:44:05.023201 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m22:44:05.023743 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.19s]
[0m22:44:05.024142 [debug] [MainThread]: On master: Close
[0m22:44:05.024628 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:44:05.024937 [debug] [MainThread]: Connection 'model.dbt_elsa.daily_consumption' was properly closed.
[0m22:44:05.025211 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m22:44:05.025573 [info ] [MainThread]: 
[0m22:44:05.026221 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 1.66 seconds (1.66s).
[0m22:44:05.027723 [debug] [MainThread]: Command end result
[0m22:44:05.197673 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:44:05.200414 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:44:05.207590 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m22:44:05.207958 [info ] [MainThread]: 
[0m22:44:05.208355 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:44:05.208747 [info ] [MainThread]: 
[0m22:44:05.209172 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m22:44:05.213376 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.009753, "process_in_blocks": "0", "process_kernel_time": 0.944502, "process_mem_max_rss": "143757312", "process_out_blocks": "0", "process_user_time": 9.280564}
[0m22:44:05.214028 [debug] [MainThread]: Command `dbt run` succeeded at 22:44:05.213891 after 8.01 seconds
[0m22:44:05.214493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a919130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5619a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aab7550>]}
[0m22:44:05.215106 [debug] [MainThread]: Flushing usage events
[0m22:44:05.677969 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:48:22.087059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b03770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051f7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051f74d0>]}


============================== 22:48:22.098145 | 30ffc97c-130f-4e4f-b29d-f021e3f0ec2b ==============================
[0m22:48:22.098145 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:48:22.099191 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:48:22.255004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30ffc97c-130f-4e4f-b29d-f021e3f0ec2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10457c510>]}
[0m22:48:22.456017 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-6vjbcaes'
[0m22:48:22.456539 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:48:22.604164 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:48:22.605692 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:48:22.687408 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:48:22.696774 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m22:48:22.770217 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m22:48:22.778898 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m22:48:22.862778 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m22:48:22.875121 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m22:48:22.970300 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m22:48:22.977931 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:48:23.399218 [info ] [MainThread]: Installed from version 1.3.0
[0m22:48:23.400161 [info ] [MainThread]: Up to date!
[0m22:48:23.401161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '30ffc97c-130f-4e4f-b29d-f021e3f0ec2b', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105082be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ce7a0>]}
[0m22:48:23.401844 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m22:48:24.093651 [info ] [MainThread]: Installed from version 0.10.9
[0m22:48:24.094128 [info ] [MainThread]: Up to date!
[0m22:48:24.094535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '30ffc97c-130f-4e4f-b29d-f021e3f0ec2b', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105400b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104af1220>]}
[0m22:48:24.094963 [info ] [MainThread]: Installing elementary-data/elementary
[0m22:48:24.624583 [info ] [MainThread]: Installed from version 0.19.0
[0m22:48:24.625189 [info ] [MainThread]: Updated version available: 0.19.1
[0m22:48:24.625738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '30ffc97c-130f-4e4f-b29d-f021e3f0ec2b', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105430ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105430f30>]}
[0m22:48:24.626479 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m22:48:24.892865 [info ] [MainThread]: Installed from version 0.14.2
[0m22:48:24.893326 [info ] [MainThread]: Up to date!
[0m22:48:24.893711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '30ffc97c-130f-4e4f-b29d-f021e3f0ec2b', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f90d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f9490>]}
[0m22:48:24.894138 [info ] [MainThread]: 
[0m22:48:24.894498 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m22:48:24.899977 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.9190516, "process_in_blocks": "0", "process_kernel_time": 0.899671, "process_mem_max_rss": "114614272", "process_out_blocks": "0", "process_user_time": 2.711656}
[0m22:48:24.901018 [debug] [MainThread]: Command `dbt deps` succeeded at 22:48:24.900824 after 2.92 seconds
[0m22:48:24.901509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054283c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10451d770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105427ed0>]}
[0m22:48:24.901927 [debug] [MainThread]: Flushing usage events
[0m22:48:25.340792 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:49:11.887893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9d7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0cb4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0cb750>]}


============================== 22:49:11.893092 | 3dd879b1-137e-403f-99a2-2c68f8e1d608 ==============================
[0m22:49:11.893092 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:49:11.893817 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:49:12.161385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3dd879b1-137e-403f-99a2-2c68f8e1d608', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b450510>]}
[0m22:49:12.233272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3dd879b1-137e-403f-99a2-2c68f8e1d608', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf57df0>]}
[0m22:49:44.455163 [error] [MainThread]: Encountered an error:

[0m22:49:44.470235 [error] [MainThread]: Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 161, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 111, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 254, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 285, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 332, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/main.py", line 307, in docs_serve
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
    ~~~~~~~~~~~~~~~~~~~^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py", line 398, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt

[0m22:49:44.474649 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 32.674274, "process_in_blocks": "0", "process_kernel_time": 0.242506, "process_mem_max_rss": "110735360", "process_out_blocks": "0", "process_user_time": 1.815006}
[0m22:49:44.475678 [debug] [MainThread]: Command `dbt docs serve` failed at 22:49:44.475487 after 32.68 seconds
[0m22:49:44.476411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c725c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c725e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6f7020>]}
[0m22:49:44.477051 [debug] [MainThread]: Flushing usage events
[0m22:49:44.940724 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:49:55.145254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eac7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101c34d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101c3750>]}


============================== 22:49:55.150454 | 2806f561-6393-4e64-b2b5-6935c5d14eff ==============================
[0m22:49:55.150454 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:49:55.151091 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:49:55.364786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2806f561-6393-4e64-b2b5-6935c5d14eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f540510>]}
[0m22:49:55.444542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2806f561-6393-4e64-b2b5-6935c5d14eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110047df0>]}
[0m22:49:55.446481 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:49:55.600456 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m22:49:55.934926 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m22:49:55.935646 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/bronze/consumption.sql
[0m22:49:55.936068 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/bronze/daily_consumption.sql
[0m22:49:56.310893 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'daily_consumption' in the 'models' section of file 'models/bronze/_elsa_bronze__models.yml'
[0m22:49:56.427886 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_elsa.not_null_daily_consumption_id.9183981eb4' (models/bronze/_elsa_bronze__models.yml) depends on a node named 'daily_consumption' in package '' which was not found
[0m22:49:56.428451 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_elsa.not_null_daily_consumption_created_at.d60c851a3a' (models/bronze/_elsa_bronze__models.yml) depends on a node named 'daily_consumption' in package '' which was not found
[0m22:49:56.428841 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_elsa.not_null_daily_consumption_date.c78a11ccee' (models/bronze/_elsa_bronze__models.yml) depends on a node named 'daily_consumption' in package '' which was not found
[0m22:49:56.429216 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_elsa.not_null_daily_consumption_time.ab08545457' (models/bronze/_elsa_bronze__models.yml) depends on a node named 'daily_consumption' in package '' which was not found
[0m22:49:56.529408 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
- seeds.dbt_elsa
[0m22:49:56.546814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2806f561-6393-4e64-b2b5-6935c5d14eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11141de50>]}
[0m22:49:56.570966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2806f561-6393-4e64-b2b5-6935c5d14eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115355e0>]}
[0m22:49:56.571500 [info ] [MainThread]: Found 31 models, 2 operations, 1 source, 1571 macros
[0m22:49:56.571893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2806f561-6393-4e64-b2b5-6935c5d14eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116bbcb0>]}
[0m22:49:56.575114 [info ] [MainThread]: 
[0m22:49:56.575575 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m22:49:56.575921 [info ] [MainThread]: 
[0m22:49:56.576590 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:49:56.583613 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m22:49:56.584248 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m22:49:56.661207 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:49:56.661737 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m22:49:56.662073 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m22:49:56.662436 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m22:49:56.662801 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:49:56.663146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:49:56.697449 [debug] [ThreadPool]: SQL status: BEGIN in 0.035 seconds
[0m22:49:56.697980 [debug] [ThreadPool]: SQL status: BEGIN in 0.035 seconds
[0m22:49:56.698309 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m22:49:56.698653 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m22:49:56.699012 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m22:49:56.699395 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m22:49:56.703828 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m22:49:56.704243 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m22:49:56.706203 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m22:49:56.707556 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m22:49:56.708358 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m22:49:56.708782 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m22:49:56.722496 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:56.722888 [debug] [MainThread]: On master: BEGIN
[0m22:49:56.723185 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:49:56.728753 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:49:56.729161 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:56.729565 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:49:56.769102 [debug] [MainThread]: SQL status: SELECT 26 in 0.039 seconds
[0m22:49:56.776532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2806f561-6393-4e64-b2b5-6935c5d14eff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119061a0>]}
[0m22:49:56.777047 [debug] [MainThread]: On master: ROLLBACK
[0m22:49:56.777620 [debug] [MainThread]: On master: Close
[0m22:49:56.782541 [debug] [Thread-8 (]: Began running node model.elementary.dbt_models
[0m22:49:56.783047 [debug] [Thread-2 (]: Began running node model.elementary.data_monitoring_metrics
[0m22:49:56.783446 [debug] [Thread-5 (]: Began running node model.elementary.dbt_groups
[0m22:49:56.783833 [debug] [Thread-6 (]: Began running node model.elementary.dbt_invocations
[0m22:49:56.784189 [debug] [Thread-11 ]: Began running node model.elementary.dbt_snapshots
[0m22:49:56.784575 [debug] [Thread-9 (]: Began running node model.elementary.dbt_run_results
[0m22:49:56.784929 [debug] [Thread-14 ]: Began running node model.elementary.dbt_tests
[0m22:49:56.785288 [debug] [Thread-15 ]: Began running node model.elementary.elementary_test_results
[0m22:49:56.785642 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m22:49:56.785993 [debug] [Thread-13 ]: Began running node model.elementary.dbt_sources
[0m22:49:56.786339 [debug] [Thread-4 (]: Began running node model.elementary.dbt_exposures
[0m22:49:56.786741 [debug] [Thread-7 (]: Began running node model.elementary.dbt_metrics
[0m22:49:56.787111 [debug] [Thread-10 ]: Began running node model.elementary.dbt_seeds
[0m22:49:56.787656 [debug] [Thread-12 ]: Began running node model.elementary.dbt_source_freshness_results
[0m22:49:56.788023 [debug] [Thread-16 ]: Began running node model.elementary.metadata
[0m22:49:56.788379 [debug] [Thread-3 (]: Began running node model.elementary.dbt_columns
[0m22:49:56.788927 [debug] [Thread-8 (]: Acquiring new postgres connection 'model.elementary.dbt_models'
[0m22:49:56.789370 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.elementary.data_monitoring_metrics)
[0m22:49:56.789863 [debug] [Thread-5 (]: Acquiring new postgres connection 'model.elementary.dbt_groups'
[0m22:49:56.790345 [debug] [Thread-6 (]: Acquiring new postgres connection 'model.elementary.dbt_invocations'
[0m22:49:56.790827 [debug] [Thread-11 ]: Acquiring new postgres connection 'model.elementary.dbt_snapshots'
[0m22:49:56.791357 [debug] [Thread-9 (]: Acquiring new postgres connection 'model.elementary.dbt_run_results'
[0m22:49:56.791842 [debug] [Thread-14 ]: Acquiring new postgres connection 'model.elementary.dbt_tests'
[0m22:49:56.792331 [debug] [Thread-15 ]: Acquiring new postgres connection 'model.elementary.elementary_test_results'
[0m22:49:56.792735 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption)
[0m22:49:56.793216 [debug] [Thread-13 ]: Acquiring new postgres connection 'model.elementary.dbt_sources'
[0m22:49:56.793699 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.elementary.dbt_exposures'
[0m22:49:56.794172 [debug] [Thread-7 (]: Acquiring new postgres connection 'model.elementary.dbt_metrics'
[0m22:49:56.794660 [debug] [Thread-10 ]: Acquiring new postgres connection 'model.elementary.dbt_seeds'
[0m22:49:56.795179 [debug] [Thread-12 ]: Acquiring new postgres connection 'model.elementary.dbt_source_freshness_results'
[0m22:49:56.795770 [debug] [Thread-16 ]: Acquiring new postgres connection 'model.elementary.metadata'
[0m22:49:56.796734 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.elementary.dbt_columns'
[0m22:49:56.797244 [debug] [Thread-8 (]: Began compiling node model.elementary.dbt_models
[0m22:49:56.797646 [debug] [Thread-2 (]: Began compiling node model.elementary.data_monitoring_metrics
[0m22:49:56.798049 [debug] [Thread-5 (]: Began compiling node model.elementary.dbt_groups
[0m22:49:56.798453 [debug] [Thread-6 (]: Began compiling node model.elementary.dbt_invocations
[0m22:49:56.798831 [debug] [Thread-11 ]: Began compiling node model.elementary.dbt_snapshots
[0m22:49:56.799301 [debug] [Thread-9 (]: Began compiling node model.elementary.dbt_run_results
[0m22:49:56.799809 [debug] [Thread-14 ]: Began compiling node model.elementary.dbt_tests
[0m22:49:56.800254 [debug] [Thread-15 ]: Began compiling node model.elementary.elementary_test_results
[0m22:49:56.800649 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m22:49:56.801041 [debug] [Thread-13 ]: Began compiling node model.elementary.dbt_sources
[0m22:49:56.801466 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_exposures
[0m22:49:56.801885 [debug] [Thread-7 (]: Began compiling node model.elementary.dbt_metrics
[0m22:49:56.802271 [debug] [Thread-10 ]: Began compiling node model.elementary.dbt_seeds
[0m22:49:56.802653 [debug] [Thread-12 ]: Began compiling node model.elementary.dbt_source_freshness_results
[0m22:49:56.803027 [debug] [Thread-16 ]: Began compiling node model.elementary.metadata
[0m22:49:56.803500 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_columns
[0m22:49:56.902956 [debug] [Thread-5 (]: Writing injected SQL for node "model.elementary.dbt_groups"
[0m22:49:56.923101 [debug] [Thread-8 (]: Writing injected SQL for node "model.elementary.dbt_models"
[0m22:49:56.935747 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.data_monitoring_metrics"
[0m22:49:56.950332 [debug] [Thread-11 ]: Writing injected SQL for node "model.elementary.dbt_snapshots"
[0m22:49:56.952257 [debug] [Thread-6 (]: Writing injected SQL for node "model.elementary.dbt_invocations"
[0m22:49:56.978051 [debug] [Thread-9 (]: Writing injected SQL for node "model.elementary.dbt_run_results"
[0m22:49:56.993191 [debug] [Thread-14 ]: Writing injected SQL for node "model.elementary.dbt_tests"
[0m22:49:57.003478 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m22:49:57.005390 [debug] [Thread-15 ]: Writing injected SQL for node "model.elementary.elementary_test_results"
[0m22:49:57.025341 [debug] [Thread-13 ]: Writing injected SQL for node "model.elementary.dbt_sources"
[0m22:49:57.040413 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_exposures"
[0m22:49:57.052813 [debug] [Thread-7 (]: Writing injected SQL for node "model.elementary.dbt_metrics"
[0m22:49:57.065086 [debug] [Thread-10 ]: Writing injected SQL for node "model.elementary.dbt_seeds"
[0m22:49:57.082755 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.dbt_source_freshness_results"
[0m22:49:57.087377 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_columns"
[0m22:49:57.088509 [debug] [Thread-16 ]: Writing injected SQL for node "model.elementary.metadata"
[0m22:49:57.090131 [debug] [Thread-14 ]: Began executing node model.elementary.dbt_tests
[0m22:49:57.090588 [debug] [Thread-5 (]: Began executing node model.elementary.dbt_groups
[0m22:49:57.090960 [debug] [Thread-8 (]: Began executing node model.elementary.dbt_models
[0m22:49:57.091512 [debug] [Thread-11 ]: Began executing node model.elementary.dbt_snapshots
[0m22:49:57.091944 [debug] [Thread-6 (]: Began executing node model.elementary.dbt_invocations
[0m22:49:57.092394 [debug] [Thread-9 (]: Began executing node model.elementary.dbt_run_results
[0m22:49:57.092838 [debug] [Thread-2 (]: Began executing node model.elementary.data_monitoring_metrics
[0m22:49:57.093716 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m22:49:57.094380 [debug] [Thread-13 ]: Began executing node model.elementary.dbt_sources
[0m22:49:57.094994 [debug] [Thread-15 ]: Began executing node model.elementary.elementary_test_results
[0m22:49:57.095756 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_exposures
[0m22:49:57.096967 [debug] [Thread-7 (]: Began executing node model.elementary.dbt_metrics
[0m22:49:57.097667 [debug] [Thread-10 ]: Began executing node model.elementary.dbt_seeds
[0m22:49:57.098483 [debug] [Thread-12 ]: Began executing node model.elementary.dbt_source_freshness_results
[0m22:49:57.099783 [debug] [Thread-14 ]: Finished running node model.elementary.dbt_tests
[0m22:49:57.101332 [debug] [Thread-5 (]: Finished running node model.elementary.dbt_groups
[0m22:49:57.102079 [debug] [Thread-16 ]: Began executing node model.elementary.metadata
[0m22:49:57.103181 [debug] [Thread-8 (]: Finished running node model.elementary.dbt_models
[0m22:49:57.103682 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_columns
[0m22:49:57.104864 [debug] [Thread-11 ]: Finished running node model.elementary.dbt_snapshots
[0m22:49:57.105909 [debug] [Thread-6 (]: Finished running node model.elementary.dbt_invocations
[0m22:49:57.107066 [debug] [Thread-9 (]: Finished running node model.elementary.dbt_run_results
[0m22:49:57.108461 [debug] [Thread-2 (]: Finished running node model.elementary.data_monitoring_metrics
[0m22:49:57.109599 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m22:49:57.110770 [debug] [Thread-13 ]: Finished running node model.elementary.dbt_sources
[0m22:49:57.112123 [debug] [Thread-15 ]: Finished running node model.elementary.elementary_test_results
[0m22:49:57.113506 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_exposures
[0m22:49:57.114912 [debug] [Thread-7 (]: Finished running node model.elementary.dbt_metrics
[0m22:49:57.116183 [debug] [Thread-10 ]: Finished running node model.elementary.dbt_seeds
[0m22:49:57.117538 [debug] [Thread-12 ]: Finished running node model.elementary.dbt_source_freshness_results
[0m22:49:57.118474 [debug] [Thread-14 ]: Began running node model.elementary.schema_columns_snapshot
[0m22:49:57.119473 [debug] [Thread-5 (]: Began running node operation.elementary.elementary-on-run-end-0
[0m22:49:57.121041 [debug] [Thread-16 ]: Finished running node model.elementary.metadata
[0m22:49:57.121839 [debug] [Thread-8 (]: Began running node operation.elementary.elementary-on-run-start-0
[0m22:49:57.123433 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_columns
[0m22:49:57.124978 [debug] [Thread-11 ]: Began running node model.elementary.job_run_results
[0m22:49:57.126199 [debug] [Thread-2 (]: Began running node model.elementary.metrics_anomaly_score
[0m22:49:57.126866 [debug] [Thread-9 (]: Began running node model.elementary.snapshot_run_results
[0m22:49:57.127700 [debug] [Thread-1 (]: Began running node model.elementary.monitors_runs
[0m22:49:57.128491 [debug] [Thread-6 (]: Began running node model.elementary.model_run_results
[0m22:49:57.130525 [debug] [Thread-15 ]: Began running node model.elementary.alerts_dbt_tests
[0m22:49:57.131281 [debug] [Thread-13 ]: Began running node model.elementary.alerts_anomaly_detection
[0m22:49:57.132035 [debug] [Thread-4 (]: Began running node model.elementary.alerts_schema_changes
[0m22:49:57.132755 [debug] [Thread-10 ]: Began running node model.elementary.seed_run_results
[0m22:49:57.133541 [debug] [Thread-7 (]: Began running node model.elementary.test_result_rows
[0m22:49:57.134607 [debug] [Thread-14 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_tests, now model.elementary.schema_columns_snapshot)
[0m22:49:57.147703 [debug] [Thread-14 ]: Began compiling node model.elementary.schema_columns_snapshot
[0m22:49:57.135476 [debug] [Thread-12 ]: Began running node model.elementary.alerts_dbt_source_freshness
[0m22:49:57.137585 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_models, now operation.elementary.elementary-on-run-start-0)
[0m22:49:57.138721 [debug] [Thread-11 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_snapshots, now model.elementary.job_run_results)
[0m22:49:57.139586 [debug] [Thread-16 ]: Began running node model.elementary.dbt_artifacts_hashes
[0m22:49:57.140369 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.data_monitoring_metrics, now model.elementary.metrics_anomaly_score)
[0m22:49:57.141445 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_run_results, now model.elementary.snapshot_run_results)
[0m22:49:57.142312 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_elsa.consumption, now model.elementary.monitors_runs)
[0m22:49:57.143038 [debug] [Thread-6 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_invocations, now model.elementary.model_run_results)
[0m22:49:57.143836 [debug] [Thread-15 ]: Re-using an available connection from the pool (formerly model.elementary.elementary_test_results, now model.elementary.alerts_dbt_tests)
[0m22:49:57.144780 [debug] [Thread-13 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_sources, now model.elementary.alerts_anomaly_detection)
[0m22:49:57.145498 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_exposures, now model.elementary.alerts_schema_changes)
[0m22:49:57.146178 [debug] [Thread-10 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_seeds, now model.elementary.seed_run_results)
[0m22:49:57.146887 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_metrics, now model.elementary.test_result_rows)
[0m22:49:57.136547 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_groups, now operation.elementary.elementary-on-run-end-0)
[0m22:49:57.159673 [debug] [Thread-12 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_source_freshness_results, now model.elementary.alerts_dbt_source_freshness)
[0m22:49:57.164746 [debug] [Thread-14 ]: Writing injected SQL for node "model.elementary.schema_columns_snapshot"
[0m22:49:57.165510 [debug] [Thread-8 (]: Began compiling node operation.elementary.elementary-on-run-start-0
[0m22:49:57.166485 [debug] [Thread-11 ]: Began compiling node model.elementary.job_run_results
[0m22:49:57.167211 [debug] [Thread-16 ]: Re-using an available connection from the pool (formerly model.elementary.metadata, now model.elementary.dbt_artifacts_hashes)
[0m22:49:57.167910 [debug] [Thread-2 (]: Began compiling node model.elementary.metrics_anomaly_score
[0m22:49:57.168601 [debug] [Thread-9 (]: Began compiling node model.elementary.snapshot_run_results
[0m22:49:57.169253 [debug] [Thread-1 (]: Began compiling node model.elementary.monitors_runs
[0m22:49:57.169955 [debug] [Thread-6 (]: Began compiling node model.elementary.model_run_results
[0m22:49:57.170633 [debug] [Thread-15 ]: Began compiling node model.elementary.alerts_dbt_tests
[0m22:49:57.171309 [debug] [Thread-13 ]: Began compiling node model.elementary.alerts_anomaly_detection
[0m22:49:57.172033 [debug] [Thread-4 (]: Began compiling node model.elementary.alerts_schema_changes
[0m22:49:57.172745 [debug] [Thread-10 ]: Began compiling node model.elementary.seed_run_results
[0m22:49:57.173471 [debug] [Thread-7 (]: Began compiling node model.elementary.test_result_rows
[0m22:49:57.174210 [debug] [Thread-5 (]: Began compiling node operation.elementary.elementary-on-run-end-0
[0m22:49:57.174920 [debug] [Thread-12 ]: Began compiling node model.elementary.alerts_dbt_source_freshness
[0m22:49:57.181286 [debug] [Thread-14 ]: Began executing node model.elementary.schema_columns_snapshot
[0m22:49:57.219890 [debug] [Thread-16 ]: Began compiling node model.elementary.dbt_artifacts_hashes
[0m22:49:57.258686 [debug] [Thread-8 (]: Elementary: Materialization override is enabled.
[0m22:49:57.277435 [debug] [Thread-9 (]: Writing injected SQL for node "model.elementary.snapshot_run_results"
[0m22:49:57.288447 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.monitors_runs"
[0m22:49:57.300108 [debug] [Thread-11 ]: Writing injected SQL for node "model.elementary.job_run_results"
[0m22:49:57.313970 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.metrics_anomaly_score"
[0m22:49:57.317251 [debug] [Thread-6 (]: Writing injected SQL for node "model.elementary.model_run_results"
[0m22:49:57.323056 [debug] [Thread-15 ]: Writing injected SQL for node "model.elementary.alerts_dbt_tests"
[0m22:49:57.329150 [debug] [Thread-13 ]: Writing injected SQL for node "model.elementary.alerts_anomaly_detection"
[0m22:49:57.335414 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.alerts_schema_changes"
[0m22:49:57.339892 [debug] [Thread-10 ]: Writing injected SQL for node "model.elementary.seed_run_results"
[0m22:49:57.347835 [debug] [Thread-7 (]: Writing injected SQL for node "model.elementary.test_result_rows"
[0m22:49:57.359839 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.alerts_dbt_source_freshness"
[0m22:49:57.365946 [debug] [Thread-14 ]: Finished running node model.elementary.schema_columns_snapshot
[0m22:49:57.365181 [debug] [Thread-5 (]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:49:57.377724 [debug] [Thread-8 (]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:49:57.383550 [debug] [Thread-16 ]: Writing injected SQL for node "model.elementary.dbt_artifacts_hashes"
[0m22:49:57.385769 [debug] [Thread-10 ]: Began executing node model.elementary.seed_run_results
[0m22:49:57.386298 [debug] [Thread-1 (]: Began executing node model.elementary.monitors_runs
[0m22:49:57.386837 [debug] [Thread-6 (]: Began executing node model.elementary.model_run_results
[0m22:49:57.387278 [debug] [Thread-2 (]: Began executing node model.elementary.metrics_anomaly_score
[0m22:49:57.387821 [debug] [Thread-11 ]: Began executing node model.elementary.job_run_results
[0m22:49:57.388467 [debug] [Thread-7 (]: Began executing node model.elementary.test_result_rows
[0m22:49:57.388997 [debug] [Thread-5 (]: Began executing node operation.elementary.elementary-on-run-end-0
[0m22:49:57.389937 [debug] [Thread-10 ]: Finished running node model.elementary.seed_run_results
[0m22:49:57.390587 [debug] [Thread-15 ]: Began executing node model.elementary.alerts_dbt_tests
[0m22:49:57.391248 [debug] [Thread-9 (]: Began executing node model.elementary.snapshot_run_results
[0m22:49:57.391865 [debug] [Thread-12 ]: Began executing node model.elementary.alerts_dbt_source_freshness
[0m22:49:57.392793 [debug] [Thread-4 (]: Began executing node model.elementary.alerts_schema_changes
[0m22:49:57.394378 [debug] [Thread-1 (]: Finished running node model.elementary.monitors_runs
[0m22:49:57.395143 [debug] [Thread-13 ]: Began executing node model.elementary.alerts_anomaly_detection
[0m22:49:57.395815 [debug] [Thread-8 (]: Began executing node operation.elementary.elementary-on-run-start-0
[0m22:49:57.397137 [debug] [Thread-6 (]: Finished running node model.elementary.model_run_results
[0m22:49:57.397785 [debug] [Thread-16 ]: Began executing node model.elementary.dbt_artifacts_hashes
[0m22:49:57.398985 [debug] [Thread-2 (]: Finished running node model.elementary.metrics_anomaly_score
[0m22:49:57.400193 [debug] [Thread-11 ]: Finished running node model.elementary.job_run_results
[0m22:49:57.401416 [debug] [Thread-7 (]: Finished running node model.elementary.test_result_rows
[0m22:49:57.402731 [debug] [Thread-5 (]: Finished running node operation.elementary.elementary-on-run-end-0
[0m22:49:57.404149 [debug] [Thread-15 ]: Finished running node model.elementary.alerts_dbt_tests
[0m22:49:57.405443 [debug] [Thread-9 (]: Finished running node model.elementary.snapshot_run_results
[0m22:49:57.406718 [debug] [Thread-12 ]: Finished running node model.elementary.alerts_dbt_source_freshness
[0m22:49:57.407901 [debug] [Thread-4 (]: Finished running node model.elementary.alerts_schema_changes
[0m22:49:57.409200 [debug] [Thread-13 ]: Finished running node model.elementary.alerts_anomaly_detection
[0m22:49:57.410268 [debug] [Thread-8 (]: Finished running node operation.elementary.elementary-on-run-start-0
[0m22:49:57.411274 [debug] [Thread-16 ]: Finished running node model.elementary.dbt_artifacts_hashes
[0m22:49:57.412116 [debug] [Thread-3 (]: Began running node model.elementary.anomaly_threshold_sensitivity
[0m22:49:57.413265 [debug] [Thread-14 ]: Began running node model.elementary.alerts_dbt_models
[0m22:49:57.414608 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_columns, now model.elementary.anomaly_threshold_sensitivity)
[0m22:49:57.415095 [debug] [Thread-14 ]: Re-using an available connection from the pool (formerly model.elementary.schema_columns_snapshot, now model.elementary.alerts_dbt_models)
[0m22:49:57.415652 [debug] [Thread-3 (]: Began compiling node model.elementary.anomaly_threshold_sensitivity
[0m22:49:57.416132 [debug] [Thread-14 ]: Began compiling node model.elementary.alerts_dbt_models
[0m22:49:57.424910 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.anomaly_threshold_sensitivity"
[0m22:49:57.431290 [debug] [Thread-14 ]: Writing injected SQL for node "model.elementary.alerts_dbt_models"
[0m22:49:57.432051 [debug] [Thread-3 (]: Began executing node model.elementary.anomaly_threshold_sensitivity
[0m22:49:57.432803 [debug] [Thread-3 (]: Finished running node model.elementary.anomaly_threshold_sensitivity
[0m22:49:57.433246 [debug] [Thread-14 ]: Began executing node model.elementary.alerts_dbt_models
[0m22:49:57.433926 [debug] [Thread-14 ]: Finished running node model.elementary.alerts_dbt_models
[0m22:49:57.435684 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:49:57.436022 [debug] [MainThread]: Connection 'model.elementary.monitors_runs' was properly closed.
[0m22:49:57.436312 [debug] [MainThread]: Connection 'model.elementary.metrics_anomaly_score' was properly closed.
[0m22:49:57.436599 [debug] [MainThread]: Connection 'operation.elementary.elementary-on-run-start-0' was properly closed.
[0m22:49:57.436881 [debug] [MainThread]: Connection 'operation.elementary.elementary-on-run-end-0' was properly closed.
[0m22:49:57.437157 [debug] [MainThread]: Connection 'model.elementary.model_run_results' was properly closed.
[0m22:49:57.437430 [debug] [MainThread]: Connection 'model.elementary.job_run_results' was properly closed.
[0m22:49:57.437703 [debug] [MainThread]: Connection 'model.elementary.snapshot_run_results' was properly closed.
[0m22:49:57.437975 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_models' was properly closed.
[0m22:49:57.438248 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_tests' was properly closed.
[0m22:49:57.438519 [debug] [MainThread]: Connection 'model.elementary.alerts_anomaly_detection' was properly closed.
[0m22:49:57.438792 [debug] [MainThread]: Connection 'model.elementary.alerts_schema_changes' was properly closed.
[0m22:49:57.439062 [debug] [MainThread]: Connection 'model.elementary.test_result_rows' was properly closed.
[0m22:49:57.439331 [debug] [MainThread]: Connection 'model.elementary.seed_run_results' was properly closed.
[0m22:49:57.439602 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_source_freshness' was properly closed.
[0m22:49:57.439889 [debug] [MainThread]: Connection 'model.elementary.dbt_artifacts_hashes' was properly closed.
[0m22:49:57.440156 [debug] [MainThread]: Connection 'model.elementary.anomaly_threshold_sensitivity' was properly closed.
[0m22:49:57.446023 [debug] [MainThread]: Command end result
[0m22:49:57.613899 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:49:57.617732 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:49:57.626907 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m22:49:57.629150 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m22:49:57.629525 [info ] [MainThread]: Building catalog
[0m22:49:57.644076 [debug] [ThreadPool]: Acquiring new postgres connection 'elsa.information_schema'
[0m22:49:57.659040 [debug] [ThreadPool]: Using postgres connection "elsa.information_schema"
[0m22:49:57.659449 [debug] [ThreadPool]: On elsa.information_schema: BEGIN
[0m22:49:57.659742 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:49:57.665449 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:49:57.665994 [debug] [ThreadPool]: Using postgres connection "elsa.information_schema"
[0m22:49:57.666638 [debug] [ThreadPool]: On elsa.information_schema: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "elsa.information_schema"} */

    
    

    select
        'elsa' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_snapshots')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_dbt_source_freshness')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('seed_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_artifacts_hashes')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_sources')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('job_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('test_result_rows')) or (upper(sch.nspname) = upper('bronze') and
           upper(tbl.relname) = upper('consumption')) or (upper(sch.nspname) = upper('bronze') and
           upper(tbl.relname) = upper('rte_eco2mix')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_models')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_exposures')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_anomaly_detection')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_dbt_models')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_seeds')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('schema_columns_snapshot')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_columns')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('monitors_runs')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_tests')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_groups')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('metadata')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_invocations')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('snapshot_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_metrics')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('data_monitoring_metrics')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('metrics_anomaly_score')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_dbt_tests')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('model_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_source_freshness_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('elementary_test_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_schema_changes')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('anomaly_threshold_sensitivity')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m22:49:57.682215 [debug] [ThreadPool]: SQL status: SELECT 542 in 0.015 seconds
[0m22:49:57.698478 [debug] [ThreadPool]: On elsa.information_schema: ROLLBACK
[0m22:49:57.699200 [debug] [ThreadPool]: On elsa.information_schema: Close
[0m22:49:57.737360 [debug] [MainThread]: Wrote artifact CatalogArtifact to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/catalog.json
[0m22:49:57.825601 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m22:49:57.828536 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m22:49:57.828916 [info ] [MainThread]: Catalog written to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/catalog.json
[0m22:49:57.832271 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.774343, "process_in_blocks": "0", "process_kernel_time": 0.434935, "process_mem_max_rss": "144818176", "process_out_blocks": "0", "process_user_time": 3.838098}
[0m22:49:57.832936 [debug] [MainThread]: Command `dbt docs generate` succeeded at 22:49:57.832809 after 2.78 seconds
[0m22:49:57.833289 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m22:49:57.833659 [debug] [MainThread]: Connection 'elsa.information_schema' was properly closed.
[0m22:49:57.834207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffbac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b192e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b1be30>]}
[0m22:49:57.834678 [debug] [MainThread]: Flushing usage events
[0m22:49:58.213879 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:50:04.895774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b8b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142b74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142b7750>]}


============================== 22:50:04.901084 | 826cd91e-28ac-44e4-a380-87a3e9a722f4 ==============================
[0m22:50:04.901084 [info ] [MainThread]: Running with dbt=1.10.4
[0m22:50:04.902164 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:50:05.108455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '826cd91e-28ac-44e4-a380-87a3e9a722f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11360c510>]}
[0m22:50:05.182210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '826cd91e-28ac-44e4-a380-87a3e9a722f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11413fdf0>]}
[0m22:50:21.648613 [error] [MainThread]: Encountered an error:

[0m22:50:21.661227 [error] [MainThread]: Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 161, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 111, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 254, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 285, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 332, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/main.py", line 307, in docs_serve
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
    ~~~~~~~~~~~~~~~~~~~^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py", line 398, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt

[0m22:50:21.667262 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 16.860096, "process_in_blocks": "0", "process_kernel_time": 0.22837, "process_mem_max_rss": "110047232", "process_out_blocks": "0", "process_user_time": 1.825937}
[0m22:50:21.668673 [debug] [MainThread]: Command `dbt docs serve` failed at 22:50:21.668417 after 16.86 seconds
[0m22:50:21.669527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114919c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114919e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148eb020>]}
[0m22:50:21.670243 [debug] [MainThread]: Flushing usage events
[0m22:50:22.077342 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:00:46.794219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbf3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112ef610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112ef4d0>]}


============================== 23:00:46.804408 | 010a8238-b4ef-4af6-8a25-440c5601a606 ==============================
[0m23:00:46.804408 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:00:46.805744 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build --select bronze', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:00:47.136799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '010a8238-b4ef-4af6-8a25-440c5601a606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11066c510>]}
[0m23:00:47.218375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '010a8238-b4ef-4af6-8a25-440c5601a606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111173df0>]}
[0m23:00:47.219658 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:00:47.377226 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:00:47.889862 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m23:00:47.890720 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/daily_consumption.sql
[0m23:00:48.323029 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:00:48.343996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '010a8238-b4ef-4af6-8a25-440c5601a606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112571350>]}
[0m23:00:48.518979 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:00:48.523487 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:00:48.591771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '010a8238-b4ef-4af6-8a25-440c5601a606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126bbc50>]}
[0m23:00:48.592418 [info ] [MainThread]: Found 32 models, 2 operations, 1 source, 1571 macros
[0m23:00:48.595057 [info ] [MainThread]: 
[0m23:00:48.595583 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:00:48.595964 [info ] [MainThread]: 
[0m23:00:48.596671 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:00:48.597583 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:00:48.670146 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:00:48.670644 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:00:48.671024 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:48.723069 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.052 seconds
[0m23:00:48.725557 [debug] [ThreadPool]: On list_elsa: Close
[0m23:00:48.733988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:00:48.734717 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:00:48.742256 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:00:48.745035 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:00:48.745426 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:00:48.745819 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:00:48.746159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:00:48.746481 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:48.754200 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:00:48.754658 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:00:48.754994 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:00:48.755334 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:00:48.755698 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:00:48.756089 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:00:48.762261 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.006 seconds
[0m23:00:48.762733 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m23:00:48.764432 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:00:48.765684 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:00:48.766257 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:00:48.766617 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:00:48.780157 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:48.780575 [debug] [MainThread]: On master: BEGIN
[0m23:00:48.780874 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:00:48.786655 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:00:48.787083 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:48.787482 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:00:48.830622 [debug] [MainThread]: SQL status: SELECT 26 in 0.043 seconds
[0m23:00:48.837872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '010a8238-b4ef-4af6-8a25-440c5601a606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b6350>]}
[0m23:00:48.838439 [debug] [MainThread]: On master: ROLLBACK
[0m23:00:48.839197 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:48.839638 [debug] [MainThread]: On master: BEGIN
[0m23:00:48.840559 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:00:48.840937 [debug] [MainThread]: On master: COMMIT
[0m23:00:48.841263 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:48.841586 [debug] [MainThread]: On master: COMMIT
[0m23:00:48.842196 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:00:48.882270 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:00:48.923306 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:48.923923 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:00:48.924937 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m23:00:48.928041 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:00:48.933049 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:00:48.933665 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:00:48.934020 [info ] [MainThread]: 
[0m23:00:48.934385 [debug] [MainThread]: On master: Close
[0m23:00:48.938491 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:00:48.939084 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m23:00:48.939876 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption)
[0m23:00:48.940493 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:00:48.945068 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:00:48.946834 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:00:48.995819 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:00:48.996787 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:00:48.997182 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:00:48.997535 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:00:49.002913 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m23:00:49.003389 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:00:49.003777 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:00:49.014423 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.010 seconds
[0m23:00:49.025711 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:00:49.026203 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:00:49.027207 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:00:49.042750 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:00:49.043242 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:00:49.043611 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:00:49.044699 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:00:49.052130 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:00:49.057626 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:00:49.058107 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:00:49.058932 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m23:00:49.061628 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:00:49.064044 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '010a8238-b4ef-4af6-8a25-440c5601a606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c44ae0>]}
[0m23:00:49.064879 [info ] [Thread-1 (]: 1 of 1 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.12s]
[0m23:00:49.065577 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:00:49.067956 [info ] [MainThread]: 
[0m23:00:49.068449 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.068792 [debug] [MainThread]: On master: BEGIN
[0m23:00:49.069107 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:00:49.075353 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:00:49.075954 [debug] [MainThread]: On master: COMMIT
[0m23:00:49.076459 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.076772 [debug] [MainThread]: On master: COMMIT
[0m23:00:49.077353 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:00:49.117604 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.118138 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:00:49.124864 [debug] [MainThread]: SQL status: SELECT 119 in 0.006 seconds
[0m23:00:49.129851 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:00:49.161722 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:00:49.239451 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:00:49.246945 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:00:49.247855 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m23:00:49.257280 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:00:49.282721 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.283254 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718210049268226230049275972"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:00:49.287234 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:00:49.311899 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.312374 [debug] [MainThread]: On master: BEGIN
[0m23:00:49.313012 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:00:49.313411 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.313790 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718210049268226230049275972'
        
      order by ordinal_position

  
[0m23:00:49.325271 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m23:00:49.330244 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718210049268226230049275972"
[0m23:00:49.374740 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:00:49.375928 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.376323 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718210049268226230049275972"
         (metadata_hash) values
    ('dd8e8ba547b55216c77b725dba89d622')
  
[0m23:00:49.377614 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:00:49.381875 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.382329 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718210049380596230049380844"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:00:49.386198 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:00:49.391402 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.391876 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718210049380596230049380844'
        
      order by ordinal_position

  
[0m23:00:49.395672 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m23:00:49.398585 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_models__tmp_20250718210049380596230049380844"
[0m23:00:49.418872 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:00:49.420030 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.420466 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718210049380596230049380844"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption','consumption','fa1c4ca81ba141cb831969824ce43dcc19b625a3d7e5a49ba6f95e16f6e8fd41','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','','consumption','dbt_elsa','models/bronze/consumption.sql','bronze/consumption.sql',NULL,'2025-07-18 21:00:49','d3b6352e51ca97cf9bc86dcef10f4233',NULL,NULL,NULL,'protected'),('model.dbt_elsa.daily_consumption','daily_consumption','fa1c4ca81ba141cb831969824ce43dcc19b625a3d7e5a49ba6f95e16f6e8fd41','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','','daily_consumption','dbt_elsa','models/silver/daily_consumption.sql','silver/daily_consumption.sql',NULL,'2025-07-18 21:00:49','ec9c72114dee2b97f7e094cdb2df7bf6',NULL,NULL,NULL,'protected')
  
[0m23:00:49.421491 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:00:49.429492 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.429999 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718210049268226230049275972");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718210049380596230049380844";
        
        commit;
    
  
[0m23:00:49.431941 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:00:49.436397 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718210049268226230049275972"
[0m23:00:49.437049 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.437428 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718210049268226230049275972" cascade
[0m23:00:49.440495 [debug] [MainThread]: SQL status: DROP TABLE in 0.003 seconds
[0m23:00:49.445975 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718210049380596230049380844"
[0m23:00:49.446690 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.447080 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718210049380596230049380844" cascade
[0m23:00:49.448840 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:00:49.450429 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:00:49.452066 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:00:49.452974 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.076430 (1 runs)
[0m23:00:49.453863 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.035108 (2 runs)
[0m23:00:49.454836 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000920 (2 runs)
[0m23:00:49.455787 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.038361 (3 runs)
[0m23:00:49.457013 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.047957 (2 runs)
[0m23:00:49.457950 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.007305 (2 runs)
[0m23:00:49.458907 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.111573 (2 runs)
[0m23:00:49.460163 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.290151 (1 runs)
[0m23:00:49.465175 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:00:49.466637 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 0 artifacts.
[0m23:00:49.467908 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:00:49.468670 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts changed.
[0m23:00:49.469510 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m23:00:49.471535 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.471926 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718210049470336230049470576"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m23:00:49.474248 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:00:49.479356 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.479845 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718210049470336230049470576'
        
      order by ordinal_position

  
[0m23:00:49.482703 [debug] [MainThread]: SQL status: SELECT 1 in 0.002 seconds
[0m23:00:49.485489 [debug] [MainThread]: Elementary: Inserting 4 rows to table "dbt_tests__tmp_20250718210049470336230049470576"
[0m23:00:49.492013 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:00:49.493126 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.493525 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250718210049470336230049470576"
         (metadata_hash) values
    ('50d0c441c7d860d924f1fef55d19e132'),('8a067ec9013321f49ce92fc705584768'),('a2b3139930021b90abaeba8bb5050171'),('ce9efa3ee5baf94e522c80c502b5b9ed')
  
[0m23:00:49.494353 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.000 seconds
[0m23:00:49.497112 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.497557 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_tests"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_tests__tmp_20250718210049470336230049470576");
        
        
        commit;
    
  
[0m23:00:49.498553 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:00:49.502926 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250718210049470336230049470576"
[0m23:00:49.503612 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.504003 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250718210049470336230049470576" cascade
[0m23:00:49.505450 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:00:49.506790 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m23:00:49.508343 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:00:49.509241 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.000406 (1 runs)
[0m23:00:49.510113 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.007834 (1 runs)
[0m23:00:49.510980 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000388 (1 runs)
[0m23:00:49.511852 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.003080 (4 runs)
[0m23:00:49.512800 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.005279 (1 runs)
[0m23:00:49.513688 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.003194 (1 runs)
[0m23:00:49.514544 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:00.020322 (1 runs)
[0m23:00:49.515402 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.042955 (1 runs)
[0m23:00:49.520940 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:00:49.540159 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 1 artifacts.
[0m23:00:49.541510 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:00:49.542268 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:00:49.543426 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:00:49.544256 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.017905 (1 runs)
[0m23:00:49.545362 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.022464 (1 runs)
[0m23:00:49.550007 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:00:49.551364 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:00:49.552523 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:00:49.553241 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:00:49.554380 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:00:49.555205 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000393 (1 runs)
[0m23:00:49.556018 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.004305 (1 runs)
[0m23:00:49.561143 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:00:49.562581 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:00:49.563746 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:00:49.564451 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:00:49.565566 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:00:49.566445 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000431 (1 runs)
[0m23:00:49.567237 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004373 (1 runs)
[0m23:00:49.571804 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:00:49.573625 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:00:49.574828 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:00:49.575835 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:00:49.577189 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:00:49.578043 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000744 (1 runs)
[0m23:00:49.578976 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005291 (1 runs)
[0m23:00:49.583814 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:00:49.585193 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:00:49.586378 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:00:49.587433 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:00:49.588574 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:00:49.589706 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000399 (1 runs)
[0m23:00:49.590543 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004697 (1 runs)
[0m23:00:49.595226 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:00:49.596731 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:00:49.597929 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:00:49.598669 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:00:49.600319 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:00:49.601183 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000495 (1 runs)
[0m23:00:49.601999 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005014 (1 runs)
[0m23:00:49.606943 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:00:49.745819 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 69 artifacts.
[0m23:00:49.747082 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:00:49.747955 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts changed.
[0m23:00:49.750607 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m23:00:49.752614 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.752985 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718210049751438230049751672"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m23:00:49.756014 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:00:49.761394 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.761882 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718210049751438230049751672'
        
      order by ordinal_position

  
[0m23:00:49.765082 [debug] [MainThread]: SQL status: SELECT 1 in 0.003 seconds
[0m23:00:49.767783 [debug] [MainThread]: Elementary: Inserting 14 rows to table "dbt_columns__tmp_20250718210049751438230049751672"
[0m23:00:49.785000 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:00:49.786143 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.786543 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718210049751438230049751672"
         (metadata_hash) values
    ('22c40f93a6414d60245a7536e5608785'),('374bd67e774675f19f28cde7c6bda29a'),('572c4c651fed95c173ad7a463718c51a'),('57bfd15cd8de45edae4068a74ccffdca'),('7ab14ad5a82cf844237c79796ea76a4d'),('8a0f0a86271b42de2ee1ac75b0d922b6'),('8f044a91afbea79bc342f32a805d9bdd'),('9f4a0fa51ccd9d73d9ed989c1bed32a2'),('b6fe1ea8e16a5c21257cb5f6e611d14b'),('c16c2c65425e41a6d8dc6cfe1a49169e'),('d290a08dfab4e1855a9893ca12f95784'),('dac2f8348537266668cd4c8850f0a0ad'),('f8c5d217d3d31b9919cbc73644d37265'),('fd67e4ad540602ffd4b4e3741871bd5e')
  
[0m23:00:49.787555 [debug] [MainThread]: SQL status: INSERT 0 14 in 0.001 seconds
[0m23:00:49.790346 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.790761 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_columns"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_columns__tmp_20250718210049751438230049751672");
        
        
        commit;
    
  
[0m23:00:49.791970 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:00:49.796346 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718210049751438230049751672"
[0m23:00:49.796983 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.797362 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718210049751438230049751672" cascade
[0m23:00:49.798835 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:00:49.800053 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m23:00:49.801564 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:00:49.802435 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.137717 (1 runs)
[0m23:00:49.803286 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.008930 (1 runs)
[0m23:00:49.804468 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000441 (1 runs)
[0m23:00:49.805318 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.010796 (14 runs)
[0m23:00:49.806164 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.015694 (1 runs)
[0m23:00:49.807050 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.003267 (1 runs)
[0m23:00:49.807881 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.031371 (1 runs)
[0m23:00:49.808850 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.194424 (1 runs)
[0m23:00:49.810014 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:00:49.814614 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:00:49.815636 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:00:49.847684 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 1 artifacts.
[0m23:00:49.851463 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.851897 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:00:49.856061 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:00:49.858785 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:00:49.881377 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:00:49.882548 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.883040 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('010a8238-b4ef-4af6-8a25-440c5601a606.model.dbt_elsa.consumption','model.dbt_elsa.consumption','010a8238-b4ef-4af6-8a25-440c5601a606','2025-07-18 21:00:49',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.12278604507446289,'2025-07-18T21:00:48.947657Z','2025-07-18T21:00:49.061466Z','2025-07-18T21:00:48.940788Z','2025-07-18T21:00:48.946622Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    data->>''gaz'' AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL)
  
[0m23:00:49.885162 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.002 seconds
[0m23:00:49.887832 [debug] [MainThread]: On master: COMMIT
[0m23:00:49.888274 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:49.888651 [debug] [MainThread]: On master: COMMIT
[0m23:00:49.889299 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:00:49.892211 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:00:49.893037 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.030536 (1 runs)
[0m23:00:49.893848 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.009602 (1 runs)
[0m23:00:49.894632 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000626 (1 runs)
[0m23:00:49.895392 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.019254 (1 runs)
[0m23:00:49.896152 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.021270 (1 runs)
[0m23:00:49.896910 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005157 (1 runs)
[0m23:00:49.897659 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002519 (1 runs)
[0m23:00:49.898409 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.042019 (1 runs)
[0m23:00:49.899159 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.075938 (1 runs)
[0m23:00:49.899923 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:00:49.909963 [debug] [MainThread]: Elementary: Handling test results.
[0m23:00:49.935948 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:00:49.951147 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:00:50.011900 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:50.012522 [debug] [MainThread]: On master: BEGIN
[0m23:00:50.013246 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:00:50.013687 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:50.014187 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:00:50.018216 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m23:00:50.021177 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:00:50.041132 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:00:50.042304 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:50.042835 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('010a8238-b4ef-4af6-8a25-440c5601a606',NULL,NULL,NULL,'2025-07-18 21:00:46','2025-07-18 21:00:49','2025-07-18 21:00:49',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:00:50.044017 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:00:50.046569 [debug] [MainThread]: On master: COMMIT
[0m23:00:50.046964 [debug] [MainThread]: Using postgres connection "master"
[0m23:00:50.047313 [debug] [MainThread]: On master: COMMIT
[0m23:00:50.048998 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:00:50.050856 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:00:50.057504 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:00:50.059664 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:00:50.060448 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.98s]
[0m23:00:50.060897 [debug] [MainThread]: On master: Close
[0m23:00:50.061431 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:00:50.061759 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:00:50.062055 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m23:00:50.062527 [info ] [MainThread]: 
[0m23:00:50.062936 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 1.47 seconds (1.47s).
[0m23:00:50.064088 [debug] [MainThread]: Command end result
[0m23:00:50.154188 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:00:50.157664 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:00:50.165721 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:00:50.166179 [info ] [MainThread]: 
[0m23:00:50.166688 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:00:50.167114 [info ] [MainThread]: 
[0m23:00:50.167543 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:00:50.170979 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.4894128, "process_in_blocks": "0", "process_kernel_time": 0.536603, "process_mem_max_rss": "142757888", "process_out_blocks": "0", "process_user_time": 4.083815}
[0m23:00:50.171549 [debug] [MainThread]: Command `dbt build` succeeded at 23:00:50.171423 after 3.49 seconds
[0m23:00:50.171980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110e6c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b6be30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b6bcd0>]}
[0m23:00:50.172706 [debug] [MainThread]: Flushing usage events
[0m23:00:50.723412 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:28:00.393292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ace7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c41f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c41f4d0>]}


============================== 23:28:00.402772 | 9f89197c-4d9e-48c6-be42-a4da463960dc ==============================
[0m23:28:00.402772 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:28:00.404144 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m23:28:00.751277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f89197c-4d9e-48c6-be42-a4da463960dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b768510>]}
[0m23:28:00.845780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f89197c-4d9e-48c6-be42-a4da463960dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c29bdf0>]}
[0m23:28:00.847119 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:28:01.015898 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:28:01.420038 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:28:01.420481 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:28:01.427957 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:28:01.490525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f89197c-4d9e-48c6-be42-a4da463960dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0b3950>]}
[0m23:28:01.759462 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:28:01.763681 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:28:01.827318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f89197c-4d9e-48c6-be42-a4da463960dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d303c50>]}
[0m23:28:01.827873 [info ] [MainThread]: Found 32 models, 2 operations, 1 source, 1571 macros
[0m23:28:01.830298 [info ] [MainThread]: 
[0m23:28:01.830757 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:28:01.831269 [info ] [MainThread]: 
[0m23:28:01.831853 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:28:01.832784 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:28:01.910760 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:28:01.911272 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:28:01.911736 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:28:01.951810 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.040 seconds
[0m23:28:01.953385 [debug] [ThreadPool]: On list_elsa: Close
[0m23:28:01.960947 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:28:01.961579 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:28:01.969460 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:28:01.972559 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:28:01.973051 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:28:01.973451 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:28:01.973872 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:28:01.974196 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:28:01.981465 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:28:01.981914 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:28:01.982280 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:28:01.982879 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:28:01.983439 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:28:01.984034 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:28:01.987836 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.005 seconds
[0m23:28:01.990037 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:28:01.990542 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m23:28:01.992277 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:28:01.992691 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:28:01.993306 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:28:02.007177 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.007574 [debug] [MainThread]: On master: BEGIN
[0m23:28:02.007867 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:28:02.013378 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:28:02.013806 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.014224 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:28:02.055438 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m23:28:02.062658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f89197c-4d9e-48c6-be42-a4da463960dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6afe70>]}
[0m23:28:02.063188 [debug] [MainThread]: On master: ROLLBACK
[0m23:28:02.063778 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.064211 [debug] [MainThread]: On master: BEGIN
[0m23:28:02.064917 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:28:02.065341 [debug] [MainThread]: On master: COMMIT
[0m23:28:02.065793 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.066114 [debug] [MainThread]: On master: COMMIT
[0m23:28:02.066569 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:28:02.106704 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:28:02.147916 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.148526 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:28:02.149625 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:28:02.153213 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:28:02.158688 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:28:02.159378 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:28:02.159786 [info ] [MainThread]: 
[0m23:28:02.160218 [debug] [MainThread]: On master: Close
[0m23:28:02.166687 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:28:02.167808 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m23:28:02.168524 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption)
[0m23:28:02.168991 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:28:02.174391 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:28:02.175704 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:28:02.220457 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:28:02.222850 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:28:02.223374 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:28:02.223751 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:28:02.229416 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:28:02.229926 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:28:02.230357 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:28:02.236279 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.005 seconds
[0m23:28:02.248596 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:28:02.249070 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m23:28:02.249985 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:28:02.254133 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:28:02.254565 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:28:02.255550 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:28:02.274015 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:28:02.274520 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:28:02.274900 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:28:02.275960 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:28:02.283709 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:28:02.289458 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:28:02.290045 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:28:02.293353 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m23:28:02.296066 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:28:02.298419 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f89197c-4d9e-48c6-be42-a4da463960dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db85cc0>]}
[0m23:28:02.299268 [info ] [Thread-1 (]: 1 of 1 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.13s]
[0m23:28:02.300242 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:28:02.303273 [info ] [MainThread]: 
[0m23:28:02.303805 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.304149 [debug] [MainThread]: On master: BEGIN
[0m23:28:02.304469 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:28:02.310462 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:28:02.310920 [debug] [MainThread]: On master: COMMIT
[0m23:28:02.311299 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.311710 [debug] [MainThread]: On master: COMMIT
[0m23:28:02.312266 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:28:02.354690 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.355212 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:28:02.360664 [debug] [MainThread]: SQL status: SELECT 102 in 0.005 seconds
[0m23:28:02.363815 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:28:02.395876 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:28:02.481254 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:28:02.489291 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:28:02.490470 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m23:28:02.492230 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:28:02.493403 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.084013 (1 runs)
[0m23:28:02.494402 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.096290 (1 runs)
[0m23:28:02.499436 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:28:02.501696 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 0 artifacts.
[0m23:28:02.503744 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:28:02.504810 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:28:02.506077 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:28:02.507239 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.000943 (1 runs)
[0m23:28:02.508534 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.006595 (1 runs)
[0m23:28:02.513888 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:28:02.535217 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 1 artifacts.
[0m23:28:02.536641 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:28:02.537440 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:28:02.538626 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:28:02.539950 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019696 (1 runs)
[0m23:28:02.541016 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024745 (1 runs)
[0m23:28:02.545924 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:28:02.547723 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:28:02.549157 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:28:02.549956 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:28:02.552097 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:28:02.553085 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000496 (1 runs)
[0m23:28:02.553943 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.006059 (1 runs)
[0m23:28:02.559671 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:28:02.561351 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:28:02.562933 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:28:02.563863 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:28:02.565303 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:28:02.566285 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000362 (1 runs)
[0m23:28:02.567608 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005546 (1 runs)
[0m23:28:02.572795 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:28:02.574608 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:28:02.575847 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:28:02.576618 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:28:02.577859 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:28:02.578929 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000348 (1 runs)
[0m23:28:02.579992 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005003 (1 runs)
[0m23:28:02.585663 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:28:02.587177 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:28:02.589323 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:28:02.590218 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:28:02.591518 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:28:02.592493 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000409 (1 runs)
[0m23:28:02.593425 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005793 (1 runs)
[0m23:28:02.598802 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:28:02.601301 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:28:02.602697 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:28:02.603546 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:28:02.605183 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:28:02.606158 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000628 (1 runs)
[0m23:28:02.607099 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.006378 (1 runs)
[0m23:28:02.612520 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:28:02.766627 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 69 artifacts.
[0m23:28:02.769118 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:28:02.770161 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:28:02.771551 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:28:02.772492 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.152858 (1 runs)
[0m23:28:02.773408 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.158985 (1 runs)
[0m23:28:02.774427 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:28:02.778814 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:28:02.780045 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:28:02.814166 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 1 artifacts.
[0m23:28:02.837474 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.837952 [debug] [MainThread]: On master: BEGIN
[0m23:28:02.838579 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:28:02.838952 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.839323 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:28:02.849109 [debug] [MainThread]: SQL status: SELECT 23 in 0.009 seconds
[0m23:28:02.854686 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:28:02.950284 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:28:02.952493 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.953051 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('9f89197c-4d9e-48c6-be42-a4da463960dc.model.dbt_elsa.consumption','model.dbt_elsa.consumption','9f89197c-4d9e-48c6-be42-a4da463960dc','2025-07-18 21:28:02',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.1282958984375,'2025-07-18T21:28:02.176003Z','2025-07-18T21:28:02.295905Z','2025-07-18T21:28:02.169261Z','2025-07-18T21:28:02.175537Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    data->>''gaz'' AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL)
  
[0m23:28:02.955472 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.002 seconds
[0m23:28:02.958531 [debug] [MainThread]: On master: COMMIT
[0m23:28:02.959197 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:02.959577 [debug] [MainThread]: On master: COMMIT
[0m23:28:02.961247 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:28:02.963939 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:28:02.964956 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.033034 (1 runs)
[0m23:28:02.965727 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.025300 (1 runs)
[0m23:28:02.966735 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000675 (1 runs)
[0m23:28:02.967765 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.063308 (1 runs)
[0m23:28:02.968574 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.074052 (1 runs)
[0m23:28:02.969297 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005994 (1 runs)
[0m23:28:02.970046 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.004078 (1 runs)
[0m23:28:02.970766 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.134084 (1 runs)
[0m23:28:02.971907 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.183659 (1 runs)
[0m23:28:02.972625 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:28:02.982401 [debug] [MainThread]: Elementary: Handling test results.
[0m23:28:03.010306 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:28:03.054048 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:28:03.139442 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:03.140033 [debug] [MainThread]: On master: BEGIN
[0m23:28:03.140776 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:28:03.141207 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:03.141690 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:28:03.145808 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:28:03.148741 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:28:03.170076 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:28:03.171163 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:03.171708 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('9f89197c-4d9e-48c6-be42-a4da463960dc',NULL,NULL,NULL,'2025-07-18 21:28:00','2025-07-18 21:28:03','2025-07-18 21:28:03',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:28:03.173013 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:28:03.175772 [debug] [MainThread]: On master: COMMIT
[0m23:28:03.176217 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:03.176582 [debug] [MainThread]: On master: COMMIT
[0m23:28:03.178896 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m23:28:03.180458 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:28:03.187197 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:28:03.188901 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:28:03.189463 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.88s]
[0m23:28:03.189872 [debug] [MainThread]: On master: Close
[0m23:28:03.190355 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:28:03.190666 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:28:03.190960 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m23:28:03.191338 [info ] [MainThread]: 
[0m23:28:03.191701 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 1.36 seconds (1.36s).
[0m23:28:03.192924 [debug] [MainThread]: Command end result
[0m23:28:03.279259 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:28:03.281833 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:28:03.289369 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:28:03.289795 [info ] [MainThread]: 
[0m23:28:03.290203 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:28:03.290541 [info ] [MainThread]: 
[0m23:28:03.290912 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:28:03.294518 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.021326, "process_in_blocks": "0", "process_kernel_time": 0.594818, "process_mem_max_rss": "134520832", "process_out_blocks": "0", "process_user_time": 3.906499}
[0m23:28:03.295237 [debug] [MainThread]: Command `dbt build` succeeded at 23:28:03.295092 after 3.02 seconds
[0m23:28:03.295792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c20ec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9d7e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9d7c20>]}
[0m23:28:03.296276 [debug] [MainThread]: Flushing usage events
[0m23:28:03.767188 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:41:32.254811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112357770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a8b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a8b4d0>]}


============================== 23:41:32.263437 | 4dc441e0-291f-4d73-8b45-d556b8556cd1 ==============================
[0m23:41:32.263437 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:41:32.264319 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build --select bronze', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m23:41:32.567581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4dc441e0-291f-4d73-8b45-d556b8556cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112dd4510>]}
[0m23:41:32.650653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4dc441e0-291f-4d73-8b45-d556b8556cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113907df0>]}
[0m23:41:32.652219 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:41:32.822264 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:41:33.254148 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 3 files added, 1 files changed.
[0m23:41:33.254950 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m23:41:33.255355 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/consumption_history.sql
[0m23:41:33.255779 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_silver__sources.yml
[0m23:41:33.256416 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:41:33.256802 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/silver/daily_consumption.sql
[0m23:41:33.924621 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_elsa.consumption_history' (models/silver/consumption_history.sql) depends on a source named 'bronze.consumption' which was not found
[0m23:41:33.930752 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.7929289, "process_in_blocks": "0", "process_kernel_time": 0.691379, "process_mem_max_rss": "127500288", "process_out_blocks": "0", "process_user_time": 3.303685}
[0m23:41:33.931374 [debug] [MainThread]: Command `dbt build` failed at 23:41:33.931250 after 1.79 seconds
[0m23:41:33.931813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ce5d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ce5c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114debd40>]}
[0m23:41:33.932434 [debug] [MainThread]: Flushing usage events
[0m23:41:34.835885 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:43:45.936965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10899b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a093610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0934d0>]}


============================== 23:43:45.944738 | 52d297eb-4168-412b-af50-0c249bc9dd82 ==============================
[0m23:43:45.944738 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:43:45.945856 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build --select bronze', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:43:46.213641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '52d297eb-4168-412b-af50-0c249bc9dd82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109410510>]}
[0m23:43:46.291708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '52d297eb-4168-412b-af50-0c249bc9dd82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f17df0>]}
[0m23:43:46.293580 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:43:46.457956 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:43:46.903020 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 3 files added, 1 files changed.
[0m23:43:46.903795 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m23:43:46.904193 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/consumption_history.sql
[0m23:43:46.904587 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_silver__sources.yml
[0m23:43:46.905117 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:43:46.905459 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/silver/daily_consumption.sql
[0m23:43:47.567671 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_elsa.consumption_history' (models/silver/consumption_history.sql) depends on a source named 'bronze.consumption' which was not found
[0m23:43:47.572330 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.7401267, "process_in_blocks": "0", "process_kernel_time": 0.693813, "process_mem_max_rss": "127930368", "process_out_blocks": "0", "process_user_time": 3.319003}
[0m23:43:47.572963 [debug] [MainThread]: Command `dbt build` failed at 23:43:47.572823 after 1.74 seconds
[0m23:43:47.573855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b309d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b309c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b413d40>]}
[0m23:43:47.574498 [debug] [MainThread]: Flushing usage events
[0m23:43:48.029294 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:45:46.330926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110727770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e63610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e634d0>]}


============================== 23:45:46.338558 | 2ebb16a3-0abe-4984-8594-071802e419b3 ==============================
[0m23:45:46.338558 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:45:46.339310 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select bronze', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:45:46.606829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ebb16a3-0abe-4984-8594-071802e419b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111b0510>]}
[0m23:45:46.686203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ebb16a3-0abe-4984-8594-071802e419b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ce3df0>]}
[0m23:45:46.687840 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:45:46.853022 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:45:47.319656 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 3 files added, 1 files changed.
[0m23:45:47.320387 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_silver__sources.yml
[0m23:45:47.320785 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/consumption_history.sql
[0m23:45:47.321213 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m23:45:47.321709 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:45:47.322048 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/silver/daily_consumption.sql
[0m23:45:47.984986 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_elsa.consumption_history' (models/silver/consumption_history.sql) depends on a source named 'bronze.consumption' which was not found
[0m23:45:47.989423 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.7638464, "process_in_blocks": "0", "process_kernel_time": 0.666274, "process_mem_max_rss": "127827968", "process_out_blocks": "0", "process_user_time": 3.326763}
[0m23:45:47.990044 [debug] [MainThread]: Command `dbt build` failed at 23:45:47.989919 after 1.76 seconds
[0m23:45:47.990493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130e1d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130e1b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112dcf4d0>]}
[0m23:45:47.990918 [debug] [MainThread]: Flushing usage events
[0m23:45:48.456623 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:48:38.309610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108def770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4e7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4e74d0>]}


============================== 23:48:38.317168 | 7667d621-1415-4a39-96ba-135745c92250 ==============================
[0m23:48:38.317168 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:48:38.317854 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build --select bronze', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m23:48:38.554285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7667d621-1415-4a39-96ba-135745c92250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109864510>]}
[0m23:48:38.637397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7667d621-1415-4a39-96ba-135745c92250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a36bdf0>]}
[0m23:48:38.639018 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:48:38.787631 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:48:39.229674 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 3 files added, 1 files changed.
[0m23:48:39.235551 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_silver__sources.yml
[0m23:48:39.236540 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/consumption_history.sql
[0m23:48:39.237481 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m23:48:39.238682 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:48:39.239446 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/silver/daily_consumption.sql
[0m23:48:39.896855 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_elsa.consumption_history' (models/silver/consumption_history.sql) depends on a source named 'bronze.consumption' which was not found
[0m23:48:39.899894 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.6850477, "process_in_blocks": "0", "process_kernel_time": 0.40914, "process_mem_max_rss": "128274432", "process_out_blocks": "0", "process_user_time": 2.854477}
[0m23:48:39.900413 [debug] [MainThread]: Command `dbt build` failed at 23:48:39.900301 after 1.69 seconds
[0m23:48:39.900805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b75dd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b75db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b44f4d0>]}
[0m23:48:39.901189 [debug] [MainThread]: Flushing usage events
[0m23:48:40.336029 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:48:48.610498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103eaf770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055a3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055a34d0>]}


============================== 23:48:48.615959 | f476290d-93f0-4c1c-a6d6-2ecdc72838d3 ==============================
[0m23:48:48.615959 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:48:48.616605 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:48:48.775328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f476290d-93f0-4c1c-a6d6-2ecdc72838d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104928510>]}
[0m23:48:48.967409 [debug] [MainThread]: Set downloads directory='/var/folders/nh/7fjwwfwj7y9cswpyn7b_dgrm0000gn/T/dbt-downloads-7_yy2xw5'
[0m23:48:48.967923 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m23:48:49.096144 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m23:48:49.098722 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m23:48:49.157557 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m23:48:49.166942 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m23:48:49.228523 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m23:48:49.238441 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m23:48:49.300011 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m23:48:49.312318 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m23:48:49.368892 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m23:48:49.373607 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m23:48:49.824039 [info ] [MainThread]: Installed from version 1.3.0
[0m23:48:49.824703 [info ] [MainThread]: Up to date!
[0m23:48:49.825376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f476290d-93f0-4c1c-a6d6-2ecdc72838d3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542ebe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10577a7a0>]}
[0m23:48:49.826113 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m23:48:50.472652 [info ] [MainThread]: Installed from version 0.10.9
[0m23:48:50.473347 [info ] [MainThread]: Up to date!
[0m23:48:50.474007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f476290d-93f0-4c1c-a6d6-2ecdc72838d3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057acb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e9d220>]}
[0m23:48:50.474682 [info ] [MainThread]: Installing elementary-data/elementary
[0m23:48:51.064380 [info ] [MainThread]: Installed from version 0.19.0
[0m23:48:51.065014 [info ] [MainThread]: Updated version available: 0.19.1
[0m23:48:51.065605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f476290d-93f0-4c1c-a6d6-2ecdc72838d3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057dcad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057dcf30>]}
[0m23:48:51.066248 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m23:48:51.395356 [info ] [MainThread]: Installed from version 0.14.2
[0m23:48:51.396246 [info ] [MainThread]: Up to date!
[0m23:48:51.396959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f476290d-93f0-4c1c-a6d6-2ecdc72838d3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057a50d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057a5490>]}
[0m23:48:51.397635 [info ] [MainThread]: 
[0m23:48:51.398266 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m23:48:51.405448 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.8884501, "process_in_blocks": "0", "process_kernel_time": 0.742312, "process_mem_max_rss": "114581504", "process_out_blocks": "0", "process_user_time": 2.155922}
[0m23:48:51.406371 [debug] [MainThread]: Command `dbt deps` succeeded at 23:48:51.406151 after 2.89 seconds
[0m23:48:51.407057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057d03c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048c9770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057cfed0>]}
[0m23:48:51.407879 [debug] [MainThread]: Flushing usage events
[0m23:48:51.786645 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:48:56.693847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ccb770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3ff610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3ff4d0>]}


============================== 23:48:56.699316 | e0148326-25c6-41eb-ab96-a44415bda97d ==============================
[0m23:48:56.699316 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:48:56.699963 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt parse', 'send_anonymous_usage_stats': 'True'}
[0m23:48:56.973086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e0148326-25c6-41eb-ab96-a44415bda97d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109754510>]}
[0m23:48:57.051976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e0148326-25c6-41eb-ab96-a44415bda97d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a287df0>]}
[0m23:48:57.053816 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:48:57.210847 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:48:57.536671 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 3 files added, 1 files changed.
[0m23:48:57.537451 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m23:48:57.537833 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/consumption_history.sql
[0m23:48:57.538209 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_silver__sources.yml
[0m23:48:57.538690 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:48:57.539018 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/silver/daily_consumption.sql
[0m23:48:58.182371 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_elsa.consumption_history' (models/silver/consumption_history.sql) depends on a source named 'bronze.consumption' which was not found
[0m23:48:58.185163 [debug] [MainThread]: Resource report: {"command_name": "parse", "command_success": false, "command_wall_clock_time": 1.584789, "process_in_blocks": "0", "process_kernel_time": 0.388156, "process_mem_max_rss": "126947328", "process_out_blocks": "0", "process_user_time": 2.840749}
[0m23:48:58.185761 [debug] [MainThread]: Command `dbt parse` failed at 23:48:58.185638 after 1.59 seconds
[0m23:48:58.186197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b685d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b685c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b78fd40>]}
[0m23:48:58.186614 [debug] [MainThread]: Flushing usage events
[0m23:48:58.582449 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:49:22.667184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5b7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fce3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fce34d0>]}


============================== 23:49:22.672229 | 87cf9d3a-971a-4e96-9e0d-2db1628335d8 ==============================
[0m23:49:22.672229 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:49:22.672875 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt parse', 'send_anonymous_usage_stats': 'True'}
[0m23:49:22.888730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '87cf9d3a-971a-4e96-9e0d-2db1628335d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f034510>]}
[0m23:49:22.968408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '87cf9d3a-971a-4e96-9e0d-2db1628335d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb67df0>]}
[0m23:49:22.969323 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:49:23.104399 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:49:23.359901 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 3 files added, 1 files changed.
[0m23:49:23.360575 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/consumption_history.sql
[0m23:49:23.360982 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_silver__sources.yml
[0m23:49:23.361391 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m23:49:23.362068 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:49:23.362550 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/silver/daily_consumption.sql
[0m23:49:24.139867 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:49:24.156178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '87cf9d3a-971a-4e96-9e0d-2db1628335d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f44d50>]}
[0m23:49:24.161551 [info ] [MainThread]: Performance info: /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/perf_info.json
[0m23:49:24.335230 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:49:24.340178 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:49:24.343172 [debug] [MainThread]: Resource report: {"command_name": "parse", "command_success": true, "command_wall_clock_time": 1.7681923, "process_in_blocks": "0", "process_kernel_time": 0.345705, "process_mem_max_rss": "134348800", "process_out_blocks": "0", "process_user_time": 3.105656}
[0m23:49:24.343814 [debug] [MainThread]: Command `dbt parse` succeeded at 23:49:24.343672 after 1.77 seconds
[0m23:49:24.344298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd22f30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c31310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111020ad0>]}
[0m23:49:24.344753 [debug] [MainThread]: Flushing usage events
[0m23:49:24.746181 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:49:34.755992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c45b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db93610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db934d0>]}


============================== 23:49:34.761377 | fae4dea9-d0b2-4c40-9c96-98400d9ae671 ==============================
[0m23:49:34.761377 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:49:34.762522 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build --select bronze', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:49:34.976406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cedc510>]}
[0m23:49:35.057954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da0fdf0>]}
[0m23:49:35.059019 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:49:35.193460 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:49:35.451515 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:49:35.451963 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:49:35.459677 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:49:35.603132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db03350>]}
[0m23:49:35.788628 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:49:35.791873 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:49:35.844721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e913c50>]}
[0m23:49:35.845502 [info ] [MainThread]: Found 32 models, 2 operations, 6 data tests, 2 sources, 1571 macros
[0m23:49:35.848402 [info ] [MainThread]: 
[0m23:49:35.848827 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:49:35.849234 [info ] [MainThread]: 
[0m23:49:35.849820 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:49:35.850759 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:49:35.923469 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:49:35.924042 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:49:35.924551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:35.959747 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.035 seconds
[0m23:49:35.961351 [debug] [ThreadPool]: On list_elsa: Close
[0m23:49:35.968784 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:49:35.969403 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:49:35.976469 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:49:35.979522 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:49:35.980031 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:49:35.980382 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:49:35.980703 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:49:35.981007 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:35.987803 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:49:35.988221 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:49:35.988619 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:49:35.989044 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:49:35.989375 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:49:35.989708 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:49:35.993247 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:49:35.993703 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:49:35.995115 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:49:35.997110 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:49:35.997814 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:49:35.998164 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:49:36.015546 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:36.015957 [debug] [MainThread]: On master: BEGIN
[0m23:49:36.016259 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:49:36.022067 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:49:36.022480 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:36.022881 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:49:36.064437 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m23:49:36.071475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1e42f0>]}
[0m23:49:36.071951 [debug] [MainThread]: On master: ROLLBACK
[0m23:49:36.072533 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:36.072865 [debug] [MainThread]: On master: BEGIN
[0m23:49:36.073453 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:49:36.073802 [debug] [MainThread]: On master: COMMIT
[0m23:49:36.074132 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:36.074447 [debug] [MainThread]: On master: COMMIT
[0m23:49:36.074956 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:49:36.115434 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:49:36.152121 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:36.152726 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:49:36.153765 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:49:36.156979 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:49:36.161748 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:49:36.162973 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:49:36.163743 [info ] [MainThread]: 
[0m23:49:36.164216 [debug] [MainThread]: On master: Close
[0m23:49:36.170469 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:49:36.171190 [info ] [Thread-1 (]: 1 of 5 START sql table model bronze.consumption ................................ [RUN]
[0m23:49:36.171976 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption)
[0m23:49:36.172437 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:49:36.177502 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:49:36.178469 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:49:36.225364 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:49:36.226713 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.227152 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:49:36.227543 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:49:36.233831 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:49:36.234314 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.234753 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:49:36.241165 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.006 seconds
[0m23:49:36.252828 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.253285 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m23:49:36.254091 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:49:36.257775 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.258211 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:49:36.259125 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:49:36.284819 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.285287 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m23:49:36.286146 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:49:36.299426 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.299931 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:49:36.309686 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.009 seconds
[0m23:49:36.315814 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.316445 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m23:49:36.317470 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:49:36.319053 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:49:36.319516 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.319907 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:49:36.320862 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:49:36.329032 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:49:36.335018 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:49:36.335501 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:49:36.338410 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:49:36.340944 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:49:36.343599 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3f1a50>]}
[0m23:49:36.344422 [info ] [Thread-1 (]: 1 of 5 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.17s]
[0m23:49:36.345353 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:49:36.346521 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:49:36.347055 [debug] [Thread-5 (]: Began running node test.dbt_elsa.not_null_consumption_time.f86477a2e3
[0m23:49:36.347453 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:49:36.347851 [info ] [Thread-3 (]: 3 of 5 START test not_null_consumption_date .................................... [RUN]
[0m23:49:36.348365 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:49:36.348761 [info ] [Thread-5 (]: 5 of 5 START test not_null_consumption_time .................................... [RUN]
[0m23:49:36.349213 [info ] [Thread-2 (]: 2 of 5 START test not_null_consumption_created_at .............................. [RUN]
[0m23:49:36.349967 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc'
[0m23:49:36.350535 [info ] [Thread-4 (]: 4 of 5 START test not_null_consumption_id ...................................... [RUN]
[0m23:49:36.351204 [debug] [Thread-5 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_time.f86477a2e3'
[0m23:49:36.351868 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m23:49:36.352670 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:49:36.353510 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m23:49:36.354012 [debug] [Thread-5 (]: Began compiling node test.dbt_elsa.not_null_consumption_time.f86477a2e3
[0m23:49:36.354461 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:49:36.366277 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:49:36.370062 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:49:36.379382 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_time.f86477a2e3"
[0m23:49:36.384111 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:49:36.389231 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:49:36.390478 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:49:36.393197 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:49:36.393764 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:49:36.394169 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:49:36.394483 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3947d0>]}
[0m23:49:36.395044 [debug] [Thread-5 (]: Began executing node test.dbt_elsa.not_null_consumption_time.f86477a2e3
[0m23:49:36.397577 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:49:36.400600 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:49:36.434729 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2af120>]}
[0m23:49:36.451218 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'fae4dea9-d0b2-4c40-9c96-98400d9ae671', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1f71b0>]}
[0m23:49:36.911794 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:49:36.913774 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:49:36.914841 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_time.f86477a2e3"
[0m23:49:36.915578 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:49:36.916570 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:49:36.916966 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m23:49:36.917333 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:49:36.917997 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:49:36.918441 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m23:49:36.918888 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:49:36.919343 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:49:36.919792 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m23:49:36.920256 [debug] [Thread-5 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_time.f86477a2e3"
[0m23:49:36.920780 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:49:36.921239 [debug] [Thread-5 (]: On test.dbt_elsa.not_null_consumption_time.f86477a2e3: BEGIN
[0m23:49:36.921895 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m23:49:36.923754 [debug] [Thread-3 (]: SQL status: BEGIN in 0.006 seconds
[0m23:49:36.924392 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:49:36.924973 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:49:36.926812 [debug] [Thread-2 (]: SQL status: BEGIN in 0.007 seconds
[0m23:49:36.927278 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:49:36.927715 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:49:36.928441 [debug] [Thread-4 (]: SQL status: BEGIN in 0.008 seconds
[0m23:49:36.941107 [debug] [Thread-5 (]: SQL status: BEGIN in 0.019 seconds
[0m23:49:36.941596 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:49:36.960571 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:49:36.973136 [debug] [Thread-5 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_time.f86477a2e3"
[0m23:49:36.980161 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m23:49:36.980783 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m23:49:36.981242 [debug] [Thread-5 (]: On test.dbt_elsa.not_null_consumption_time.f86477a2e3: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_time.f86477a2e3"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select time
from "elsa"."bronze"."consumption"
where time is null



  
  
      
    ) dbt_internal_test
[0m23:49:36.981875 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m23:49:36.982503 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m23:49:36.988622 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.007 seconds
[0m23:49:36.989040 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m23:49:36.989442 [debug] [Thread-5 (]: Postgres adapter: Postgres error: column "time" does not exist
LINE 16: select time
                ^

[0m23:49:36.990085 [info ] [Thread-3 (]: 3 of 5 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.64s]
[0m23:49:36.996245 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m23:49:36.997014 [debug] [Thread-5 (]: On test.dbt_elsa.not_null_consumption_time.f86477a2e3: ROLLBACK
[0m23:49:36.997479 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m23:49:36.998273 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:49:36.999286 [info ] [Thread-2 (]: 2 of 5 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.65s]
[0m23:49:36.999915 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m23:49:37.001204 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:49:37.002315 [debug] [Thread-5 (]: On test.dbt_elsa.not_null_consumption_time.f86477a2e3: Close
[0m23:49:37.003012 [info ] [Thread-4 (]: 4 of 5 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.65s]
[0m23:49:37.003895 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:49:37.023943 [debug] [Thread-5 (]: Database Error in test not_null_consumption_time (models/bronze/_elsa_bronze__models.yml)
  column "time" does not exist
  LINE 16: select time
                  ^
  compiled code at target/run/dbt_elsa/models/bronze/_elsa_bronze__models.yml/not_null_consumption_time.sql
[0m23:49:37.024710 [error] [Thread-5 (]: 5 of 5 ERROR not_null_consumption_time ......................................... [[31mERROR[0m in 0.67s]
[0m23:49:37.025493 [debug] [Thread-5 (]: Finished running node test.dbt_elsa.not_null_consumption_time.f86477a2e3
[0m23:49:37.026333 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_time.f86477a2e3' to be skipped because of status 'error'.  Reason: Database Error in test not_null_consumption_time (models/bronze/_elsa_bronze__models.yml)
  column "time" does not exist
  LINE 16: select time
                  ^
  compiled code at target/run/dbt_elsa/models/bronze/_elsa_bronze__models.yml/not_null_consumption_time.sql.
[0m23:49:37.029013 [info ] [MainThread]: 
[0m23:49:37.029590 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.030172 [debug] [MainThread]: On master: BEGIN
[0m23:49:37.030554 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:49:37.035843 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:49:37.036572 [debug] [MainThread]: On master: COMMIT
[0m23:49:37.037059 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.037408 [debug] [MainThread]: On master: COMMIT
[0m23:49:37.037940 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:49:37.073060 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.073574 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:49:37.079614 [debug] [MainThread]: SQL status: SELECT 102 in 0.005 seconds
[0m23:49:37.082544 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:49:37.114776 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:49:37.167193 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:49:37.174570 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:49:37.176021 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m23:49:37.186463 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:49:37.214460 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.214943 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718214937198561234937206735"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:49:37.218586 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:49:37.239015 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.239573 [debug] [MainThread]: On master: BEGIN
[0m23:49:37.240434 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:49:37.240854 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.241450 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718214937198561234937206735'
        
      order by ordinal_position

  
[0m23:49:37.250182 [debug] [MainThread]: SQL status: SELECT 1 in 0.008 seconds
[0m23:49:37.252616 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_models__tmp_20250718214937198561234937206735"
[0m23:49:37.294889 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:37.296489 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.297008 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718214937198561234937206735"
         (metadata_hash) values
    ('d3b6352e51ca97cf9bc86dcef10f4233'),('ec9c72114dee2b97f7e094cdb2df7bf6')
  
[0m23:49:37.297962 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:49:37.302270 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.302708 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718214937300863234937301114"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:49:37.306143 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:49:37.310981 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.311455 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718214937300863234937301114'
        
      order by ordinal_position

  
[0m23:49:37.315515 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:49:37.318302 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_models__tmp_20250718214937300863234937301114"
[0m23:49:37.337739 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:37.338866 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.339313 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718214937300863234937301114"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption','consumption','fa1c4ca81ba141cb831969824ce43dcc19b625a3d7e5a49ba6f95e16f6e8fd41','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','The aim of this table is to track houtly energy consumption for a given day
','consumption','dbt_elsa','models/bronze/consumption.sql','bronze/consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-18 21:49:37','0a2e8bb8f83dd30e9733f42917cec9ed',NULL,NULL,NULL,'protected'),('model.dbt_elsa.consumption_history','consumption_history','f5e17e076cd6ea97212c95f1998e6684f065a51e9c3fca328aff134bfc1c5801','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.consumption"]','The aim of this table is to consolidate history data for consumption
','consumption_history','dbt_elsa','models/silver/consumption_history.sql','silver/consumption_history.sql','dbt_elsa://models/silver/_elsa_bronze__models.yml','2025-07-18 21:49:37','c1c15c5ab0c60c74d7979adba1df2bbf',NULL,NULL,NULL,'protected')
  
[0m23:49:37.340301 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:49:37.348909 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.349379 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718214937198561234937206735");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718214937300863234937301114";
        
        commit;
    
  
[0m23:49:37.351268 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:49:37.355420 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718214937198561234937206735"
[0m23:49:37.356052 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.356439 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718214937198561234937206735" cascade
[0m23:49:37.358338 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:49:37.362193 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718214937300863234937301114"
[0m23:49:37.363033 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.363637 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718214937300863234937301114" cascade
[0m23:49:37.365233 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:49:37.366585 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:49:37.368441 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:49:37.369447 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.051129 (1 runs)
[0m23:49:37.370364 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.027330 (2 runs)
[0m23:49:37.371266 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000890 (2 runs)
[0m23:49:37.372189 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.035597 (4 runs)
[0m23:49:37.373105 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.044578 (2 runs)
[0m23:49:37.374325 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.007371 (2 runs)
[0m23:49:37.375250 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.100532 (2 runs)
[0m23:49:37.376332 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.253403 (1 runs)
[0m23:49:37.382060 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:49:37.401625 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 6 artifacts.
[0m23:49:37.402975 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:49:37.403808 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts changed.
[0m23:49:37.404671 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m23:49:37.406853 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.407273 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718214937405602234937405863"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m23:49:37.409519 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:49:37.414915 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.415395 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718214937405602234937405863'
        
      order by ordinal_position

  
[0m23:49:37.419337 [debug] [MainThread]: SQL status: SELECT 29 in 0.003 seconds
[0m23:49:37.422033 [debug] [MainThread]: Elementary: Inserting 6 rows to table "dbt_tests__tmp_20250718214937405602234937405863"
[0m23:49:37.487754 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:37.489334 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.489928 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250718214937405602234937405863"
         (unique_id,database_name,schema_name,name,short_name,alias,test_column_name,severity,warn_if,error_if,test_params,test_namespace,test_original_name,tags,model_tags,model_owners,meta,depends_on_macros,depends_on_nodes,parent_model_unique_id,description,package_name,type,original_path,path,generated_at,metadata_hash,quality_dimension,group_name) values
    ('test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','elsa','bronze','not_null_consumption_history_created_at','not_null','not_null_consumption_history_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_created_at.sql','2025-07-18 21:49:37','74e3435900f5472019e670236520300f','completeness',NULL),('test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','elsa','bronze','not_null_consumption_history_date','not_null','not_null_consumption_history_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_date.sql','2025-07-18 21:49:37','86ccb896bbf4c86cfbc4de4e060771eb','completeness',NULL),('test.dbt_elsa.not_null_consumption_id.186948fd55','elsa','bronze','not_null_consumption_id','not_null','not_null_consumption_id','id','ERROR','!= 0','!= 0','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption"]','model.dbt_elsa.consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_consumption_id.sql','2025-07-18 21:49:37','f210eff676b62b5f5ad68760ba2f46c8','completeness',NULL),('test.dbt_elsa.not_null_consumption_created_at.93906ad963','elsa','bronze','not_null_consumption_created_at','not_null','not_null_consumption_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption"]','model.dbt_elsa.consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_consumption_created_at.sql','2025-07-18 21:49:37','37dd210f2b364de61791df38a93fff0a','completeness',NULL),('test.dbt_elsa.not_null_consumption_date.0e210070dc','elsa','bronze','not_null_consumption_date','not_null','not_null_consumption_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption"]','model.dbt_elsa.consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_consumption_date.sql','2025-07-18 21:49:37','056167eee57e746a29aabb5e8ff038f0','completeness',NULL),('test.dbt_elsa.not_null_consumption_time.f86477a2e3','elsa','bronze','not_null_consumption_time','not_null','not_null_consumption_time','time','ERROR','!= 0','!= 0','{"column_name": "time", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption"]','model.dbt_elsa.consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_consumption_time.sql','2025-07-18 21:49:37','b93705874487df8e109b36babf08de5e','completeness',NULL)
  
[0m23:49:37.491459 [debug] [MainThread]: SQL status: INSERT 0 6 in 0.001 seconds
[0m23:49:37.494328 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.494738 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_tests" select * from "dbt_tests__tmp_20250718214937405602234937405863";
        
        commit;
    
  
[0m23:49:37.496977 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m23:49:37.500910 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250718214937405602234937405863"
[0m23:49:37.501539 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.501954 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250718214937405602234937405863" cascade
[0m23:49:37.503365 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:49:37.504674 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m23:49:37.506924 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:49:37.508003 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.018438 (1 runs)
[0m23:49:37.509000 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.009640 (1 runs)
[0m23:49:37.510088 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000503 (1 runs)
[0m23:49:37.511064 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.061336 (6 runs)
[0m23:49:37.511934 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.064475 (1 runs)
[0m23:49:37.513472 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.004226 (1 runs)
[0m23:49:37.514476 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:00.081856 (1 runs)
[0m23:49:37.515344 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.124618 (1 runs)
[0m23:49:37.520576 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:49:37.542277 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:49:37.543931 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:49:37.545001 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts changed.
[0m23:49:37.546227 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_sources"
[0m23:49:37.548352 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.548751 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_sources__tmp_20250718214937547142234937547390"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_sources"
        WHERE 1 = 0
    
  );
  
  
[0m23:49:37.551647 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:49:37.556128 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.556553 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_sources__tmp_20250718214937547142234937547390'
        
      order by ordinal_position

  
[0m23:49:37.560164 [debug] [MainThread]: SQL status: SELECT 22 in 0.003 seconds
[0m23:49:37.563101 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_sources__tmp_20250718214937547142234937547390"
[0m23:49:37.573307 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:37.574417 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.574860 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_sources__tmp_20250718214937547142234937547390"
         (unique_id,database_name,schema_name,source_name,name,identifier,loaded_at_field,freshness_warn_after,freshness_error_after,freshness_filter,freshness_description,relation_name,tags,meta,owner,package_name,original_path,path,source_description,description,generated_at,metadata_hash) values
    ('source.dbt_elsa.bronze.consumption','elsa','bronze','bronze','consumption','consumption',NULL,'{"count": null, "period": null}','{"count": null, "period": null}',NULL,'Source freshness validates if the time elapsed between the test execution to the latest record is above an acceptable SLA threshold.','"elsa"."bronze"."consumption"','[]','{}','[]','dbt_elsa','models/silver/_elsa_silver__sources.yml','models/silver/_elsa_silver__sources.yml','','Données raw','2025-07-18 21:49:37','57e62e882484c591a0ce7597a6fcae35')
  
[0m23:49:37.575916 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:49:37.579505 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.580004 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_sources" select * from "dbt_sources__tmp_20250718214937547142234937547390";
        
        commit;
    
  
[0m23:49:37.581168 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:49:37.586620 [debug] [MainThread]: Applying DROP to: "dbt_sources__tmp_20250718214937547142234937547390"
[0m23:49:37.587316 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.587719 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_sources__tmp_20250718214937547142234937547390" cascade
[0m23:49:37.589326 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:49:37.590678 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_sources"
[0m23:49:37.592362 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:49:37.593318 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019801 (1 runs)
[0m23:49:37.594217 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_columns_in_relation: 0:00:00.008912 (1 runs)
[0m23:49:37.595106 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000466 (1 runs)
[0m23:49:37.596305 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.007433 (1 runs)
[0m23:49:37.597503 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries: 0:00:00.008870 (1 runs)
[0m23:49:37.598417 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.run_insert_rows_query: 0:00:00.003780 (1 runs)
[0m23:49:37.599320 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows: 0:00:00.025163 (1 runs)
[0m23:49:37.600655 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.071549 (1 runs)
[0m23:49:37.605526 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:49:37.606967 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:49:37.608187 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:49:37.608999 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:49:37.610516 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:49:37.611463 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000412 (1 runs)
[0m23:49:37.612538 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.004859 (1 runs)
[0m23:49:37.618077 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:49:37.619494 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:49:37.620699 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:49:37.621448 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:49:37.622644 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:49:37.623506 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000358 (1 runs)
[0m23:49:37.624600 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004909 (1 runs)
[0m23:49:37.629680 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:49:37.631507 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:49:37.633152 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:49:37.633906 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:49:37.635255 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:49:37.636121 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000359 (1 runs)
[0m23:49:37.636965 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005588 (1 runs)
[0m23:49:37.641730 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:49:37.643517 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:49:37.645521 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:49:37.646712 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:49:37.648490 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:49:37.649608 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000515 (1 runs)
[0m23:49:37.650459 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.006579 (1 runs)
[0m23:49:37.655864 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:49:37.657597 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:49:37.658943 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:49:37.659723 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:49:37.660941 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:49:37.662564 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000543 (1 runs)
[0m23:49:37.663638 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005063 (1 runs)
[0m23:49:37.668669 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:49:37.854020 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:49:37.855388 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:49:37.856395 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts changed.
[0m23:49:37.859325 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m23:49:37.861538 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.861970 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718214937860276234937860532"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m23:49:37.865429 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:49:37.870541 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:37.871015 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718214937860276234937860532'
        
      order by ordinal_position

  
[0m23:49:37.874238 [debug] [MainThread]: SQL status: SELECT 13 in 0.003 seconds
[0m23:49:37.877307 [debug] [MainThread]: Elementary: Inserting 26 rows to table "dbt_columns__tmp_20250718214937860276234937860532"
[0m23:49:38.112603 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:38.114653 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.115623 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718214937860276234937860532"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.dbt_elsa.consumption.id','model.dbt_elsa.consumption','id','integer','[]','{}','elsa','bronze','consumption','ID','model','2025-07-18 21:49:37','1b339d8bc84c2644c964b35d2efcaebb'),('column.model.dbt_elsa.consumption.created_at','model.dbt_elsa.consumption','created_at','datetime','[]','{}','elsa','bronze','consumption','datetime','model','2025-07-18 21:49:37','4f5046ce89934f74491d7499868f6aff'),('column.model.dbt_elsa.consumption.date','model.dbt_elsa.consumption','date','date','[]','{}','elsa','bronze','consumption','date','model','2025-07-18 21:49:37','933f56a529e08b007b899618c489a5b7'),('column.model.dbt_elsa.consumption.time','model.dbt_elsa.consumption','time','time','[]','{}','elsa','bronze','consumption','time','model','2025-07-18 21:49:37','9a430aa16d9a208634bbf5b03e472797'),('column.model.dbt_elsa.consumption.gaz','model.dbt_elsa.consumption','gaz','float','[]','{}','elsa','bronze','consumption','Production for gaz energy in TWH','model','2025-07-18 21:49:37','dd2412abb57e483c63caf1a237490aff'),('column.model.dbt_elsa.consumption.nucleaire','model.dbt_elsa.consumption','nucleaire','float','[]','{}','elsa','bronze','consumption','Production for nuclear energy in TWH','model','2025-07-18 21:49:37','f563de7c8b74ce826a111ef060ab8806'),('column.model.dbt_elsa.consumption.charbon','model.dbt_elsa.consumption','charbon','float','[]','{}','elsa','bronze','consumption','Production for coal energy in TWH','model','2025-07-18 21:49:37','4c3550f0c6ec4d8727f0b206f1b0c31a'),('column.model.dbt_elsa.consumption.solaire','model.dbt_elsa.consumption','solaire','float','[]','{}','elsa','bronze','consumption','Production for solar energy in TWH','model','2025-07-18 21:49:37','e6ac4bf60c127d0ea76623e9819e97a1'),('column.model.dbt_elsa.consumption.eolien','model.dbt_elsa.consumption','eolien','float','[]','{}','elsa','bronze','consumption','Production for eolian energy in TWH','model','2025-07-18 21:49:37','63015cebfacece7326d29f874d130ce2'),('column.model.dbt_elsa.consumption.hydraulique','model.dbt_elsa.consumption','hydraulique','float','[]','{}','elsa','bronze','consumption','Production for hydrolic energy in TWH','model','2025-07-18 21:49:37','32cca35b1835cf06ed22f29f652ad5fc'),('column.model.dbt_elsa.consumption.bioenergies','model.dbt_elsa.consumption','bioenergies','float','[]','{}','elsa','bronze','consumption','Production for bioenergy energy in TWH','model','2025-07-18 21:49:37','27b3018fa9dfce045d354aa54cf2c2f7'),('column.model.dbt_elsa.consumption.autres','model.dbt_elsa.consumption','autres','float','[]','{}','elsa','bronze','consumption','Production for other energy in TWH','model','2025-07-18 21:49:37','f1c87c5682ba5dab264e421d12be22b9'),('column.model.dbt_elsa.consumption.prevision_j','model.dbt_elsa.consumption','prevision_j','float','[]','{}','elsa','bronze','consumption','Pprevision_j','model','2025-07-18 21:49:37','ceba17353da2e845b0abf550d1348760'),('column.model.dbt_elsa.consumption.prevision_j1','model.dbt_elsa.consumption','prevision_j1','float','[]','{}','elsa','bronze','consumption','prevision_j1','model','2025-07-18 21:49:37','9afa5108fd7f7aef797e7cd192fc835a'),('column.model.dbt_elsa.consumption_history.created_at','model.dbt_elsa.consumption_history','created_at','datetime','[]','{}','elsa','bronze','consumption_history','datetime','model','2025-07-18 21:49:37','459d5fd9dd3fc2af636f7ccd6d1e4390'),('column.model.dbt_elsa.consumption_history.date','model.dbt_elsa.consumption_history','date','date','[]','{}','elsa','bronze','consumption_history','date','model','2025-07-18 21:49:37','a2c72a9e53f093f32e547c075472c38f'),('column.model.dbt_elsa.consumption_history.gaz','model.dbt_elsa.consumption_history','gaz','float','[]','{}','elsa','bronze','consumption_history','Production for gaz energy in TWH','model','2025-07-18 21:49:37','5b7524fa6e1aa4c403bbe3be67a42363'),('column.model.dbt_elsa.consumption_history.nucleaire','model.dbt_elsa.consumption_history','nucleaire','float','[]','{}','elsa','bronze','consumption_history','Production for nuclear energy in TWH','model','2025-07-18 21:49:37','ab8508f49e9fc1376e3acb4068306645'),('column.model.dbt_elsa.consumption_history.charbon','model.dbt_elsa.consumption_history','charbon','float','[]','{}','elsa','bronze','consumption_history','Production for coal energy in TWH','model','2025-07-18 21:49:37','6f60579d0e68fda24fcb14b4dd4622e2'),('column.model.dbt_elsa.consumption_history.solaire','model.dbt_elsa.consumption_history','solaire','float','[]','{}','elsa','bronze','consumption_history','Production for solar energy in TWH','model','2025-07-18 21:49:37','31439eece050a791bf6d02222e47bdb2'),('column.model.dbt_elsa.consumption_history.eolien','model.dbt_elsa.consumption_history','eolien','float','[]','{}','elsa','bronze','consumption_history','Production for eolian energy in TWH','model','2025-07-18 21:49:37','c27e8c2253456f22ba08c02069ab5ba6'),('column.model.dbt_elsa.consumption_history.hydraulique','model.dbt_elsa.consumption_history','hydraulique','float','[]','{}','elsa','bronze','consumption_history','Production for hydrolic energy in TWH','model','2025-07-18 21:49:37','bd0716acb1a1ebf8ba62155b11bb960a'),('column.model.dbt_elsa.consumption_history.bioenergies','model.dbt_elsa.consumption_history','bioenergies','float','[]','{}','elsa','bronze','consumption_history','Production for bioenergy energy in TWH','model','2025-07-18 21:49:37','e907861df8ca52274144c88c697b299f'),('column.model.dbt_elsa.consumption_history.autres','model.dbt_elsa.consumption_history','autres','float','[]','{}','elsa','bronze','consumption_history','Production for other energy in TWH','model','2025-07-18 21:49:37','0ff60f0dfb1b01f26b525a30de9a3275'),('column.model.dbt_elsa.consumption_history.prevision_j','model.dbt_elsa.consumption_history','prevision_j','float','[]','{}','elsa','bronze','consumption_history','Pprevision_j','model','2025-07-18 21:49:37','700f6d919e8be314d8f2666779c8b7c6'),('column.model.dbt_elsa.consumption_history.prevision_j1','model.dbt_elsa.consumption_history','prevision_j1','float','[]','{}','elsa','bronze','consumption_history','prevision_j1','model','2025-07-18 21:49:37','bbe58f35ab87a908d3ae6b88128b4125')
  
[0m23:49:38.117848 [debug] [MainThread]: SQL status: INSERT 0 26 in 0.001 seconds
[0m23:49:38.120724 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.121164 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250718214937860276234937860532";
        
        commit;
    
  
[0m23:49:38.123711 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m23:49:38.128089 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718214937860276234937860532"
[0m23:49:38.129345 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.130012 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718214937860276234937860532" cascade
[0m23:49:38.131576 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:49:38.132819 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m23:49:38.134324 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:49:38.135418 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.184265 (1 runs)
[0m23:49:38.136299 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.009146 (1 runs)
[0m23:49:38.137148 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.002006 (1 runs)
[0m23:49:38.137993 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.220959 (26 runs)
[0m23:49:38.138846 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.233250 (1 runs)
[0m23:49:38.139694 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.005418 (1 runs)
[0m23:49:38.140537 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.252593 (1 runs)
[0m23:49:38.141383 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.465440 (1 runs)
[0m23:49:38.142946 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:49:38.147922 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:49:38.148942 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:49:38.175945 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 5 artifacts.
[0m23:49:38.181326 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.181920 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:49:38.186304 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:49:38.189355 [debug] [MainThread]: Elementary: Inserting 5 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:49:38.273165 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:38.274474 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.275131 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('fae4dea9-d0b2-4c40-9c96-98400d9ae671.model.dbt_elsa.consumption','model.dbt_elsa.consumption','fae4dea9-d0b2-4c40-9c96-98400d9ae671','2025-07-18 21:49:38',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.16968894004821777,'2025-07-18T21:49:36.179086Z','2025-07-18T21:49:36.340789Z','2025-07-18T21:49:36.172723Z','2025-07-18T21:49:36.178288Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    data->>''gaz'' AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','fae4dea9-d0b2-4c40-9c96-98400d9ae671','2025-07-18 21:49:38',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'pass','test',0.6403300762176514,'2025-07-18T21:49:36.398016Z','2025-07-18T21:49:36.979975Z','2025-07-18T21:49:36.354743Z','2025-07-18T21:49:36.394044Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','fae4dea9-d0b2-4c40-9c96-98400d9ae671','2025-07-18 21:49:38',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'pass','test',0.6474101543426514,'2025-07-18T21:49:36.390803Z','2025-07-18T21:49:36.988305Z','2025-07-18T21:49:36.379750Z','2025-07-18T21:49:36.390272Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','fae4dea9-d0b2-4c40-9c96-98400d9ae671','2025-07-18 21:49:38',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'pass','test',0.6496710777282715,'2025-07-18T21:49:36.395374Z','2025-07-18T21:49:36.995228Z','2025-07-18T21:49:36.384720Z','2025-07-18T21:49:36.393620Z',1,False,'
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',0,NULL,'Thread-4 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_time.f86477a2e3','test.dbt_elsa.not_null_consumption_time.f86477a2e3','fae4dea9-d0b2-4c40-9c96-98400d9ae671','2025-07-18 21:49:38',
    current_timestamp::timestamp
,'not_null_consumption_time','Database Error in test not_null_consumption_time (models/bronze/_elsa_bronze__models.yml)
  column "time" does not exist
  LINE 16: select time
                  ^
  compiled code at target/run/dbt_elsa/models/bronze/_elsa_bronze__models.yml/not_null_consumption_time.sql','error','test',0.6735432147979736,'2025-07-18T21:49:36.407650Z','2025-07-18T21:49:37.002152Z','2025-07-18T21:49:36.370435Z','2025-07-18T21:49:36.394833Z',NULL,False,'
    
    



select time
from "elsa"."bronze"."consumption"
where time is null


',NULL,NULL,'Thread-5 (worker)','test','{}',NULL)
  
[0m23:49:38.277361 [debug] [MainThread]: SQL status: INSERT 0 5 in 0.001 seconds
[0m23:49:38.280644 [debug] [MainThread]: On master: COMMIT
[0m23:49:38.281125 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.281491 [debug] [MainThread]: On master: COMMIT
[0m23:49:38.282163 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:49:38.284580 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:49:38.285429 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025923 (1 runs)
[0m23:49:38.286183 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.011294 (1 runs)
[0m23:49:38.286919 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000732 (1 runs)
[0m23:49:38.287663 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.077952 (5 runs)
[0m23:49:38.288405 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.082090 (1 runs)
[0m23:49:38.289166 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.006143 (1 runs)
[0m23:49:38.289934 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002532 (1 runs)
[0m23:49:38.290775 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.106123 (1 runs)
[0m23:49:38.291619 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.135374 (1 runs)
[0m23:49:38.292488 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:49:38.303209 [debug] [MainThread]: Elementary: Handling test results.
[0m23:49:38.420142 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.420658 [debug] [MainThread]: On master: BEGIN
[0m23:49:38.421366 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:49:38.421827 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.422338 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:49:38.426865 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:49:38.429889 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:49:38.505773 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:38.507415 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.508252 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','fae4dea9-d0b2-4c40-9c96-98400d9ae671',cast('2025-07-18 21:49:36' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_date',NULL,0),('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','fae4dea9-d0b2-4c40-9c96-98400d9ae671',cast('2025-07-18 21:49:36' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_created_at',NULL,0),('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','fae4dea9-d0b2-4c40-9c96-98400d9ae671',cast('2025-07-18 21:49:36' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]','
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_id',NULL,0),('fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_time.f86477a2e3',NULL,'fae4dea9-d0b2-4c40-9c96-98400d9ae671.test.dbt_elsa.not_null_consumption_time.f86477a2e3','test.dbt_elsa.not_null_consumption_time.f86477a2e3','model.dbt_elsa.consumption','fae4dea9-d0b2-4c40-9c96-98400d9ae671',cast('2025-07-18 21:49:38' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','time','dbt_test','generic','Database Error in test not_null_consumption_time (models/bronze/_elsa_bronze__models.yml)
  column "time" does not exist
  LINE 16: select time
                  ^
  compiled code at target/run/dbt_elsa/models/bronze/_elsa_bronze__models.yml/not_null_consumption_time.sql','[]','[]','
    
    



select time
from "elsa"."bronze"."consumption"
where time is null


',NULL,'not_null_consumption_time','{"column_name": "time", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','error',NULL,'not_null','not_null_consumption_time',NULL,NULL)
  
[0m23:49:38.509819 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m23:49:38.512560 [debug] [MainThread]: On master: COMMIT
[0m23:49:38.513043 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.513416 [debug] [MainThread]: On master: COMMIT
[0m23:49:38.514348 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:49:38.516179 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:49:38.532966 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:49:38.600845 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.601414 [debug] [MainThread]: On master: BEGIN
[0m23:49:38.602100 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:49:38.602515 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.602988 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:49:38.606977 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m23:49:38.610404 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:49:38.633699 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:49:38.634836 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.635424 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('fae4dea9-d0b2-4c40-9c96-98400d9ae671',NULL,NULL,NULL,'2025-07-18 21:49:34','2025-07-18 21:49:38','2025-07-18 21:49:38',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:49:38.636506 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:49:38.639158 [debug] [MainThread]: On master: COMMIT
[0m23:49:38.639603 [debug] [MainThread]: Using postgres connection "master"
[0m23:49:38.639973 [debug] [MainThread]: On master: COMMIT
[0m23:49:38.640855 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:49:38.642988 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:49:38.650036 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:49:38.651579 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:49:38.652241 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.61s]
[0m23:49:38.652673 [debug] [MainThread]: On master: Close
[0m23:49:38.653146 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:49:38.653449 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:49:38.653731 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m23:49:38.654011 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m23:49:38.654287 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_time.f86477a2e3' was properly closed.
[0m23:49:38.654561 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m23:49:38.654938 [info ] [MainThread]: 
[0m23:49:38.655369 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 4 data tests in 0 hours 0 minutes and 2.81 seconds (2.81s).
[0m23:49:38.657311 [debug] [MainThread]: Command end result
[0m23:49:38.746512 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:49:38.750128 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:49:38.757753 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:49:38.758139 [info ] [MainThread]: 
[0m23:49:38.758542 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:49:38.758919 [info ] [MainThread]: 
[0m23:49:38.759372 [error] [MainThread]: [31mFailure in test not_null_consumption_time (models/bronze/_elsa_bronze__models.yml)[0m
[0m23:49:38.759850 [error] [MainThread]:   Database Error in test not_null_consumption_time (models/bronze/_elsa_bronze__models.yml)
  column "time" does not exist
  LINE 16: select time
                  ^
  compiled code at target/run/dbt_elsa/models/bronze/_elsa_bronze__models.yml/not_null_consumption_time.sql
[0m23:49:38.760243 [info ] [MainThread]: 
[0m23:49:38.760655 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/_elsa_bronze__models.yml/not_null_consumption_time.sql
[0m23:49:38.761002 [info ] [MainThread]: 
[0m23:49:38.761591 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=7
[0m23:49:38.762358 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 4 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:49:38.765650 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.1016283, "process_in_blocks": "0", "process_kernel_time": 0.52131, "process_mem_max_rss": "138145792", "process_out_blocks": "0", "process_user_time": 4.972586}
[0m23:49:38.766340 [debug] [MainThread]: Command `dbt build` failed at 23:49:38.766180 after 4.10 seconds
[0m23:49:38.766815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea0ab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e89b2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbc62e0>]}
[0m23:49:38.767327 [debug] [MainThread]: Flushing usage events
[0m23:49:39.148449 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:50:06.558410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11250b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c43610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c434d0>]}


============================== 23:50:06.563826 | dd7ee73c-3bd0-4362-b688-5ceda2fc4772 ==============================
[0m23:50:06.563826 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:50:06.564514 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select bronze', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:50:06.785264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd7ee73c-3bd0-4362-b688-5ceda2fc4772', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f90510>]}
[0m23:50:06.864768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dd7ee73c-3bd0-4362-b688-5ceda2fc4772', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ac3df0>]}
[0m23:50:06.865725 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:50:06.999346 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:50:07.265461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:50:07.266427 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:50:07.897263 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:50:07.917534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd7ee73c-3bd0-4362-b688-5ceda2fc4772', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114eee650>]}
[0m23:50:08.092660 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:50:08.096232 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:50:08.131263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd7ee73c-3bd0-4362-b688-5ceda2fc4772', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1153de4e0>]}
[0m23:50:08.131807 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:50:08.134475 [info ] [MainThread]: 
[0m23:50:08.134882 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:50:08.135219 [info ] [MainThread]: 
[0m23:50:08.135735 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:50:08.136588 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:50:08.195014 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:50:08.195629 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:50:08.196038 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:50:08.222272 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.026 seconds
[0m23:50:08.223944 [debug] [ThreadPool]: On list_elsa: Close
[0m23:50:08.231326 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:50:08.237086 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:50:08.239020 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:50:08.241916 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:50:08.242349 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:50:08.242758 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:50:08.243107 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:50:08.243462 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:50:08.249382 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:50:08.249788 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:50:08.250111 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:50:08.250434 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:50:08.250817 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:50:08.251199 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:50:08.255257 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:50:08.255651 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:50:08.257106 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:50:08.258929 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:50:08.259483 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:50:08.259811 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:50:08.274023 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:08.274414 [debug] [MainThread]: On master: BEGIN
[0m23:50:08.274719 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:50:08.280187 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:50:08.280575 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:08.281700 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:50:08.322676 [debug] [MainThread]: SQL status: SELECT 26 in 0.040 seconds
[0m23:50:08.330231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd7ee73c-3bd0-4362-b688-5ceda2fc4772', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11532f230>]}
[0m23:50:08.330770 [debug] [MainThread]: On master: ROLLBACK
[0m23:50:08.331342 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:08.331696 [debug] [MainThread]: On master: BEGIN
[0m23:50:08.332321 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:50:08.332683 [debug] [MainThread]: On master: COMMIT
[0m23:50:08.333025 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:08.333340 [debug] [MainThread]: On master: COMMIT
[0m23:50:08.333795 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:50:08.375123 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:50:08.414679 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:08.415285 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:50:08.416313 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m23:50:08.419512 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:50:08.423314 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:50:08.424080 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:50:08.424494 [info ] [MainThread]: 
[0m23:50:08.424907 [debug] [MainThread]: On master: Close
[0m23:50:08.430236 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:50:08.430902 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m23:50:08.431527 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption)
[0m23:50:08.431965 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:50:08.436377 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:50:08.437400 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:50:08.481478 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:50:08.482376 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.482757 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:50:08.483104 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:50:08.489266 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:50:08.489721 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.490132 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz' AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:50:08.495299 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.005 seconds
[0m23:50:08.506707 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.507193 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m23:50:08.507965 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:50:08.512058 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.512593 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:50:08.513551 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:50:08.540792 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.541266 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m23:50:08.542393 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m23:50:08.557064 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.557674 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:50:08.568385 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.010 seconds
[0m23:50:08.573379 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.573955 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m23:50:08.574870 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:50:08.576238 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:50:08.576676 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.577078 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:50:08.578182 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:50:08.585996 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:50:08.591464 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:50:08.591913 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:50:08.594367 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:50:08.597120 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:50:08.599463 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd7ee73c-3bd0-4362-b688-5ceda2fc4772', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11585a4e0>]}
[0m23:50:08.600203 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.17s]
[0m23:50:08.600912 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:50:08.601759 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:50:08.602177 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m23:50:08.602653 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m23:50:08.603039 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:50:08.608400 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:50:08.620366 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m23:50:08.619957 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:50:08.621068 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:50:08.621565 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc'
[0m23:50:08.622084 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m23:50:08.622621 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:50:08.623093 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:50:08.623627 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m23:50:08.629100 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:50:08.632194 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:50:08.632775 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:50:08.633235 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'dd7ee73c-3bd0-4362-b688-5ceda2fc4772', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115381490>]}
[0m23:50:08.641999 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:50:08.654676 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:50:08.695118 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:50:09.039004 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:50:09.040892 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:50:09.041781 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:50:09.042675 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:50:09.043148 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m23:50:09.043682 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:50:09.044707 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:50:09.045434 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:50:09.046010 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m23:50:09.046584 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m23:50:09.046999 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:50:09.047374 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:50:09.050736 [debug] [Thread-3 (]: SQL status: BEGIN in 0.007 seconds
[0m23:50:09.051218 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:50:09.051607 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:50:09.052913 [debug] [Thread-2 (]: SQL status: BEGIN in 0.006 seconds
[0m23:50:09.053387 [debug] [Thread-4 (]: SQL status: BEGIN in 0.006 seconds
[0m23:50:09.053798 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:50:09.054231 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:50:09.054883 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:50:09.055499 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:50:09.072260 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m23:50:09.102879 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.013 seconds
[0m23:50:09.116783 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m23:50:09.121980 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m23:50:09.122437 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.007 seconds
[0m23:50:09.128267 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m23:50:09.127843 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m23:50:09.128827 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m23:50:09.131056 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m23:50:09.129887 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.53s]
[0m23:50:09.130696 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.51s]
[0m23:50:09.132004 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.51s]
[0m23:50:09.132699 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:50:09.133298 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:50:09.133922 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:50:09.136113 [info ] [MainThread]: 
[0m23:50:09.136675 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.137060 [debug] [MainThread]: On master: BEGIN
[0m23:50:09.137617 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:50:09.143659 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:50:09.144110 [debug] [MainThread]: On master: COMMIT
[0m23:50:09.144436 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.144780 [debug] [MainThread]: On master: COMMIT
[0m23:50:09.145945 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:50:09.185323 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.185938 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:50:09.189546 [debug] [MainThread]: SQL status: SELECT 135 in 0.003 seconds
[0m23:50:09.192174 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:50:09.227100 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:50:09.279108 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:50:09.287202 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:50:09.288490 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m23:50:09.289719 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:50:09.290584 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.050586 (1 runs)
[0m23:50:09.291422 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.062640 (1 runs)
[0m23:50:09.297146 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:50:09.311523 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:50:09.313228 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:50:09.314419 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts changed.
[0m23:50:09.323473 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m23:50:09.352469 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.352969 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718215009335440235009343736"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m23:50:09.356661 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:50:09.375313 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.375793 [debug] [MainThread]: On master: BEGIN
[0m23:50:09.376461 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:50:09.376882 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.377263 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718215009335440235009343736'
        
      order by ordinal_position

  
[0m23:50:09.384398 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m23:50:09.386658 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_tests__tmp_20250718215009335440235009343736"
[0m23:50:09.427259 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:50:09.430458 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.430955 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250718215009335440235009343736"
         (metadata_hash) values
    ('b93705874487df8e109b36babf08de5e')
  
[0m23:50:09.431946 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:50:09.439955 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.440445 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_tests"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_tests__tmp_20250718215009335440235009343736");
        
        
        commit;
    
  
[0m23:50:09.442211 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:50:09.446587 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250718215009335440235009343736"
[0m23:50:09.447535 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.447993 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250718215009335440235009343736" cascade
[0m23:50:09.449874 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:50:09.451180 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m23:50:09.452830 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:50:09.453752 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.013144 (1 runs)
[0m23:50:09.454651 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.013766 (1 runs)
[0m23:50:09.455597 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000392 (1 runs)
[0m23:50:09.456509 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.018773 (1 runs)
[0m23:50:09.457428 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.025623 (1 runs)
[0m23:50:09.458520 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.003536 (1 runs)
[0m23:50:09.459783 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:00.061808 (1 runs)
[0m23:50:09.460936 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.155513 (1 runs)
[0m23:50:09.466880 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:50:09.488442 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:50:09.489774 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:50:09.490557 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:50:09.491752 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:50:09.492672 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019753 (1 runs)
[0m23:50:09.493686 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024822 (1 runs)
[0m23:50:09.499259 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:50:09.500855 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:50:09.502549 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:50:09.503468 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:50:09.504885 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:50:09.506232 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000415 (1 runs)
[0m23:50:09.507204 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005454 (1 runs)
[0m23:50:09.512830 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:50:09.514515 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:50:09.515804 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:50:09.516572 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:50:09.517852 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:50:09.518725 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000361 (1 runs)
[0m23:50:09.519552 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005557 (1 runs)
[0m23:50:09.524196 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:50:09.525587 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:50:09.527434 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:50:09.528461 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:50:09.529990 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:50:09.530930 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000351 (1 runs)
[0m23:50:09.531764 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005665 (1 runs)
[0m23:50:09.536559 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:50:09.537989 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:50:09.539192 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:50:09.540332 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:50:09.541670 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:50:09.542601 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000414 (1 runs)
[0m23:50:09.543455 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005001 (1 runs)
[0m23:50:09.548776 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:50:09.550219 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:50:09.551482 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:50:09.552231 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:50:09.553409 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:50:09.554600 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000354 (1 runs)
[0m23:50:09.555436 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004593 (1 runs)
[0m23:50:09.560761 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:50:09.744807 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:50:09.746353 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:50:09.747502 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:50:09.748984 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:50:09.749892 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.182789 (1 runs)
[0m23:50:09.750814 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.188183 (1 runs)
[0m23:50:09.751773 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:50:09.755799 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:50:09.756691 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:50:09.783324 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 4 artifacts.
[0m23:50:09.787185 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.787615 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:50:09.791860 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:50:09.795067 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:50:09.860643 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:50:09.862405 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.863085 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('dd7ee73c-3bd0-4362-b688-5ceda2fc4772.model.dbt_elsa.consumption','model.dbt_elsa.consumption','dd7ee73c-3bd0-4362-b688-5ceda2fc4772','2025-07-18 21:50:09',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.16634225845336914,'2025-07-18T21:50:08.437706Z','2025-07-18T21:50:08.596946Z','2025-07-18T21:50:08.432231Z','2025-07-18T21:50:08.437233Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    data->>''gaz'' AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','dd7ee73c-3bd0-4362-b688-5ceda2fc4772','2025-07-18 21:50:09',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'pass','test',0.5270190238952637,'2025-07-18T21:50:08.629467Z','2025-07-18T21:50:09.121822Z','2025-07-18T21:50:08.603299Z','2025-07-18T21:50:08.622934Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','dd7ee73c-3bd0-4362-b688-5ceda2fc4772','2025-07-18 21:50:09',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'pass','test',0.5090861320495605,'2025-07-18T21:50:08.665582Z','2025-07-18T21:50:09.116600Z','2025-07-18T21:50:08.623952Z','2025-07-18T21:50:08.654495Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','dd7ee73c-3bd0-4362-b688-5ceda2fc4772','2025-07-18 21:50:09',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'pass','test',0.5084311962127686,'2025-07-18T21:50:08.709435Z','2025-07-18T21:50:09.127656Z','2025-07-18T21:50:08.633546Z','2025-07-18T21:50:08.694833Z',1,False,'
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',0,NULL,'Thread-4 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m23:50:09.865160 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m23:50:09.867421 [debug] [MainThread]: On master: COMMIT
[0m23:50:09.867949 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.868475 [debug] [MainThread]: On master: COMMIT
[0m23:50:09.869197 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:50:09.871979 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:50:09.872899 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025629 (1 runs)
[0m23:50:09.873726 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.010032 (1 runs)
[0m23:50:09.875149 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000677 (1 runs)
[0m23:50:09.875970 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.060025 (4 runs)
[0m23:50:09.876688 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.063921 (1 runs)
[0m23:50:09.877392 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005117 (1 runs)
[0m23:50:09.878094 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002804 (1 runs)
[0m23:50:09.878992 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.086339 (1 runs)
[0m23:50:09.879940 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.114993 (1 runs)
[0m23:50:09.881064 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:50:09.890349 [debug] [MainThread]: Elementary: Handling test results.
[0m23:50:09.921777 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.922297 [debug] [MainThread]: On master: BEGIN
[0m23:50:09.922988 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:50:09.923408 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:09.923910 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:50:09.928726 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:50:09.931770 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:50:10.079569 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:50:10.081265 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:10.082008 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','dd7ee73c-3bd0-4362-b688-5ceda2fc4772',cast('2025-07-18 21:50:08' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_created_at',NULL,0),('dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','dd7ee73c-3bd0-4362-b688-5ceda2fc4772',cast('2025-07-18 21:50:08' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_date',NULL,0),('dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'dd7ee73c-3bd0-4362-b688-5ceda2fc4772.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','dd7ee73c-3bd0-4362-b688-5ceda2fc4772',cast('2025-07-18 21:50:08' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]','
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_id',NULL,0)
  
[0m23:50:10.083288 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:50:10.085577 [debug] [MainThread]: On master: COMMIT
[0m23:50:10.086002 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:10.086359 [debug] [MainThread]: On master: COMMIT
[0m23:50:10.087750 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:50:10.089531 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:50:10.107392 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:50:10.175487 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:10.176046 [debug] [MainThread]: On master: BEGIN
[0m23:50:10.176797 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:50:10.177209 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:10.177763 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:50:10.182204 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:50:10.185116 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:50:10.212716 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:50:10.214091 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:10.214704 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('dd7ee73c-3bd0-4362-b688-5ceda2fc4772',NULL,NULL,NULL,'2025-07-18 21:50:06','2025-07-18 21:50:10','2025-07-18 21:50:10',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:50:10.215779 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:50:10.218598 [debug] [MainThread]: On master: COMMIT
[0m23:50:10.219127 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:10.219561 [debug] [MainThread]: On master: COMMIT
[0m23:50:10.220442 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:50:10.222515 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:50:10.230422 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:50:10.231675 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:50:10.232353 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.09s]
[0m23:50:10.232839 [debug] [MainThread]: On master: Close
[0m23:50:10.233442 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:50:10.233794 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:50:10.234089 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m23:50:10.234389 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m23:50:10.234677 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m23:50:10.235073 [info ] [MainThread]: 
[0m23:50:10.235648 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 2.10 seconds (2.10s).
[0m23:50:10.237917 [debug] [MainThread]: Command end result
[0m23:50:10.327213 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:50:10.330418 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:50:10.337156 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:50:10.337542 [info ] [MainThread]: 
[0m23:50:10.337947 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:50:10.338309 [info ] [MainThread]: 
[0m23:50:10.338873 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:50:10.339516 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:50:10.342726 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.8751767, "process_in_blocks": "0", "process_kernel_time": 0.513443, "process_mem_max_rss": "144539648", "process_out_blocks": "0", "process_user_time": 4.914985}
[0m23:50:10.343300 [debug] [MainThread]: Command `dbt build` succeeded at 23:50:10.343171 after 3.88 seconds
[0m23:50:10.344153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11592fc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115023930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115023d90>]}
[0m23:50:10.345403 [debug] [MainThread]: Flushing usage events
[0m23:50:10.787022 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:50:29.211233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084f7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c2b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c2b4d0>]}


============================== 23:50:29.216648 | 5160e298-2249-4fee-b7c4-7d8fac8935dc ==============================
[0m23:50:29.216648 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:50:29.217462 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select silver', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:50:29.435315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5160e298-2249-4fee-b7c4-7d8fac8935dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f74510>]}
[0m23:50:29.513924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5160e298-2249-4fee-b7c4-7d8fac8935dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109aa7df0>]}
[0m23:50:29.514876 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:50:29.647812 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:50:29.914091 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:50:29.914563 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:50:29.922208 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:50:30.071322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5160e298-2249-4fee-b7c4-7d8fac8935dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ba3350>]}
[0m23:50:30.260759 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:50:30.264373 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:50:30.300654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5160e298-2249-4fee-b7c4-7d8fac8935dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9b7c50>]}
[0m23:50:30.301207 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:50:30.303779 [info ] [MainThread]: 
[0m23:50:30.304176 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:50:30.304502 [info ] [MainThread]: 
[0m23:50:30.305024 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:50:30.305883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:50:30.368738 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:50:30.369182 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:50:30.369515 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:50:30.395348 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.026 seconds
[0m23:50:30.396968 [debug] [ThreadPool]: On list_elsa: Close
[0m23:50:30.403825 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:50:30.410910 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:50:30.411497 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:50:30.414623 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:50:30.415074 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:50:30.415389 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:50:30.415694 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:50:30.416027 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:50:30.422252 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:50:30.422671 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:50:30.423009 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:50:30.423398 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:50:30.423731 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:50:30.424057 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:50:30.427101 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:50:30.429117 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:50:30.429626 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m23:50:30.431160 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:50:30.431584 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:50:30.431938 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:50:30.448480 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.448905 [debug] [MainThread]: On master: BEGIN
[0m23:50:30.449204 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:50:30.454591 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:50:30.455002 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.455398 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:50:30.497437 [debug] [MainThread]: SQL status: SELECT 26 in 0.042 seconds
[0m23:50:30.504739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5160e298-2249-4fee-b7c4-7d8fac8935dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab674d0>]}
[0m23:50:30.505330 [debug] [MainThread]: On master: ROLLBACK
[0m23:50:30.505970 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.506356 [debug] [MainThread]: On master: BEGIN
[0m23:50:30.507345 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:50:30.508311 [debug] [MainThread]: On master: COMMIT
[0m23:50:30.508740 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.509062 [debug] [MainThread]: On master: COMMIT
[0m23:50:30.509637 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:50:30.549544 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:50:30.585663 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.586272 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:50:30.587331 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:50:30.590455 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:50:30.595057 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:50:30.596223 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:50:30.596668 [info ] [MainThread]: 
[0m23:50:30.597048 [debug] [MainThread]: On master: Close
[0m23:50:30.601033 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m23:50:30.602067 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze.consumption_history ........................ [RUN]
[0m23:50:30.602786 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption_history)
[0m23:50:30.603263 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m23:50:30.609095 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m23:50:30.610200 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m23:50:30.654622 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m23:50:30.655628 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:50:30.656024 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m23:50:30.656380 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:50:30.662499 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:50:30.663061 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:50:30.663501 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(production_j) AS production_j,
    SUM(production_j1) AS production_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at
  );
  
[0m23:50:30.665559 [debug] [Thread-1 (]: Postgres adapter: Postgres error: function sum(text) does not exist
LINE 18:     SUM(gaz) AS gaz,
             ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m23:50:30.665994 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m23:50:30.666612 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m23:50:30.676018 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  function sum(text) does not exist
  LINE 18:     SUM(gaz) AS gaz,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m23:50:30.677818 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5160e298-2249-4fee-b7c4-7d8fac8935dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3e1d90>]}
[0m23:50:30.678494 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model bronze.consumption_history ............... [[31mERROR[0m in 0.07s]
[0m23:50:30.679745 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m23:50:30.680638 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  function sum(text) does not exist
  LINE 18:     SUM(gaz) AS gaz,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m23:50:30.681757 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:50:30.682245 [info ] [Thread-2 (]: 2 of 3 SKIP test not_null_consumption_history_created_at ....................... [[33mSKIP[0m]
[0m23:50:30.682852 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:50:30.683250 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' to be skipped because of status 'skipped'. 
[0m23:50:30.683739 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:50:30.684368 [info ] [Thread-3 (]: 3 of 3 SKIP test not_null_consumption_history_date ............................. [[33mSKIP[0m]
[0m23:50:30.685081 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:50:30.685501 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' to be skipped because of status 'skipped'. 
[0m23:50:30.687723 [info ] [MainThread]: 
[0m23:50:30.688379 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.688986 [debug] [MainThread]: On master: BEGIN
[0m23:50:30.689465 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:50:30.695800 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:50:30.696360 [debug] [MainThread]: On master: COMMIT
[0m23:50:30.696723 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.697183 [debug] [MainThread]: On master: COMMIT
[0m23:50:30.697796 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:50:30.743466 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:30.743993 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:50:30.748025 [debug] [MainThread]: SQL status: SELECT 134 in 0.004 seconds
[0m23:50:30.750792 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:50:30.783215 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:50:30.868464 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:50:30.876474 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:50:30.877441 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m23:50:30.879107 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:50:30.880393 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.084029 (1 runs)
[0m23:50:30.881346 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.095730 (1 runs)
[0m23:50:30.886228 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:50:31.014670 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:50:31.016362 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:50:31.017183 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:50:31.018478 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:50:31.019363 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.127341 (1 runs)
[0m23:50:31.020211 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.132168 (1 runs)
[0m23:50:31.025055 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:50:31.046841 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:50:31.048394 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:50:31.049166 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:50:31.050334 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:50:31.051294 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020462 (1 runs)
[0m23:50:31.052278 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.025250 (1 runs)
[0m23:50:31.056933 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:50:31.058586 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:50:31.060807 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:50:31.062132 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:50:31.063565 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:50:31.064457 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000488 (1 runs)
[0m23:50:31.065311 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.006535 (1 runs)
[0m23:50:31.069993 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:50:31.071341 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:50:31.072710 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:50:31.073522 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:50:31.075248 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:50:31.076161 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000348 (1 runs)
[0m23:50:31.077002 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005154 (1 runs)
[0m23:50:31.082272 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:50:31.083700 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:50:31.084966 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:50:31.085729 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:50:31.086900 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:50:31.088067 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000347 (1 runs)
[0m23:50:31.088901 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004601 (1 runs)
[0m23:50:31.093935 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:50:31.096254 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:50:31.097554 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:50:31.098318 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:50:31.099471 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:50:31.100302 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000561 (1 runs)
[0m23:50:31.101198 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005563 (1 runs)
[0m23:50:31.106147 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:50:31.107730 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:50:31.109092 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:50:31.109880 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:50:31.111072 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:50:31.111918 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000434 (1 runs)
[0m23:50:31.113035 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004855 (1 runs)
[0m23:50:31.118467 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:50:31.301764 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:50:31.303360 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:50:31.304304 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:50:31.305578 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:50:31.306455 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.181455 (1 runs)
[0m23:50:31.307401 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.187051 (1 runs)
[0m23:50:31.308380 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:50:31.312748 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:50:31.314134 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:50:31.342269 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m23:50:31.366043 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.366523 [debug] [MainThread]: On master: BEGIN
[0m23:50:31.367160 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:50:31.367539 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.367910 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:50:31.376898 [debug] [MainThread]: SQL status: SELECT 23 in 0.009 seconds
[0m23:50:31.382578 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:50:31.490320 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:50:31.491629 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.492197 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('5160e298-2249-4fee-b7c4-7d8fac8935dc.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','5160e298-2249-4fee-b7c4-7d8fac8935dc','2025-07-18 21:50:31',
    current_timestamp::timestamp
,'consumption_history','Database Error in model consumption_history (models/silver/consumption_history.sql)
  function sum(text) does not exist
  LINE 18:     SUM(gaz) AS gaz,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql','error','model',0.07389688491821289,'2025-07-18T21:50:30.610513Z','2025-07-18T21:50:30.666470Z','2025-07-18T21:50:30.603547Z','2025-07-18T21:50:30.610010Z',NULL,False,'SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(production_j) AS production_j,
    SUM(production_j1) AS production_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('5160e298-2249-4fee-b7c4-7d8fac8935dc.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','5160e298-2249-4fee-b7c4-7d8fac8935dc','2025-07-18 21:50:31',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)','test','{}',NULL),('5160e298-2249-4fee-b7c4-7d8fac8935dc.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','5160e298-2249-4fee-b7c4-7d8fac8935dc','2025-07-18 21:50:31',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-3 (worker)','test','{}',NULL)
  
[0m23:50:31.494427 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.002 seconds
[0m23:50:31.497493 [debug] [MainThread]: On master: COMMIT
[0m23:50:31.497979 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.498350 [debug] [MainThread]: On master: COMMIT
[0m23:50:31.500052 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:50:31.502668 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:50:31.503510 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.027033 (1 runs)
[0m23:50:31.504279 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.024567 (1 runs)
[0m23:50:31.505002 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000688 (1 runs)
[0m23:50:31.505765 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.075148 (3 runs)
[0m23:50:31.506873 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.085883 (1 runs)
[0m23:50:31.507865 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005751 (1 runs)
[0m23:50:31.508651 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003755 (1 runs)
[0m23:50:31.509391 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.144169 (1 runs)
[0m23:50:31.510108 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.188347 (1 runs)
[0m23:50:31.510902 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:50:31.521328 [debug] [MainThread]: Elementary: Handling test results.
[0m23:50:31.575922 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.576486 [debug] [MainThread]: On master: BEGIN
[0m23:50:31.577206 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:50:31.577626 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.578104 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:50:31.582997 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:50:31.585787 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:50:31.626755 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:50:31.628370 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.629210 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('5160e298-2249-4fee-b7c4-7d8fac8935dc.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'5160e298-2249-4fee-b7c4-7d8fac8935dc.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','5160e298-2249-4fee-b7c4-7d8fac8935dc',cast('2025-07-18 21:50:31' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_created_at',NULL,NULL),('5160e298-2249-4fee-b7c4-7d8fac8935dc.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'5160e298-2249-4fee-b7c4-7d8fac8935dc.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','5160e298-2249-4fee-b7c4-7d8fac8935dc',cast('2025-07-18 21:50:31' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','date','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_date',NULL,NULL)
  
[0m23:50:31.630737 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:50:31.633062 [debug] [MainThread]: On master: COMMIT
[0m23:50:31.633451 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.633811 [debug] [MainThread]: On master: COMMIT
[0m23:50:31.634982 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:50:31.636436 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:50:31.653549 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:50:31.720529 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.721046 [debug] [MainThread]: On master: BEGIN
[0m23:50:31.721713 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:50:31.722202 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.722712 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:50:31.726995 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:50:31.730227 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:50:31.753559 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:50:31.754774 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.755338 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('5160e298-2249-4fee-b7c4-7d8fac8935dc',NULL,NULL,NULL,'2025-07-18 21:50:29','2025-07-18 21:50:31','2025-07-18 21:50:31',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:50:31.756438 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:50:31.759012 [debug] [MainThread]: On master: COMMIT
[0m23:50:31.759484 [debug] [MainThread]: Using postgres connection "master"
[0m23:50:31.759867 [debug] [MainThread]: On master: COMMIT
[0m23:50:31.761012 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:50:31.763440 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:50:31.770112 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:50:31.771112 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:50:31.771627 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.07s]
[0m23:50:31.772017 [debug] [MainThread]: On master: Close
[0m23:50:31.772483 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:50:31.772782 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m23:50:31.773060 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m23:50:31.773435 [info ] [MainThread]: 
[0m23:50:31.773802 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.47 seconds (1.47s).
[0m23:50:31.775174 [debug] [MainThread]: Command end result
[0m23:50:31.870845 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:50:31.873409 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:50:31.880355 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:50:31.880771 [info ] [MainThread]: 
[0m23:50:31.881153 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:50:31.881490 [info ] [MainThread]: 
[0m23:50:31.881917 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m23:50:31.882337 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  function sum(text) does not exist
  LINE 18:     SUM(gaz) AS gaz,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m23:50:31.882672 [info ] [MainThread]: 
[0m23:50:31.883058 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m23:50:31.883378 [info ] [MainThread]: 
[0m23:50:31.883741 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=5
[0m23:50:31.886386 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.768596, "process_in_blocks": "0", "process_kernel_time": 0.497889, "process_mem_max_rss": "136269824", "process_out_blocks": "0", "process_user_time": 3.875036}
[0m23:50:31.887090 [debug] [MainThread]: Command `dbt build` failed at 23:50:31.886942 after 2.77 seconds
[0m23:50:31.887556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a1ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b343cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b343c20>]}
[0m23:50:31.887971 [debug] [MainThread]: Flushing usage events
[0m23:50:32.285215 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:54:50.351460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdf7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11152b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11152b4d0>]}


============================== 23:54:50.359043 | 716b6ad7-c1eb-4474-94c9-d540535bfb44 ==============================
[0m23:54:50.359043 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:54:50.360029 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select bronze', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:54:50.654727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '716b6ad7-c1eb-4474-94c9-d540535bfb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110874510>]}
[0m23:54:50.735227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '716b6ad7-c1eb-4474-94c9-d540535bfb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113a7df0>]}
[0m23:54:50.736914 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:54:50.923335 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:54:51.337378 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m23:54:51.338415 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/_elsa_bronze__models.yml
[0m23:54:51.338837 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/consumption.sql
[0m23:54:51.997424 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:54:52.016477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '716b6ad7-c1eb-4474-94c9-d540535bfb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b2550>]}
[0m23:54:52.211033 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:54:52.216114 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:54:52.284556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '716b6ad7-c1eb-4474-94c9-d540535bfb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a9e4e0>]}
[0m23:54:52.285099 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:54:52.287676 [info ] [MainThread]: 
[0m23:54:52.288057 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:54:52.288549 [info ] [MainThread]: 
[0m23:54:52.289289 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:54:52.290150 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:54:52.363910 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:54:52.364376 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:54:52.364718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:54:52.404353 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.040 seconds
[0m23:54:52.406322 [debug] [ThreadPool]: On list_elsa: Close
[0m23:54:52.414973 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m23:54:52.415707 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m23:54:52.423300 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:54:52.426295 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:54:52.426749 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:54:52.427096 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:54:52.427425 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:54:52.427760 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:54:52.435465 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:54:52.435906 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:54:52.436274 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:54:52.436683 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m23:54:52.437030 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:54:52.437385 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:54:52.441001 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:54:52.441471 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:54:52.443096 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:54:52.445051 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:54:52.445718 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:54:52.446490 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:54:52.461438 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.461864 [debug] [MainThread]: On master: BEGIN
[0m23:54:52.462169 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:54:52.468091 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:54:52.468510 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.468914 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:54:52.510675 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m23:54:52.518233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '716b6ad7-c1eb-4474-94c9-d540535bfb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ad7230>]}
[0m23:54:52.518788 [debug] [MainThread]: On master: ROLLBACK
[0m23:54:52.519399 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.519738 [debug] [MainThread]: On master: BEGIN
[0m23:54:52.520322 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:54:52.520655 [debug] [MainThread]: On master: COMMIT
[0m23:54:52.520971 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.521275 [debug] [MainThread]: On master: COMMIT
[0m23:54:52.521756 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:54:52.561225 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:54:52.603614 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.604226 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:54:52.605280 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:54:52.608425 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:54:52.613723 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:54:52.614436 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:54:52.614792 [info ] [MainThread]: 
[0m23:54:52.615161 [debug] [MainThread]: On master: Close
[0m23:54:52.620379 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:54:52.621267 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m23:54:52.622015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption)
[0m23:54:52.622579 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:54:52.627916 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:54:52.629284 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:54:52.673611 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:54:52.674992 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:54:52.675445 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:54:52.675835 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:54:52.682495 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m23:54:52.682983 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:54:52.683403 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    data->>'gaz'::int AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:54:52.685116 [debug] [Thread-1 (]: Postgres adapter: Postgres error: invalid input syntax for type integer: "gaz"
LINE 17:     data->>'gaz'::int AS gaz,
                    ^

[0m23:54:52.685565 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m23:54:52.686319 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:54:52.700141 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  invalid input syntax for type integer: "gaz"
  LINE 17:     data->>'gaz'::int AS gaz,
                      ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m23:54:52.702721 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '716b6ad7-c1eb-4474-94c9-d540535bfb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113016340>]}
[0m23:54:52.703642 [error] [Thread-1 (]: 1 of 4 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.08s]
[0m23:54:52.704446 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:54:52.705120 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  invalid input syntax for type integer: "gaz"
  LINE 17:     data->>'gaz'::int AS gaz,
                      ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m23:54:52.706410 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:54:52.706939 [info ] [Thread-2 (]: 2 of 4 SKIP test not_null_consumption_created_at ............................... [[33mSKIP[0m]
[0m23:54:52.707536 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:54:52.708088 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:54:52.708568 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:54:52.709504 [info ] [Thread-4 (]: 4 of 4 SKIP test not_null_consumption_id ....................................... [[33mSKIP[0m]
[0m23:54:52.710684 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' to be skipped because of status 'skipped'. 
[0m23:54:52.711717 [info ] [Thread-3 (]: 3 of 4 SKIP test not_null_consumption_date ..................................... [[33mSKIP[0m]
[0m23:54:52.713217 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:54:52.714240 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:54:52.714687 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_id.186948fd55' to be skipped because of status 'skipped'. 
[0m23:54:52.715150 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_date.0e210070dc' to be skipped because of status 'skipped'. 
[0m23:54:52.717441 [info ] [MainThread]: 
[0m23:54:52.717972 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.718506 [debug] [MainThread]: On master: BEGIN
[0m23:54:52.718971 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:54:52.725728 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m23:54:52.726213 [debug] [MainThread]: On master: COMMIT
[0m23:54:52.726659 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.727006 [debug] [MainThread]: On master: COMMIT
[0m23:54:52.727536 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:54:52.771368 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.771891 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:54:52.776450 [debug] [MainThread]: SQL status: SELECT 134 in 0.004 seconds
[0m23:54:52.779950 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:54:52.812272 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:54:52.896736 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:54:52.904533 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:54:52.905500 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m23:54:52.917685 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:54:52.946778 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.947279 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215452929569235452938891"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:54:52.952005 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m23:54:52.975954 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.976461 [debug] [MainThread]: On master: BEGIN
[0m23:54:52.977211 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:54:52.977693 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:52.978107 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215452929569235452938891'
        
      order by ordinal_position

  
[0m23:54:52.987683 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m23:54:52.992308 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215452929569235452938891"
[0m23:54:53.039637 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:54:53.041050 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.041631 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215452929569235452938891"
         (metadata_hash) values
    ('0a2e8bb8f83dd30e9733f42917cec9ed')
  
[0m23:54:53.042619 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:54:53.047495 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.047971 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215453046118235453046456"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:54:53.050085 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:54:53.054847 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.055318 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215453046118235453046456'
        
      order by ordinal_position

  
[0m23:54:53.059173 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m23:54:53.062037 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215453046118235453046456"
[0m23:54:53.073441 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:54:53.074576 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.075137 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215453046118235453046456"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption','consumption','7a32d88f121424d90122c3b73e986c40b70810a57fa5de4001c80fc0d8110635','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','The aim of this table is to track houtly energy consumption for a given day
','consumption','dbt_elsa','models/bronze/consumption.sql','bronze/consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-18 21:54:52','45309375f29ba85ba4ca443ab99ce304',NULL,NULL,NULL,'protected')
  
[0m23:54:53.076110 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:54:53.084881 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.085423 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718215452929569235452938891");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718215453046118235453046456";
        
        commit;
    
  
[0m23:54:53.087296 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:54:53.096693 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215452929569235452938891"
[0m23:54:53.101486 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.101984 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215452929569235452938891" cascade
[0m23:54:53.103890 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:54:53.108116 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215453046118235453046456"
[0m23:54:53.108827 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.109262 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215453046118235453046456" cascade
[0m23:54:53.111220 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:54:53.113407 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:54:53.115172 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:54:53.116275 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.082510 (1 runs)
[0m23:54:53.117188 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.032452 (2 runs)
[0m23:54:53.118567 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001132 (2 runs)
[0m23:54:53.119534 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.031433 (2 runs)
[0m23:54:53.120425 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.041405 (2 runs)
[0m23:54:53.121440 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.007606 (2 runs)
[0m23:54:53.122390 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.103598 (2 runs)
[0m23:54:53.123262 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.302710 (1 runs)
[0m23:54:53.128341 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:54:53.257558 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:54:53.259363 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:54:53.260198 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:54:53.261390 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:54:53.262574 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.127949 (1 runs)
[0m23:54:53.263734 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.133002 (1 runs)
[0m23:54:53.268519 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:54:53.289590 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:54:53.290993 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:54:53.291884 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:54:53.293126 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:54:53.294003 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020026 (1 runs)
[0m23:54:53.294851 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024529 (1 runs)
[0m23:54:53.300396 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:54:53.301897 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:54:53.303500 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:54:53.304253 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:54:53.305445 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:54:53.306344 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000414 (1 runs)
[0m23:54:53.307287 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005004 (1 runs)
[0m23:54:53.313600 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:54:53.315121 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:54:53.316376 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:54:53.317127 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:54:53.318903 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:54:53.319837 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000356 (1 runs)
[0m23:54:53.320686 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005139 (1 runs)
[0m23:54:53.325612 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:54:53.327116 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:54:53.328374 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:54:53.329280 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:54:53.331025 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:54:53.332353 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000364 (1 runs)
[0m23:54:53.333202 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005380 (1 runs)
[0m23:54:53.337864 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:54:53.339427 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:54:53.340666 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:54:53.341566 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:54:53.342895 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:54:53.343950 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000433 (1 runs)
[0m23:54:53.344953 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004915 (1 runs)
[0m23:54:53.350619 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:54:53.352050 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:54:53.353243 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:54:53.353998 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:54:53.355186 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:54:53.356101 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000347 (1 runs)
[0m23:54:53.356958 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004525 (1 runs)
[0m23:54:53.362135 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:54:53.549811 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:54:53.551537 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:54:53.552562 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts changed.
[0m23:54:53.555948 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m23:54:53.558351 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.558832 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718215453556870235453557149"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m23:54:53.561378 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:54:53.567058 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.567549 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718215453556870235453557149'
        
      order by ordinal_position

  
[0m23:54:53.570286 [debug] [MainThread]: SQL status: SELECT 1 in 0.002 seconds
[0m23:54:53.572666 [debug] [MainThread]: Elementary: Inserting 10 rows to table "dbt_columns__tmp_20250718215453556870235453557149"
[0m23:54:53.586297 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:54:53.587492 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.587936 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718215453556870235453557149"
         (metadata_hash) values
    ('27b3018fa9dfce045d354aa54cf2c2f7'),('32cca35b1835cf06ed22f29f652ad5fc'),('4c3550f0c6ec4d8727f0b206f1b0c31a'),('63015cebfacece7326d29f874d130ce2'),('9afa5108fd7f7aef797e7cd192fc835a'),('ceba17353da2e845b0abf550d1348760'),('dd2412abb57e483c63caf1a237490aff'),('e6ac4bf60c127d0ea76623e9819e97a1'),('f1c87c5682ba5dab264e421d12be22b9'),('f563de7c8b74ce826a111ef060ab8806')
  
[0m23:54:53.588938 [debug] [MainThread]: SQL status: INSERT 0 10 in 0.001 seconds
[0m23:54:53.593290 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.593773 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718215453592028235453592282"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m23:54:53.596777 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:54:53.601550 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.602052 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718215453592028235453592282'
        
      order by ordinal_position

  
[0m23:54:53.605281 [debug] [MainThread]: SQL status: SELECT 13 in 0.003 seconds
[0m23:54:53.607897 [debug] [MainThread]: Elementary: Inserting 10 rows to table "dbt_columns__tmp_20250718215453592028235453592282"
[0m23:54:53.664102 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:54:53.665254 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.665746 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718215453592028235453592282"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.dbt_elsa.consumption.gaz','model.dbt_elsa.consumption','gaz','integer','[]','{}','elsa','bronze','consumption','Production for gaz energy in TWH','model','2025-07-18 21:54:53','c1381ba8bc7d677af0f60682093b014a'),('column.model.dbt_elsa.consumption.nucleaire','model.dbt_elsa.consumption','nucleaire','integer','[]','{}','elsa','bronze','consumption','Production for nuclear energy in TWH','model','2025-07-18 21:54:53','6477b04956e409ee3e1e3a33599fd7ce'),('column.model.dbt_elsa.consumption.charbon','model.dbt_elsa.consumption','charbon','integer','[]','{}','elsa','bronze','consumption','Production for coal energy in TWH','model','2025-07-18 21:54:53','73015f45e474a2f472eac8a0b8bec6ca'),('column.model.dbt_elsa.consumption.solaire','model.dbt_elsa.consumption','solaire','integer','[]','{}','elsa','bronze','consumption','Production for solar energy in TWH','model','2025-07-18 21:54:53','b7ebd61d6e15c578e58c04dcf3f9aab8'),('column.model.dbt_elsa.consumption.eolien','model.dbt_elsa.consumption','eolien','integer','[]','{}','elsa','bronze','consumption','Production for eolian energy in TWH','model','2025-07-18 21:54:53','bfe4d991806cb107fe21daf8a76f88ec'),('column.model.dbt_elsa.consumption.hydraulique','model.dbt_elsa.consumption','hydraulique','integer','[]','{}','elsa','bronze','consumption','Production for hydrolic energy in TWH','model','2025-07-18 21:54:53','e9dd011749620cabab33fc53fd12d90e'),('column.model.dbt_elsa.consumption.bioenergies','model.dbt_elsa.consumption','bioenergies','integer','[]','{}','elsa','bronze','consumption','Production for bioenergy energy in TWH','model','2025-07-18 21:54:53','aee8888eb22af332c4d6cc954e0305e7'),('column.model.dbt_elsa.consumption.autres','model.dbt_elsa.consumption','autres','integer','[]','{}','elsa','bronze','consumption','Production for other energy in TWH','model','2025-07-18 21:54:53','bf60a317f0d62f814c35af46cd70442a'),('column.model.dbt_elsa.consumption.prevision_j','model.dbt_elsa.consumption','prevision_j','integer','[]','{}','elsa','bronze','consumption','Pprevision_j','model','2025-07-18 21:54:53','15b304ac3e18ec9865268b2a711ad58b'),('column.model.dbt_elsa.consumption.prevision_j1','model.dbt_elsa.consumption','prevision_j1','integer','[]','{}','elsa','bronze','consumption','prevision_j1','model','2025-07-18 21:54:53','2cf20940ce3473fdaa10c880d022986e')
  
[0m23:54:53.666929 [debug] [MainThread]: SQL status: INSERT 0 10 in 0.001 seconds
[0m23:54:53.669774 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.670227 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_columns"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_columns__tmp_20250718215453556870235453557149");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250718215453592028235453592282";
        
        commit;
    
  
[0m23:54:53.671737 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:54:53.675929 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718215453556870235453557149"
[0m23:54:53.676666 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.677240 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718215453556870235453557149" cascade
[0m23:54:53.678992 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:54:53.683064 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718215453592028235453592282"
[0m23:54:53.683742 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.684131 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718215453592028235453592282" cascade
[0m23:54:53.685716 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:54:53.686994 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m23:54:53.688568 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:54:53.689606 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.185827 (1 runs)
[0m23:54:53.690539 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.016441 (2 runs)
[0m23:54:53.691499 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000842 (2 runs)
[0m23:54:53.692454 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.058500 (20 runs)
[0m23:54:53.693372 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.066619 (2 runs)
[0m23:54:53.694271 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.007154 (2 runs)
[0m23:54:53.695505 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.097967 (2 runs)
[0m23:54:53.696704 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.326202 (1 runs)
[0m23:54:53.698019 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:54:53.702271 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:54:53.703205 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:54:53.731619 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 4 artifacts.
[0m23:54:53.736014 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:53.736488 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:54:53.740486 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:54:53.743170 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:54:54.069810 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:54:54.072853 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.073759 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('716b6ad7-c1eb-4474-94c9-d540535bfb44.model.dbt_elsa.consumption','model.dbt_elsa.consumption','716b6ad7-c1eb-4474-94c9-d540535bfb44','2025-07-18 21:54:53',
    current_timestamp::timestamp
,'consumption','Database Error in model consumption (models/bronze/consumption.sql)
  invalid input syntax for type integer: "gaz"
  LINE 17:     data->>''gaz''::int AS gaz,
                      ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql','error','model',0.07882809638977051,'2025-07-18T21:54:52.629734Z','2025-07-18T21:54:52.686166Z','2025-07-18T21:54:52.622891Z','2025-07-18T21:54:52.629075Z',NULL,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    data->>''gaz''::int AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','716b6ad7-c1eb-4474-94c9-d540535bfb44','2025-07-18 21:54:53',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)','test','{}',NULL),('716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','716b6ad7-c1eb-4474-94c9-d540535bfb44','2025-07-18 21:54:53',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-4 (worker)','test','{}',NULL),('716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','716b6ad7-c1eb-4474-94c9-d540535bfb44','2025-07-18 21:54:53',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-3 (worker)','test','{}',NULL)
  
[0m23:54:54.133751 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.059 seconds
[0m23:54:54.136235 [debug] [MainThread]: On master: COMMIT
[0m23:54:54.136710 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.137344 [debug] [MainThread]: On master: COMMIT
[0m23:54:54.141665 [debug] [MainThread]: SQL status: COMMIT in 0.004 seconds
[0m23:54:54.144473 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:54:54.145365 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.027392 (1 runs)
[0m23:54:54.146957 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.009412 (1 runs)
[0m23:54:54.148302 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001012 (1 runs)
[0m23:54:54.149766 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.318334 (4 runs)
[0m23:54:54.151082 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.324322 (1 runs)
[0m23:54:54.151983 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.063673 (1 runs)
[0m23:54:54.153202 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.006548 (1 runs)
[0m23:54:54.154411 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.410020 (1 runs)
[0m23:54:54.155312 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.440846 (1 runs)
[0m23:54:54.156177 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:54:54.167904 [debug] [MainThread]: Elementary: Handling test results.
[0m23:54:54.243342 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.244131 [debug] [MainThread]: On master: BEGIN
[0m23:54:54.245448 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:54:54.246353 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.246885 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:54:54.251120 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:54:54.253950 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:54:54.320568 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:54:54.322163 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.322817 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','716b6ad7-c1eb-4474-94c9-d540535bfb44',cast('2025-07-18 21:54:54' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_created_at',NULL,NULL),('716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','716b6ad7-c1eb-4474-94c9-d540535bfb44',cast('2025-07-18 21:54:54' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_id',NULL,NULL),('716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'716b6ad7-c1eb-4474-94c9-d540535bfb44.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','716b6ad7-c1eb-4474-94c9-d540535bfb44',cast('2025-07-18 21:54:54' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_date',NULL,NULL)
  
[0m23:54:54.324169 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:54:54.326891 [debug] [MainThread]: On master: COMMIT
[0m23:54:54.327334 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.327703 [debug] [MainThread]: On master: COMMIT
[0m23:54:54.328869 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:54:54.330670 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:54:54.347410 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:54:54.430312 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.430944 [debug] [MainThread]: On master: BEGIN
[0m23:54:54.431774 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:54:54.432258 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.432751 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:54:54.437786 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:54:54.441208 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:54:54.465662 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:54:54.466863 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.467423 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('716b6ad7-c1eb-4474-94c9-d540535bfb44',NULL,NULL,NULL,'2025-07-18 21:54:50','2025-07-18 21:54:54','2025-07-18 21:54:54',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:54:54.468579 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:54:54.471259 [debug] [MainThread]: On master: COMMIT
[0m23:54:54.471794 [debug] [MainThread]: Using postgres connection "master"
[0m23:54:54.472233 [debug] [MainThread]: On master: COMMIT
[0m23:54:54.473697 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:54:54.475535 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:54:54.482803 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:54:54.484856 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:54:54.485525 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.76s]
[0m23:54:54.485961 [debug] [MainThread]: On master: Close
[0m23:54:54.486580 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:54:54.486976 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:54:54.487287 [debug] [MainThread]: Connection 'list_elsa_bronze_tec_elsa' was properly closed.
[0m23:54:54.487694 [info ] [MainThread]: 
[0m23:54:54.488067 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 2.20 seconds (2.20s).
[0m23:54:54.489382 [debug] [MainThread]: Command end result
[0m23:54:54.579639 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:54:54.582274 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:54:54.590213 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:54:54.590603 [info ] [MainThread]: 
[0m23:54:54.591062 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:54:54.591518 [info ] [MainThread]: 
[0m23:54:54.592001 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m23:54:54.592624 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  invalid input syntax for type integer: "gaz"
  LINE 17:     data->>'gaz'::int AS gaz,
                      ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m23:54:54.593186 [info ] [MainThread]: 
[0m23:54:54.593634 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m23:54:54.593993 [info ] [MainThread]: 
[0m23:54:54.594362 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=3 NO-OP=0 TOTAL=6
[0m23:54:54.598363 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.3608227, "process_in_blocks": "0", "process_kernel_time": 0.826224, "process_mem_max_rss": "142352384", "process_out_blocks": "0", "process_user_time": 5.111541}
[0m23:54:54.598934 [debug] [MainThread]: Command `dbt build` failed at 23:54:54.598814 after 4.36 seconds
[0m23:54:54.599348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11325fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11325fb70>]}
[0m23:54:54.599735 [debug] [MainThread]: Flushing usage events
[0m23:54:55.047001 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:55:13.193490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122c3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139fb610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139fb4d0>]}


============================== 23:55:13.198932 | b5718af2-535f-4acf-ba0d-4a5ca1c26615 ==============================
[0m23:55:13.198932 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:55:13.199565 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:55:13.420649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d48510>]}
[0m23:55:13.499436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11387bdf0>]}
[0m23:55:13.500518 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:55:13.635383 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:55:13.893685 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:55:13.894822 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/consumption.sql
[0m23:55:14.626297 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:55:14.644823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ca6550>]}
[0m23:55:14.834542 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:55:14.837135 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:55:14.871355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11519e4e0>]}
[0m23:55:14.871867 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:55:14.874657 [info ] [MainThread]: 
[0m23:55:14.875074 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:55:14.875410 [info ] [MainThread]: 
[0m23:55:14.875937 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:55:14.876775 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:55:14.927467 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:55:14.927883 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:55:14.928287 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:55:14.951386 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.023 seconds
[0m23:55:14.952856 [debug] [ThreadPool]: On list_elsa: Close
[0m23:55:14.959351 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:55:14.966867 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:55:14.967443 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:55:14.970214 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:55:14.970655 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:55:14.970973 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:55:14.971278 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:55:14.971602 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:55:14.977693 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:55:14.978094 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:55:14.978440 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:55:14.978869 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:55:14.979327 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:55:14.979814 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:55:14.983874 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:55:14.984296 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:55:14.985738 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:55:14.987307 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:55:14.987805 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:55:14.988158 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:55:15.002127 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.002515 [debug] [MainThread]: On master: BEGIN
[0m23:55:15.002824 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:55:15.008048 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:55:15.008439 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.008896 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:55:15.051186 [debug] [MainThread]: SQL status: SELECT 26 in 0.042 seconds
[0m23:55:15.058412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150e7150>]}
[0m23:55:15.058907 [debug] [MainThread]: On master: ROLLBACK
[0m23:55:15.059482 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.059851 [debug] [MainThread]: On master: BEGIN
[0m23:55:15.060546 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:15.061017 [debug] [MainThread]: On master: COMMIT
[0m23:55:15.061380 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.061676 [debug] [MainThread]: On master: COMMIT
[0m23:55:15.062185 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:55:15.102279 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:55:15.142549 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.143148 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:55:15.144144 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m23:55:15.147520 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:55:15.151454 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:55:15.152026 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:55:15.152379 [info ] [MainThread]: 
[0m23:55:15.152742 [debug] [MainThread]: On master: Close
[0m23:55:15.156501 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:55:15.157099 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m23:55:15.157773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption)
[0m23:55:15.158351 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:55:15.162269 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:55:15.164009 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:55:15.207070 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:55:15.207949 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.208345 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:55:15.208702 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:55:15.214252 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m23:55:15.214705 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.215102 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    (data->>'gaz')::int AS gaz,
    data->>'nucleaire' AS nucleaire,
    data->>'charbon' AS charbon,
    data->>'solaire' AS solaire,
    data->>'eolien' AS eolien,
    data->>'hydraulique' AS hydraulique,
    data->>'bioenergies' AS bioenergies,
    data->>'autres' AS autres,
    data->>'prevision_j' AS prevision_j,
    data->>'prevision_j1' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:55:15.219965 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.004 seconds
[0m23:55:15.231528 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.231978 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m23:55:15.232949 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:55:15.236745 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.237180 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:55:15.238099 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:55:15.264380 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.264851 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m23:55:15.265718 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:55:15.279211 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.279857 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:55:15.287801 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.007 seconds
[0m23:55:15.292835 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.293474 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m23:55:15.294493 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:55:15.295883 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:55:15.296596 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.297064 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:55:15.298711 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:55:15.306721 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:55:15.312473 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:15.313079 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:55:15.315780 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:55:15.318340 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:55:15.320124 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11560a4e0>]}
[0m23:55:15.320797 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.16s]
[0m23:55:15.321468 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:55:15.322264 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:15.322700 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m23:55:15.323156 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:15.323699 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m23:55:15.324088 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:15.324560 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m23:55:15.324999 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:15.325395 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m23:55:15.326228 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc'
[0m23:55:15.339239 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m23:55:15.341496 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:15.341930 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:15.342312 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:15.347395 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:15.352482 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:15.352959 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:15.363389 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:15.363819 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:15.362770 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:55:15.366447 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:55:15.369985 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:55:15.371706 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151341d0>]}
[0m23:55:15.372277 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115153490>]}
[0m23:55:15.372934 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b5718af2-535f-4acf-ba0d-4a5ca1c26615', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115153540>]}
[0m23:55:15.795101 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:15.796242 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:15.798927 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:15.799741 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:15.800141 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m23:55:15.800497 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:55:15.801235 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:15.801663 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m23:55:15.802189 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:15.802577 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:15.802992 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m23:55:15.803548 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:55:15.807203 [debug] [Thread-4 (]: SQL status: BEGIN in 0.007 seconds
[0m23:55:15.807799 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:15.808469 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m23:55:15.809751 [debug] [Thread-3 (]: SQL status: BEGIN in 0.007 seconds
[0m23:55:15.810343 [debug] [Thread-2 (]: SQL status: BEGIN in 0.007 seconds
[0m23:55:15.810885 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:15.811646 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:55:15.812649 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:15.813924 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:55:15.826225 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:55:15.855110 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.012 seconds
[0m23:55:15.891592 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m23:55:15.892245 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.013 seconds
[0m23:55:15.899621 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m23:55:15.906886 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m23:55:15.907381 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m23:55:15.908439 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.57s]
[0m23:55:15.909120 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m23:55:15.909670 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m23:55:15.910527 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:15.911492 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.59s]
[0m23:55:15.912578 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.59s]
[0m23:55:15.913993 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:15.915181 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:15.917824 [info ] [MainThread]: 
[0m23:55:15.918753 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.919292 [debug] [MainThread]: On master: BEGIN
[0m23:55:15.919765 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:55:15.926309 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m23:55:15.926773 [debug] [MainThread]: On master: COMMIT
[0m23:55:15.927141 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.927469 [debug] [MainThread]: On master: COMMIT
[0m23:55:15.928236 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:55:15.964232 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:15.964740 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:55:15.968143 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:55:15.970553 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:55:16.003836 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:55:16.058086 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:55:16.066547 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:55:16.067783 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m23:55:16.077312 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:55:16.105048 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.105514 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215516089052235516097849"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:55:16.109081 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:55:16.127735 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.128192 [debug] [MainThread]: On master: BEGIN
[0m23:55:16.128816 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:16.129396 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.129812 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215516089052235516097849'
        
      order by ordinal_position

  
[0m23:55:16.136918 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m23:55:16.139264 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215516089052235516097849"
[0m23:55:16.181525 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:16.182686 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.183073 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215516089052235516097849"
         (metadata_hash) values
    ('45309375f29ba85ba4ca443ab99ce304')
  
[0m23:55:16.183940 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:55:16.188103 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.188527 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215516186497235516187117"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:55:16.190379 [debug] [MainThread]: SQL status: SELECT 0 in 0.001 seconds
[0m23:55:16.195139 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.195618 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215516186497235516187117'
        
      order by ordinal_position

  
[0m23:55:16.199433 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m23:55:16.202311 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215516186497235516187117"
[0m23:55:16.215185 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:16.216308 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.216734 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215516186497235516187117"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption','consumption','f5949867c8ccd721047f1c83bf4e0bba9c3c63bb4a3267d3e61ca3f54b8306d2','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','The aim of this table is to track houtly energy consumption for a given day
','consumption','dbt_elsa','models/bronze/consumption.sql','bronze/consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-18 21:55:16','f72215f6f09b7511cb1897d6a2d7c239',NULL,NULL,NULL,'protected')
  
[0m23:55:16.217623 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:55:16.225455 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.225915 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718215516089052235516097849");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718215516186497235516187117";
        
        commit;
    
  
[0m23:55:16.227684 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:55:16.232424 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215516089052235516097849"
[0m23:55:16.233095 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.233476 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215516089052235516097849" cascade
[0m23:55:16.235397 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m23:55:16.239314 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215516186497235516187117"
[0m23:55:16.239985 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.240394 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215516186497235516187117" cascade
[0m23:55:16.241965 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:55:16.243276 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:55:16.245059 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:55:16.246126 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.053020 (1 runs)
[0m23:55:16.247355 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.023628 (2 runs)
[0m23:55:16.248342 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000895 (2 runs)
[0m23:55:16.249255 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.029599 (2 runs)
[0m23:55:16.250133 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.038378 (2 runs)
[0m23:55:16.250979 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.006481 (2 runs)
[0m23:55:16.252121 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.089084 (2 runs)
[0m23:55:16.252964 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.240979 (1 runs)
[0m23:55:16.257794 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:55:16.272805 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:55:16.274504 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:55:16.275320 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:55:16.276546 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:55:16.277409 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.013954 (1 runs)
[0m23:55:16.278245 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.018668 (1 runs)
[0m23:55:16.283351 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:55:16.304441 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:55:16.305971 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:55:16.306807 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:55:16.308140 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:55:16.309070 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019972 (1 runs)
[0m23:55:16.309936 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024714 (1 runs)
[0m23:55:16.315031 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:55:16.316564 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:55:16.317801 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:55:16.318913 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:55:16.320107 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:55:16.320961 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000434 (1 runs)
[0m23:55:16.321791 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005045 (1 runs)
[0m23:55:16.326652 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:55:16.328200 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:55:16.329693 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:55:16.330698 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:55:16.332392 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:55:16.333259 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000393 (1 runs)
[0m23:55:16.334088 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005342 (1 runs)
[0m23:55:16.338853 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:55:16.340243 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:55:16.341566 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:55:16.342364 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:55:16.343600 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:55:16.344461 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000367 (1 runs)
[0m23:55:16.345299 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004662 (1 runs)
[0m23:55:16.350862 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:55:16.352375 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:55:16.353624 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:55:16.354381 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:55:16.355599 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:55:16.356466 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000427 (1 runs)
[0m23:55:16.357323 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004685 (1 runs)
[0m23:55:16.362966 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:55:16.364843 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:55:16.366020 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:55:16.366743 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:55:16.367918 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:55:16.368767 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000347 (1 runs)
[0m23:55:16.369591 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005033 (1 runs)
[0m23:55:16.374827 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:55:16.562384 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:55:16.564743 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:55:16.565874 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:55:16.567714 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:55:16.568709 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.186185 (1 runs)
[0m23:55:16.569718 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.192816 (1 runs)
[0m23:55:16.570644 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:55:16.575249 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:55:16.576269 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:55:16.602472 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 4 artifacts.
[0m23:55:16.606631 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.607065 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:55:16.611328 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:55:16.614578 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:55:16.771058 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:16.772492 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.773129 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('b5718af2-535f-4acf-ba0d-4a5ca1c26615.model.dbt_elsa.consumption','model.dbt_elsa.consumption','b5718af2-535f-4acf-ba0d-4a5ca1c26615','2025-07-18 21:55:16',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.16141295433044434,'2025-07-18T21:55:15.164558Z','2025-07-18T21:55:15.318189Z','2025-07-18T21:55:15.158667Z','2025-07-18T21:55:15.163830Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    (data->>''gaz'')::int AS gaz,
    data->>''nucleaire'' AS nucleaire,
    data->>''charbon'' AS charbon,
    data->>''solaire'' AS solaire,
    data->>''eolien'' AS eolien,
    data->>''hydraulique'' AS hydraulique,
    data->>''bioenergies'' AS bioenergies,
    data->>''autres'' AS autres,
    data->>''prevision_j'' AS prevision_j,
    data->>''prevision_j1'' AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','b5718af2-535f-4acf-ba0d-4a5ca1c26615','2025-07-18 21:55:16',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'pass','test',0.5691211223602295,'2025-07-18T21:55:15.364192Z','2025-07-18T21:55:15.891328Z','2025-07-18T21:55:15.347929Z','2025-07-18T21:55:15.363115Z',1,False,'
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',0,NULL,'Thread-4 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','b5718af2-535f-4acf-ba0d-4a5ca1c26615','2025-07-18 21:55:16',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'pass','test',0.5854899883270264,'2025-07-18T21:55:15.366969Z','2025-07-18T21:55:15.899448Z','2025-07-18T21:55:15.342699Z','2025-07-18T21:55:15.363685Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','b5718af2-535f-4acf-ba0d-4a5ca1c26615','2025-07-18 21:55:16',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'pass','test',0.5887429714202881,'2025-07-18T21:55:15.353414Z','2025-07-18T21:55:15.906682Z','2025-07-18T21:55:15.326920Z','2025-07-18T21:55:15.352812Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m23:55:16.775258 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m23:55:16.777798 [debug] [MainThread]: On master: COMMIT
[0m23:55:16.778266 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.778679 [debug] [MainThread]: On master: COMMIT
[0m23:55:16.779493 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:55:16.782525 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:55:16.783533 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025201 (1 runs)
[0m23:55:16.784410 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.010099 (1 runs)
[0m23:55:16.785264 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000690 (1 runs)
[0m23:55:16.786078 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.151124 (4 runs)
[0m23:55:16.786915 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.154922 (1 runs)
[0m23:55:16.787782 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005220 (1 runs)
[0m23:55:16.789097 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003088 (1 runs)
[0m23:55:16.790197 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.177409 (1 runs)
[0m23:55:16.791091 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.205935 (1 runs)
[0m23:55:16.791886 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:55:16.802700 [debug] [MainThread]: Elementary: Handling test results.
[0m23:55:16.835327 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.835851 [debug] [MainThread]: On master: BEGIN
[0m23:55:16.836528 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:16.837043 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.837589 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:55:16.842345 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:55:16.845289 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:55:16.904655 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:16.905916 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.906532 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','b5718af2-535f-4acf-ba0d-4a5ca1c26615',cast('2025-07-18 21:55:15' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]','
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_id',NULL,0),('b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','b5718af2-535f-4acf-ba0d-4a5ca1c26615',cast('2025-07-18 21:55:15' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_date',NULL,0),('b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'b5718af2-535f-4acf-ba0d-4a5ca1c26615.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','b5718af2-535f-4acf-ba0d-4a5ca1c26615',cast('2025-07-18 21:55:15' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_created_at',NULL,0)
  
[0m23:55:16.908242 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:55:16.910644 [debug] [MainThread]: On master: COMMIT
[0m23:55:16.911050 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:16.911398 [debug] [MainThread]: On master: COMMIT
[0m23:55:16.912707 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:55:16.914538 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:55:16.931036 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:55:17.006860 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:17.007434 [debug] [MainThread]: On master: BEGIN
[0m23:55:17.008184 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:17.008637 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:17.009128 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:55:17.013668 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:55:17.016579 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:55:17.037299 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:17.038394 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:17.038923 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('b5718af2-535f-4acf-ba0d-4a5ca1c26615',NULL,NULL,NULL,'2025-07-18 21:55:13','2025-07-18 21:55:16','2025-07-18 21:55:16',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:55:17.040030 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:55:17.042679 [debug] [MainThread]: On master: COMMIT
[0m23:55:17.043114 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:17.043468 [debug] [MainThread]: On master: COMMIT
[0m23:55:17.044863 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:55:17.046870 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:55:17.053754 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:55:17.054733 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:55:17.055280 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.13s]
[0m23:55:17.055780 [debug] [MainThread]: On master: Close
[0m23:55:17.056301 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:55:17.056631 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:55:17.056924 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m23:55:17.057205 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m23:55:17.057481 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m23:55:17.057865 [info ] [MainThread]: 
[0m23:55:17.058363 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 2.18 seconds (2.18s).
[0m23:55:17.061062 [debug] [MainThread]: Command end result
[0m23:55:17.160409 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:55:17.163717 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:55:17.170344 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:55:17.170739 [info ] [MainThread]: 
[0m23:55:17.171120 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:55:17.171457 [info ] [MainThread]: 
[0m23:55:17.171822 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:55:17.172387 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:55:17.175059 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 4.072402, "process_in_blocks": "0", "process_kernel_time": 0.483502, "process_mem_max_rss": "144920576", "process_out_blocks": "0", "process_user_time": 5.037619}
[0m23:55:17.175622 [debug] [MainThread]: Command `dbt build` succeeded at 23:55:17.175498 after 4.07 seconds
[0m23:55:17.176030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f54f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115340dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f116040>]}
[0m23:55:17.176415 [debug] [MainThread]: Flushing usage events
[0m23:55:17.574025 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:55:55.303677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c57770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10838f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10838f4d0>]}


============================== 23:55:55.310055 | 9f4baa19-8d70-4f3f-95e9-06516ab721d9 ==============================
[0m23:55:55.310055 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:55:55.310707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m23:55:55.611331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076dc510>]}
[0m23:55:55.689509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10820fdf0>]}
[0m23:55:55.690397 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:55:55.822211 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:55:56.077470 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:55:56.078543 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/consumption.sql
[0m23:55:56.703786 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:55:56.723351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109636550>]}
[0m23:55:56.898410 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:55:56.901244 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:55:56.935760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b2e4e0>]}
[0m23:55:56.936284 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:55:56.938836 [info ] [MainThread]: 
[0m23:55:56.939234 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:55:56.939557 [info ] [MainThread]: 
[0m23:55:56.940061 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:55:56.940943 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:55:56.992430 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:55:56.992879 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:55:56.993222 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:55:57.019809 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.027 seconds
[0m23:55:57.021352 [debug] [ThreadPool]: On list_elsa: Close
[0m23:55:57.028426 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:55:57.029518 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:55:57.037811 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:55:57.040880 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:55:57.041395 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:55:57.041730 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:55:57.042042 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:55:57.042367 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:55:57.048408 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:55:57.048808 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:55:57.049194 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:55:57.049534 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:55:57.049877 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:55:57.050256 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:55:57.054470 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:55:57.054895 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:55:57.056330 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:55:57.057865 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:55:57.058375 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:55:57.058747 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:55:57.073174 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:57.073599 [debug] [MainThread]: On master: BEGIN
[0m23:55:57.073897 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:55:57.080111 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:55:57.080689 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:57.081126 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:55:57.122853 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m23:55:57.131112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a7f150>]}
[0m23:55:57.131623 [debug] [MainThread]: On master: ROLLBACK
[0m23:55:57.132204 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:57.132553 [debug] [MainThread]: On master: BEGIN
[0m23:55:57.133105 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:57.133427 [debug] [MainThread]: On master: COMMIT
[0m23:55:57.133737 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:57.134031 [debug] [MainThread]: On master: COMMIT
[0m23:55:57.134695 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:55:57.174813 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:55:57.219132 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:57.219911 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:55:57.221495 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:55:57.225309 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:55:57.229894 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:55:57.230541 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.10s]
[0m23:55:57.230891 [info ] [MainThread]: 
[0m23:55:57.231320 [debug] [MainThread]: On master: Close
[0m23:55:57.235155 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:55:57.235758 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m23:55:57.236386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption)
[0m23:55:57.236910 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:55:57.241418 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:55:57.242647 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:55:57.286719 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:55:57.287589 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.287978 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:55:57.288331 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:55:57.294083 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:55:57.294634 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.295176 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    data->>'date' AS date,
    data->>'heure' AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:55:57.300815 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.005 seconds
[0m23:55:57.313728 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.314494 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m23:55:57.315812 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:55:57.319735 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.320159 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:55:57.321113 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:55:57.348825 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.349411 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m23:55:57.350581 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m23:55:57.365872 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.366409 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:55:57.374258 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.007 seconds
[0m23:55:57.380140 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.380720 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m23:55:57.381661 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:55:57.382966 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:55:57.383377 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.383756 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:55:57.384699 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:55:57.392588 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:55:57.399140 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:55:57.399613 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:55:57.401929 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:55:57.404569 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:55:57.406434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e04e4e0>]}
[0m23:55:57.407211 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.17s]
[0m23:55:57.408083 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:55:57.409040 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:57.409487 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:57.409862 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:57.410239 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m23:55:57.410752 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m23:55:57.411189 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m23:55:57.411898 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m23:55:57.412928 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc'
[0m23:55:57.413925 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m23:55:57.414511 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:57.414996 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:57.415595 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:57.430747 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:57.436425 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:57.441593 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:57.442591 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:57.449416 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:57.449897 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:57.450945 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:55:57.453425 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:55:57.456152 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:55:57.456645 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ac8650>]}
[0m23:55:57.457165 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ae7490>]}
[0m23:55:57.457527 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '9f4baa19-8d70-4f3f-95e9-06516ab721d9', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ae7540>]}
[0m23:55:57.888184 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:57.889857 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:57.887125 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:57.890982 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:57.891408 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m23:55:57.891873 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:57.892517 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:57.893096 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:57.893673 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m23:55:57.894269 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m23:55:57.894806 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:55:57.895325 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:55:57.899369 [debug] [Thread-3 (]: SQL status: BEGIN in 0.007 seconds
[0m23:55:57.899847 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:55:57.900234 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:55:57.901640 [debug] [Thread-2 (]: SQL status: BEGIN in 0.007 seconds
[0m23:55:57.902153 [debug] [Thread-4 (]: SQL status: BEGIN in 0.007 seconds
[0m23:55:57.902601 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:55:57.903125 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:55:57.903580 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:55:57.904071 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:55:57.916090 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m23:55:57.940257 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.008 seconds
[0m23:55:57.968031 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m23:55:57.968719 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.008 seconds
[0m23:55:57.979973 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m23:55:58.002960 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m23:55:58.008569 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m23:55:58.019380 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m23:55:58.020947 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.61s]
[0m23:55:58.023716 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:55:58.024417 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m23:55:58.022640 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.61s]
[0m23:55:58.025885 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:55:58.026700 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.61s]
[0m23:55:58.028288 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:55:58.032792 [info ] [MainThread]: 
[0m23:55:58.033452 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.033910 [debug] [MainThread]: On master: BEGIN
[0m23:55:58.034421 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:55:58.040818 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:55:58.041353 [debug] [MainThread]: On master: COMMIT
[0m23:55:58.041761 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.042129 [debug] [MainThread]: On master: COMMIT
[0m23:55:58.042717 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:55:58.079241 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.079828 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:55:58.083396 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:55:58.086073 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:55:58.121280 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:55:58.177569 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:55:58.185899 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:55:58.187168 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m23:55:58.199547 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:55:58.233494 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.233983 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215558215077235558225077"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:55:58.237322 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:55:58.254958 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.255432 [debug] [MainThread]: On master: BEGIN
[0m23:55:58.256049 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:58.256417 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.256784 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215558215077235558225077'
        
      order by ordinal_position

  
[0m23:55:58.264458 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m23:55:58.266786 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215558215077235558225077"
[0m23:55:58.307975 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:58.309246 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.309680 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215558215077235558225077"
         (metadata_hash) values
    ('f72215f6f09b7511cb1897d6a2d7c239')
  
[0m23:55:58.310563 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:55:58.315233 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.315737 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215558313199235558314005"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:55:58.317822 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:55:58.322643 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.323102 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215558313199235558314005'
        
      order by ordinal_position

  
[0m23:55:58.326911 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m23:55:58.329991 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215558313199235558314005"
[0m23:55:58.341955 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:58.343062 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.343478 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215558313199235558314005"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption','consumption','239a1931e1466bb16d75cd089290472c500c4c8af63c4b423af7d372cf2ba893','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','The aim of this table is to track houtly energy consumption for a given day
','consumption','dbt_elsa','models/bronze/consumption.sql','bronze/consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-18 21:55:58','3ce1ef891becc1969c0aef25e2a6171b',NULL,NULL,NULL,'protected')
  
[0m23:55:58.344389 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:55:58.352719 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.353191 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718215558215077235558225077");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718215558313199235558314005";
        
        commit;
    
  
[0m23:55:58.354978 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:55:58.359253 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215558215077235558225077"
[0m23:55:58.359933 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.360395 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215558215077235558225077" cascade
[0m23:55:58.363103 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m23:55:58.366847 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215558313199235558314005"
[0m23:55:58.367463 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.367965 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215558313199235558314005" cascade
[0m23:55:58.369647 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:55:58.370895 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:55:58.372535 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:55:58.373497 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.055002 (1 runs)
[0m23:55:58.374514 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.023747 (2 runs)
[0m23:55:58.375451 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000913 (2 runs)
[0m23:55:58.376356 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.028017 (2 runs)
[0m23:55:58.377218 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.036549 (2 runs)
[0m23:55:58.378056 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.006532 (2 runs)
[0m23:55:58.379205 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.087577 (2 runs)
[0m23:55:58.380381 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.251041 (1 runs)
[0m23:55:58.385441 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:55:58.400614 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:55:58.402277 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:55:58.403076 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:55:58.404268 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:55:58.405120 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.014049 (1 runs)
[0m23:55:58.405957 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.018773 (1 runs)
[0m23:55:58.410836 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:55:58.432101 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:55:58.433434 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:55:58.434202 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:55:58.435415 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:55:58.436276 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020142 (1 runs)
[0m23:55:58.437131 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024516 (1 runs)
[0m23:55:58.441938 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:55:58.443426 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:55:58.444645 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:55:58.445733 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:55:58.447178 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:55:58.448179 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000425 (1 runs)
[0m23:55:58.449057 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005054 (1 runs)
[0m23:55:58.453856 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:55:58.455213 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:55:58.456448 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:55:58.457213 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:55:58.458439 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:55:58.459794 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000361 (1 runs)
[0m23:55:58.460981 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004505 (1 runs)
[0m23:55:58.466407 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:55:58.467821 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:55:58.469036 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:55:58.469777 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:55:58.471032 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:55:58.471886 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000353 (1 runs)
[0m23:55:58.472794 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004576 (1 runs)
[0m23:55:58.478143 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:55:58.479862 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:55:58.481392 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:55:58.482169 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:55:58.483355 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:55:58.484188 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000541 (1 runs)
[0m23:55:58.485071 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005150 (1 runs)
[0m23:55:58.489822 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:55:58.491558 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:55:58.492802 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:55:58.493691 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:55:58.495082 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:55:58.496027 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000363 (1 runs)
[0m23:55:58.497397 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005164 (1 runs)
[0m23:55:58.502618 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:55:58.686163 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:55:58.687437 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:55:58.688380 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:55:58.689903 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:55:58.690760 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.182433 (1 runs)
[0m23:55:58.691687 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.187240 (1 runs)
[0m23:55:58.692692 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:55:58.697409 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:55:58.698400 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:55:58.724309 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 4 artifacts.
[0m23:55:58.729024 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.729782 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:55:58.733985 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:55:58.736667 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:55:58.888813 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:58.890068 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.890589 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('9f4baa19-8d70-4f3f-95e9-06516ab721d9.model.dbt_elsa.consumption','model.dbt_elsa.consumption','9f4baa19-8d70-4f3f-95e9-06516ab721d9','2025-07-18 21:55:58',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.16895413398742676,'2025-07-18T21:55:57.243143Z','2025-07-18T21:55:57.404407Z','2025-07-18T21:55:57.237271Z','2025-07-18T21:55:57.242304Z',96,False,'SELECT
    id,
    created_at,
    data->>''date'' AS date,
    data->>''heure'' AS heure,   
    (data->>''gaz'')::int AS gaz,
    (data->>''nucleaire'')::int AS nucleaire,
    (data->>''charbon'')::int AS charbon,
    (data->>''solaire'')::int AS solaire,
    (data->>''eolien'')::int AS eolien,
    (data->>''hydraulique'')::int AS hydraulique,
    (data->>''bioenergies'')::int AS bioenergies,
    (data->>''autres'')::int AS autres,
    (data->>''prevision_j'')::int AS prevision_j,
    (data->>''prevision_j1'')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','9f4baa19-8d70-4f3f-95e9-06516ab721d9','2025-07-18 21:55:58',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'pass','test',0.6080329418182373,'2025-07-18T21:55:57.453833Z','2025-07-18T21:55:57.967818Z','2025-07-18T21:55:57.431101Z','2025-07-18T21:55:57.449764Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','9f4baa19-8d70-4f3f-95e9-06516ab721d9','2025-07-18 21:55:58',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'pass','test',0.6106770038604736,'2025-07-18T21:55:57.442895Z','2025-07-18T21:55:57.979603Z','2025-07-18T21:55:57.416028Z','2025-07-18T21:55:57.442423Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','9f4baa19-8d70-4f3f-95e9-06516ab721d9','2025-07-18 21:55:58',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'pass','test',0.6129131317138672,'2025-07-18T21:55:57.451367Z','2025-07-18T21:55:58.008247Z','2025-07-18T21:55:57.436817Z','2025-07-18T21:55:57.449226Z',1,False,'
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',0,NULL,'Thread-4 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m23:55:58.892914 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.002 seconds
[0m23:55:58.896167 [debug] [MainThread]: On master: COMMIT
[0m23:55:58.896804 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.897221 [debug] [MainThread]: On master: COMMIT
[0m23:55:58.898015 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:55:58.900652 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:55:58.901595 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.024884 (1 runs)
[0m23:55:58.902911 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.010295 (1 runs)
[0m23:55:58.904171 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000635 (1 runs)
[0m23:55:58.905747 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.147275 (4 runs)
[0m23:55:58.906937 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.150780 (1 runs)
[0m23:55:58.908051 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005594 (1 runs)
[0m23:55:58.909469 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003061 (1 runs)
[0m23:55:58.910317 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.173723 (1 runs)
[0m23:55:58.911079 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.201989 (1 runs)
[0m23:55:58.912169 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:55:58.922608 [debug] [MainThread]: Elementary: Handling test results.
[0m23:55:58.956514 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.957037 [debug] [MainThread]: On master: BEGIN
[0m23:55:58.957727 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:58.958141 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:58.958625 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:55:58.964091 [debug] [MainThread]: SQL status: SELECT 28 in 0.005 seconds
[0m23:55:58.966955 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:55:59.034295 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:59.036292 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:59.037057 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','9f4baa19-8d70-4f3f-95e9-06516ab721d9',cast('2025-07-18 21:55:57' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_date',NULL,0),('9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','9f4baa19-8d70-4f3f-95e9-06516ab721d9',cast('2025-07-18 21:55:57' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_created_at',NULL,0),('9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'9f4baa19-8d70-4f3f-95e9-06516ab721d9.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','9f4baa19-8d70-4f3f-95e9-06516ab721d9',cast('2025-07-18 21:55:57' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]','
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_id',NULL,0)
  
[0m23:55:59.038678 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:55:59.041253 [debug] [MainThread]: On master: COMMIT
[0m23:55:59.041982 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:59.042426 [debug] [MainThread]: On master: COMMIT
[0m23:55:59.043903 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:55:59.045563 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:55:59.062878 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:55:59.133139 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:59.133672 [debug] [MainThread]: On master: BEGIN
[0m23:55:59.134366 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:55:59.134801 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:59.135379 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:55:59.139679 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:55:59.142599 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:55:59.166059 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:55:59.167204 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:59.168054 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('9f4baa19-8d70-4f3f-95e9-06516ab721d9',NULL,NULL,NULL,'2025-07-18 21:55:55','2025-07-18 21:55:59','2025-07-18 21:55:59',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:55:59.169425 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m23:55:59.172425 [debug] [MainThread]: On master: COMMIT
[0m23:55:59.172906 [debug] [MainThread]: Using postgres connection "master"
[0m23:55:59.173268 [debug] [MainThread]: On master: COMMIT
[0m23:55:59.174474 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:55:59.176382 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:55:59.183498 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:55:59.184764 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:55:59.185396 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.14s]
[0m23:55:59.185806 [debug] [MainThread]: On master: Close
[0m23:55:59.186293 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:55:59.186594 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:55:59.186873 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m23:55:59.187145 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m23:55:59.187417 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m23:55:59.187786 [info ] [MainThread]: 
[0m23:55:59.188137 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 2.25 seconds (2.25s).
[0m23:55:59.189734 [debug] [MainThread]: Command end result
[0m23:55:59.321435 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:55:59.324085 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:55:59.332186 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:55:59.332578 [info ] [MainThread]: 
[0m23:55:59.333023 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:55:59.333381 [info ] [MainThread]: 
[0m23:55:59.333742 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:55:59.334424 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:55:59.337691 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 4.130902, "process_in_blocks": "0", "process_kernel_time": 0.491184, "process_mem_max_rss": "145125376", "process_out_blocks": "0", "process_user_time": 5.032104}
[0m23:55:59.338696 [debug] [MainThread]: Command `dbt build` succeeded at 23:55:59.338490 after 4.13 seconds
[0m23:55:59.339357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e8f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089ae1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103aaa040>]}
[0m23:55:59.339823 [debug] [MainThread]: Flushing usage events
[0m23:55:59.738135 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:56:16.513219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105293770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10698f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10698f4d0>]}


============================== 23:56:16.518476 | 123a88a2-be87-4f61-9b6d-33c53e83884a ==============================
[0m23:56:16.518476 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:56:16.519130 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt build --select silver', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:56:16.734839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '123a88a2-be87-4f61-9b6d-33c53e83884a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d0c510>]}
[0m23:56:16.813734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '123a88a2-be87-4f61-9b6d-33c53e83884a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106813df0>]}
[0m23:56:16.814989 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:56:16.946774 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:56:17.206398 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:56:17.206849 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:56:17.215298 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:56:17.358415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '123a88a2-be87-4f61-9b6d-33c53e83884a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106903350>]}
[0m23:56:17.545216 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:56:17.549358 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:56:17.584442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '123a88a2-be87-4f61-9b6d-33c53e83884a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10775bc50>]}
[0m23:56:17.584985 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:56:17.587532 [info ] [MainThread]: 
[0m23:56:17.587920 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:56:17.588246 [info ] [MainThread]: 
[0m23:56:17.588761 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:56:17.589601 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:56:17.645046 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:56:17.645540 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:56:17.646284 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:56:17.669539 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.023 seconds
[0m23:56:17.671082 [debug] [ThreadPool]: On list_elsa: Close
[0m23:56:17.678120 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:56:17.679011 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:56:17.686154 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:56:17.688888 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:56:17.689320 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:56:17.689650 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:56:17.689971 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:56:17.690280 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:56:17.696629 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:56:17.697305 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:56:17.697644 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:56:17.697978 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:56:17.698333 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:56:17.698708 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:56:17.703297 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:56:17.703741 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m23:56:17.705488 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:56:17.706811 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:56:17.707396 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:56:17.707770 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:56:17.725941 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:17.726376 [debug] [MainThread]: On master: BEGIN
[0m23:56:17.726688 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:56:17.733475 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m23:56:17.733905 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:17.734407 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:56:17.775909 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m23:56:17.783963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '123a88a2-be87-4f61-9b6d-33c53e83884a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078db4d0>]}
[0m23:56:17.784514 [debug] [MainThread]: On master: ROLLBACK
[0m23:56:17.785100 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:17.785452 [debug] [MainThread]: On master: BEGIN
[0m23:56:17.786061 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:56:17.786409 [debug] [MainThread]: On master: COMMIT
[0m23:56:17.786740 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:17.787059 [debug] [MainThread]: On master: COMMIT
[0m23:56:17.787506 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:56:17.828220 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:56:17.866078 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:17.866716 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:56:17.867712 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m23:56:17.870975 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:56:17.874839 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:56:17.875469 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:56:17.875873 [info ] [MainThread]: 
[0m23:56:17.876292 [debug] [MainThread]: On master: Close
[0m23:56:17.881013 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m23:56:17.881754 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze.consumption_history ........................ [RUN]
[0m23:56:17.882443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption_history)
[0m23:56:17.882902 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m23:56:17.887054 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m23:56:17.888351 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m23:56:17.933030 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m23:56:17.933977 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:56:17.934370 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m23:56:17.934718 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:56:17.940358 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:56:17.940823 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:56:17.941337 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(production_j) AS production_j,
    SUM(production_j1) AS production_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at
  );
  
[0m23:56:17.942667 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "production_j" does not exist
LINE 26:     SUM(production_j) AS production_j,
                 ^
HINT:  There is a column named "production_j" in table "*SELECT* 1", but it cannot be referenced from this part of the query.

[0m23:56:17.943148 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m23:56:17.943846 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m23:56:17.950679 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  column "production_j" does not exist
  LINE 26:     SUM(production_j) AS production_j,
                   ^
  HINT:  There is a column named "production_j" in table "*SELECT* 1", but it cannot be referenced from this part of the query.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m23:56:17.952457 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '123a88a2-be87-4f61-9b6d-33c53e83884a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108189d90>]}
[0m23:56:17.953153 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model bronze.consumption_history ............... [[31mERROR[0m in 0.07s]
[0m23:56:17.953814 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m23:56:17.954378 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  column "production_j" does not exist
  LINE 26:     SUM(production_j) AS production_j,
                   ^
  HINT:  There is a column named "production_j" in table "*SELECT* 1", but it cannot be referenced from this part of the query.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m23:56:17.955308 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:56:17.955762 [info ] [Thread-2 (]: 2 of 3 SKIP test not_null_consumption_history_created_at ....................... [[33mSKIP[0m]
[0m23:56:17.956327 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:56:17.956727 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' to be skipped because of status 'skipped'. 
[0m23:56:17.957250 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:56:17.957673 [info ] [Thread-3 (]: 3 of 3 SKIP test not_null_consumption_history_date ............................. [[33mSKIP[0m]
[0m23:56:17.958459 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:56:17.959069 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' to be skipped because of status 'skipped'. 
[0m23:56:17.961195 [info ] [MainThread]: 
[0m23:56:17.961891 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:17.962508 [debug] [MainThread]: On master: BEGIN
[0m23:56:17.962940 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:56:17.968414 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:56:17.968863 [debug] [MainThread]: On master: COMMIT
[0m23:56:17.969368 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:17.969835 [debug] [MainThread]: On master: COMMIT
[0m23:56:17.970480 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:56:18.016134 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.016657 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:56:18.020602 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:56:18.023385 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:56:18.056303 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:56:18.143028 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:56:18.151351 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:56:18.152404 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m23:56:18.153954 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:56:18.154819 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.085470 (1 runs)
[0m23:56:18.155664 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.097618 (1 runs)
[0m23:56:18.160888 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:56:18.285797 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:56:18.287464 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:56:18.288261 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:56:18.289459 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:56:18.290309 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.123743 (1 runs)
[0m23:56:18.291143 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.128533 (1 runs)
[0m23:56:18.297061 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:56:18.319344 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:56:18.320682 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:56:18.321458 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:56:18.322648 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:56:18.323514 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020918 (1 runs)
[0m23:56:18.324376 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.025641 (1 runs)
[0m23:56:18.330263 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:56:18.331982 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:56:18.333668 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:56:18.334619 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:56:18.335908 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:56:18.336822 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000425 (1 runs)
[0m23:56:18.337702 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005823 (1 runs)
[0m23:56:18.343034 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:56:18.344881 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:56:18.346491 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:56:18.347705 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:56:18.349365 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:56:18.350290 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000451 (1 runs)
[0m23:56:18.351144 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.006299 (1 runs)
[0m23:56:18.355873 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:56:18.357218 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:56:18.358548 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:56:18.359360 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:56:18.360987 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:56:18.362690 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000350 (1 runs)
[0m23:56:18.363837 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004934 (1 runs)
[0m23:56:18.368559 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:56:18.369987 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:56:18.371211 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:56:18.371998 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:56:18.373250 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:56:18.374125 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000416 (1 runs)
[0m23:56:18.375030 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004613 (1 runs)
[0m23:56:18.381282 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:56:18.382961 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:56:18.384279 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:56:18.385219 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:56:18.386489 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:56:18.387389 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000371 (1 runs)
[0m23:56:18.388460 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005168 (1 runs)
[0m23:56:18.393704 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:56:18.579549 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:56:18.581502 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:56:18.582499 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:56:18.583713 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:56:18.584664 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.183798 (1 runs)
[0m23:56:18.585586 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.189963 (1 runs)
[0m23:56:18.586470 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:56:18.590522 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:56:18.591663 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:56:18.620282 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m23:56:18.642916 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.643463 [debug] [MainThread]: On master: BEGIN
[0m23:56:18.644184 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:56:18.644638 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.645058 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:56:18.654568 [debug] [MainThread]: SQL status: SELECT 23 in 0.009 seconds
[0m23:56:18.659800 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:56:18.765898 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:56:18.767126 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.767621 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('123a88a2-be87-4f61-9b6d-33c53e83884a.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','123a88a2-be87-4f61-9b6d-33c53e83884a','2025-07-18 21:56:18',
    current_timestamp::timestamp
,'consumption_history','Database Error in model consumption_history (models/silver/consumption_history.sql)
  column "production_j" does not exist
  LINE 26:     SUM(production_j) AS production_j,
                   ^
  HINT:  There is a column named "production_j" in table "*SELECT* 1", but it cannot be referenced from this part of the query.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql','error','model',0.06886911392211914,'2025-07-18T21:56:17.888684Z','2025-07-18T21:56:17.943631Z','2025-07-18T21:56:17.883169Z','2025-07-18T21:56:17.888157Z',NULL,False,'SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(production_j) AS production_j,
    SUM(production_j1) AS production_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('123a88a2-be87-4f61-9b6d-33c53e83884a.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','123a88a2-be87-4f61-9b6d-33c53e83884a','2025-07-18 21:56:18',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)','test','{}',NULL),('123a88a2-be87-4f61-9b6d-33c53e83884a.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','123a88a2-be87-4f61-9b6d-33c53e83884a','2025-07-18 21:56:18',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-3 (worker)','test','{}',NULL)
  
[0m23:56:18.769062 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:56:18.771508 [debug] [MainThread]: On master: COMMIT
[0m23:56:18.771906 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.772266 [debug] [MainThread]: On master: COMMIT
[0m23:56:18.773844 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:56:18.776679 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:56:18.777724 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.027571 (1 runs)
[0m23:56:18.778940 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.023912 (1 runs)
[0m23:56:18.780187 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000704 (1 runs)
[0m23:56:18.781048 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.075698 (3 runs)
[0m23:56:18.781839 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.085540 (1 runs)
[0m23:56:18.782806 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.004319 (1 runs)
[0m23:56:18.783575 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003518 (1 runs)
[0m23:56:18.784308 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.140094 (1 runs)
[0m23:56:18.785165 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.184683 (1 runs)
[0m23:56:18.785991 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:56:18.796573 [debug] [MainThread]: Elementary: Handling test results.
[0m23:56:18.850440 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.850958 [debug] [MainThread]: On master: BEGIN
[0m23:56:18.851752 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:56:18.852176 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.852650 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:56:18.857154 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:56:18.860055 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:56:18.902073 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:56:18.903222 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.903804 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('123a88a2-be87-4f61-9b6d-33c53e83884a.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'123a88a2-be87-4f61-9b6d-33c53e83884a.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','123a88a2-be87-4f61-9b6d-33c53e83884a',cast('2025-07-18 21:56:18' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_created_at',NULL,NULL),('123a88a2-be87-4f61-9b6d-33c53e83884a.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'123a88a2-be87-4f61-9b6d-33c53e83884a.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','123a88a2-be87-4f61-9b6d-33c53e83884a',cast('2025-07-18 21:56:18' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','date','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_date',NULL,NULL)
  
[0m23:56:18.905078 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:56:18.907283 [debug] [MainThread]: On master: COMMIT
[0m23:56:18.907679 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.908039 [debug] [MainThread]: On master: COMMIT
[0m23:56:18.909103 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:56:18.910755 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:56:18.928815 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:56:18.993769 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.994280 [debug] [MainThread]: On master: BEGIN
[0m23:56:18.995111 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:56:18.995521 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:18.996128 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:56:19.000559 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:56:19.003367 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:56:19.027016 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:56:19.028123 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:19.028667 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('123a88a2-be87-4f61-9b6d-33c53e83884a',NULL,NULL,NULL,'2025-07-18 21:56:16','2025-07-18 21:56:18','2025-07-18 21:56:18',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:56:19.029854 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:56:19.032674 [debug] [MainThread]: On master: COMMIT
[0m23:56:19.033137 [debug] [MainThread]: Using postgres connection "master"
[0m23:56:19.033506 [debug] [MainThread]: On master: COMMIT
[0m23:56:19.035159 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:56:19.037315 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:56:19.043956 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:56:19.044962 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:56:19.045480 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.07s]
[0m23:56:19.045918 [debug] [MainThread]: On master: Close
[0m23:56:19.046921 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:56:19.047555 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m23:56:19.047871 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m23:56:19.048270 [info ] [MainThread]: 
[0m23:56:19.048633 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.46 seconds (1.46s).
[0m23:56:19.049826 [debug] [MainThread]: Command end result
[0m23:56:19.142417 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:56:19.145145 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:56:19.151973 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:56:19.152352 [info ] [MainThread]: 
[0m23:56:19.152761 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:56:19.153141 [info ] [MainThread]: 
[0m23:56:19.153561 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m23:56:19.153971 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  column "production_j" does not exist
  LINE 26:     SUM(production_j) AS production_j,
                   ^
  HINT:  There is a column named "production_j" in table "*SELECT* 1", but it cannot be referenced from this part of the query.
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m23:56:19.154300 [info ] [MainThread]: 
[0m23:56:19.154700 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m23:56:19.155031 [info ] [MainThread]: 
[0m23:56:19.155389 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=5
[0m23:56:19.157997 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.7358575, "process_in_blocks": "0", "process_kernel_time": 0.453641, "process_mem_max_rss": "137158656", "process_out_blocks": "0", "process_user_time": 3.848563}
[0m23:56:19.158773 [debug] [MainThread]: Command `dbt build` failed at 23:56:19.158559 after 2.74 seconds
[0m23:56:19.159252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106786c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080d7cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080d7c20>]}
[0m23:56:19.159651 [debug] [MainThread]: Flushing usage events
[0m23:56:19.591485 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:57:11.449152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034db770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bd7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bd74d0>]}


============================== 23:57:11.453998 | b2964646-88e7-4fa3-abb2-b6dee0dd04ff ==============================
[0m23:57:11.453998 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:57:11.454627 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select silver', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:57:11.674638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b2964646-88e7-4fa3-abb2-b6dee0dd04ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f54510>]}
[0m23:57:11.753850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b2964646-88e7-4fa3-abb2-b6dee0dd04ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a5bdf0>]}
[0m23:57:11.754832 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:57:11.890009 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:57:12.156576 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:57:12.157469 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m23:57:12.780784 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:57:12.801519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b2964646-88e7-4fa3-abb2-b6dee0dd04ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e76750>]}
[0m23:57:12.976026 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:57:12.979073 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:57:13.015510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b2964646-88e7-4fa3-abb2-b6dee0dd04ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061625d0>]}
[0m23:57:13.016044 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:57:13.018848 [info ] [MainThread]: 
[0m23:57:13.019282 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:57:13.019613 [info ] [MainThread]: 
[0m23:57:13.020127 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:57:13.020956 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:57:13.080570 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:57:13.081076 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:57:13.081400 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:57:13.105109 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.024 seconds
[0m23:57:13.106645 [debug] [ThreadPool]: On list_elsa: Close
[0m23:57:13.114371 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:57:13.115008 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:57:13.121871 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:57:13.124591 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:57:13.124991 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:57:13.125316 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:57:13.125629 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:57:13.125944 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:57:13.132967 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:57:13.133389 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:57:13.133729 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:57:13.134101 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:57:13.134432 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:57:13.134764 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:57:13.137908 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:57:13.139438 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:57:13.139882 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.005 seconds
[0m23:57:13.140203 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:57:13.141811 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:57:13.143812 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:57:13.157440 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.157919 [debug] [MainThread]: On master: BEGIN
[0m23:57:13.158248 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:57:13.164256 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:57:13.164681 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.165085 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:57:13.205429 [debug] [MainThread]: SQL status: SELECT 26 in 0.040 seconds
[0m23:57:13.212803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b2964646-88e7-4fa3-abb2-b6dee0dd04ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106303230>]}
[0m23:57:13.213837 [debug] [MainThread]: On master: ROLLBACK
[0m23:57:13.214909 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.215596 [debug] [MainThread]: On master: BEGIN
[0m23:57:13.216300 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:57:13.216662 [debug] [MainThread]: On master: COMMIT
[0m23:57:13.216999 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.217315 [debug] [MainThread]: On master: COMMIT
[0m23:57:13.217843 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:57:13.263152 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:57:13.300527 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.301162 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:57:13.302306 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m23:57:13.305965 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:57:13.309946 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:57:13.310553 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:57:13.310902 [info ] [MainThread]: 
[0m23:57:13.311265 [debug] [MainThread]: On master: Close
[0m23:57:13.316479 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m23:57:13.317137 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze.consumption_history ........................ [RUN]
[0m23:57:13.317816 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption_history)
[0m23:57:13.318288 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m23:57:13.323338 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m23:57:13.324179 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m23:57:13.369081 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m23:57:13.370132 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:57:13.370555 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m23:57:13.370907 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:57:13.376743 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:57:13.377333 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:57:13.377780 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(prevision_j) AS prevision_j,
    SUM(prevision_j1) AS prevision_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at
  );
  
[0m23:57:13.379774 [debug] [Thread-1 (]: Postgres adapter: Postgres error: UNION types date and text cannot be matched
LINE 16:     date,
             ^

[0m23:57:13.380273 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m23:57:13.381036 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m23:57:13.387225 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  UNION types date and text cannot be matched
  LINE 16:     date,
               ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m23:57:13.389051 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b2964646-88e7-4fa3-abb2-b6dee0dd04ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106762820>]}
[0m23:57:13.389744 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model bronze.consumption_history ............... [[31mERROR[0m in 0.07s]
[0m23:57:13.390394 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m23:57:13.390955 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  UNION types date and text cannot be matched
  LINE 16:     date,
               ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m23:57:13.392066 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:57:13.392558 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:57:13.392993 [info ] [Thread-2 (]: 2 of 3 SKIP test not_null_consumption_history_created_at ....................... [[33mSKIP[0m]
[0m23:57:13.393534 [info ] [Thread-3 (]: 3 of 3 SKIP test not_null_consumption_history_date ............................. [[33mSKIP[0m]
[0m23:57:13.394238 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:57:13.394781 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:57:13.395766 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' to be skipped because of status 'skipped'. 
[0m23:57:13.397527 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' to be skipped because of status 'skipped'. 
[0m23:57:13.399910 [info ] [MainThread]: 
[0m23:57:13.400434 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.400760 [debug] [MainThread]: On master: BEGIN
[0m23:57:13.401058 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:57:13.407538 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:57:13.408093 [debug] [MainThread]: On master: COMMIT
[0m23:57:13.408496 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.408812 [debug] [MainThread]: On master: COMMIT
[0m23:57:13.409308 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:57:13.452003 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.452521 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:57:13.456004 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:57:13.458982 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:57:13.490756 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:57:13.575971 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:57:13.583970 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:57:13.584931 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m23:57:13.595181 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:57:13.622800 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.623334 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215713607038235713615726"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:57:13.627253 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:57:13.650640 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.651111 [debug] [MainThread]: On master: BEGIN
[0m23:57:13.651909 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:57:13.652314 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.652686 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215713607038235713615726'
        
      order by ordinal_position

  
[0m23:57:13.660912 [debug] [MainThread]: SQL status: SELECT 1 in 0.008 seconds
[0m23:57:13.666842 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215713607038235713615726"
[0m23:57:13.713968 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:57:13.715420 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.715816 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215713607038235713615726"
         (metadata_hash) values
    ('c1c15c5ab0c60c74d7979adba1df2bbf')
  
[0m23:57:13.716708 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:57:13.720972 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.721424 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215713719655235713719959"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:57:13.723732 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:57:13.728696 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.729332 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215713719655235713719959'
        
      order by ordinal_position

  
[0m23:57:13.733080 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m23:57:13.735808 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215713719655235713719959"
[0m23:57:13.747270 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:57:13.748400 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.748815 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215713719655235713719959"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption_history','consumption_history','ec948cc51036ad1513f55e8c4b59a9675ca3fc2c3b0f46ee355eafa7be61b816','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.consumption"]','The aim of this table is to consolidate history data for consumption
','consumption_history','dbt_elsa','models/silver/consumption_history.sql','silver/consumption_history.sql','dbt_elsa://models/silver/_elsa_bronze__models.yml','2025-07-18 21:57:13','7486413f222e8693a1475cac07ff2121',NULL,NULL,NULL,'protected')
  
[0m23:57:13.749740 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:57:13.757589 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.758095 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718215713607038235713615726");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718215713719655235713719959";
        
        commit;
    
  
[0m23:57:13.759996 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:57:13.769436 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215713607038235713615726"
[0m23:57:13.773881 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.774324 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215713607038235713615726" cascade
[0m23:57:13.776437 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m23:57:13.781227 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215713719655235713719959"
[0m23:57:13.781958 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:13.782367 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215713719655235713719959" cascade
[0m23:57:13.783922 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:57:13.785221 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:57:13.786823 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:57:13.787706 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.084023 (1 runs)
[0m23:57:13.788549 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.033359 (2 runs)
[0m23:57:13.789857 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000872 (2 runs)
[0m23:57:13.790705 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.031239 (2 runs)
[0m23:57:13.791537 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.040144 (2 runs)
[0m23:57:13.792456 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.006434 (2 runs)
[0m23:57:13.793341 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.103018 (2 runs)
[0m23:57:13.794401 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.295858 (1 runs)
[0m23:57:13.800035 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:57:13.926366 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:57:13.928513 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:57:13.930191 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:57:13.932002 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:57:13.933272 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.125136 (1 runs)
[0m23:57:13.934180 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.131780 (1 runs)
[0m23:57:13.939640 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:57:13.960620 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:57:13.962768 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:57:13.963903 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:57:13.965248 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:57:13.966102 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019687 (1 runs)
[0m23:57:13.966919 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.025566 (1 runs)
[0m23:57:13.971507 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:57:13.972932 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:57:13.974449 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:57:13.975508 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:57:13.976897 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:57:13.977757 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000446 (1 runs)
[0m23:57:13.978587 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005227 (1 runs)
[0m23:57:13.984142 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:57:13.985623 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:57:13.986857 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:57:13.987610 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:57:13.989150 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:57:13.990009 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000355 (1 runs)
[0m23:57:13.990884 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004983 (1 runs)
[0m23:57:13.996738 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:57:13.998314 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:57:13.999506 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:57:14.000256 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:57:14.001419 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:57:14.002597 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000348 (1 runs)
[0m23:57:14.003423 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004724 (1 runs)
[0m23:57:14.008225 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:57:14.009983 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:57:14.011379 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:57:14.013614 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:57:14.015008 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:57:14.015867 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000457 (1 runs)
[0m23:57:14.016702 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.006768 (1 runs)
[0m23:57:14.021774 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:57:14.023254 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:57:14.024440 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:57:14.025227 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:57:14.026464 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:57:14.027690 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000350 (1 runs)
[0m23:57:14.028976 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004600 (1 runs)
[0m23:57:14.034382 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:57:14.217429 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:57:14.219102 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:57:14.220074 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:57:14.221269 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:57:14.222120 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.181510 (1 runs)
[0m23:57:14.222960 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.186842 (1 runs)
[0m23:57:14.223845 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:57:14.228331 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:57:14.229731 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:57:14.257148 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m23:57:14.261446 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.262232 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:57:14.266813 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:57:14.269753 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:57:14.325201 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:57:14.326429 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.326962 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('b2964646-88e7-4fa3-abb2-b6dee0dd04ff.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','b2964646-88e7-4fa3-abb2-b6dee0dd04ff','2025-07-18 21:57:14',
    current_timestamp::timestamp
,'consumption_history','Database Error in model consumption_history (models/silver/consumption_history.sql)
  UNION types date and text cannot be matched
  LINE 16:     date,
               ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql','error','model',0.07014775276184082,'2025-07-18T21:57:13.324453Z','2025-07-18T21:57:13.380890Z','2025-07-18T21:57:13.318563Z','2025-07-18T21:57:13.324032Z',NULL,False,'SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(prevision_j) AS prevision_j,
    SUM(prevision_j1) AS prevision_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('b2964646-88e7-4fa3-abb2-b6dee0dd04ff.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','b2964646-88e7-4fa3-abb2-b6dee0dd04ff','2025-07-18 21:57:14',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)','test','{}',NULL),('b2964646-88e7-4fa3-abb2-b6dee0dd04ff.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','b2964646-88e7-4fa3-abb2-b6dee0dd04ff','2025-07-18 21:57:14',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-3 (worker)','test','{}',NULL)
  
[0m23:57:14.328570 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:57:14.331516 [debug] [MainThread]: On master: COMMIT
[0m23:57:14.332032 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.332504 [debug] [MainThread]: On master: COMMIT
[0m23:57:14.333226 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:57:14.335867 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:57:14.336723 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.026178 (1 runs)
[0m23:57:14.337463 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.011101 (1 runs)
[0m23:57:14.338553 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000680 (1 runs)
[0m23:57:14.339793 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.050890 (3 runs)
[0m23:57:14.340594 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.054039 (1 runs)
[0m23:57:14.341481 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.004975 (1 runs)
[0m23:57:14.342267 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002739 (1 runs)
[0m23:57:14.343017 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.076443 (1 runs)
[0m23:57:14.343738 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.106032 (1 runs)
[0m23:57:14.344464 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:57:14.354484 [debug] [MainThread]: Elementary: Handling test results.
[0m23:57:14.409962 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.410541 [debug] [MainThread]: On master: BEGIN
[0m23:57:14.411222 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:57:14.411625 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.412088 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:57:14.416844 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:57:14.419556 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:57:14.460904 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:57:14.463214 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.465373 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('b2964646-88e7-4fa3-abb2-b6dee0dd04ff.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'b2964646-88e7-4fa3-abb2-b6dee0dd04ff.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','b2964646-88e7-4fa3-abb2-b6dee0dd04ff',cast('2025-07-18 21:57:14' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_created_at',NULL,NULL),('b2964646-88e7-4fa3-abb2-b6dee0dd04ff.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'b2964646-88e7-4fa3-abb2-b6dee0dd04ff.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','b2964646-88e7-4fa3-abb2-b6dee0dd04ff',cast('2025-07-18 21:57:14' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','date','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_date',NULL,NULL)
  
[0m23:57:14.468247 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:57:14.471895 [debug] [MainThread]: On master: COMMIT
[0m23:57:14.472634 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.473035 [debug] [MainThread]: On master: COMMIT
[0m23:57:14.474199 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:57:14.476073 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:57:14.491959 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:57:14.568334 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.568924 [debug] [MainThread]: On master: BEGIN
[0m23:57:14.569574 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:57:14.570003 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.570476 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:57:14.574373 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m23:57:14.577341 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:57:14.671707 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:57:14.673435 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.674232 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('b2964646-88e7-4fa3-abb2-b6dee0dd04ff',NULL,NULL,NULL,'2025-07-18 21:57:11','2025-07-18 21:57:14','2025-07-18 21:57:14',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:57:14.675687 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:57:14.679284 [debug] [MainThread]: On master: COMMIT
[0m23:57:14.680034 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:14.680777 [debug] [MainThread]: On master: COMMIT
[0m23:57:14.682005 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:57:14.683857 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:57:14.691380 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:57:14.692538 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:57:14.693204 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.28s]
[0m23:57:14.693816 [debug] [MainThread]: On master: Close
[0m23:57:14.694343 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:57:14.694743 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m23:57:14.695038 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m23:57:14.695425 [info ] [MainThread]: 
[0m23:57:14.695855 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.68 seconds (1.68s).
[0m23:57:14.697675 [debug] [MainThread]: Command end result
[0m23:57:14.789021 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:57:14.791689 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:57:14.798883 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:57:14.799311 [info ] [MainThread]: 
[0m23:57:14.799699 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:57:14.800046 [info ] [MainThread]: 
[0m23:57:14.800484 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m23:57:14.800910 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  UNION types date and text cannot be matched
  LINE 16:     date,
               ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m23:57:14.801293 [info ] [MainThread]: 
[0m23:57:14.801725 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m23:57:14.802070 [info ] [MainThread]: 
[0m23:57:14.802444 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=5
[0m23:57:14.805090 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 3.4459043, "process_in_blocks": "0", "process_kernel_time": 0.504714, "process_mem_max_rss": "145047552", "process_out_blocks": "0", "process_user_time": 4.508316}
[0m23:57:14.805782 [debug] [MainThread]: Command `dbt build` failed at 23:57:14.805593 after 3.45 seconds
[0m23:57:14.806398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049cec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106703b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106703cd0>]}
[0m23:57:14.806830 [debug] [MainThread]: Flushing usage events
[0m23:57:15.196955 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:58:18.468643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dabb770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1b7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1b74d0>]}


============================== 23:58:18.473681 | 341b5f08-3cbc-4c4b-8b97-93f6e3d69dde ==============================
[0m23:58:18.473681 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:58:18.474372 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'invocation_command': 'dbt build --select bronze', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:58:18.689811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '341b5f08-3cbc-4c4b-8b97-93f6e3d69dde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e534510>]}
[0m23:58:18.766737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '341b5f08-3cbc-4c4b-8b97-93f6e3d69dde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f03bdf0>]}
[0m23:58:18.767644 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:58:18.897708 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:58:19.156379 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:58:19.157259 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/consumption.sql
[0m23:58:19.769812 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:58:19.788319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '341b5f08-3cbc-4c4b-8b97-93f6e3d69dde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11045a550>]}
[0m23:58:19.962880 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:58:19.965932 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:58:20.000493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '341b5f08-3cbc-4c4b-8b97-93f6e3d69dde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107264e0>]}
[0m23:58:20.001116 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:58:20.003865 [info ] [MainThread]: 
[0m23:58:20.004331 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:58:20.004661 [info ] [MainThread]: 
[0m23:58:20.005195 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:58:20.006067 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:58:20.064966 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:58:20.065404 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:58:20.065730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:58:20.088164 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.022 seconds
[0m23:58:20.089675 [debug] [ThreadPool]: On list_elsa: Close
[0m23:58:20.096708 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m23:58:20.097685 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m23:58:20.104534 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:58:20.107307 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:58:20.107700 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:58:20.108029 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:58:20.108374 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:58:20.108684 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:58:20.114961 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:58:20.115367 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:58:20.115678 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:58:20.115999 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:58:20.116341 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:58:20.116711 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:58:20.120917 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:58:20.121368 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:58:20.123113 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:58:20.124384 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:58:20.124930 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:58:20.125313 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:58:20.138815 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:20.139211 [debug] [MainThread]: On master: BEGIN
[0m23:58:20.139521 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:58:20.145556 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:58:20.146058 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:20.146542 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:58:20.187105 [debug] [MainThread]: SQL status: SELECT 26 in 0.040 seconds
[0m23:58:20.194246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '341b5f08-3cbc-4c4b-8b97-93f6e3d69dde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108d7230>]}
[0m23:58:20.194768 [debug] [MainThread]: On master: ROLLBACK
[0m23:58:20.195525 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:20.196030 [debug] [MainThread]: On master: BEGIN
[0m23:58:20.197009 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:58:20.197381 [debug] [MainThread]: On master: COMMIT
[0m23:58:20.197696 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:20.197990 [debug] [MainThread]: On master: COMMIT
[0m23:58:20.198504 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:58:20.237170 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:58:20.276261 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:20.276866 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:58:20.277908 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:58:20.281371 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:58:20.285193 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:58:20.285776 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:58:20.286127 [info ] [MainThread]: 
[0m23:58:20.286493 [debug] [MainThread]: On master: Close
[0m23:58:20.290233 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:58:20.290834 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m23:58:20.291378 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption)
[0m23:58:20.292356 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:58:20.297282 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:58:20.298279 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:58:20.340409 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:58:20.341306 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.341798 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:58:20.342162 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:58:20.348144 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:58:20.348635 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.349050 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:58:20.352968 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.003 seconds
[0m23:58:20.364744 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.365225 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m23:58:20.366121 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:58:20.370038 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.370453 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:58:20.371411 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:58:20.398084 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.398577 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m23:58:20.399515 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m23:58:20.412959 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.413741 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:58:20.421870 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.007 seconds
[0m23:58:20.426893 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.427468 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m23:58:20.428480 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:58:20.430168 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:58:20.430790 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.431198 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:58:20.432981 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:58:20.440762 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:58:20.446573 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:58:20.447281 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:58:20.450001 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:58:20.452597 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:58:20.454335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '341b5f08-3cbc-4c4b-8b97-93f6e3d69dde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dae4e0>]}
[0m23:58:20.455047 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.16s]
[0m23:58:20.455723 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:58:20.456549 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:58:20.456969 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m23:58:20.457459 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m23:58:20.457857 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:58:20.458276 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:58:20.458638 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:58:20.459037 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m23:58:20.459466 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m23:58:20.470561 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc'
[0m23:58:20.475790 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:58:20.476369 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m23:58:20.476769 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:58:20.477281 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:58:20.483199 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:58:20.488217 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:58:20.488760 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:58:20.495379 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:58:20.495953 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '341b5f08-3cbc-4c4b-8b97-93f6e3d69dde', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109b0950>]}
[0m23:58:20.496769 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:58:20.509710 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:58:20.928500 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:58:20.929339 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:58:20.930961 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:58:20.932073 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:58:20.932483 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m23:58:20.932845 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:58:20.933400 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:58:20.933866 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:58:20.934283 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m23:58:20.934703 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m23:58:20.935089 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:58:20.935505 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:58:20.939371 [debug] [Thread-2 (]: SQL status: BEGIN in 0.006 seconds
[0m23:58:20.939876 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:58:20.940287 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:58:20.941151 [debug] [Thread-3 (]: SQL status: BEGIN in 0.006 seconds
[0m23:58:20.941564 [debug] [Thread-4 (]: SQL status: BEGIN in 0.006 seconds
[0m23:58:20.941989 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:58:20.942385 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:58:20.942803 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:58:20.943321 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:58:20.949592 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m23:58:20.979340 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.013 seconds
[0m23:58:20.988735 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.009 seconds
[0m23:58:21.007473 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m23:58:21.010238 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m23:58:21.017536 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m23:58:21.018201 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m23:58:21.018619 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m23:58:21.019024 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m23:58:21.019802 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.56s]
[0m23:58:21.020587 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.55s]
[0m23:58:21.021740 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:58:21.022537 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.55s]
[0m23:58:21.023334 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:58:21.024160 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:58:21.026435 [info ] [MainThread]: 
[0m23:58:21.027016 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.027654 [debug] [MainThread]: On master: BEGIN
[0m23:58:21.028277 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:58:21.035006 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:58:21.035520 [debug] [MainThread]: On master: COMMIT
[0m23:58:21.036059 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.036745 [debug] [MainThread]: On master: COMMIT
[0m23:58:21.037704 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:58:21.074333 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.074849 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:58:21.078546 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:58:21.081364 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:58:21.112538 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:58:21.163134 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:58:21.170837 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:58:21.172082 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m23:58:21.181838 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:58:21.209061 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.209579 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215821193292235821201972"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:58:21.213364 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m23:58:21.231450 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.231927 [debug] [MainThread]: On master: BEGIN
[0m23:58:21.232564 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:58:21.232936 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.233304 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215821193292235821201972'
        
      order by ordinal_position

  
[0m23:58:21.240358 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m23:58:21.242801 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215821193292235821201972"
[0m23:58:21.284222 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:21.285407 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.285830 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215821193292235821201972"
         (metadata_hash) values
    ('3ce1ef891becc1969c0aef25e2a6171b')
  
[0m23:58:21.286761 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:58:21.290881 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.291384 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718215821289271235821289900"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m23:58:21.293655 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m23:58:21.298912 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.299392 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718215821289271235821289900'
        
      order by ordinal_position

  
[0m23:58:21.303288 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m23:58:21.306013 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718215821289271235821289900"
[0m23:58:21.320407 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:21.321505 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.321920 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718215821289271235821289900"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption','consumption','1d41ebae6088f8ff7276bfc5ad428e48e64acd4966f3e6159afb124dbbf05129','table','[]','{}','[]','elsa','bronze','[]','["source.dbt_elsa.bronze.rte_eco2mix"]','The aim of this table is to track houtly energy consumption for a given day
','consumption','dbt_elsa','models/bronze/consumption.sql','bronze/consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-18 21:58:21','98fee0c443beda65d81d75967ccd956b',NULL,NULL,NULL,'protected')
  
[0m23:58:21.322875 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:58:21.331253 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.331744 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718215821193292235821201972");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718215821289271235821289900";
        
        commit;
    
  
[0m23:58:21.333536 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:58:21.337849 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215821193292235821201972"
[0m23:58:21.338505 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.338907 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215821193292235821201972" cascade
[0m23:58:21.340854 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m23:58:21.344861 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718215821289271235821289900"
[0m23:58:21.345534 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.345939 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718215821289271235821289900" cascade
[0m23:58:21.347828 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m23:58:21.349152 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m23:58:21.350786 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:58:21.351717 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.049153 (1 runs)
[0m23:58:21.352664 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.024445 (2 runs)
[0m23:58:21.353564 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000931 (2 runs)
[0m23:58:21.354448 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.029609 (2 runs)
[0m23:58:21.355332 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.038772 (2 runs)
[0m23:58:21.356209 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.006600 (2 runs)
[0m23:58:21.357361 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.090665 (2 runs)
[0m23:58:21.358233 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.238060 (1 runs)
[0m23:58:21.363297 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:58:21.377570 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:58:21.379256 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:58:21.380308 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:58:21.381775 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:58:21.382647 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.012821 (1 runs)
[0m23:58:21.383493 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.018521 (1 runs)
[0m23:58:21.388287 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:58:21.408862 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:58:21.410241 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:58:21.411015 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:58:21.412177 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:58:21.413224 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019044 (1 runs)
[0m23:58:21.414542 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.023826 (1 runs)
[0m23:58:21.419216 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:58:21.420598 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:58:21.421796 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:58:21.422896 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:58:21.424076 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:58:21.424964 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000397 (1 runs)
[0m23:58:21.425822 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.004791 (1 runs)
[0m23:58:21.431027 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:58:21.432544 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:58:21.433742 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:58:21.434481 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:58:21.435648 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:58:21.436837 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000360 (1 runs)
[0m23:58:21.437662 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004672 (1 runs)
[0m23:58:21.442618 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:58:21.444033 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:58:21.445194 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:58:21.445919 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:58:21.447536 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:58:21.448498 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000352 (1 runs)
[0m23:58:21.449328 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004681 (1 runs)
[0m23:58:21.454522 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:58:21.455960 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:58:21.457137 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:58:21.457855 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:58:21.459105 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:58:21.459959 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000400 (1 runs)
[0m23:58:21.460783 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004469 (1 runs)
[0m23:58:21.466119 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:58:21.469434 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:58:21.470649 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:58:21.471372 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:58:21.472589 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:58:21.473426 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000350 (1 runs)
[0m23:58:21.474234 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.006412 (1 runs)
[0m23:58:21.479214 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:58:21.658393 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:58:21.659820 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:58:21.660923 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:58:21.662604 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:58:21.664429 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.177702 (1 runs)
[0m23:58:21.665437 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.183296 (1 runs)
[0m23:58:21.666418 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:58:21.670628 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:58:21.671529 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:58:21.696564 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 4 artifacts.
[0m23:58:21.701435 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.701933 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:58:21.706110 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m23:58:21.708906 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:58:21.862597 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:21.864510 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.865438 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.model.dbt_elsa.consumption','model.dbt_elsa.consumption','341b5f08-3cbc-4c4b-8b97-93f6e3d69dde','2025-07-18 21:58:21',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.16189098358154297,'2025-07-18T21:58:20.298612Z','2025-07-18T21:58:20.452454Z','2025-07-18T21:58:20.292793Z','2025-07-18T21:58:20.298110Z',96,False,'SELECT
    id,
    created_at,
    (data->>''date'')::date AS date,
    (data->>''heure'')::time AS heure,   
    (data->>''gaz'')::int AS gaz,
    (data->>''nucleaire'')::int AS nucleaire,
    (data->>''charbon'')::int AS charbon,
    (data->>''solaire'')::int AS solaire,
    (data->>''eolien'')::int AS eolien,
    (data->>''hydraulique'')::int AS hydraulique,
    (data->>''bioenergies'')::int AS bioenergies,
    (data->>''autres'')::int AS autres,
    (data->>''prevision_j'')::int AS prevision_j,
    (data->>''prevision_j1'')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','341b5f08-3cbc-4c4b-8b97-93f6e3d69dde','2025-07-18 21:58:21',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'pass','test',0.5622820854187012,'2025-07-18T21:58:20.489231Z','2025-07-18T21:58:21.007287Z','2025-07-18T21:58:20.459862Z','2025-07-18T21:58:20.488611Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','341b5f08-3cbc-4c4b-8b97-93f6e3d69dde','2025-07-18 21:58:21',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'pass','test',0.5500779151916504,'2025-07-18T21:58:20.529382Z','2025-07-18T21:58:21.010037Z','2025-07-18T21:58:20.477562Z','2025-07-18T21:58:20.509524Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','341b5f08-3cbc-4c4b-8b97-93f6e3d69dde','2025-07-18 21:58:21',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'pass','test',0.5461771488189697,'2025-07-18T21:58:20.510040Z','2025-07-18T21:58:21.017354Z','2025-07-18T21:58:20.483626Z','2025-07-18T21:58:20.496599Z',1,False,'
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',0,NULL,'Thread-4 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m23:58:21.867824 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.002 seconds
[0m23:58:21.870403 [debug] [MainThread]: On master: COMMIT
[0m23:58:21.870871 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.871292 [debug] [MainThread]: On master: COMMIT
[0m23:58:21.871939 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:58:21.874460 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:58:21.875316 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.023803 (1 runs)
[0m23:58:21.876517 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.009897 (1 runs)
[0m23:58:21.877711 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000630 (1 runs)
[0m23:58:21.878774 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.148085 (4 runs)
[0m23:58:21.880016 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.152199 (1 runs)
[0m23:58:21.881028 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.006098 (1 runs)
[0m23:58:21.881941 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002580 (1 runs)
[0m23:58:21.883180 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.174928 (1 runs)
[0m23:58:21.883957 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.202670 (1 runs)
[0m23:58:21.884738 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:58:21.894308 [debug] [MainThread]: Elementary: Handling test results.
[0m23:58:21.925535 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.926086 [debug] [MainThread]: On master: BEGIN
[0m23:58:21.926800 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:58:21.927213 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.927690 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:58:21.932709 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:58:21.935578 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:58:21.991959 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:21.993421 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.994026 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','341b5f08-3cbc-4c4b-8b97-93f6e3d69dde',cast('2025-07-18 21:58:20' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_created_at',NULL,0),('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','341b5f08-3cbc-4c4b-8b97-93f6e3d69dde',cast('2025-07-18 21:58:20' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_date',NULL,0),('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'341b5f08-3cbc-4c4b-8b97-93f6e3d69dde.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','341b5f08-3cbc-4c4b-8b97-93f6e3d69dde',cast('2025-07-18 21:58:20' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]','
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_id',NULL,0)
  
[0m23:58:21.995606 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:58:21.998484 [debug] [MainThread]: On master: COMMIT
[0m23:58:21.998941 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:21.999294 [debug] [MainThread]: On master: COMMIT
[0m23:58:22.000893 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:58:22.002918 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:58:22.019205 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:58:22.088873 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:22.089624 [debug] [MainThread]: On master: BEGIN
[0m23:58:22.090445 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:58:22.090969 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:22.091484 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:58:22.096858 [debug] [MainThread]: SQL status: SELECT 35 in 0.005 seconds
[0m23:58:22.100241 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:58:22.122162 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:22.123590 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:22.124323 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('341b5f08-3cbc-4c4b-8b97-93f6e3d69dde',NULL,NULL,NULL,'2025-07-18 21:58:18','2025-07-18 21:58:22','2025-07-18 21:58:22',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:58:22.125773 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:58:22.128587 [debug] [MainThread]: On master: COMMIT
[0m23:58:22.129091 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:22.129477 [debug] [MainThread]: On master: COMMIT
[0m23:58:22.130824 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:58:22.132446 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:58:22.138962 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:58:22.139973 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:58:22.140501 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.10s]
[0m23:58:22.140898 [debug] [MainThread]: On master: Close
[0m23:58:22.141379 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:58:22.141681 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:58:22.141964 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m23:58:22.142242 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m23:58:22.142518 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m23:58:22.142895 [info ] [MainThread]: 
[0m23:58:22.143249 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 2.14 seconds (2.14s).
[0m23:58:22.144848 [debug] [MainThread]: Command end result
[0m23:58:22.232608 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:58:22.235519 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:58:22.242130 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:58:22.242657 [info ] [MainThread]: 
[0m23:58:22.243057 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:58:22.243431 [info ] [MainThread]: 
[0m23:58:22.243803 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:58:22.244435 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:58:22.247370 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.8664749, "process_in_blocks": "0", "process_kernel_time": 0.499215, "process_mem_max_rss": "146599936", "process_out_blocks": "0", "process_user_time": 4.904463}
[0m23:58:22.247916 [debug] [MainThread]: Command `dbt build` succeeded at 23:58:22.247799 after 3.87 seconds
[0m23:58:22.248310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d8fc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d9f930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d9c410>]}
[0m23:58:22.248952 [debug] [MainThread]: Flushing usage events
[0m23:58:22.686859 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:58:26.508090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107233770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108967610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089674d0>]}


============================== 23:58:26.513948 | 4b7f9f93-84c5-423d-9a60-035eb0a5938a ==============================
[0m23:58:26.513948 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:58:26.514954 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build --select silver', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m23:58:26.726262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b7f9f93-84c5-423d-9a60-035eb0a5938a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cb0510>]}
[0m23:58:26.803531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4b7f9f93-84c5-423d-9a60-035eb0a5938a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e3df0>]}
[0m23:58:26.804458 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:58:26.938862 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:58:27.194985 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:58:27.195456 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:58:27.203685 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:58:27.337988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4b7f9f93-84c5-423d-9a60-035eb0a5938a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088d7350>]}
[0m23:58:27.593486 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:58:27.596553 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:58:27.630363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4b7f9f93-84c5-423d-9a60-035eb0a5938a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096f3c50>]}
[0m23:58:27.630944 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:58:27.633572 [info ] [MainThread]: 
[0m23:58:27.633974 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:58:27.634304 [info ] [MainThread]: 
[0m23:58:27.634916 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:58:27.635769 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:58:27.688169 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:58:27.688602 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:58:27.688932 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:58:27.711245 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.022 seconds
[0m23:58:27.713303 [debug] [ThreadPool]: On list_elsa: Close
[0m23:58:27.720221 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m23:58:27.720877 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m23:58:27.733691 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:58:27.734289 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:58:27.734724 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:58:27.733207 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:58:27.735472 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:58:27.735771 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:58:27.740561 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:58:27.741076 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:58:27.741431 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:58:27.741765 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:58:27.742114 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:58:27.742546 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:58:27.746105 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:58:27.746712 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.004 seconds
[0m23:58:27.748515 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:58:27.749829 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:58:27.750390 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:58:27.750790 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:58:27.767516 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:27.768001 [debug] [MainThread]: On master: BEGIN
[0m23:58:27.768367 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:58:27.773922 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:58:27.774322 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:27.774728 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:58:27.815179 [debug] [MainThread]: SQL status: SELECT 26 in 0.040 seconds
[0m23:58:27.822302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b7f9f93-84c5-423d-9a60-035eb0a5938a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fb82f0>]}
[0m23:58:27.822810 [debug] [MainThread]: On master: ROLLBACK
[0m23:58:27.823407 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:27.823747 [debug] [MainThread]: On master: BEGIN
[0m23:58:27.824334 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:58:27.824668 [debug] [MainThread]: On master: COMMIT
[0m23:58:27.824985 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:27.825288 [debug] [MainThread]: On master: COMMIT
[0m23:58:27.825767 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:58:27.866287 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:58:27.902363 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:27.903018 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:58:27.904039 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m23:58:27.907234 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:58:27.911362 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:58:27.912123 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:58:27.912644 [info ] [MainThread]: 
[0m23:58:27.913098 [debug] [MainThread]: On master: Close
[0m23:58:27.916894 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m23:58:27.917493 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze.consumption_history ........................ [RUN]
[0m23:58:27.918180 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption_history)
[0m23:58:27.918628 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m23:58:27.922518 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m23:58:27.923548 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m23:58:27.966503 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m23:58:27.967358 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:27.967753 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m23:58:27.968110 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:58:27.973758 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:58:27.974225 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:27.974623 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(prevision_j) AS prevision_j,
    SUM(prevision_j1) AS prevision_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at
  );
  
[0m23:58:27.979999 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m23:58:27.991359 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:27.991818 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."bronze"."consumption_history" rename to "consumption_history__dbt_backup"
[0m23:58:27.992651 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:58:27.996941 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:27.997450 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."bronze"."consumption_history__dbt_tmp" rename to "consumption_history"
[0m23:58:27.998367 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:58:28.024632 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:28.025115 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  comment on table "elsa"."bronze"."consumption_history" is $dbt_comment_literal_block$The aim of this table is to consolidate history data for consumption
$dbt_comment_literal_block$;

  
[0m23:58:28.026017 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:58:28.039675 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:28.040202 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption_history'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:58:28.048642 [debug] [Thread-1 (]: SQL status: SELECT 12 in 0.008 seconds
[0m23:58:28.053486 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:28.054037 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption_history".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  

  
[0m23:58:28.054911 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:58:28.056243 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m23:58:28.056689 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:28.057082 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m23:58:28.058224 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:58:28.066293 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption_history__dbt_backup"
[0m23:58:28.072050 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:58:28.072523 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
drop table if exists "elsa"."bronze"."consumption_history__dbt_backup" cascade
[0m23:58:28.074652 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:58:28.077413 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m23:58:28.079273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b7f9f93-84c5-423d-9a60-035eb0a5938a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1bd7e0>]}
[0m23:58:28.080179 [info ] [Thread-1 (]: 1 of 3 OK created sql table model bronze.consumption_history ................... [[32mSELECT 2[0m in 0.16s]
[0m23:58:28.081044 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m23:58:28.081947 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:58:28.082404 [info ] [Thread-2 (]: 2 of 3 START test not_null_consumption_history_created_at ...................... [RUN]
[0m23:58:28.082868 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:58:28.083397 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9)
[0m23:58:28.083854 [info ] [Thread-3 (]: 3 of 3 START test not_null_consumption_history_date ............................ [RUN]
[0m23:58:28.084327 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:58:28.084866 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4'
[0m23:58:28.090873 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:58:28.106157 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:58:28.109274 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:58:28.110293 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:58:28.113258 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:58:28.113870 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '4b7f9f93-84c5-423d-9a60-035eb0a5938a', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c5f950>]}
[0m23:58:28.114463 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:58:28.419824 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:58:28.421059 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:58:28.422167 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:58:28.422640 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:58:28.423080 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: BEGIN
[0m23:58:28.423482 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: BEGIN
[0m23:58:28.423879 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:58:28.424265 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:58:28.431332 [debug] [Thread-2 (]: SQL status: BEGIN in 0.007 seconds
[0m23:58:28.431795 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:58:28.432182 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:58:28.432645 [debug] [Thread-3 (]: SQL status: BEGIN in 0.008 seconds
[0m23:58:28.433023 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:58:28.433408 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:58:28.433876 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m23:58:28.441433 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.008 seconds
[0m23:58:28.525019 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: ROLLBACK
[0m23:58:28.525599 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: ROLLBACK
[0m23:58:28.526336 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: Close
[0m23:58:28.526811 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: Close
[0m23:58:28.527471 [info ] [Thread-2 (]: 2 of 3 PASS not_null_consumption_history_created_at ............................ [[32mPASS[0m in 0.44s]
[0m23:58:28.528166 [info ] [Thread-3 (]: 3 of 3 PASS not_null_consumption_history_date .................................. [[32mPASS[0m in 0.44s]
[0m23:58:28.529133 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:58:28.530210 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:58:28.532414 [info ] [MainThread]: 
[0m23:58:28.532855 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:28.533375 [debug] [MainThread]: On master: BEGIN
[0m23:58:28.533732 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:58:28.539696 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:58:28.540128 [debug] [MainThread]: On master: COMMIT
[0m23:58:28.540465 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:28.540778 [debug] [MainThread]: On master: COMMIT
[0m23:58:28.541198 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:58:28.576388 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:28.576902 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:58:28.580554 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:58:28.583193 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:58:28.614668 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:58:28.667683 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:58:28.675235 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:58:28.676470 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m23:58:28.677685 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:58:28.678514 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.051829 (1 runs)
[0m23:58:28.679320 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.062997 (1 runs)
[0m23:58:28.684636 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:58:28.699563 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:58:28.700933 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:58:28.701772 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:58:28.703054 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:58:28.703960 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.013699 (1 runs)
[0m23:58:28.704823 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.018353 (1 runs)
[0m23:58:28.709629 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:58:28.731440 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:58:28.732774 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:58:28.733541 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:58:28.734800 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:58:28.735756 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020726 (1 runs)
[0m23:58:28.736608 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.025084 (1 runs)
[0m23:58:28.741777 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:58:28.743172 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:58:28.744329 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:58:28.745056 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:58:28.746295 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:58:28.747845 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000402 (1 runs)
[0m23:58:28.748751 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.004363 (1 runs)
[0m23:58:28.753787 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:58:28.755716 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:58:28.757063 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:58:28.757930 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:58:28.759171 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:58:28.760083 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000844 (1 runs)
[0m23:58:28.760903 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005319 (1 runs)
[0m23:58:28.766192 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:58:28.767798 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:58:28.769333 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:58:28.770444 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:58:28.771622 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:58:28.772468 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000467 (1 runs)
[0m23:58:28.773396 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005399 (1 runs)
[0m23:58:28.778364 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:58:28.780186 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:58:28.781495 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:58:28.782243 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:58:28.784003 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:58:28.784895 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000508 (1 runs)
[0m23:58:28.785794 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005558 (1 runs)
[0m23:58:28.790541 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:58:28.791883 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:58:28.793032 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:58:28.793745 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:58:28.794876 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:58:28.795718 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000342 (1 runs)
[0m23:58:28.796732 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004273 (1 runs)
[0m23:58:28.802879 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:58:28.983748 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:58:28.985088 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:58:28.986059 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:58:28.987246 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:58:28.988111 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.179709 (1 runs)
[0m23:58:28.988955 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.184329 (1 runs)
[0m23:58:28.989901 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:58:28.994043 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:58:28.994947 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:58:29.021244 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m23:58:29.039350 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.039837 [debug] [MainThread]: On master: BEGIN
[0m23:58:29.040485 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:58:29.040880 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.041269 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:58:29.050436 [debug] [MainThread]: SQL status: SELECT 23 in 0.009 seconds
[0m23:58:29.053408 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:58:29.150821 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:29.152202 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.152723 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('4b7f9f93-84c5-423d-9a60-035eb0a5938a.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','4b7f9f93-84c5-423d-9a60-035eb0a5938a','2025-07-18 21:58:29',
    current_timestamp::timestamp
,'consumption_history','SELECT 2','success','model',0.16010594367980957,'2025-07-18T21:58:27.923891Z','2025-07-18T21:58:28.077237Z','2025-07-18T21:58:27.918964Z','2025-07-18T21:58:27.923371Z',2,False,'SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(prevision_j) AS prevision_j,
    SUM(prevision_j1) AS prevision_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 2", "code": "SELECT", "rows_affected": 2}',NULL),('4b7f9f93-84c5-423d-9a60-035eb0a5938a.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','4b7f9f93-84c5-423d-9a60-035eb0a5938a','2025-07-18 21:58:29',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'pass','test',0.44403719902038574,'2025-07-18T21:58:28.126712Z','2025-07-18T21:58:28.524824Z','2025-07-18T21:58:28.085158Z','2025-07-18T21:58:28.114288Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('4b7f9f93-84c5-423d-9a60-035eb0a5938a.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','4b7f9f93-84c5-423d-9a60-035eb0a5938a','2025-07-18 21:58:29',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'pass','test',0.4433600902557373,'2025-07-18T21:58:28.110649Z','2025-07-18T21:58:28.525459Z','2025-07-18T21:58:28.096930Z','2025-07-18T21:58:28.110147Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m23:58:29.154334 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:58:29.156581 [debug] [MainThread]: On master: COMMIT
[0m23:58:29.157005 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.157352 [debug] [MainThread]: On master: COMMIT
[0m23:58:29.158641 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:58:29.160956 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:58:29.161733 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025320 (1 runs)
[0m23:58:29.162455 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.016585 (1 runs)
[0m23:58:29.163479 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000684 (1 runs)
[0m23:58:29.164335 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.066417 (3 runs)
[0m23:58:29.165076 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.076915 (1 runs)
[0m23:58:29.165802 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.004346 (1 runs)
[0m23:58:29.166523 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003098 (1 runs)
[0m23:58:29.167645 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.123693 (1 runs)
[0m23:58:29.168374 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.165793 (1 runs)
[0m23:58:29.169166 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:58:29.178757 [debug] [MainThread]: Elementary: Handling test results.
[0m23:58:29.208842 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.209350 [debug] [MainThread]: On master: BEGIN
[0m23:58:29.210032 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:58:29.210445 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.210913 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:58:29.215712 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:58:29.218538 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:58:29.259492 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:29.260650 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.261221 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('4b7f9f93-84c5-423d-9a60-035eb0a5938a.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'4b7f9f93-84c5-423d-9a60-035eb0a5938a.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','4b7f9f93-84c5-423d-9a60-035eb0a5938a',cast('2025-07-18 21:58:28' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null


',NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_history_created_at',NULL,0),('4b7f9f93-84c5-423d-9a60-035eb0a5938a.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'4b7f9f93-84c5-423d-9a60-035eb0a5938a.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','4b7f9f93-84c5-423d-9a60-035eb0a5938a',cast('2025-07-18 21:58:28' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null


',NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_history_date',NULL,0)
  
[0m23:58:29.262904 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:58:29.265374 [debug] [MainThread]: On master: COMMIT
[0m23:58:29.265776 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.266118 [debug] [MainThread]: On master: COMMIT
[0m23:58:29.267565 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:58:29.269258 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:58:29.285873 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:58:29.351469 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.352015 [debug] [MainThread]: On master: BEGIN
[0m23:58:29.352843 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:58:29.353256 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.353711 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:58:29.357913 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:58:29.360677 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:58:29.381152 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:58:29.382333 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.382872 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('4b7f9f93-84c5-423d-9a60-035eb0a5938a',NULL,NULL,NULL,'2025-07-18 21:58:26','2025-07-18 21:58:29','2025-07-18 21:58:29',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:58:29.383973 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:58:29.386425 [debug] [MainThread]: On master: COMMIT
[0m23:58:29.386817 [debug] [MainThread]: Using postgres connection "master"
[0m23:58:29.387171 [debug] [MainThread]: On master: COMMIT
[0m23:58:29.388672 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:58:29.390465 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:58:29.397785 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:58:29.398811 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:58:29.399351 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.86s]
[0m23:58:29.399757 [debug] [MainThread]: On master: Close
[0m23:58:29.400250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:58:29.400565 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m23:58:29.400859 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' was properly closed.
[0m23:58:29.401147 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' was properly closed.
[0m23:58:29.401527 [info ] [MainThread]: 
[0m23:58:29.401898 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.77 seconds (1.77s).
[0m23:58:29.403412 [debug] [MainThread]: Command end result
[0m23:58:29.498057 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:58:29.500556 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:58:29.507088 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:58:29.507478 [info ] [MainThread]: 
[0m23:58:29.507866 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:58:29.508232 [info ] [MainThread]: 
[0m23:58:29.508593 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m23:58:29.509339 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:58:29.512443 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.0935814, "process_in_blocks": "0", "process_kernel_time": 0.442875, "process_mem_max_rss": "137060352", "process_out_blocks": "0", "process_user_time": 4.132378}
[0m23:58:29.513994 [debug] [MainThread]: Command `dbt build` succeeded at 23:58:29.513815 after 3.10 seconds
[0m23:58:29.514441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a07fe30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a283890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a281590>]}
[0m23:58:29.515539 [debug] [MainThread]: Flushing usage events
[0m23:58:29.903869 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:59:35.953174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8ef770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d023610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0234d0>]}


============================== 23:59:35.958597 | cd39f1e6-9366-4e87-a963-906dc0505cbd ==============================
[0m23:59:35.958597 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:59:35.959870 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select bronze', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m23:59:36.176250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cd39f1e6-9366-4e87-a963-906dc0505cbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c370510>]}
[0m23:59:36.253482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cd39f1e6-9366-4e87-a963-906dc0505cbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cea3df0>]}
[0m23:59:36.254475 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:59:36.405454 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:59:36.857157 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:59:36.857667 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:59:36.867287 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:59:37.014490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd39f1e6-9366-4e87-a963-906dc0505cbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf97350>]}
[0m23:59:37.194740 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:59:37.198545 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:59:37.271031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd39f1e6-9366-4e87-a963-906dc0505cbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dec3c50>]}
[0m23:59:37.271659 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:59:37.274701 [info ] [MainThread]: 
[0m23:59:37.275195 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:59:37.275802 [info ] [MainThread]: 
[0m23:59:37.276539 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:59:37.277723 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:59:37.352964 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:59:37.353422 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:59:37.353750 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:59:37.390337 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.036 seconds
[0m23:59:37.392462 [debug] [ThreadPool]: On list_elsa: Close
[0m23:59:37.400601 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m23:59:37.401305 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m23:59:37.409064 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:59:37.412660 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:59:37.413131 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:59:37.413469 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:59:37.413792 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:59:37.414106 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:59:37.421400 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m23:59:37.421822 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:59:37.422227 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:59:37.422799 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m23:59:37.423133 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:59:37.423475 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:59:37.427241 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:59:37.429060 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:59:37.429445 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m23:59:37.430703 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:59:37.431046 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:59:37.431419 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:59:37.447988 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:37.448398 [debug] [MainThread]: On master: BEGIN
[0m23:59:37.448692 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:59:37.453820 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:59:37.454221 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:37.454614 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:59:37.496196 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m23:59:37.503255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cd39f1e6-9366-4e87-a963-906dc0505cbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df734d0>]}
[0m23:59:37.503808 [debug] [MainThread]: On master: ROLLBACK
[0m23:59:37.504396 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:37.504743 [debug] [MainThread]: On master: BEGIN
[0m23:59:37.505355 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:37.505699 [debug] [MainThread]: On master: COMMIT
[0m23:59:37.506028 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:37.506339 [debug] [MainThread]: On master: COMMIT
[0m23:59:37.506777 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:59:37.547788 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:59:37.583258 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:37.583849 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:59:37.584919 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:59:37.588027 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:59:37.592076 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:59:37.593235 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m23:59:37.593788 [info ] [MainThread]: 
[0m23:59:37.594320 [debug] [MainThread]: On master: Close
[0m23:59:37.599696 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m23:59:37.600548 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m23:59:37.601302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption)
[0m23:59:37.601772 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m23:59:37.605850 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m23:59:37.607180 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m23:59:37.652456 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m23:59:37.653329 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.653729 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m23:59:37.654078 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:59:37.660146 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:59:37.660604 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.660992 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m23:59:37.665646 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.004 seconds
[0m23:59:37.676892 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.677408 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m23:59:37.678288 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:59:37.682495 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.682944 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m23:59:37.683896 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:59:37.710136 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.710663 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m23:59:37.711649 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m23:59:37.724744 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.725372 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:59:37.734244 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.008 seconds
[0m23:59:37.739340 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.739879 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m23:59:37.740865 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:59:37.742332 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:59:37.742913 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.743494 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m23:59:37.745219 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:59:37.752931 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m23:59:37.758028 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m23:59:37.758447 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m23:59:37.761169 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:59:37.763795 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m23:59:37.765997 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd39f1e6-9366-4e87-a963-906dc0505cbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128c9a50>]}
[0m23:59:37.766843 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.16s]
[0m23:59:37.767541 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m23:59:37.768420 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:59:37.768970 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m23:59:37.769627 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:59:37.770122 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:59:37.770585 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m23:59:37.771088 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m23:59:37.771595 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m23:59:37.772288 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:59:37.772954 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m23:59:37.773744 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc'
[0m23:59:37.785167 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:59:37.788638 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:59:37.789111 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:59:37.800320 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:59:37.805077 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:59:37.805715 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:59:37.808426 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:59:37.809137 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'cd39f1e6-9366-4e87-a963-906dc0505cbd', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7c8290>]}
[0m23:59:37.828710 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:59:37.841754 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:59:38.210634 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:59:38.211575 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:59:38.213112 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:59:38.214363 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:59:38.214796 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m23:59:38.215175 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:59:38.215801 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:59:38.216435 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:59:38.217005 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m23:59:38.217487 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m23:59:38.217896 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:59:38.218281 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:59:38.221914 [debug] [Thread-4 (]: SQL status: BEGIN in 0.007 seconds
[0m23:59:38.222385 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m23:59:38.222768 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m23:59:38.225402 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:59:38.226094 [debug] [Thread-3 (]: SQL status: BEGIN in 0.008 seconds
[0m23:59:38.226483 [debug] [Thread-2 (]: SQL status: BEGIN in 0.009 seconds
[0m23:59:38.232829 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m23:59:38.251451 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m23:59:38.268660 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:59:38.278235 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m23:59:38.278741 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:59:38.279397 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m23:59:38.280097 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.51s]
[0m23:59:38.280651 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m23:59:38.281248 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m23:59:38.281612 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:59:38.287528 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m23:59:38.296361 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m23:59:38.297045 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m23:59:38.297464 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m23:59:38.298491 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.52s]
[0m23:59:38.300257 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m23:59:38.299308 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.53s]
[0m23:59:38.301385 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m23:59:38.303210 [info ] [MainThread]: 
[0m23:59:38.303657 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.304172 [debug] [MainThread]: On master: BEGIN
[0m23:59:38.304491 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:59:38.309568 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:59:38.310110 [debug] [MainThread]: On master: COMMIT
[0m23:59:38.310467 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.310776 [debug] [MainThread]: On master: COMMIT
[0m23:59:38.311283 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:59:38.346442 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.346952 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:59:38.350429 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:59:38.353095 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:59:38.385054 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:59:38.436253 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:59:38.444093 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:59:38.445350 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m23:59:38.446540 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:59:38.447474 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.050036 (1 runs)
[0m23:59:38.448347 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.061451 (1 runs)
[0m23:59:38.453031 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:59:38.467915 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:59:38.469368 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:59:38.470281 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:59:38.471489 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:59:38.472324 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.013760 (1 runs)
[0m23:59:38.473133 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.018378 (1 runs)
[0m23:59:38.478449 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:59:38.500161 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:59:38.501469 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:59:38.502257 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:59:38.503452 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:59:38.504374 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020514 (1 runs)
[0m23:59:38.505214 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024993 (1 runs)
[0m23:59:38.511449 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:59:38.513282 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:59:38.514832 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:59:38.515587 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:59:38.516756 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:59:38.517582 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000440 (1 runs)
[0m23:59:38.518421 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005475 (1 runs)
[0m23:59:38.523233 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:59:38.525052 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:59:38.526721 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:59:38.527645 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:59:38.528877 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:59:38.529734 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000748 (1 runs)
[0m23:59:38.530580 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005585 (1 runs)
[0m23:59:38.535523 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:59:38.536985 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:59:38.538233 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:59:38.539354 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:59:38.540537 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:59:38.541382 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000362 (1 runs)
[0m23:59:38.542368 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004951 (1 runs)
[0m23:59:38.547686 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:59:38.549212 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:59:38.550422 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:59:38.551170 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:59:38.552709 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:59:38.553625 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000408 (1 runs)
[0m23:59:38.554490 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004627 (1 runs)
[0m23:59:38.559491 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:59:38.561190 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:59:38.562437 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:59:38.563191 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:59:38.564364 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:59:38.565294 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000396 (1 runs)
[0m23:59:38.566130 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004933 (1 runs)
[0m23:59:38.571411 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:59:38.747604 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:59:38.748963 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:59:38.749978 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:59:38.751236 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:59:38.752136 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.175059 (1 runs)
[0m23:59:38.753269 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.179757 (1 runs)
[0m23:59:38.754330 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:59:38.758551 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:59:38.759805 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:59:38.785962 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 4 artifacts.
[0m23:59:38.803687 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.804160 [debug] [MainThread]: On master: BEGIN
[0m23:59:38.804790 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:38.805168 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.805535 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:59:38.814441 [debug] [MainThread]: SQL status: SELECT 23 in 0.008 seconds
[0m23:59:38.817165 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:59:38.930467 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:59:38.931684 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.932202 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('cd39f1e6-9366-4e87-a963-906dc0505cbd.model.dbt_elsa.consumption','model.dbt_elsa.consumption','cd39f1e6-9366-4e87-a963-906dc0505cbd','2025-07-18 21:59:38',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.1632399559020996,'2025-07-18T21:59:37.607529Z','2025-07-18T21:59:37.763643Z','2025-07-18T21:59:37.602066Z','2025-07-18T21:59:37.606966Z',96,False,'SELECT
    id,
    created_at,
    (data->>''date'')::date AS date,
    (data->>''heure'')::time AS heure,   
    (data->>''gaz'')::int AS gaz,
    (data->>''nucleaire'')::int AS nucleaire,
    (data->>''charbon'')::int AS charbon,
    (data->>''solaire'')::int AS solaire,
    (data->>''eolien'')::int AS eolien,
    (data->>''hydraulique'')::int AS hydraulique,
    (data->>''bioenergies'')::int AS bioenergies,
    (data->>''autres'')::int AS autres,
    (data->>''prevision_j'')::int AS prevision_j,
    (data->>''prevision_j1'')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','cd39f1e6-9366-4e87-a963-906dc0505cbd','2025-07-18 21:59:38',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'pass','test',0.5072121620178223,'2025-07-18T21:59:37.835250Z','2025-07-18T21:59:38.278053Z','2025-07-18T21:59:37.789385Z','2025-07-18T21:59:37.828510Z',1,False,'
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',0,NULL,'Thread-4 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','cd39f1e6-9366-4e87-a963-906dc0505cbd','2025-07-18 21:59:38',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'pass','test',0.5247838497161865,'2025-07-18T21:59:37.848062Z','2025-07-18T21:59:38.296184Z','2025-07-18T21:59:37.800798Z','2025-07-18T21:59:37.841532Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','cd39f1e6-9366-4e87-a963-906dc0505cbd','2025-07-18 21:59:38',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'pass','test',0.5286870002746582,'2025-07-18T21:59:37.806123Z','2025-07-18T21:59:38.287299Z','2025-07-18T21:59:37.774038Z','2025-07-18T21:59:37.805568Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m23:59:38.933692 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m23:59:38.935903 [debug] [MainThread]: On master: COMMIT
[0m23:59:38.936330 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.936687 [debug] [MainThread]: On master: COMMIT
[0m23:59:38.938216 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:59:38.940777 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:59:38.942304 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025052 (1 runs)
[0m23:59:38.943263 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.015975 (1 runs)
[0m23:59:38.944006 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000684 (1 runs)
[0m23:59:38.944729 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.082627 (4 runs)
[0m23:59:38.945450 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.093071 (1 runs)
[0m23:59:38.946171 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.004135 (1 runs)
[0m23:59:38.946897 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003459 (1 runs)
[0m23:59:38.947622 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.139053 (1 runs)
[0m23:59:38.948344 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.180800 (1 runs)
[0m23:59:38.949073 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:59:38.958701 [debug] [MainThread]: Elementary: Handling test results.
[0m23:59:38.989912 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.990469 [debug] [MainThread]: On master: BEGIN
[0m23:59:38.991364 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:38.992020 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:38.992895 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:59:38.997868 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:59:39.000969 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:59:39.059712 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:59:39.060853 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:39.061452 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','cd39f1e6-9366-4e87-a963-906dc0505cbd',cast('2025-07-18 21:59:38' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]','
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_id',NULL,0),('cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','cd39f1e6-9366-4e87-a963-906dc0505cbd',cast('2025-07-18 21:59:38' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_date',NULL,0),('cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'cd39f1e6-9366-4e87-a963-906dc0505cbd.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','cd39f1e6-9366-4e87-a963-906dc0505cbd',cast('2025-07-18 21:59:38' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_created_at',NULL,0)
  
[0m23:59:39.062806 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:59:39.065057 [debug] [MainThread]: On master: COMMIT
[0m23:59:39.065441 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:39.065779 [debug] [MainThread]: On master: COMMIT
[0m23:59:39.067279 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:59:39.069129 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:59:39.085799 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:59:39.150699 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:39.151238 [debug] [MainThread]: On master: BEGIN
[0m23:59:39.152014 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:39.152429 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:39.152895 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:59:39.157060 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m23:59:39.160895 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:59:39.181468 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:59:39.182582 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:39.183116 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('cd39f1e6-9366-4e87-a963-906dc0505cbd',NULL,NULL,NULL,'2025-07-18 21:59:35','2025-07-18 21:59:39','2025-07-18 21:59:39',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:59:39.184240 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:59:39.186790 [debug] [MainThread]: On master: COMMIT
[0m23:59:39.187225 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:39.187582 [debug] [MainThread]: On master: COMMIT
[0m23:59:39.188722 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:59:39.190160 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:59:39.197432 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:59:39.199733 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:59:39.200451 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.89s]
[0m23:59:39.200897 [debug] [MainThread]: On master: Close
[0m23:59:39.201404 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:59:39.201723 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m23:59:39.202020 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m23:59:39.202308 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m23:59:39.202595 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m23:59:39.202988 [info ] [MainThread]: 
[0m23:59:39.203361 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 1.93 seconds (1.93s).
[0m23:59:39.204974 [debug] [MainThread]: Command end result
[0m23:59:39.378822 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:59:39.381136 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:59:39.387704 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:59:39.388056 [info ] [MainThread]: 
[0m23:59:39.388544 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:59:39.388945 [info ] [MainThread]: 
[0m23:59:39.389355 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:59:39.389937 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:59:39.393609 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.5363102, "process_in_blocks": "0", "process_kernel_time": 0.545254, "process_mem_max_rss": "137838592", "process_out_blocks": "0", "process_user_time": 4.359171}
[0m23:59:39.394164 [debug] [MainThread]: Command `dbt build` succeeded at 23:59:39.394028 after 3.54 seconds
[0m23:59:39.394869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e773c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e503750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e503a70>]}
[0m23:59:39.395444 [debug] [MainThread]: Flushing usage events
[0m23:59:39.833195 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:59:45.629203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b98b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0c3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0c34d0>]}


============================== 23:59:45.634174 | b34f1898-1b33-4d16-9851-33a5e8528356 ==============================
[0m23:59:45.634174 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:59:45.634826 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select silve', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:59:45.847475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b34f1898-1b33-4d16-9851-33a5e8528356', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c40c510>]}
[0m23:59:45.926655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b34f1898-1b33-4d16-9851-33a5e8528356', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf3fdf0>]}
[0m23:59:45.927615 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:59:46.056478 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:59:46.310134 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:59:46.310637 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:59:46.317985 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:59:46.458978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b34f1898-1b33-4d16-9851-33a5e8528356', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d037350>]}
[0m23:59:46.638687 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:59:46.641722 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:59:46.699410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b34f1898-1b33-4d16-9851-33a5e8528356', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de4fc50>]}
[0m23:59:46.699924 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:59:46.700837 [warn ] [MainThread]: The selection criterion 'silve' does not match any enabled nodes
[0m23:59:46.701537 [warn ] [MainThread]: The selection criterion 'silve' does not match any enabled nodes
[0m23:59:46.702150 [warn ] [MainThread]: The selection criterion 'silve' does not match any enabled nodes
[0m23:59:46.703633 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m23:59:46.706377 [debug] [MainThread]: Command end result
[0m23:59:46.791821 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:59:46.794592 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:59:46.798226 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:59:46.800679 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 1.2611213, "process_in_blocks": "0", "process_kernel_time": 0.335595, "process_mem_max_rss": "126451712", "process_out_blocks": "0", "process_user_time": 2.574794}
[0m23:59:46.801212 [debug] [MainThread]: Command `dbt build` succeeded at 23:59:46.801093 after 1.26 seconds
[0m23:59:46.801617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cfafe70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d68b3f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e40dbf0>]}
[0m23:59:46.802123 [debug] [MainThread]: Flushing usage events
[0m23:59:47.213173 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:59:50.811971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af4b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c67f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c67f4d0>]}


============================== 23:59:50.816948 | adb08787-8716-44ef-b057-31972e24a38c ==============================
[0m23:59:50.816948 [info ] [MainThread]: Running with dbt=1.10.4
[0m23:59:50.817595 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --select silver', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:59:51.032998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9cc510>]}
[0m23:59:51.113341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4ffdf0>]}
[0m23:59:51.114257 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:59:51.249806 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m23:59:51.513870 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:59:51.514329 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:59:51.522151 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m23:59:51.665575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5f7350>]}
[0m23:59:51.853992 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:59:51.857367 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:59:51.897174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4e7c50>]}
[0m23:59:51.897736 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m23:59:51.900351 [info ] [MainThread]: 
[0m23:59:51.900746 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m23:59:51.901074 [info ] [MainThread]: 
[0m23:59:51.901600 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:59:51.902528 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m23:59:51.963043 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m23:59:51.963532 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m23:59:51.963887 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:59:51.989684 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.026 seconds
[0m23:59:51.991417 [debug] [ThreadPool]: On list_elsa: Close
[0m23:59:51.998748 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m23:59:51.999379 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m23:59:52.006576 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:59:52.010154 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:59:52.010609 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m23:59:52.010939 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m23:59:52.011253 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:59:52.011555 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:59:52.017820 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m23:59:52.018226 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m23:59:52.018721 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m23:59:52.019195 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m23:59:52.019551 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m23:59:52.019892 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m23:59:52.022786 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m23:59:52.024548 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m23:59:52.024944 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m23:59:52.026757 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m23:59:52.027142 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m23:59:52.032726 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m23:59:52.044992 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.045398 [debug] [MainThread]: On master: BEGIN
[0m23:59:52.045701 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:59:52.051146 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m23:59:52.051546 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.051981 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:59:52.094943 [debug] [MainThread]: SQL status: SELECT 26 in 0.042 seconds
[0m23:59:52.102306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcf82f0>]}
[0m23:59:52.102812 [debug] [MainThread]: On master: ROLLBACK
[0m23:59:52.103345 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.103680 [debug] [MainThread]: On master: BEGIN
[0m23:59:52.104275 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:52.104712 [debug] [MainThread]: On master: COMMIT
[0m23:59:52.105038 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.105339 [debug] [MainThread]: On master: COMMIT
[0m23:59:52.105782 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:59:52.146077 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m23:59:52.209607 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.210602 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m23:59:52.212348 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m23:59:52.216776 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:59:52.224204 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:59:52.226420 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.12s]
[0m23:59:52.227282 [info ] [MainThread]: 
[0m23:59:52.228003 [debug] [MainThread]: On master: Close
[0m23:59:52.238986 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m23:59:52.239953 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze.consumption_history ........................ [RUN]
[0m23:59:52.240934 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption_history)
[0m23:59:52.241640 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m23:59:52.251513 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m23:59:52.253204 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m23:59:52.312752 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m23:59:52.313954 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.314516 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m23:59:52.314973 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:59:52.321259 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m23:59:52.321853 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.322389 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(prevision_j) AS prevision_j,
    SUM(prevision_j1) AS prevision_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at
  );
  
[0m23:59:52.327400 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m23:59:52.339560 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.340150 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."bronze"."consumption_history" rename to "consumption_history__dbt_backup"
[0m23:59:52.341079 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m23:59:52.345871 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.346331 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."bronze"."consumption_history__dbt_tmp" rename to "consumption_history"
[0m23:59:52.347294 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:59:52.374346 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.375172 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  comment on table "elsa"."bronze"."consumption_history" is $dbt_comment_literal_block$The aim of this table is to consolidate history data for consumption
$dbt_comment_literal_block$;

  
[0m23:59:52.376759 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m23:59:52.394618 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.395143 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption_history'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m23:59:52.403121 [debug] [Thread-1 (]: SQL status: SELECT 12 in 0.007 seconds
[0m23:59:52.408153 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.408809 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption_history".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  

  
[0m23:59:52.409752 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m23:59:52.411030 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m23:59:52.411469 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.411845 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m23:59:52.412752 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m23:59:52.420460 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption_history__dbt_backup"
[0m23:59:52.426320 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m23:59:52.426813 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
drop table if exists "elsa"."bronze"."consumption_history__dbt_backup" cascade
[0m23:59:52.428905 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m23:59:52.431658 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m23:59:52.434257 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df417e0>]}
[0m23:59:52.435144 [info ] [Thread-1 (]: 1 of 3 OK created sql table model bronze.consumption_history ................... [[32mSELECT 2[0m in 0.19s]
[0m23:59:52.435895 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m23:59:52.436810 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:59:52.437312 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:59:52.437789 [info ] [Thread-2 (]: 2 of 3 START test not_null_consumption_history_created_at ...................... [RUN]
[0m23:59:52.438324 [info ] [Thread-3 (]: 3 of 3 START test not_null_consumption_history_date ............................ [RUN]
[0m23:59:52.438980 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9)
[0m23:59:52.439531 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4'
[0m23:59:52.439940 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:59:52.440567 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:59:52.466764 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:59:52.467941 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:59:52.468817 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:59:52.471587 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:59:52.472115 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:59:52.472428 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9ceb10>]}
[0m23:59:52.474690 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m23:59:52.485812 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'adb08787-8716-44ef-b057-31972e24a38c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddcd020>]}
[0m23:59:52.777403 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:59:52.777899 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:59:52.778671 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:59:52.779058 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: BEGIN
[0m23:59:52.779418 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:59:52.780035 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:59:52.780529 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: BEGIN
[0m23:59:52.780906 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:59:52.785185 [debug] [Thread-2 (]: SQL status: BEGIN in 0.006 seconds
[0m23:59:52.785719 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m23:59:52.786127 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m23:59:52.786597 [debug] [Thread-3 (]: SQL status: BEGIN in 0.006 seconds
[0m23:59:52.786992 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m23:59:52.787380 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null



  
  
      
    ) dbt_internal_test
[0m23:59:52.787878 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m23:59:52.794381 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.007 seconds
[0m23:59:52.878590 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: ROLLBACK
[0m23:59:52.879487 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: ROLLBACK
[0m23:59:52.880137 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: Close
[0m23:59:52.880603 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: Close
[0m23:59:52.881236 [info ] [Thread-3 (]: 3 of 3 PASS not_null_consumption_history_date .................................. [[32mPASS[0m in 0.44s]
[0m23:59:52.881895 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m23:59:52.882556 [info ] [Thread-2 (]: 2 of 3 PASS not_null_consumption_history_created_at ............................ [[32mPASS[0m in 0.44s]
[0m23:59:52.883250 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m23:59:52.885038 [info ] [MainThread]: 
[0m23:59:52.885470 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.885793 [debug] [MainThread]: On master: BEGIN
[0m23:59:52.886094 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:59:52.892311 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:59:52.892741 [debug] [MainThread]: On master: COMMIT
[0m23:59:52.893101 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.893416 [debug] [MainThread]: On master: COMMIT
[0m23:59:52.894089 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:59:52.929886 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:52.930443 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m23:59:52.933856 [debug] [MainThread]: SQL status: SELECT 134 in 0.003 seconds
[0m23:59:52.936575 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:59:52.967739 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:59:53.023329 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:59:53.032066 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m23:59:53.033355 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m23:59:53.034615 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m23:59:53.035499 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.054419 (1 runs)
[0m23:59:53.036382 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.066835 (1 runs)
[0m23:59:53.041345 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:59:53.056457 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m23:59:53.057802 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m23:59:53.058687 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m23:59:53.060167 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m23:59:53.061141 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.013694 (1 runs)
[0m23:59:53.062013 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.018708 (1 runs)
[0m23:59:53.066767 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:59:53.087352 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m23:59:53.088767 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m23:59:53.089651 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m23:59:53.090896 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m23:59:53.091912 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019539 (1 runs)
[0m23:59:53.093261 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024045 (1 runs)
[0m23:59:53.098521 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:59:53.099980 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:59:53.101189 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m23:59:53.101989 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m23:59:53.103248 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m23:59:53.104173 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000414 (1 runs)
[0m23:59:53.105038 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.004667 (1 runs)
[0m23:59:53.110184 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:59:53.112008 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:59:53.113233 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m23:59:53.113990 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m23:59:53.115202 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m23:59:53.116077 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000731 (1 runs)
[0m23:59:53.116924 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004973 (1 runs)
[0m23:59:53.121853 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:59:53.123393 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:59:53.124812 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m23:59:53.126219 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m23:59:53.127514 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m23:59:53.128389 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000456 (1 runs)
[0m23:59:53.129221 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005596 (1 runs)
[0m23:59:53.133924 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:59:53.135523 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:59:53.136840 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m23:59:53.137651 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m23:59:53.139461 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m23:59:53.140317 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000525 (1 runs)
[0m23:59:53.141150 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005445 (1 runs)
[0m23:59:53.146209 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m23:59:53.147659 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m23:59:53.148893 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m23:59:53.149647 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m23:59:53.150833 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m23:59:53.151673 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000366 (1 runs)
[0m23:59:53.152578 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.004576 (1 runs)
[0m23:59:53.158183 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m23:59:53.354192 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 95 artifacts.
[0m23:59:53.355571 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m23:59:53.356657 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m23:59:53.357972 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m23:59:53.359114 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.194390 (1 runs)
[0m23:59:53.360168 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.199728 (1 runs)
[0m23:59:53.361076 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m23:59:53.365284 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:59:53.366308 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:59:53.393021 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m23:59:53.411050 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.411531 [debug] [MainThread]: On master: BEGIN
[0m23:59:53.412157 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:53.412526 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.412893 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:59:53.421738 [debug] [MainThread]: SQL status: SELECT 23 in 0.008 seconds
[0m23:59:53.424770 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m23:59:53.525965 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:59:53.527282 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.527804 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('adb08787-8716-44ef-b057-31972e24a38c.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','adb08787-8716-44ef-b057-31972e24a38c','2025-07-18 21:59:53',
    current_timestamp::timestamp
,'consumption_history','SELECT 2','success','model',0.1916360855102539,'2025-07-18T21:59:52.253634Z','2025-07-18T21:59:52.431491Z','2025-07-18T21:59:52.242226Z','2025-07-18T21:59:52.252912Z',2,False,'SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT
    date,
    created_at,
    SUM(gaz) AS gaz,
    SUM(nucleaire) AS nucleaire,
    SUM(charbon) AS charbon,
    SUM(solaire) AS solaire,
    SUM(eolien) AS eolien,
    SUM(hydraulique) AS hydraulique,
    SUM(bioenergies) AS bioenergies,
    SUM(autres) AS autres,
    SUM(prevision_j) AS prevision_j,
    SUM(prevision_j1) AS prevision_j1
FROM "elsa"."bronze"."consumption"
GROUP BY
    date,
    created_at',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 2", "code": "SELECT", "rows_affected": 2}',NULL),('adb08787-8716-44ef-b057-31972e24a38c.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','adb08787-8716-44ef-b057-31972e24a38c','2025-07-18 21:59:53',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'pass','test',0.44171786308288574,'2025-07-18T21:59:52.469172Z','2025-07-18T21:59:52.878393Z','2025-07-18T21:59:52.446722Z','2025-07-18T21:59:52.468636Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('adb08787-8716-44ef-b057-31972e24a38c.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','adb08787-8716-44ef-b057-31972e24a38c','2025-07-18 21:59:53',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'pass','test',0.44358301162719727,'2025-07-18T21:59:52.472705Z','2025-07-18T21:59:52.879333Z','2025-07-18T21:59:52.440936Z','2025-07-18T21:59:52.471977Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m23:59:53.529253 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m23:59:53.531430 [debug] [MainThread]: On master: COMMIT
[0m23:59:53.531852 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.532216 [debug] [MainThread]: On master: COMMIT
[0m23:59:53.533272 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:59:53.535836 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m23:59:53.536747 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025708 (1 runs)
[0m23:59:53.537566 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.016405 (1 runs)
[0m23:59:53.538375 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000678 (1 runs)
[0m23:59:53.539161 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.068011 (3 runs)
[0m23:59:53.539935 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.078264 (1 runs)
[0m23:59:53.540719 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.004017 (1 runs)
[0m23:59:53.541496 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002956 (1 runs)
[0m23:59:53.543045 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.126984 (1 runs)
[0m23:59:53.543978 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.169292 (1 runs)
[0m23:59:53.544766 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:59:53.554403 [debug] [MainThread]: Elementary: Handling test results.
[0m23:59:53.585300 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.585819 [debug] [MainThread]: On master: BEGIN
[0m23:59:53.586543 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:53.586976 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.587457 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:59:53.592120 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m23:59:53.595239 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m23:59:53.636136 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:59:53.637461 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.638099 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('adb08787-8716-44ef-b057-31972e24a38c.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'adb08787-8716-44ef-b057-31972e24a38c.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','adb08787-8716-44ef-b057-31972e24a38c',cast('2025-07-18 21:59:52' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null


',NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_history_date',NULL,0),('adb08787-8716-44ef-b057-31972e24a38c.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'adb08787-8716-44ef-b057-31972e24a38c.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','adb08787-8716-44ef-b057-31972e24a38c',cast('2025-07-18 21:59:52' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null


',NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_history_created_at',NULL,0)
  
[0m23:59:53.639580 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m23:59:53.641871 [debug] [MainThread]: On master: COMMIT
[0m23:59:53.642592 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.643062 [debug] [MainThread]: On master: COMMIT
[0m23:59:53.644760 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:59:53.646405 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m23:59:53.662736 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:59:53.731306 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.731826 [debug] [MainThread]: On master: BEGIN
[0m23:59:53.732519 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:59:53.732945 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.733421 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m23:59:53.737460 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m23:59:53.740393 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m23:59:53.761292 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:59:53.762413 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.762955 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('adb08787-8716-44ef-b057-31972e24a38c',NULL,NULL,NULL,'2025-07-18 21:59:50','2025-07-18 21:59:53','2025-07-18 21:59:53',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m23:59:53.764029 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m23:59:53.766528 [debug] [MainThread]: On master: COMMIT
[0m23:59:53.766928 [debug] [MainThread]: Using postgres connection "master"
[0m23:59:53.767283 [debug] [MainThread]: On master: COMMIT
[0m23:59:53.768616 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:59:53.770512 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:59:53.777998 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:59:53.778960 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:59:53.779465 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.88s]
[0m23:59:53.779850 [debug] [MainThread]: On master: Close
[0m23:59:53.780313 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:59:53.780608 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m23:59:53.780883 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' was properly closed.
[0m23:59:53.781284 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' was properly closed.
[0m23:59:53.781715 [info ] [MainThread]: 
[0m23:59:53.782080 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.88 seconds (1.88s).
[0m23:59:53.783459 [debug] [MainThread]: Command end result
[0m23:59:53.877580 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m23:59:53.880798 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m23:59:53.888607 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m23:59:53.889076 [info ] [MainThread]: 
[0m23:59:53.889486 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:59:53.889881 [info ] [MainThread]: 
[0m23:59:53.890279 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m23:59:53.890879 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m23:59:53.893891 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.1746614, "process_in_blocks": "0", "process_kernel_time": 0.467865, "process_mem_max_rss": "138334208", "process_out_blocks": "0", "process_user_time": 4.228205}
[0m23:59:53.894483 [debug] [MainThread]: Command `dbt build` succeeded at 23:59:53.894366 after 3.18 seconds
[0m23:59:53.894893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de120d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9c05f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc04250>]}
[0m23:59:53.895446 [debug] [MainThread]: Flushing usage events
[0m23:59:54.279248 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:30:29.407921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126e7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e23610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e234d0>]}


============================== 00:30:29.415373 | f9615342-2dfc-4a26-9516-088df06b88a7 ==============================
[0m00:30:29.415373 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:30:29.416113 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select silver', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:30:29.728716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9615342-2dfc-4a26-9516-088df06b88a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113170510>]}
[0m00:30:29.810508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9615342-2dfc-4a26-9516-088df06b88a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ca3df0>]}
[0m00:30:29.812180 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:30:29.974289 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:30:30.382313 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m00:30:30.383264 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m00:30:30.383655 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m00:30:30.913412 [error] [MainThread]: Encountered an error:
Compilation Error
  Documentation for 'model.dbt_elsa.consumption_history' depends on doc 'filiere'  which was not found
[0m00:30:30.918118 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 1.6151847, "process_in_blocks": "0", "process_kernel_time": 0.675731, "process_mem_max_rss": "125902848", "process_out_blocks": "0", "process_user_time": 3.100966}
[0m00:30:30.918809 [debug] [MainThread]: Command `dbt build` failed at 00:30:30.918663 after 1.62 seconds
[0m00:30:30.919295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150c6150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150c6250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115384140>]}
[0m00:30:30.919755 [debug] [MainThread]: Flushing usage events
[0m00:30:31.383853 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:34:03.327207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dd3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b507610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5074d0>]}


============================== 00:34:03.335809 | b38a442d-a5d6-4071-a0c2-7626af5b3372 ==============================
[0m00:34:03.335809 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:34:03.336594 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --select silver', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m00:34:03.645899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b38a442d-a5d6-4071-a0c2-7626af5b3372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a854510>]}
[0m00:34:03.727710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b38a442d-a5d6-4071-a0c2-7626af5b3372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b387df0>]}
[0m00:34:03.729141 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:34:03.893496 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:34:04.348660 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m00:34:04.349604 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/_elsa_bronze__models.yml
[0m00:34:04.350216 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/docs.md
[0m00:34:04.350592 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m00:34:04.998522 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m00:34:05.020153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b38a442d-a5d6-4071-a0c2-7626af5b3372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7ae550>]}
[0m00:34:05.199221 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:34:05.204000 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:34:05.272275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b38a442d-a5d6-4071-a0c2-7626af5b3372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca6e4e0>]}
[0m00:34:05.272841 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m00:34:05.275570 [info ] [MainThread]: 
[0m00:34:05.275976 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:34:05.276305 [info ] [MainThread]: 
[0m00:34:05.277209 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:34:05.278575 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:34:05.353439 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:34:05.353899 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:34:05.354237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:05.397136 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.043 seconds
[0m00:34:05.398749 [debug] [ThreadPool]: On list_elsa: Close
[0m00:34:05.405996 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m00:34:05.406672 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m00:34:05.415129 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:34:05.417960 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:34:05.418454 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:34:05.418857 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m00:34:05.419231 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:34:05.419603 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:05.427011 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:34:05.427668 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m00:34:05.428050 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:34:05.428397 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:34:05.428775 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m00:34:05.429151 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:34:05.434020 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m00:34:05.434459 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m00:34:05.436219 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m00:34:05.437860 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:34:05.438532 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m00:34:05.439173 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:34:05.454204 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.454644 [debug] [MainThread]: On master: BEGIN
[0m00:34:05.454961 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:34:05.460793 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:34:05.461434 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.461869 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:34:05.503442 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m00:34:05.510707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b38a442d-a5d6-4071-a0c2-7626af5b3372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc03230>]}
[0m00:34:05.511458 [debug] [MainThread]: On master: ROLLBACK
[0m00:34:05.512176 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.512540 [debug] [MainThread]: On master: BEGIN
[0m00:34:05.513170 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:05.513501 [debug] [MainThread]: On master: COMMIT
[0m00:34:05.513814 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.514112 [debug] [MainThread]: On master: COMMIT
[0m00:34:05.514534 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:34:05.557018 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:34:05.595547 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.596165 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m00:34:05.597241 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m00:34:05.600427 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:34:05.606540 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:34:05.607254 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m00:34:05.607666 [info ] [MainThread]: 
[0m00:34:05.608100 [debug] [MainThread]: On master: Close
[0m00:34:05.614345 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m00:34:05.615386 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze.consumption_history ........................ [RUN]
[0m00:34:05.616459 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption_history)
[0m00:34:05.617270 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m00:34:05.623275 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m00:34:05.624505 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m00:34:05.672288 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m00:34:05.673298 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:05.673747 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m00:34:05.674119 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:34:05.680268 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m00:34:05.680733 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:05.681127 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere;
  );
  
[0m00:34:05.682216 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 34:     unpivot.filiere;
                            ^

[0m00:34:05.682608 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m00:34:05.683290 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m00:34:05.697864 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  syntax error at or near ";"
  LINE 34:     unpivot.filiere;
                              ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:34:05.700057 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b38a442d-a5d6-4071-a0c2-7626af5b3372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0a9b20>]}
[0m00:34:05.700898 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model bronze.consumption_history ............... [[31mERROR[0m in 0.08s]
[0m00:34:05.701574 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m00:34:05.702177 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  syntax error at or near ";"
  LINE 34:     unpivot.filiere;
                              ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m00:34:05.703481 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:05.704053 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:05.704685 [info ] [Thread-2 (]: 2 of 3 SKIP test not_null_consumption_history_created_at ....................... [[33mSKIP[0m]
[0m00:34:05.705321 [info ] [Thread-3 (]: 3 of 3 SKIP test not_null_consumption_history_date ............................. [[33mSKIP[0m]
[0m00:34:05.705842 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:05.706263 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:05.706689 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' to be skipped because of status 'skipped'. 
[0m00:34:05.707131 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' to be skipped because of status 'skipped'. 
[0m00:34:05.709098 [info ] [MainThread]: 
[0m00:34:05.710229 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.711520 [debug] [MainThread]: On master: BEGIN
[0m00:34:05.712021 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:34:05.718804 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m00:34:05.719376 [debug] [MainThread]: On master: COMMIT
[0m00:34:05.720037 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.720448 [debug] [MainThread]: On master: COMMIT
[0m00:34:05.721031 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:34:05.763003 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.763518 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m00:34:05.770275 [debug] [MainThread]: SQL status: SELECT 134 in 0.006 seconds
[0m00:34:05.773353 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:34:05.804102 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m00:34:05.890404 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m00:34:05.898645 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m00:34:05.899643 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m00:34:05.909744 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m00:34:05.937838 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.938326 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718223405921969003405930664"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m00:34:05.942646 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m00:34:05.965681 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.966128 [debug] [MainThread]: On master: BEGIN
[0m00:34:05.966768 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:05.967172 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:05.967550 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718223405921969003405930664'
        
      order by ordinal_position

  
[0m00:34:05.978426 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m00:34:05.982976 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718223405921969003405930664"
[0m00:34:06.029006 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:06.030153 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.030549 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718223405921969003405930664"
         (metadata_hash) values
    ('7486413f222e8693a1475cac07ff2121')
  
[0m00:34:06.031490 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m00:34:06.035510 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.035936 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718223406034222003406034492"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m00:34:06.038003 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:34:06.042943 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.043384 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718223406034222003406034492'
        
      order by ordinal_position

  
[0m00:34:06.047224 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m00:34:06.050243 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718223406034222003406034492"
[0m00:34:06.060832 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:06.062176 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.062660 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718223406034222003406034492"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption_history','consumption_history','47b48aacd5bafc947751a951375651d4fcc5d4e494c0ba6111b295c252456b7e','table','[]','{}','[]','elsa','bronze','[]','[]','The aim of this table is to consolidate history data for consumption
','consumption_history','dbt_elsa','models/silver/consumption_history.sql','silver/consumption_history.sql','dbt_elsa://models/silver/_elsa_bronze__models.yml','2025-07-18 22:34:05','774b36f31f126fa34c24fc3bf145ef57',NULL,NULL,NULL,'protected')
  
[0m00:34:06.063571 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m00:34:06.071926 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.072409 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718223405921969003405930664");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718223406034222003406034492";
        
        commit;
    
  
[0m00:34:06.074504 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m00:34:06.083675 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718223405921969003405930664"
[0m00:34:06.088457 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.088919 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718223405921969003405930664" cascade
[0m00:34:06.090999 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m00:34:06.095669 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718223406034222003406034492"
[0m00:34:06.096385 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.096795 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718223406034222003406034492" cascade
[0m00:34:06.098373 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:34:06.099718 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m00:34:06.101356 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m00:34:06.102298 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.085039 (1 runs)
[0m00:34:06.103209 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.033316 (2 runs)
[0m00:34:06.104271 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000958 (2 runs)
[0m00:34:06.105305 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.030583 (2 runs)
[0m00:34:06.106314 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.039750 (2 runs)
[0m00:34:06.107218 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.006843 (2 runs)
[0m00:34:06.108446 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.100875 (2 runs)
[0m00:34:06.109421 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.297129 (1 runs)
[0m00:34:06.115014 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m00:34:06.242874 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m00:34:06.244642 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m00:34:06.245649 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m00:34:06.247291 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m00:34:06.248295 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.126765 (1 runs)
[0m00:34:06.249168 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.131835 (1 runs)
[0m00:34:06.254336 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m00:34:06.275446 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m00:34:06.277148 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m00:34:06.278289 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m00:34:06.280000 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m00:34:06.281081 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019909 (1 runs)
[0m00:34:06.281977 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.025515 (1 runs)
[0m00:34:06.286863 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m00:34:06.288593 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m00:34:06.290004 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m00:34:06.290775 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m00:34:06.292299 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m00:34:06.293147 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000445 (1 runs)
[0m00:34:06.294009 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005375 (1 runs)
[0m00:34:06.299289 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m00:34:06.300807 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m00:34:06.302141 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m00:34:06.302921 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m00:34:06.304279 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m00:34:06.305326 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000367 (1 runs)
[0m00:34:06.306528 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004826 (1 runs)
[0m00:34:06.311370 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m00:34:06.313041 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m00:34:06.314348 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m00:34:06.315108 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m00:34:06.316387 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m00:34:06.317260 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000364 (1 runs)
[0m00:34:06.318106 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004954 (1 runs)
[0m00:34:06.323716 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m00:34:06.325221 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m00:34:06.326448 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m00:34:06.327252 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m00:34:06.328949 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m00:34:06.329975 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000410 (1 runs)
[0m00:34:06.330854 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005136 (1 runs)
[0m00:34:06.335761 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m00:34:06.337691 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m00:34:06.339087 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m00:34:06.339861 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m00:34:06.341093 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m00:34:06.341958 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000838 (1 runs)
[0m00:34:06.342801 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005244 (1 runs)
[0m00:34:06.348238 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m00:34:06.519907 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 87 artifacts.
[0m00:34:06.521927 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m00:34:06.523052 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts changed.
[0m00:34:06.527047 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m00:34:06.530326 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.530809 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718223406528770003406529099"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m00:34:06.533103 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:34:06.538123 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.538657 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718223406528770003406529099'
        
      order by ordinal_position

  
[0m00:34:06.541381 [debug] [MainThread]: SQL status: SELECT 1 in 0.002 seconds
[0m00:34:06.544407 [debug] [MainThread]: Elementary: Inserting 10 rows to table "dbt_columns__tmp_20250718223406528770003406529099"
[0m00:34:06.558196 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:06.559387 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.559817 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718223406528770003406529099"
         (metadata_hash) values
    ('0ff60f0dfb1b01f26b525a30de9a3275'),('31439eece050a791bf6d02222e47bdb2'),('5b7524fa6e1aa4c403bbe3be67a42363'),('6f60579d0e68fda24fcb14b4dd4622e2'),('700f6d919e8be314d8f2666779c8b7c6'),('ab8508f49e9fc1376e3acb4068306645'),('bbe58f35ab87a908d3ae6b88128b4125'),('bd0716acb1a1ebf8ba62155b11bb960a'),('c27e8c2253456f22ba08c02069ab5ba6'),('e907861df8ca52274144c88c697b299f')
  
[0m00:34:06.561050 [debug] [MainThread]: SQL status: INSERT 0 10 in 0.001 seconds
[0m00:34:06.565454 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.565909 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718223406564227003406564475"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m00:34:06.568023 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:34:06.573279 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.573790 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718223406564227003406564475'
        
      order by ordinal_position

  
[0m00:34:06.577311 [debug] [MainThread]: SQL status: SELECT 13 in 0.003 seconds
[0m00:34:06.580086 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_columns__tmp_20250718223406564227003406564475"
[0m00:34:06.592797 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:06.594534 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.595206 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718223406564227003406564475"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.dbt_elsa.consumption_history.filiere','model.dbt_elsa.consumption_history','filiere','text','[]','{}','elsa','bronze','consumption_history','filiere','model','2025-07-18 22:34:06','642a41c8141e4fbebd3e29d13641c01a'),('column.model.dbt_elsa.consumption_history.volume','model.dbt_elsa.consumption_history','volume','integer','[]','{}','elsa','bronze','consumption_history','volume','model','2025-07-18 22:34:06','5de2266142800ba55cb18fd1db535ecf')
  
[0m00:34:06.596305 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m00:34:06.599154 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.599609 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_columns"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_columns__tmp_20250718223406528770003406529099");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250718223406564227003406564475";
        
        commit;
    
  
[0m00:34:06.600943 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:34:06.605479 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718223406528770003406529099"
[0m00:34:06.606177 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.606566 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718223406528770003406529099" cascade
[0m00:34:06.608037 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:34:06.611874 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718223406564227003406564475"
[0m00:34:06.612848 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.613251 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718223406564227003406564475" cascade
[0m00:34:06.614846 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:34:06.616279 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m00:34:06.617922 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m00:34:06.619082 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.170372 (1 runs)
[0m00:34:06.620076 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.017974 (2 runs)
[0m00:34:06.620999 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000910 (2 runs)
[0m00:34:06.621890 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.017897 (12 runs)
[0m00:34:06.622776 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.023646 (2 runs)
[0m00:34:06.623663 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.008685 (2 runs)
[0m00:34:06.624553 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.057340 (2 runs)
[0m00:34:06.625439 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.269467 (1 runs)
[0m00:34:06.626342 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:34:06.630913 [debug] [MainThread]: Elementary: Uploading run results.
[0m00:34:06.631946 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m00:34:06.661224 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m00:34:06.665571 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.666059 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:34:06.670255 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m00:34:06.673278 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m00:34:06.728536 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:06.729994 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.730479 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('b38a442d-a5d6-4071-a0c2-7626af5b3372.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','b38a442d-a5d6-4071-a0c2-7626af5b3372','2025-07-18 22:34:06',
    current_timestamp::timestamp
,'consumption_history','Database Error in model consumption_history (models/silver/consumption_history.sql)
  syntax error at or near ";"
  LINE 34:     unpivot.filiere;
                              ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql','error','model',0.0821073055267334,'2025-07-18T22:34:05.624814Z','2025-07-18T22:34:05.683093Z','2025-07-18T22:34:05.617756Z','2025-07-18T22:34:05.624328Z',NULL,False,'SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    (''gaz'', consumption.gaz),
    (''nucleaire'', consumption.nucleaire),
    (''charbon'', consumption.charbon),
    (''solaire'', consumption.solaire),
    (''eolien'', consumption.eolien),
    (''hydraulique'', consumption.hydraulique),
    (''bioenergies'', consumption.bioenergies),
    (''autres'', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere;',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('b38a442d-a5d6-4071-a0c2-7626af5b3372.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','b38a442d-a5d6-4071-a0c2-7626af5b3372','2025-07-18 22:34:06',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)','test','{}',NULL),('b38a442d-a5d6-4071-a0c2-7626af5b3372.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','b38a442d-a5d6-4071-a0c2-7626af5b3372','2025-07-18 22:34:06',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-3 (worker)','test','{}',NULL)
  
[0m00:34:06.733550 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.003 seconds
[0m00:34:06.735855 [debug] [MainThread]: On master: COMMIT
[0m00:34:06.736303 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.736676 [debug] [MainThread]: On master: COMMIT
[0m00:34:06.737341 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:34:06.740323 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m00:34:06.741111 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.027957 (1 runs)
[0m00:34:06.741826 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.010233 (1 runs)
[0m00:34:06.742538 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000654 (1 runs)
[0m00:34:06.743246 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.050524 (3 runs)
[0m00:34:06.744188 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.053696 (1 runs)
[0m00:34:06.745446 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005773 (1 runs)
[0m00:34:06.746307 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002627 (1 runs)
[0m00:34:06.747042 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.076803 (1 runs)
[0m00:34:06.747847 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.108166 (1 runs)
[0m00:34:06.748576 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m00:34:06.758641 [debug] [MainThread]: Elementary: Handling test results.
[0m00:34:06.814927 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.815450 [debug] [MainThread]: On master: BEGIN
[0m00:34:06.816135 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:06.816556 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.817028 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:34:06.821772 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m00:34:06.824841 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m00:34:06.952181 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:06.953343 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.953948 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('b38a442d-a5d6-4071-a0c2-7626af5b3372.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'b38a442d-a5d6-4071-a0c2-7626af5b3372.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','b38a442d-a5d6-4071-a0c2-7626af5b3372',cast('2025-07-18 22:34:06' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_created_at',NULL,NULL),('b38a442d-a5d6-4071-a0c2-7626af5b3372.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'b38a442d-a5d6-4071-a0c2-7626af5b3372.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','b38a442d-a5d6-4071-a0c2-7626af5b3372',cast('2025-07-18 22:34:06' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','date','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_date',NULL,NULL)
  
[0m00:34:06.955993 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m00:34:06.958503 [debug] [MainThread]: On master: COMMIT
[0m00:34:06.958923 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:06.959300 [debug] [MainThread]: On master: COMMIT
[0m00:34:06.960164 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:34:06.962075 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:34:06.978759 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m00:34:07.045416 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:07.045925 [debug] [MainThread]: On master: BEGIN
[0m00:34:07.046524 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:07.046937 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:07.047409 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:34:07.051653 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m00:34:07.054823 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m00:34:07.076299 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:07.077958 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:07.078558 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('b38a442d-a5d6-4071-a0c2-7626af5b3372',NULL,NULL,NULL,'2025-07-18 22:34:03','2025-07-18 22:34:06','2025-07-18 22:34:06',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m00:34:07.079573 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m00:34:07.082132 [debug] [MainThread]: On master: COMMIT
[0m00:34:07.082539 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:07.082901 [debug] [MainThread]: On master: COMMIT
[0m00:34:07.084235 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:34:07.086782 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m00:34:07.094800 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:34:07.096538 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:34:07.097146 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.38s]
[0m00:34:07.097620 [debug] [MainThread]: On master: Close
[0m00:34:07.098119 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:34:07.098425 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m00:34:07.098709 [debug] [MainThread]: Connection 'list_elsa_bronze_tec_elsa' was properly closed.
[0m00:34:07.099093 [info ] [MainThread]: 
[0m00:34:07.099481 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.82 seconds (1.82s).
[0m00:34:07.100886 [debug] [MainThread]: Command end result
[0m00:34:07.319831 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:34:07.323308 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:34:07.330902 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:34:07.331275 [info ] [MainThread]: 
[0m00:34:07.331650 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m00:34:07.331992 [info ] [MainThread]: 
[0m00:34:07.332562 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m00:34:07.333036 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  syntax error at or near ";"
  LINE 34:     unpivot.filiere;
                              ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:34:07.333549 [info ] [MainThread]: 
[0m00:34:07.334194 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m00:34:07.334567 [info ] [MainThread]: 
[0m00:34:07.334942 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=5
[0m00:34:07.338923 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 4.134028, "process_in_blocks": "0", "process_kernel_time": 0.841068, "process_mem_max_rss": "143859712", "process_out_blocks": "0", "process_user_time": 5.073289}
[0m00:34:07.339540 [debug] [MainThread]: Command `dbt build` failed at 00:34:07.339395 after 4.13 seconds
[0m00:34:07.339986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2f6c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2b7b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2b7cd0>]}
[0m00:34:07.340409 [debug] [MainThread]: Flushing usage events
[0m00:34:07.829668 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:34:34.034286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11127b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129af610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129af4d0>]}


============================== 00:34:34.041623 | 27428173-802b-4a4f-97cb-c2f6dc5448ff ==============================
[0m00:34:34.041623 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:34:34.042324 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build --select silver', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m00:34:34.301149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '27428173-802b-4a4f-97cb-c2f6dc5448ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cfc510>]}
[0m00:34:34.388898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '27428173-802b-4a4f-97cb-c2f6dc5448ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11282fdf0>]}
[0m00:34:34.390973 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:34:34.546076 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:34:35.007060 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m00:34:35.007910 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m00:34:35.625054 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m00:34:35.643608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27428173-802b-4a4f-97cb-c2f6dc5448ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c52750>]}
[0m00:34:35.820634 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:34:35.824224 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:34:35.878008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '27428173-802b-4a4f-97cb-c2f6dc5448ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11415e6c0>]}
[0m00:34:35.878659 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m00:34:35.881366 [info ] [MainThread]: 
[0m00:34:35.881767 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:34:35.882094 [info ] [MainThread]: 
[0m00:34:35.882658 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:34:35.883470 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:34:35.948391 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:34:35.948827 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:34:35.949296 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:35.986168 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.037 seconds
[0m00:34:35.987772 [debug] [ThreadPool]: On list_elsa: Close
[0m00:34:35.994887 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m00:34:35.995538 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m00:34:36.002686 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:34:36.005731 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:34:36.006224 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m00:34:36.006545 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:34:36.006853 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:34:36.007160 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:36.013611 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m00:34:36.014043 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:34:36.014352 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:34:36.014689 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:34:36.015059 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:34:36.015437 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m00:34:36.020281 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m00:34:36.020717 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m00:34:36.022432 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m00:34:36.023709 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:34:36.024213 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m00:34:36.024563 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:34:36.038171 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.038628 [debug] [MainThread]: On master: BEGIN
[0m00:34:36.038952 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:34:36.044346 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m00:34:36.044869 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.045385 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:34:36.091425 [debug] [MainThread]: SQL status: SELECT 26 in 0.046 seconds
[0m00:34:36.098883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27428173-802b-4a4f-97cb-c2f6dc5448ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140aa190>]}
[0m00:34:36.099405 [debug] [MainThread]: On master: ROLLBACK
[0m00:34:36.100063 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.100419 [debug] [MainThread]: On master: BEGIN
[0m00:34:36.101098 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:36.101430 [debug] [MainThread]: On master: COMMIT
[0m00:34:36.101747 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.102047 [debug] [MainThread]: On master: COMMIT
[0m00:34:36.102545 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:34:36.141953 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:34:36.183288 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.183957 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m00:34:36.185031 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m00:34:36.188327 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:34:36.192641 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:34:36.193238 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m00:34:36.193757 [info ] [MainThread]: 
[0m00:34:36.194413 [debug] [MainThread]: On master: Close
[0m00:34:36.199080 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m00:34:36.199780 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze.consumption_history ........................ [RUN]
[0m00:34:36.200455 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption_history)
[0m00:34:36.200914 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m00:34:36.204982 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m00:34:36.206173 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m00:34:36.252437 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m00:34:36.253326 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.253730 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m00:34:36.254086 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:34:36.259480 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m00:34:36.259956 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.260357 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m00:34:36.267003 [debug] [Thread-1 (]: SQL status: SELECT 16 in 0.006 seconds
[0m00:34:36.279158 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.279652 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."bronze"."consumption_history" rename to "consumption_history__dbt_backup"
[0m00:34:36.280450 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m00:34:36.284511 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.285015 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."bronze"."consumption_history__dbt_tmp" rename to "consumption_history"
[0m00:34:36.286212 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:34:36.313120 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.313651 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  comment on table "elsa"."bronze"."consumption_history" is $dbt_comment_literal_block$The aim of this table is to consolidate history data for consumption
$dbt_comment_literal_block$;

  
[0m00:34:36.314598 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m00:34:36.328177 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.328991 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption_history'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m00:34:36.336779 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.007 seconds
[0m00:34:36.341949 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.342466 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption_history".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".filiere is $dbt_comment_literal_block$filiere$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption_history".volume is $dbt_comment_literal_block$volume$dbt_comment_literal_block$;
  

  
[0m00:34:36.343251 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m00:34:36.345276 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m00:34:36.345769 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.346149 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m00:34:36.347412 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m00:34:36.355743 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption_history__dbt_backup"
[0m00:34:36.361275 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:34:36.361958 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
drop table if exists "elsa"."bronze"."consumption_history__dbt_backup" cascade
[0m00:34:36.364470 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m00:34:36.367190 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m00:34:36.369264 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27428173-802b-4a4f-97cb-c2f6dc5448ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145d94a0>]}
[0m00:34:36.370097 [info ] [Thread-1 (]: 1 of 3 OK created sql table model bronze.consumption_history ................... [[32mSELECT 16[0m in 0.17s]
[0m00:34:36.370892 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m00:34:36.371954 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:36.372576 [info ] [Thread-2 (]: 2 of 3 START test not_null_consumption_history_created_at ...................... [RUN]
[0m00:34:36.373032 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:36.373476 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9)
[0m00:34:36.373887 [info ] [Thread-3 (]: 3 of 3 START test not_null_consumption_history_date ............................ [RUN]
[0m00:34:36.374415 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:36.374949 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4'
[0m00:34:36.391249 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:34:36.391704 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:36.397147 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:34:36.397842 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:36.400623 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:34:36.401135 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '27428173-802b-4a4f-97cb-c2f6dc5448ff', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f79910>]}
[0m00:34:36.413121 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:36.706404 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:34:36.705099 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:34:36.707445 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:34:36.707850 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: BEGIN
[0m00:34:36.708213 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:34:36.708775 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:34:36.709182 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: BEGIN
[0m00:34:36.709575 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:34:36.714543 [debug] [Thread-2 (]: SQL status: BEGIN in 0.006 seconds
[0m00:34:36.715103 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:34:36.715526 [debug] [Thread-3 (]: SQL status: BEGIN in 0.006 seconds
[0m00:34:36.715910 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m00:34:36.716332 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:34:36.716800 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null



  
  
      
    ) dbt_internal_test
[0m00:34:36.717947 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m00:34:36.718419 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.001 seconds
[0m00:34:36.824531 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: ROLLBACK
[0m00:34:36.827457 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: ROLLBACK
[0m00:34:36.827975 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: Close
[0m00:34:36.828887 [info ] [Thread-2 (]: 2 of 3 PASS not_null_consumption_history_created_at ............................ [[32mPASS[0m in 0.46s]
[0m00:34:36.829406 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: Close
[0m00:34:36.829996 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:36.830808 [info ] [Thread-3 (]: 3 of 3 PASS not_null_consumption_history_date .................................. [[32mPASS[0m in 0.46s]
[0m00:34:36.831440 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:36.833191 [info ] [MainThread]: 
[0m00:34:36.833636 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.833958 [debug] [MainThread]: On master: BEGIN
[0m00:34:36.834256 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:34:36.840553 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:34:36.840962 [debug] [MainThread]: On master: COMMIT
[0m00:34:36.841280 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.841585 [debug] [MainThread]: On master: COMMIT
[0m00:34:36.842076 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:34:36.876546 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:36.877046 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m00:34:36.882181 [debug] [MainThread]: SQL status: SELECT 126 in 0.005 seconds
[0m00:34:36.884922 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:34:36.916888 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m00:34:36.969819 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m00:34:36.977783 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m00:34:36.979333 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m00:34:36.988962 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m00:34:37.017510 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.017987 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718223437000702003437009306"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m00:34:37.021535 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m00:34:37.039332 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.039797 [debug] [MainThread]: On master: BEGIN
[0m00:34:37.040399 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:37.040800 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.041192 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718223437000702003437009306'
        
      order by ordinal_position

  
[0m00:34:37.048652 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m00:34:37.050950 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718223437000702003437009306"
[0m00:34:37.092237 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:37.093406 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.093809 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718223437000702003437009306"
         (metadata_hash) values
    ('774b36f31f126fa34c24fc3bf145ef57')
  
[0m00:34:37.094748 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m00:34:37.099142 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.099586 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718223437097866003437098135"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m00:34:37.101697 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:34:37.106520 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.106999 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718223437097866003437098135'
        
      order by ordinal_position

  
[0m00:34:37.110806 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m00:34:37.113497 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718223437097866003437098135"
[0m00:34:37.124467 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:37.125578 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.126020 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718223437097866003437098135"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption_history','consumption_history','ededa83e3a9b60961e0c6f15a05939372e9e0ea821c459c89b556e53735e7ff2','table','[]','{}','[]','elsa','bronze','[]','[]','The aim of this table is to consolidate history data for consumption
','consumption_history','dbt_elsa','models/silver/consumption_history.sql','silver/consumption_history.sql','dbt_elsa://models/silver/_elsa_bronze__models.yml','2025-07-18 22:34:36','aa141a21362d2c0ddeff68a69467ac16',NULL,NULL,NULL,'protected')
  
[0m00:34:37.127122 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m00:34:37.135420 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.135982 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718223437000702003437009306");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718223437097866003437098135";
        
        commit;
    
  
[0m00:34:37.138051 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m00:34:37.142355 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718223437000702003437009306"
[0m00:34:37.143022 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.143409 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718223437000702003437009306" cascade
[0m00:34:37.145997 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m00:34:37.149816 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718223437097866003437098135"
[0m00:34:37.150651 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.151108 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718223437097866003437098135" cascade
[0m00:34:37.152507 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:34:37.153933 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m00:34:37.155549 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m00:34:37.156548 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.051799 (1 runs)
[0m00:34:37.157492 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.023509 (2 runs)
[0m00:34:37.158358 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000857 (2 runs)
[0m00:34:37.159245 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.026502 (2 runs)
[0m00:34:37.160112 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.035212 (2 runs)
[0m00:34:37.161531 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.007243 (2 runs)
[0m00:34:37.162634 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.086818 (2 runs)
[0m00:34:37.163512 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.238462 (1 runs)
[0m00:34:37.168929 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m00:34:37.186646 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m00:34:37.188411 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m00:34:37.189244 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m00:34:37.190455 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m00:34:37.191309 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.016622 (1 runs)
[0m00:34:37.192156 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.021468 (1 runs)
[0m00:34:37.197502 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m00:34:37.219105 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m00:34:37.220472 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m00:34:37.221311 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m00:34:37.222541 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m00:34:37.223419 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020472 (1 runs)
[0m00:34:37.224272 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024984 (1 runs)
[0m00:34:37.229434 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m00:34:37.230965 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m00:34:37.232599 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m00:34:37.233416 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m00:34:37.234722 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m00:34:37.235655 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000423 (1 runs)
[0m00:34:37.236534 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005222 (1 runs)
[0m00:34:37.241587 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m00:34:37.243046 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m00:34:37.244675 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m00:34:37.245552 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m00:34:37.247357 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m00:34:37.248316 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000365 (1 runs)
[0m00:34:37.249195 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005684 (1 runs)
[0m00:34:37.254130 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m00:34:37.255590 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m00:34:37.256892 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m00:34:37.257720 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m00:34:37.258985 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m00:34:37.260542 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000365 (1 runs)
[0m00:34:37.261940 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004774 (1 runs)
[0m00:34:37.267141 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m00:34:37.268662 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m00:34:37.270033 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m00:34:37.271112 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m00:34:37.272560 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m00:34:37.273637 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000420 (1 runs)
[0m00:34:37.274622 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.005327 (1 runs)
[0m00:34:37.281295 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m00:34:37.283044 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m00:34:37.284802 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m00:34:37.286372 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m00:34:37.288083 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m00:34:37.289400 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000368 (1 runs)
[0m00:34:37.290355 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.006683 (1 runs)
[0m00:34:37.295837 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m00:34:37.469207 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 87 artifacts.
[0m00:34:37.470564 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m00:34:37.471730 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m00:34:37.473036 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m00:34:37.473915 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.171547 (1 runs)
[0m00:34:37.474763 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.177148 (1 runs)
[0m00:34:37.475632 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:34:37.480039 [debug] [MainThread]: Elementary: Uploading run results.
[0m00:34:37.481030 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m00:34:37.506795 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m00:34:37.510551 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.511148 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:34:37.515452 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m00:34:37.518123 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m00:34:37.570756 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:37.572147 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.572671 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('27428173-802b-4a4f-97cb-c2f6dc5448ff.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','27428173-802b-4a4f-97cb-c2f6dc5448ff','2025-07-18 22:34:37',
    current_timestamp::timestamp
,'consumption_history','SELECT 16','success','model',0.1674051284790039,'2025-07-18T22:34:36.206936Z','2025-07-18T22:34:36.367036Z','2025-07-18T22:34:36.201188Z','2025-07-18T22:34:36.205898Z',16,False,'SELECT *
FROM "elsa"."bronze"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    (''gaz'', consumption.gaz),
    (''nucleaire'', consumption.nucleaire),
    (''charbon'', consumption.charbon),
    (''solaire'', consumption.solaire),
    (''eolien'', consumption.eolien),
    (''hydraulique'', consumption.hydraulique),
    (''bioenergies'', consumption.bioenergies),
    (''autres'', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 16", "code": "SELECT", "rows_affected": 16}',NULL),('27428173-802b-4a4f-97cb-c2f6dc5448ff.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','27428173-802b-4a4f-97cb-c2f6dc5448ff','2025-07-18 22:34:37',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'pass','test',0.45533299446105957,'2025-07-18T22:34:36.398239Z','2025-07-18T22:34:36.824338Z','2025-07-18T22:34:36.375228Z','2025-07-18T22:34:36.397677Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('27428173-802b-4a4f-97cb-c2f6dc5448ff.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','27428173-802b-4a4f-97cb-c2f6dc5448ff','2025-07-18 22:34:37',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'pass','test',0.45590806007385254,'2025-07-18T22:34:36.419706Z','2025-07-18T22:34:36.827253Z','2025-07-18T22:34:36.392090Z','2025-07-18T22:34:36.412915Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m00:34:37.575663 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.002 seconds
[0m00:34:37.578582 [debug] [MainThread]: On master: COMMIT
[0m00:34:37.579222 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.579672 [debug] [MainThread]: On master: COMMIT
[0m00:34:37.580381 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:34:37.583041 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m00:34:37.584306 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.024745 (1 runs)
[0m00:34:37.585086 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.009796 (1 runs)
[0m00:34:37.585915 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000674 (1 runs)
[0m00:34:37.586699 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.048013 (3 runs)
[0m00:34:37.587477 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.051048 (1 runs)
[0m00:34:37.588301 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.006215 (1 runs)
[0m00:34:37.589149 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.003037 (1 runs)
[0m00:34:37.589932 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.074158 (1 runs)
[0m00:34:37.590713 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.101766 (1 runs)
[0m00:34:37.591826 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m00:34:37.602132 [debug] [MainThread]: Elementary: Handling test results.
[0m00:34:37.633061 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.633619 [debug] [MainThread]: On master: BEGIN
[0m00:34:37.634342 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:37.634766 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.635246 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:34:37.639946 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m00:34:37.643029 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m00:34:37.779309 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:37.780722 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.781449 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('27428173-802b-4a4f-97cb-c2f6dc5448ff.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'27428173-802b-4a4f-97cb-c2f6dc5448ff.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','27428173-802b-4a4f-97cb-c2f6dc5448ff',cast('2025-07-18 22:34:36' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption_history"
where created_at is null


',NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_history_created_at',NULL,0),('27428173-802b-4a4f-97cb-c2f6dc5448ff.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'27428173-802b-4a4f-97cb-c2f6dc5448ff.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','27428173-802b-4a4f-97cb-c2f6dc5448ff',cast('2025-07-18 22:34:36' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption_history','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption_history"
where date is null


',NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_history_date',NULL,0)
  
[0m00:34:37.784160 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.002 seconds
[0m00:34:37.787079 [debug] [MainThread]: On master: COMMIT
[0m00:34:37.787613 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.788050 [debug] [MainThread]: On master: COMMIT
[0m00:34:37.789118 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:34:37.791024 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:34:37.808760 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m00:34:37.880685 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.881396 [debug] [MainThread]: On master: BEGIN
[0m00:34:37.882249 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:34:37.882707 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:37.883182 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:34:37.887316 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m00:34:37.890142 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m00:34:38.008712 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:34:38.010471 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:38.011302 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('27428173-802b-4a4f-97cb-c2f6dc5448ff',NULL,NULL,NULL,'2025-07-18 22:34:34','2025-07-18 22:34:37','2025-07-18 22:34:37',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m00:34:38.012481 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m00:34:38.015278 [debug] [MainThread]: On master: COMMIT
[0m00:34:38.015749 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:38.016558 [debug] [MainThread]: On master: COMMIT
[0m00:34:38.018155 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:34:38.020134 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m00:34:38.026715 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:34:38.027817 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:34:38.028785 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.19s]
[0m00:34:38.029319 [debug] [MainThread]: On master: Close
[0m00:34:38.029809 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:34:38.030117 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m00:34:38.030408 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' was properly closed.
[0m00:34:38.030689 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' was properly closed.
[0m00:34:38.031058 [info ] [MainThread]: 
[0m00:34:38.031409 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 2.15 seconds (2.15s).
[0m00:34:38.032909 [debug] [MainThread]: Command end result
[0m00:34:38.144977 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:34:38.148009 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:34:38.154865 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:34:38.155292 [info ] [MainThread]: 
[0m00:34:38.155729 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:34:38.156085 [info ] [MainThread]: 
[0m00:34:38.156454 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m00:34:38.157025 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m00:34:38.160617 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 4.225176, "process_in_blocks": "0", "process_kernel_time": 0.664921, "process_mem_max_rss": "142970880", "process_out_blocks": "0", "process_user_time": 5.182868}
[0m00:34:38.162346 [debug] [MainThread]: Command `dbt build` succeeded at 00:34:38.161882 after 4.23 seconds
[0m00:34:38.162906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114633e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ea1130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ea3d90>]}
[0m00:34:38.163367 [debug] [MainThread]: Flushing usage events
[0m00:34:38.549937 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:34:48.236365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10717f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b34d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b3750>]}


============================== 00:34:48.258448 | 731946fb-b8ce-4af2-86fc-6e56082497b3 ==============================
[0m00:34:48.258448 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:34:48.261815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m00:34:48.503050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '731946fb-b8ce-4af2-86fc-6e56082497b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c00510>]}
[0m00:34:48.580981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '731946fb-b8ce-4af2-86fc-6e56082497b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108733df0>]}
[0m00:34:48.581928 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:34:48.718185 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:34:48.975835 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:34:48.976284 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:34:48.984358 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_elsa.gold
[0m00:34:49.130290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '731946fb-b8ce-4af2-86fc-6e56082497b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108827350>]}
[0m00:34:49.158350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '731946fb-b8ce-4af2-86fc-6e56082497b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109822e40>]}
[0m00:34:49.158971 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m00:34:49.159405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '731946fb-b8ce-4af2-86fc-6e56082497b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089aaeb0>]}
[0m00:34:49.163980 [info ] [MainThread]: 
[0m00:34:49.164838 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:34:49.165476 [info ] [MainThread]: 
[0m00:34:49.166477 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:34:49.177548 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m00:34:49.189296 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_tec_elsa'
[0m00:34:49.249369 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:34:49.249861 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:34:49.250196 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m00:34:49.250532 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:34:49.250853 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:49.251216 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:49.278200 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m00:34:49.278693 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m00:34:49.279039 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:34:49.279392 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:34:49.279765 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m00:34:49.280169 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:34:49.284733 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.004 seconds
[0m00:34:49.287322 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m00:34:49.287790 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.007 seconds
[0m00:34:49.289704 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:34:49.290216 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m00:34:49.296048 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:34:49.306675 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:49.307180 [debug] [MainThread]: On master: BEGIN
[0m00:34:49.307510 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:34:49.314042 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:34:49.314550 [debug] [MainThread]: Using postgres connection "master"
[0m00:34:49.314986 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:34:49.356665 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m00:34:49.364988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '731946fb-b8ce-4af2-86fc-6e56082497b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10955f040>]}
[0m00:34:49.365496 [debug] [MainThread]: On master: ROLLBACK
[0m00:34:49.366092 [debug] [MainThread]: On master: Close
[0m00:34:49.371102 [debug] [Thread-14 ]: Began running node model.elementary.dbt_sources
[0m00:34:49.371651 [debug] [Thread-3 (]: Began running node model.elementary.data_monitoring_metrics
[0m00:34:49.372057 [debug] [Thread-4 (]: Began running node model.elementary.dbt_columns
[0m00:34:49.372499 [debug] [Thread-5 (]: Began running node model.elementary.dbt_exposures
[0m00:34:49.372897 [debug] [Thread-7 (]: Began running node model.elementary.dbt_invocations
[0m00:34:49.373318 [debug] [Thread-8 (]: Began running node model.elementary.dbt_metrics
[0m00:34:49.373711 [debug] [Thread-9 (]: Began running node model.elementary.dbt_models
[0m00:34:49.374143 [debug] [Thread-10 ]: Began running node model.elementary.dbt_run_results
[0m00:34:49.374519 [debug] [Thread-11 ]: Began running node model.elementary.dbt_seeds
[0m00:34:49.374881 [debug] [Thread-12 ]: Began running node model.elementary.dbt_snapshots
[0m00:34:49.375256 [debug] [Thread-6 (]: Began running node model.elementary.dbt_groups
[0m00:34:49.375614 [debug] [Thread-2 (]: Began running node model.dbt_elsa.consumption_history
[0m00:34:49.375970 [debug] [Thread-15 ]: Began running node model.elementary.dbt_tests
[0m00:34:49.376334 [debug] [Thread-13 ]: Began running node model.elementary.dbt_source_freshness_results
[0m00:34:49.376716 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m00:34:49.377103 [debug] [Thread-16 ]: Began running node model.elementary.elementary_test_results
[0m00:34:49.377779 [debug] [Thread-14 ]: Acquiring new postgres connection 'model.elementary.dbt_sources'
[0m00:34:49.378549 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.elementary.data_monitoring_metrics'
[0m00:34:49.379119 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.elementary.dbt_columns'
[0m00:34:49.379657 [debug] [Thread-5 (]: Acquiring new postgres connection 'model.elementary.dbt_exposures'
[0m00:34:49.380168 [debug] [Thread-7 (]: Acquiring new postgres connection 'model.elementary.dbt_invocations'
[0m00:34:49.380651 [debug] [Thread-8 (]: Acquiring new postgres connection 'model.elementary.dbt_metrics'
[0m00:34:49.381145 [debug] [Thread-9 (]: Acquiring new postgres connection 'model.elementary.dbt_models'
[0m00:34:49.381670 [debug] [Thread-10 ]: Acquiring new postgres connection 'model.elementary.dbt_run_results'
[0m00:34:49.382157 [debug] [Thread-11 ]: Acquiring new postgres connection 'model.elementary.dbt_seeds'
[0m00:34:49.382642 [debug] [Thread-12 ]: Acquiring new postgres connection 'model.elementary.dbt_snapshots'
[0m00:34:49.383158 [debug] [Thread-6 (]: Acquiring new postgres connection 'model.elementary.dbt_groups'
[0m00:34:49.383586 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption_history)
[0m00:34:49.384424 [debug] [Thread-15 ]: Acquiring new postgres connection 'model.elementary.dbt_tests'
[0m00:34:49.384925 [debug] [Thread-13 ]: Acquiring new postgres connection 'model.elementary.dbt_source_freshness_results'
[0m00:34:49.385332 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption)
[0m00:34:49.385909 [debug] [Thread-16 ]: Acquiring new postgres connection 'model.elementary.elementary_test_results'
[0m00:34:49.386324 [debug] [Thread-14 ]: Began compiling node model.elementary.dbt_sources
[0m00:34:49.386755 [debug] [Thread-3 (]: Began compiling node model.elementary.data_monitoring_metrics
[0m00:34:49.387157 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_columns
[0m00:34:49.387540 [debug] [Thread-5 (]: Began compiling node model.elementary.dbt_exposures
[0m00:34:49.387919 [debug] [Thread-7 (]: Began compiling node model.elementary.dbt_invocations
[0m00:34:49.388292 [debug] [Thread-8 (]: Began compiling node model.elementary.dbt_metrics
[0m00:34:49.388672 [debug] [Thread-9 (]: Began compiling node model.elementary.dbt_models
[0m00:34:49.389097 [debug] [Thread-10 ]: Began compiling node model.elementary.dbt_run_results
[0m00:34:49.389474 [debug] [Thread-11 ]: Began compiling node model.elementary.dbt_seeds
[0m00:34:49.389850 [debug] [Thread-12 ]: Began compiling node model.elementary.dbt_snapshots
[0m00:34:49.390268 [debug] [Thread-6 (]: Began compiling node model.elementary.dbt_groups
[0m00:34:49.390666 [debug] [Thread-2 (]: Began compiling node model.dbt_elsa.consumption_history
[0m00:34:49.391046 [debug] [Thread-15 ]: Began compiling node model.elementary.dbt_tests
[0m00:34:49.391429 [debug] [Thread-13 ]: Began compiling node model.elementary.dbt_source_freshness_results
[0m00:34:49.391804 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m00:34:49.392188 [debug] [Thread-16 ]: Began compiling node model.elementary.elementary_test_results
[0m00:34:49.505305 [debug] [Thread-14 ]: Writing injected SQL for node "model.elementary.dbt_sources"
[0m00:34:49.515359 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_columns"
[0m00:34:49.518522 [debug] [Thread-5 (]: Writing injected SQL for node "model.elementary.dbt_exposures"
[0m00:34:49.532520 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.data_monitoring_metrics"
[0m00:34:49.551789 [debug] [Thread-7 (]: Writing injected SQL for node "model.elementary.dbt_invocations"
[0m00:34:49.558370 [debug] [Thread-8 (]: Writing injected SQL for node "model.elementary.dbt_metrics"
[0m00:34:49.578955 [debug] [Thread-9 (]: Writing injected SQL for node "model.elementary.dbt_models"
[0m00:34:49.603199 [debug] [Thread-10 ]: Writing injected SQL for node "model.elementary.dbt_run_results"
[0m00:34:49.608549 [debug] [Thread-11 ]: Writing injected SQL for node "model.elementary.dbt_seeds"
[0m00:34:49.618618 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.dbt_snapshots"
[0m00:34:49.627912 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m00:34:49.631423 [debug] [Thread-6 (]: Writing injected SQL for node "model.elementary.dbt_groups"
[0m00:34:49.652984 [debug] [Thread-15 ]: Writing injected SQL for node "model.elementary.dbt_tests"
[0m00:34:49.658140 [debug] [Thread-13 ]: Writing injected SQL for node "model.elementary.dbt_source_freshness_results"
[0m00:34:49.662521 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m00:34:49.680872 [debug] [Thread-16 ]: Writing injected SQL for node "model.elementary.elementary_test_results"
[0m00:34:49.683333 [debug] [Thread-12 ]: Began executing node model.elementary.dbt_snapshots
[0m00:34:49.683951 [debug] [Thread-9 (]: Began executing node model.elementary.dbt_models
[0m00:34:49.684399 [debug] [Thread-8 (]: Began executing node model.elementary.dbt_metrics
[0m00:34:49.685020 [debug] [Thread-2 (]: Began executing node model.dbt_elsa.consumption_history
[0m00:34:49.686750 [debug] [Thread-12 ]: Finished running node model.elementary.dbt_snapshots
[0m00:34:49.687435 [debug] [Thread-15 ]: Began executing node model.elementary.dbt_tests
[0m00:34:49.687930 [debug] [Thread-6 (]: Began executing node model.elementary.dbt_groups
[0m00:34:49.688389 [debug] [Thread-11 ]: Began executing node model.elementary.dbt_seeds
[0m00:34:49.688832 [debug] [Thread-10 ]: Began executing node model.elementary.dbt_run_results
[0m00:34:49.689258 [debug] [Thread-14 ]: Began executing node model.elementary.dbt_sources
[0m00:34:49.689838 [debug] [Thread-5 (]: Began executing node model.elementary.dbt_exposures
[0m00:34:49.690260 [debug] [Thread-3 (]: Began executing node model.elementary.data_monitoring_metrics
[0m00:34:49.690706 [debug] [Thread-7 (]: Began executing node model.elementary.dbt_invocations
[0m00:34:49.691117 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_columns
[0m00:34:49.691928 [debug] [Thread-9 (]: Finished running node model.elementary.dbt_models
[0m00:34:49.692890 [debug] [Thread-8 (]: Finished running node model.elementary.dbt_metrics
[0m00:34:49.693465 [debug] [Thread-16 ]: Began executing node model.elementary.elementary_test_results
[0m00:34:49.694019 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m00:34:49.694650 [debug] [Thread-13 ]: Began executing node model.elementary.dbt_source_freshness_results
[0m00:34:49.695450 [debug] [Thread-2 (]: Finished running node model.dbt_elsa.consumption_history
[0m00:34:49.695931 [debug] [Thread-12 ]: Began running node model.elementary.metadata
[0m00:34:49.696642 [debug] [Thread-15 ]: Finished running node model.elementary.dbt_tests
[0m00:34:49.697401 [debug] [Thread-6 (]: Finished running node model.elementary.dbt_groups
[0m00:34:49.698082 [debug] [Thread-11 ]: Finished running node model.elementary.dbt_seeds
[0m00:34:49.698784 [debug] [Thread-10 ]: Finished running node model.elementary.dbt_run_results
[0m00:34:49.699535 [debug] [Thread-14 ]: Finished running node model.elementary.dbt_sources
[0m00:34:49.700261 [debug] [Thread-5 (]: Finished running node model.elementary.dbt_exposures
[0m00:34:49.701013 [debug] [Thread-3 (]: Finished running node model.elementary.data_monitoring_metrics
[0m00:34:49.701727 [debug] [Thread-7 (]: Finished running node model.elementary.dbt_invocations
[0m00:34:49.702411 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_columns
[0m00:34:49.702853 [debug] [Thread-9 (]: Began running node model.elementary.schema_columns_snapshot
[0m00:34:49.703290 [debug] [Thread-8 (]: Began running node operation.elementary.elementary-on-run-end-0
[0m00:34:49.704188 [debug] [Thread-16 ]: Finished running node model.elementary.elementary_test_results
[0m00:34:49.705076 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m00:34:49.706004 [debug] [Thread-13 ]: Finished running node model.elementary.dbt_source_freshness_results
[0m00:34:49.706476 [debug] [Thread-2 (]: Began running node operation.elementary.elementary-on-run-start-0
[0m00:34:49.706971 [debug] [Thread-12 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_snapshots, now model.elementary.metadata)
[0m00:34:49.707518 [debug] [Thread-15 ]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:49.707985 [debug] [Thread-6 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:49.708684 [debug] [Thread-14 ]: Began running node model.elementary.snapshot_run_results
[0m00:34:49.709082 [debug] [Thread-11 ]: Began running node model.elementary.model_run_results
[0m00:34:49.709450 [debug] [Thread-10 ]: Began running node model.elementary.seed_run_results
[0m00:34:49.710458 [debug] [Thread-3 (]: Began running node model.elementary.monitors_runs
[0m00:34:49.711033 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_models, now model.elementary.schema_columns_snapshot)
[0m00:34:49.711477 [debug] [Thread-7 (]: Began running node model.elementary.dbt_artifacts_hashes
[0m00:34:49.711871 [debug] [Thread-4 (]: Began running node model.elementary.job_run_results
[0m00:34:49.712249 [debug] [Thread-5 (]: Began running node model.elementary.metrics_anomaly_score
[0m00:34:49.712707 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_metrics, now operation.elementary.elementary-on-run-end-0)
[0m00:34:49.713398 [debug] [Thread-13 ]: Began running node model.elementary.alerts_schema_changes
[0m00:34:49.713778 [debug] [Thread-16 ]: Began running node model.elementary.alerts_anomaly_detection
[0m00:34:49.714202 [debug] [Thread-1 (]: Began running node model.elementary.alerts_dbt_tests
[0m00:34:49.714670 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.dbt_elsa.consumption_history, now operation.elementary.elementary-on-run-start-0)
[0m00:34:49.715075 [debug] [Thread-12 ]: Began compiling node model.elementary.metadata
[0m00:34:49.715483 [debug] [Thread-15 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_tests, now test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9)
[0m00:34:49.715887 [debug] [Thread-6 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_groups, now test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4)
[0m00:34:49.716288 [debug] [Thread-14 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_sources, now model.elementary.snapshot_run_results)
[0m00:34:49.716690 [debug] [Thread-11 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_seeds, now model.elementary.model_run_results)
[0m00:34:49.717130 [debug] [Thread-10 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_run_results, now model.elementary.seed_run_results)
[0m00:34:49.717526 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.data_monitoring_metrics, now model.elementary.monitors_runs)
[0m00:34:49.717925 [debug] [Thread-9 (]: Began compiling node model.elementary.schema_columns_snapshot
[0m00:34:49.718321 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_invocations, now model.elementary.dbt_artifacts_hashes)
[0m00:34:49.718734 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_columns, now model.elementary.job_run_results)
[0m00:34:49.719159 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_exposures, now model.elementary.metrics_anomaly_score)
[0m00:34:49.719555 [debug] [Thread-8 (]: Began compiling node operation.elementary.elementary-on-run-end-0
[0m00:34:49.719968 [debug] [Thread-13 ]: Re-using an available connection from the pool (formerly model.elementary.dbt_source_freshness_results, now model.elementary.alerts_schema_changes)
[0m00:34:49.720375 [debug] [Thread-16 ]: Re-using an available connection from the pool (formerly model.elementary.elementary_test_results, now model.elementary.alerts_anomaly_detection)
[0m00:34:49.720778 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_elsa.consumption, now model.elementary.alerts_dbt_tests)
[0m00:34:49.721168 [debug] [Thread-2 (]: Began compiling node operation.elementary.elementary-on-run-start-0
[0m00:34:49.728143 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.metadata"
[0m00:34:49.728731 [debug] [Thread-15 ]: Began compiling node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:49.729164 [debug] [Thread-6 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:49.729571 [debug] [Thread-14 ]: Began compiling node model.elementary.snapshot_run_results
[0m00:34:49.729957 [debug] [Thread-11 ]: Began compiling node model.elementary.model_run_results
[0m00:34:49.730334 [debug] [Thread-10 ]: Began compiling node model.elementary.seed_run_results
[0m00:34:49.730709 [debug] [Thread-3 (]: Began compiling node model.elementary.monitors_runs
[0m00:34:49.739958 [debug] [Thread-9 (]: Writing injected SQL for node "model.elementary.schema_columns_snapshot"
[0m00:34:49.740421 [debug] [Thread-7 (]: Began compiling node model.elementary.dbt_artifacts_hashes
[0m00:34:49.740844 [debug] [Thread-4 (]: Began compiling node model.elementary.job_run_results
[0m00:34:49.741230 [debug] [Thread-5 (]: Began compiling node model.elementary.metrics_anomaly_score
[0m00:34:49.753260 [debug] [Thread-13 ]: Began compiling node model.elementary.alerts_schema_changes
[0m00:34:49.755188 [debug] [Thread-8 (]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:34:49.755672 [debug] [Thread-16 ]: Began compiling node model.elementary.alerts_anomaly_detection
[0m00:34:49.756164 [debug] [Thread-1 (]: Began compiling node model.elementary.alerts_dbt_tests
[0m00:34:49.776638 [debug] [Thread-2 (]: Elementary: Materialization override is enabled.
[0m00:34:49.793752 [debug] [Thread-12 ]: Began executing node model.elementary.metadata
[0m00:34:49.797714 [debug] [Thread-15 ]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:34:49.798366 [debug] [Thread-6 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:34:49.803072 [debug] [Thread-14 ]: Writing injected SQL for node "model.elementary.snapshot_run_results"
[0m00:34:49.812317 [debug] [Thread-11 ]: Writing injected SQL for node "model.elementary.model_run_results"
[0m00:34:49.817081 [debug] [Thread-10 ]: Writing injected SQL for node "model.elementary.seed_run_results"
[0m00:34:49.821327 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.monitors_runs"
[0m00:34:49.827182 [debug] [Thread-7 (]: Writing injected SQL for node "model.elementary.dbt_artifacts_hashes"
[0m00:34:49.844001 [debug] [Thread-9 (]: Began executing node model.elementary.schema_columns_snapshot
[0m00:34:49.877091 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.job_run_results"
[0m00:34:49.862024 [debug] [Thread-13 ]: Writing injected SQL for node "model.elementary.alerts_schema_changes"
[0m00:34:49.894338 [debug] [Thread-5 (]: Writing injected SQL for node "model.elementary.metrics_anomaly_score"
[0m00:34:49.900793 [debug] [Thread-16 ]: Writing injected SQL for node "model.elementary.alerts_anomaly_detection"
[0m00:34:49.907135 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.alerts_dbt_tests"
[0m00:34:49.912844 [debug] [Thread-8 (]: Began executing node operation.elementary.elementary-on-run-end-0
[0m00:34:49.914522 [debug] [Thread-2 (]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:34:49.915345 [debug] [Thread-12 ]: Finished running node model.elementary.metadata
[0m00:34:49.916340 [debug] [Thread-15 ]: Began executing node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:49.916794 [debug] [Thread-6 (]: Began executing node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:49.917386 [debug] [Thread-14 ]: Began executing node model.elementary.snapshot_run_results
[0m00:34:49.918038 [debug] [Thread-11 ]: Began executing node model.elementary.model_run_results
[0m00:34:49.919107 [debug] [Thread-9 (]: Finished running node model.elementary.schema_columns_snapshot
[0m00:34:49.919822 [debug] [Thread-3 (]: Began executing node model.elementary.monitors_runs
[0m00:34:49.920263 [debug] [Thread-10 ]: Began executing node model.elementary.seed_run_results
[0m00:34:49.920856 [debug] [Thread-7 (]: Began executing node model.elementary.dbt_artifacts_hashes
[0m00:34:49.922131 [debug] [Thread-4 (]: Began executing node model.elementary.job_run_results
[0m00:34:49.922868 [debug] [Thread-13 ]: Began executing node model.elementary.alerts_schema_changes
[0m00:34:49.924106 [debug] [Thread-8 (]: Finished running node operation.elementary.elementary-on-run-end-0
[0m00:34:49.924863 [debug] [Thread-5 (]: Began executing node model.elementary.metrics_anomaly_score
[0m00:34:49.925744 [debug] [Thread-12 ]: Began running node model.elementary.test_result_rows
[0m00:34:49.926366 [debug] [Thread-1 (]: Began executing node model.elementary.alerts_dbt_tests
[0m00:34:49.927064 [debug] [Thread-16 ]: Began executing node model.elementary.alerts_anomaly_detection
[0m00:34:49.928892 [debug] [Thread-15 ]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:34:49.929718 [debug] [Thread-2 (]: Began executing node operation.elementary.elementary-on-run-start-0
[0m00:34:49.931267 [debug] [Thread-6 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:34:49.932876 [debug] [Thread-14 ]: Finished running node model.elementary.snapshot_run_results
[0m00:34:49.934314 [debug] [Thread-11 ]: Finished running node model.elementary.model_run_results
[0m00:34:49.935117 [debug] [Thread-9 (]: Began running node model.elementary.alerts_dbt_source_freshness
[0m00:34:49.936503 [debug] [Thread-3 (]: Finished running node model.elementary.monitors_runs
[0m00:34:49.937898 [debug] [Thread-10 ]: Finished running node model.elementary.seed_run_results
[0m00:34:49.939326 [debug] [Thread-7 (]: Finished running node model.elementary.dbt_artifacts_hashes
[0m00:34:49.940784 [debug] [Thread-4 (]: Finished running node model.elementary.job_run_results
[0m00:34:49.942143 [debug] [Thread-13 ]: Finished running node model.elementary.alerts_schema_changes
[0m00:34:49.942987 [debug] [Thread-8 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:34:49.944913 [debug] [Thread-5 (]: Finished running node model.elementary.metrics_anomaly_score
[0m00:34:49.945815 [debug] [Thread-12 ]: Re-using an available connection from the pool (formerly model.elementary.metadata, now model.elementary.test_result_rows)
[0m00:34:49.947285 [debug] [Thread-1 (]: Finished running node model.elementary.alerts_dbt_tests
[0m00:34:49.948661 [debug] [Thread-16 ]: Finished running node model.elementary.alerts_anomaly_detection
[0m00:34:49.949395 [debug] [Thread-15 ]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:34:49.950795 [debug] [Thread-2 (]: Finished running node operation.elementary.elementary-on-run-start-0
[0m00:34:49.951502 [debug] [Thread-6 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:34:49.952597 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly model.elementary.schema_columns_snapshot, now model.elementary.alerts_dbt_source_freshness)
[0m00:34:49.953296 [debug] [Thread-14 ]: Began running node model.elementary.alerts_dbt_models
[0m00:34:49.954704 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly operation.elementary.elementary-on-run-end-0, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m00:34:49.955675 [debug] [Thread-12 ]: Began compiling node model.elementary.test_result_rows
[0m00:34:49.956372 [debug] [Thread-11 ]: Began running node model.elementary.anomaly_threshold_sensitivity
[0m00:34:49.957399 [debug] [Thread-15 ]: Re-using an available connection from the pool (formerly test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9, now test.dbt_elsa.not_null_consumption_date.0e210070dc)
[0m00:34:49.958301 [debug] [Thread-6 (]: Re-using an available connection from the pool (formerly test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4, now test.dbt_elsa.not_null_consumption_id.186948fd55)
[0m00:34:49.959036 [debug] [Thread-9 (]: Began compiling node model.elementary.alerts_dbt_source_freshness
[0m00:34:49.959760 [debug] [Thread-14 ]: Re-using an available connection from the pool (formerly model.elementary.snapshot_run_results, now model.elementary.alerts_dbt_models)
[0m00:34:49.960626 [debug] [Thread-8 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:34:49.972859 [debug] [Thread-11 ]: Re-using an available connection from the pool (formerly model.elementary.model_run_results, now model.elementary.anomaly_threshold_sensitivity)
[0m00:34:49.974066 [debug] [Thread-12 ]: Writing injected SQL for node "model.elementary.test_result_rows"
[0m00:34:49.974544 [debug] [Thread-15 ]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:34:49.974928 [debug] [Thread-6 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:34:49.981428 [debug] [Thread-9 (]: Writing injected SQL for node "model.elementary.alerts_dbt_source_freshness"
[0m00:34:49.981972 [debug] [Thread-14 ]: Began compiling node model.elementary.alerts_dbt_models
[0m00:34:49.986878 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:34:49.987381 [debug] [Thread-11 ]: Began compiling node model.elementary.anomaly_threshold_sensitivity
[0m00:34:49.992274 [debug] [Thread-15 ]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:34:49.997577 [debug] [Thread-6 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:34:49.998322 [debug] [Thread-12 ]: Began executing node model.elementary.test_result_rows
[0m00:34:50.005501 [debug] [Thread-14 ]: Writing injected SQL for node "model.elementary.alerts_dbt_models"
[0m00:34:50.024480 [debug] [Thread-11 ]: Writing injected SQL for node "model.elementary.anomaly_threshold_sensitivity"
[0m00:34:50.025105 [debug] [Thread-9 (]: Began executing node model.elementary.alerts_dbt_source_freshness
[0m00:34:50.025571 [debug] [Thread-8 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:34:50.026524 [debug] [Thread-12 ]: Finished running node model.elementary.test_result_rows
[0m00:34:50.027090 [debug] [Thread-15 ]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:34:50.027692 [debug] [Thread-6 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:34:50.028885 [debug] [Thread-9 (]: Finished running node model.elementary.alerts_dbt_source_freshness
[0m00:34:50.029730 [debug] [Thread-8 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:34:50.030838 [debug] [Thread-15 ]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:34:50.031325 [debug] [Thread-11 ]: Began executing node model.elementary.anomaly_threshold_sensitivity
[0m00:34:50.032036 [debug] [Thread-6 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:34:50.032391 [debug] [Thread-14 ]: Began executing node model.elementary.alerts_dbt_models
[0m00:34:50.033383 [debug] [Thread-11 ]: Finished running node model.elementary.anomaly_threshold_sensitivity
[0m00:34:50.034153 [debug] [Thread-14 ]: Finished running node model.elementary.alerts_dbt_models
[0m00:34:50.035997 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:34:50.036351 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_tests' was properly closed.
[0m00:34:50.036658 [debug] [MainThread]: Connection 'operation.elementary.elementary-on-run-start-0' was properly closed.
[0m00:34:50.036956 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_models' was properly closed.
[0m00:34:50.037408 [debug] [MainThread]: Connection 'model.elementary.monitors_runs' was properly closed.
[0m00:34:50.037790 [debug] [MainThread]: Connection 'model.elementary.job_run_results' was properly closed.
[0m00:34:50.038215 [debug] [MainThread]: Connection 'model.elementary.metrics_anomaly_score' was properly closed.
[0m00:34:50.038516 [debug] [MainThread]: Connection 'model.elementary.dbt_artifacts_hashes' was properly closed.
[0m00:34:50.038882 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m00:34:50.039188 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_source_freshness' was properly closed.
[0m00:34:50.039484 [debug] [MainThread]: Connection 'model.elementary.seed_run_results' was properly closed.
[0m00:34:50.039777 [debug] [MainThread]: Connection 'model.elementary.anomaly_threshold_sensitivity' was properly closed.
[0m00:34:50.040059 [debug] [MainThread]: Connection 'model.elementary.test_result_rows' was properly closed.
[0m00:34:50.040340 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m00:34:50.040621 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m00:34:50.041254 [debug] [MainThread]: Connection 'model.elementary.alerts_schema_changes' was properly closed.
[0m00:34:50.041709 [debug] [MainThread]: Connection 'model.elementary.alerts_anomaly_detection' was properly closed.
[0m00:34:50.050456 [debug] [MainThread]: Command end result
[0m00:34:50.224124 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:34:50.227662 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:34:50.237551 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:34:50.242827 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m00:34:50.243442 [info ] [MainThread]: Building catalog
[0m00:34:50.264454 [debug] [ThreadPool]: Acquiring new postgres connection 'elsa.information_schema'
[0m00:34:50.277883 [debug] [ThreadPool]: Using postgres connection "elsa.information_schema"
[0m00:34:50.278336 [debug] [ThreadPool]: On elsa.information_schema: BEGIN
[0m00:34:50.278659 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:34:50.285536 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:34:50.286264 [debug] [ThreadPool]: Using postgres connection "elsa.information_schema"
[0m00:34:50.287107 [debug] [ThreadPool]: On elsa.information_schema: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "elsa.information_schema"} */

    
    

    select
        'elsa' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('elementary_test_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_source_freshness_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_seeds')) or (upper(sch.nspname) = upper('bronze') and
           upper(tbl.relname) = upper('consumption')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('job_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('test_result_rows')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_dbt_source_freshness')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('monitors_runs')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('metadata')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('model_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_dbt_tests')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_exposures')) or (upper(sch.nspname) = upper('bronze') and
           upper(tbl.relname) = upper('consumption_history')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_groups')) or (upper(sch.nspname) = upper('bronze') and
           upper(tbl.relname) = upper('rte_eco2mix')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_sources')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_metrics')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_invocations')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('schema_columns_snapshot')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('metrics_anomaly_score')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_anomaly_detection')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_models')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_dbt_models')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('snapshot_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_tests')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('data_monitoring_metrics')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_artifacts_hashes')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_snapshots')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('seed_run_results')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('anomaly_threshold_sensitivity')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('alerts_schema_changes')) or (upper(sch.nspname) = upper('bronze_tec_elsa') and
           upper(tbl.relname) = upper('dbt_columns')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m00:34:50.298211 [debug] [ThreadPool]: SQL status: SELECT 560 in 0.010 seconds
[0m00:34:50.313736 [debug] [ThreadPool]: On elsa.information_schema: ROLLBACK
[0m00:34:50.314416 [debug] [ThreadPool]: On elsa.information_schema: Close
[0m00:34:50.342009 [debug] [MainThread]: Wrote artifact CatalogArtifact to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/catalog.json
[0m00:34:50.426047 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:34:50.428450 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:34:50.428924 [info ] [MainThread]: Catalog written to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/catalog.json
[0m00:34:50.433321 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.288723, "process_in_blocks": "0", "process_kernel_time": 0.418563, "process_mem_max_rss": "134688768", "process_out_blocks": "0", "process_user_time": 3.444964}
[0m00:34:50.434020 [debug] [MainThread]: Command `dbt docs generate` succeeded at 00:34:50.433885 after 2.29 seconds
[0m00:34:50.434391 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m00:34:50.434694 [debug] [MainThread]: Connection 'elsa.information_schema' was properly closed.
[0m00:34:50.435067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086a2c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e053ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e053d80>]}
[0m00:34:50.435470 [debug] [MainThread]: Flushing usage events
[0m00:34:50.829133 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:34:56.352493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10368b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104db74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104db7750>]}


============================== 00:34:56.357971 | b14416d4-a566-4c23-94d5-b56c62a5253b ==============================
[0m00:34:56.357971 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:34:56.358670 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt docs serve', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m00:34:56.576596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b14416d4-a566-4c23-94d5-b56c62a5253b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104108510>]}
[0m00:34:56.655098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b14416d4-a566-4c23-94d5-b56c62a5253b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c3bdf0>]}
[0m00:46:00.343563 [error] [MainThread]: Encountered an error:

[0m00:46:00.364018 [error] [MainThread]: Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 161, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 111, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 254, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 285, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/requires.py", line 332, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/cli/main.py", line 307, in docs_serve
    results = task.run()
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
    ~~~~~~~~~~~~~~~~~~~^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py", line 398, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt

[0m00:46:00.374544 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_success": false, "command_wall_clock_time": 664.0997, "process_in_blocks": "0", "process_kernel_time": 0.301909, "process_mem_max_rss": "109506560", "process_out_blocks": "0", "process_user_time": 1.93557}
[0m00:46:00.377222 [debug] [MainThread]: Command `dbt docs serve` failed at 00:46:00.376559 after 664.10 seconds
[0m00:46:00.378974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105411c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105411e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053e3020>]}
[0m00:46:00.380018 [debug] [MainThread]: Flushing usage events
[0m00:46:00.832619 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:47:11.289385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9e3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0df610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0df4d0>]}


============================== 00:47:11.297194 | 51079c27-f60f-46a2-a972-c81cf81918a1 ==============================
[0m00:47:11.297194 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:47:11.297938 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build --select bronze', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:47:11.575447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '51079c27-f60f-46a2-a972-c81cf81918a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e45c510>]}
[0m00:47:11.657390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '51079c27-f60f-46a2-a972-c81cf81918a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef63df0>]}
[0m00:47:11.659108 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:47:11.810708 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:47:12.353370 [debug] [MainThread]: Partial parsing enabled: 6 files deleted, 6 files added, 0 files changed.
[0m00:47:12.354378 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/energy/silver/consumption_history.sql
[0m00:47:12.355149 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/energy/bronze/_elsa_bronze__models.yml
[0m00:47:12.355727 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/energy/bronze/_elsa_bronze__sources.yml
[0m00:47:12.356225 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/energy/silver/_elsa_silver__sources.yml
[0m00:47:12.356686 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/energy/silver/_elsa_bronze__models.yml
[0m00:47:12.357096 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/energy/bronze/consumption.sql
[0m00:47:12.357747 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/bronze/consumption.sql
[0m00:47:12.358108 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/silver/consumption_history.sql
[0m00:47:13.111457 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- models.dbt_elsa.silver
[0m00:47:13.126487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '51079c27-f60f-46a2-a972-c81cf81918a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110378f50>]}
[0m00:47:13.300651 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:47:13.305823 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:47:13.375864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '51079c27-f60f-46a2-a972-c81cf81918a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106cb2f0>]}
[0m00:47:13.376474 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m00:47:13.377510 [warn ] [MainThread]: The selection criterion 'bronze' does not match any enabled nodes
[0m00:47:13.378350 [warn ] [MainThread]: The selection criterion 'bronze' does not match any enabled nodes
[0m00:47:13.379015 [warn ] [MainThread]: The selection criterion 'bronze' does not match any enabled nodes
[0m00:47:13.380492 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m00:47:13.381076 [debug] [MainThread]: Command end result
[0m00:47:13.466835 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:47:13.469545 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:47:13.474655 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:47:13.477862 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 2.2959945, "process_in_blocks": "0", "process_kernel_time": 0.756889, "process_mem_max_rss": "135323648", "process_out_blocks": "0", "process_user_time": 3.868453}
[0m00:47:13.478487 [debug] [MainThread]: Command `dbt build` succeeded at 00:47:13.478344 after 2.30 seconds
[0m00:47:13.478964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efcfe70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6a73f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110797c70>]}
[0m00:47:13.479423 [debug] [MainThread]: Flushing usage events
[0m00:47:13.876065 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:47:41.820974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103a7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111adb610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111adb4d0>]}


============================== 00:47:41.841622 | 5bac047c-ccc7-478c-8aa4-b93077f9ae66 ==============================
[0m00:47:41.841622 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:47:41.843331 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build --select bronze', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m00:47:42.069016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e28510>]}
[0m00:47:42.146425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11195bdf0>]}
[0m00:47:42.147363 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:47:42.278692 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:47:42.443028 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m00:47:42.443564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d74550>]}
[0m00:47:47.462694 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m00:47:47.477053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d418b0>]}
[0m00:47:47.650772 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:47:47.653547 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:47:47.688178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e70f30>]}
[0m00:47:47.688756 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m00:47:47.691669 [info ] [MainThread]: 
[0m00:47:47.692164 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:47:47.692508 [info ] [MainThread]: 
[0m00:47:47.693029 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:47:47.693877 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:47:47.764216 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:47:47.764695 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:47:47.765080 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:47.800862 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.036 seconds
[0m00:47:47.802554 [debug] [ThreadPool]: On list_elsa: Close
[0m00:47:47.810461 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze_tec_elsa)
[0m00:47:47.817497 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_silver'
[0m00:47:47.818808 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:47:47.819338 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m00:47:47.822078 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_silver"
[0m00:47:47.822540 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m00:47:47.825653 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:47:47.826107 [debug] [ThreadPool]: On list_elsa_bronze_silver: BEGIN
[0m00:47:47.826447 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:47:47.826779 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:47:47.827100 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:47.827667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:47.834318 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m00:47:47.834756 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m00:47:47.835088 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:47:47.835384 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m00:47:47.835704 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_silver"
[0m00:47:47.836046 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m00:47:47.836386 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:47:47.836726 [debug] [ThreadPool]: On list_elsa_bronze_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_silver'
  
[0m00:47:47.837204 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:47:47.842158 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m00:47:47.842613 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m00:47:47.843863 [debug] [ThreadPool]: On list_elsa_bronze_silver: ROLLBACK
[0m00:47:47.844171 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.007 seconds
[0m00:47:47.845461 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:47:47.847280 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m00:47:47.847649 [debug] [ThreadPool]: On list_elsa_bronze_silver: Close
[0m00:47:47.848127 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:47:47.848669 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m00:47:47.862438 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:47.862854 [debug] [MainThread]: On master: BEGIN
[0m00:47:47.863234 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:47:47.868576 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m00:47:47.868972 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:47.869361 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:47:47.910853 [debug] [MainThread]: SQL status: SELECT 26 in 0.041 seconds
[0m00:47:47.918052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132ca340>]}
[0m00:47:47.918592 [debug] [MainThread]: On master: ROLLBACK
[0m00:47:47.919192 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:47.919542 [debug] [MainThread]: On master: BEGIN
[0m00:47:47.920163 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:47.920521 [debug] [MainThread]: On master: COMMIT
[0m00:47:47.920854 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:47.921170 [debug] [MainThread]: On master: COMMIT
[0m00:47:47.921696 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:47:47.943569 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:47:47.979184 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:47.979824 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m00:47:47.980857 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m00:47:47.984054 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:47:47.987948 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:47:47.988602 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.07s]
[0m00:47:47.989164 [info ] [MainThread]: 
[0m00:47:47.989615 [debug] [MainThread]: On master: Close
[0m00:47:47.995204 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m00:47:47.996070 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m00:47:47.997184 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption)
[0m00:47:47.997685 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m00:47:48.001964 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m00:47:48.003640 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m00:47:48.053328 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m00:47:48.055838 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.056510 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m00:47:48.056924 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:47:48.062265 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m00:47:48.062730 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.063131 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m00:47:48.068416 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.005 seconds
[0m00:47:48.079832 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.080300 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m00:47:48.081144 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m00:47:48.085340 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.085833 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m00:47:48.086897 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:48.112702 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.113200 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m00:47:48.114361 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m00:47:48.128058 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.128602 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m00:47:48.140203 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.011 seconds
[0m00:47:48.145195 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.145772 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m00:47:48.146786 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m00:47:48.148068 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m00:47:48.148475 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.148843 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m00:47:48.149967 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m00:47:48.157907 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m00:47:48.163712 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:47:48.164155 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m00:47:48.167773 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m00:47:48.170409 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m00:47:48.172695 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ef7ad0>]}
[0m00:47:48.173710 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.17s]
[0m00:47:48.174479 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m00:47:48.175239 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:47:48.175654 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m00:47:48.176187 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_date.0e210070dc)
[0m00:47:48.176598 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:47:48.181973 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:47:48.188268 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:47:48.192628 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:47:48.193094 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m00:47:48.193615 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m00:47:48.194523 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m00:47:48.195339 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_silver, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m00:47:48.195828 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:47:48.196215 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:47:48.201954 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:47:48.201505 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:47:48.208136 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:47:48.210809 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:47:48.211592 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '5bac047c-ccc7-478c-8aa4-b93077f9ae66', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11357c730>]}
[0m00:47:48.240340 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:47:48.258450 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:47:48.649016 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:47:48.651166 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:47:48.652504 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:47:48.654052 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:47:48.654456 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m00:47:48.654819 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:47:48.655524 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:47:48.656126 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:47:48.656805 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m00:47:48.657368 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m00:47:48.657795 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m00:47:48.658176 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:47:48.661847 [debug] [Thread-3 (]: SQL status: BEGIN in 0.007 seconds
[0m00:47:48.662293 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:47:48.662717 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m00:47:48.664091 [debug] [Thread-4 (]: SQL status: BEGIN in 0.006 seconds
[0m00:47:48.664763 [debug] [Thread-2 (]: SQL status: BEGIN in 0.006 seconds
[0m00:47:48.665251 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:47:48.665693 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m00:47:48.666108 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:47:48.666514 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m00:47:48.677744 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m00:47:48.697441 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.007 seconds
[0m00:47:48.715299 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.018 seconds
[0m00:47:48.737475 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m00:47:48.739603 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m00:47:48.740357 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m00:47:48.740793 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m00:47:48.741409 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m00:47:48.742051 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.55s]
[0m00:47:48.742486 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m00:47:48.743246 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.55s]
[0m00:47:48.743971 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:47:48.744715 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:47:48.745259 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.57s]
[0m00:47:48.746274 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:47:48.748186 [info ] [MainThread]: 
[0m00:47:48.748729 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:48.749147 [debug] [MainThread]: On master: BEGIN
[0m00:47:48.749654 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:47:48.755970 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:47:48.756443 [debug] [MainThread]: On master: COMMIT
[0m00:47:48.756892 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:48.757229 [debug] [MainThread]: On master: COMMIT
[0m00:47:48.757812 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:47:48.782231 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:48.782735 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m00:47:48.788536 [debug] [MainThread]: SQL status: SELECT 126 in 0.005 seconds
[0m00:47:48.791528 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:47:48.819548 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m00:47:48.871547 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m00:47:48.881005 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m00:47:48.882035 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m00:47:48.892139 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m00:47:48.921063 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:48.921617 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718224748904413004748913250"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m00:47:48.926554 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m00:47:48.945945 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:48.946404 [debug] [MainThread]: On master: BEGIN
[0m00:47:48.947040 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:48.947423 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:48.947796 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718224748904413004748913250'
        
      order by ordinal_position

  
[0m00:47:48.955281 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m00:47:48.958261 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718224748904413004748913250"
[0m00:47:49.003965 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.006130 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.006581 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718224748904413004748913250"
         (metadata_hash) values
    ('aa141a21362d2c0ddeff68a69467ac16')
  
[0m00:47:49.007559 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m00:47:49.011809 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.012273 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250718224749010206004749010552"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m00:47:49.015026 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:47:49.019845 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.020332 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250718224749010206004749010552'
        
      order by ordinal_position

  
[0m00:47:49.024267 [debug] [MainThread]: SQL status: SELECT 23 in 0.003 seconds
[0m00:47:49.026912 [debug] [MainThread]: Elementary: Inserting 1 rows to table "dbt_models__tmp_20250718224749010206004749010552"
[0m00:47:49.038767 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.039951 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.040409 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250718224749010206004749010552"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.consumption_history','consumption_history','ededa83e3a9b60961e0c6f15a05939372e9e0ea821c459c89b556e53735e7ff2','table','[]','{}','[]','elsa','bronze_silver','[]','[]','The aim of this table is to consolidate history data for consumption
','consumption_history','dbt_elsa','models/silver/consumption_history.sql','silver/consumption_history.sql','dbt_elsa://models/silver/_elsa_bronze__models.yml','2025-07-18 22:47:48','92b09df52c98edb3afd91027a53e9750',NULL,NULL,NULL,'protected')
  
[0m00:47:49.041304 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.000 seconds
[0m00:47:49.049706 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.050175 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250718224748904413004748913250");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250718224749010206004749010552";
        
        commit;
    
  
[0m00:47:49.051915 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:49.056747 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718224748904413004748913250"
[0m00:47:49.057454 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.057868 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718224748904413004748913250" cascade
[0m00:47:49.059737 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:47:49.064141 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250718224749010206004749010552"
[0m00:47:49.064811 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.065236 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250718224749010206004749010552" cascade
[0m00:47:49.066718 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:47:49.068031 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_models"
[0m00:47:49.069932 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m00:47:49.070884 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.050738 (1 runs)
[0m00:47:49.071780 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.024321 (2 runs)
[0m00:47:49.073180 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001044 (2 runs)
[0m00:47:49.074257 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.029276 (2 runs)
[0m00:47:49.075177 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.038949 (2 runs)
[0m00:47:49.076131 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.007369 (2 runs)
[0m00:47:49.077222 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.093616 (2 runs)
[0m00:47:49.078629 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.250158 (1 runs)
[0m00:47:49.080580 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m00:47:49.097876 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m00:47:49.099191 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m00:47:49.100129 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts changed.
[0m00:47:49.101180 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m00:47:49.103254 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.103650 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718224749102036004749102287"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m00:47:49.105642 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:47:49.110516 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.110978 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718224749102036004749102287'
        
      order by ordinal_position

  
[0m00:47:49.187844 [debug] [MainThread]: SQL status: SELECT 1 in 0.076 seconds
[0m00:47:49.191466 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_tests__tmp_20250718224749102036004749102287"
[0m00:47:49.198620 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.199777 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.200435 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250718224749102036004749102287"
         (metadata_hash) values
    ('74e3435900f5472019e670236520300f'),('86ccb896bbf4c86cfbc4de4e060771eb')
  
[0m00:47:49.203601 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.003 seconds
[0m00:47:49.208730 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.209397 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250718224749207240004749207504"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m00:47:49.214608 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m00:47:49.220489 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.220938 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250718224749207240004749207504'
        
      order by ordinal_position

  
[0m00:47:49.225037 [debug] [MainThread]: SQL status: SELECT 29 in 0.004 seconds
[0m00:47:49.228927 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_tests__tmp_20250718224749207240004749207504"
[0m00:47:49.253282 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.254452 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.254919 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250718224749207240004749207504"
         (unique_id,database_name,schema_name,name,short_name,alias,test_column_name,severity,warn_if,error_if,test_params,test_namespace,test_original_name,tags,model_tags,model_owners,meta,depends_on_macros,depends_on_nodes,parent_model_unique_id,description,package_name,type,original_path,path,generated_at,metadata_hash,quality_dimension,group_name) values
    ('test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','elsa','bronze_silver','not_null_consumption_history_created_at','not_null','not_null_consumption_history_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_created_at.sql','2025-07-18 22:47:49','4b5e46ddb20111a7645db0341d95d19d','completeness',NULL),('test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','elsa','bronze_silver','not_null_consumption_history_date','not_null','not_null_consumption_history_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_date.sql','2025-07-18 22:47:49','80fe0f17e2154d8ae5b04390c4cb03fe','completeness',NULL)
  
[0m00:47:49.256080 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m00:47:49.259736 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.260212 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_tests"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_tests__tmp_20250718224749102036004749102287");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_tests" select * from "dbt_tests__tmp_20250718224749207240004749207504";
        
        commit;
    
  
[0m00:47:49.261553 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:49.265528 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250718224749102036004749102287"
[0m00:47:49.267816 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.268280 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250718224749102036004749102287" cascade
[0m00:47:49.269830 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:47:49.274296 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250718224749207240004749207504"
[0m00:47:49.275262 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.275748 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250718224749207240004749207504" cascade
[0m00:47:49.277593 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:47:49.279137 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_tests"
[0m00:47:49.281692 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m00:47:49.282839 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.016271 (1 runs)
[0m00:47:49.283765 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.094382 (2 runs)
[0m00:47:49.284668 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000870 (2 runs)
[0m00:47:49.285565 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.023880 (4 runs)
[0m00:47:49.286467 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.028662 (2 runs)
[0m00:47:49.287368 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.010617 (2 runs)
[0m00:47:49.288262 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:00.141351 (2 runs)
[0m00:47:49.289158 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.200673 (1 runs)
[0m00:47:49.291573 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m00:47:49.313488 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m00:47:49.314873 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m00:47:49.315678 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m00:47:49.316908 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m00:47:49.317774 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.020708 (1 runs)
[0m00:47:49.318640 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.025284 (1 runs)
[0m00:47:49.320851 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m00:47:49.322649 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m00:47:49.323992 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m00:47:49.324765 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m00:47:49.325987 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m00:47:49.326844 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000542 (1 runs)
[0m00:47:49.327754 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005126 (1 runs)
[0m00:47:49.329850 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m00:47:49.331293 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m00:47:49.332874 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m00:47:49.333678 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m00:47:49.334900 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m00:47:49.335756 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000376 (1 runs)
[0m00:47:49.336624 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.004996 (1 runs)
[0m00:47:49.338543 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m00:47:49.340114 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m00:47:49.341477 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m00:47:49.342594 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m00:47:49.343858 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m00:47:49.344852 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000404 (1 runs)
[0m00:47:49.345875 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.005179 (1 runs)
[0m00:47:49.347666 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m00:47:49.349053 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m00:47:49.350285 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m00:47:49.351043 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m00:47:49.352251 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m00:47:49.353468 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000421 (1 runs)
[0m00:47:49.354421 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004492 (1 runs)
[0m00:47:49.356944 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m00:47:49.358376 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m00:47:49.359601 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m00:47:49.360506 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m00:47:49.362237 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m00:47:49.363287 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000365 (1 runs)
[0m00:47:49.364157 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005049 (1 runs)
[0m00:47:49.366267 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m00:47:49.628041 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 87 artifacts.
[0m00:47:49.629782 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m00:47:49.630983 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts changed.
[0m00:47:49.634308 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m00:47:49.636870 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.637414 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718224749635480004749635841"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m00:47:49.640090 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:47:49.645653 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.646134 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718224749635480004749635841'
        
      order by ordinal_position

  
[0m00:47:49.649352 [debug] [MainThread]: SQL status: SELECT 1 in 0.003 seconds
[0m00:47:49.651525 [debug] [MainThread]: Elementary: Inserting 4 rows to table "dbt_columns__tmp_20250718224749635480004749635841"
[0m00:47:49.660044 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.661707 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.662172 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718224749635480004749635841"
         (metadata_hash) values
    ('459d5fd9dd3fc2af636f7ccd6d1e4390'),('5de2266142800ba55cb18fd1db535ecf'),('642a41c8141e4fbebd3e29d13641c01a'),('a2c72a9e53f093f32e547c075472c38f')
  
[0m00:47:49.663018 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.000 seconds
[0m00:47:49.666737 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.667167 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250718224749665529004749665772"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."bronze_tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m00:47:49.669184 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m00:47:49.674531 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.675004 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250718224749665529004749665772'
        
      order by ordinal_position

  
[0m00:47:49.678290 [debug] [MainThread]: SQL status: SELECT 13 in 0.003 seconds
[0m00:47:49.680732 [debug] [MainThread]: Elementary: Inserting 4 rows to table "dbt_columns__tmp_20250718224749665529004749665772"
[0m00:47:49.703885 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.705443 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.706237 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250718224749665529004749665772"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.dbt_elsa.consumption_history.created_at','model.dbt_elsa.consumption_history','created_at','datetime','[]','{}','elsa','bronze_silver','consumption_history','datetime','model','2025-07-18 22:47:49','c776526cc348d192c29691840d97aced'),('column.model.dbt_elsa.consumption_history.date','model.dbt_elsa.consumption_history','date','date','[]','{}','elsa','bronze_silver','consumption_history','date','model','2025-07-18 22:47:49','5cfb39c28096294534f0ee5be0b1cb08'),('column.model.dbt_elsa.consumption_history.filiere','model.dbt_elsa.consumption_history','filiere','text','[]','{}','elsa','bronze_silver','consumption_history','filiere','model','2025-07-18 22:47:49','841cf999b79b7fece1d20d8c3c0b2ec0'),('column.model.dbt_elsa.consumption_history.volume','model.dbt_elsa.consumption_history','volume','integer','[]','{}','elsa','bronze_silver','consumption_history','volume','model','2025-07-18 22:47:49','4b4c15a33f8cd99e2f1895ab1d9d7891')
  
[0m00:47:49.707298 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m00:47:49.710932 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.711564 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."bronze_tec_elsa"."dbt_columns"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_columns__tmp_20250718224749635480004749635841");
        
        
            insert into "elsa"."bronze_tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250718224749665529004749665772";
        
        commit;
    
  
[0m00:47:49.712912 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:49.717345 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718224749635480004749635841"
[0m00:47:49.718059 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.718470 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718224749635480004749635841" cascade
[0m00:47:49.719904 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:47:49.724001 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250718224749665529004749665772"
[0m00:47:49.724797 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.725223 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250718224749665529004749665772" cascade
[0m00:47:49.726620 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m00:47:49.727839 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."bronze_tec_elsa"."dbt_columns"
[0m00:47:49.729430 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m00:47:49.730483 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.260727 (1 runs)
[0m00:47:49.731392 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.017305 (2 runs)
[0m00:47:49.732371 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000928 (2 runs)
[0m00:47:49.733287 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.023895 (8 runs)
[0m00:47:49.734508 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.029137 (2 runs)
[0m00:47:49.735371 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.007883 (2 runs)
[0m00:47:49.736218 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.061313 (2 runs)
[0m00:47:49.737058 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.362920 (1 runs)
[0m00:47:49.737939 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:47:49.742346 [debug] [MainThread]: Elementary: Uploading run results.
[0m00:47:49.743338 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m00:47:49.769732 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 4 artifacts.
[0m00:47:49.773904 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.774407 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:47:49.778531 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m00:47:49.781395 [debug] [MainThread]: Elementary: Inserting 4 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m00:47:49.843934 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.845261 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.845849 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('5bac047c-ccc7-478c-8aa4-b93077f9ae66.model.dbt_elsa.consumption','model.dbt_elsa.consumption','5bac047c-ccc7-478c-8aa4-b93077f9ae66','2025-07-18 22:47:49',
    current_timestamp::timestamp
,'consumption','SELECT 96','success','model',0.17401885986328125,'2025-07-18T22:47:48.003978Z','2025-07-18T22:47:48.170261Z','2025-07-18T22:47:47.997956Z','2025-07-18T22:47:48.003441Z',96,False,'SELECT
    id,
    created_at,
    (data->>''date'')::date AS date,
    (data->>''heure'')::time AS heure,   
    (data->>''gaz'')::int AS gaz,
    (data->>''nucleaire'')::int AS nucleaire,
    (data->>''charbon'')::int AS charbon,
    (data->>''solaire'')::int AS solaire,
    (data->>''eolien'')::int AS eolien,
    (data->>''hydraulique'')::int AS hydraulique,
    (data->>''bioenergies'')::int AS bioenergies,
    (data->>''autres'')::int AS autres,
    (data->>''prevision_j'')::int AS prevision_j,
    (data->>''prevision_j1'')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 96", "code": "SELECT", "rows_affected": 96}',NULL),('5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','5bac047c-ccc7-478c-8aa4-b93077f9ae66','2025-07-18 22:47:49',
    current_timestamp::timestamp
,'not_null_consumption_id',NULL,'pass','test',0.547745943069458,'2025-07-18T22:47:48.245980Z','2025-07-18T22:47:48.737292Z','2025-07-18T22:47:48.196492Z','2025-07-18T22:47:48.240131Z',1,False,'
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',0,NULL,'Thread-4 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','5bac047c-ccc7-478c-8aa4-b93077f9ae66','2025-07-18 22:47:49',
    current_timestamp::timestamp
,'not_null_consumption_created_at',NULL,'pass','test',0.5479059219360352,'2025-07-18T22:47:48.265115Z','2025-07-18T22:47:48.739398Z','2025-07-18T22:47:48.202428Z','2025-07-18T22:47:48.258255Z',1,False,'
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',0,NULL,'Thread-2 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','5bac047c-ccc7-478c-8aa4-b93077f9ae66','2025-07-18 22:47:49',
    current_timestamp::timestamp
,'not_null_consumption_date',NULL,'pass','test',0.5691180229187012,'2025-07-18T22:47:48.208557Z','2025-07-18T22:47:48.740198Z','2025-07-18T22:47:48.176862Z','2025-07-18T22:47:48.201804Z',1,False,'
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',0,NULL,'Thread-3 (worker)','test','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m00:47:49.848549 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.002 seconds
[0m00:47:49.851300 [debug] [MainThread]: On master: COMMIT
[0m00:47:49.851788 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.852175 [debug] [MainThread]: On master: COMMIT
[0m00:47:49.852770 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:47:49.855853 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m00:47:49.856892 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.025376 (1 runs)
[0m00:47:49.857737 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.010094 (1 runs)
[0m00:47:49.858566 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000731 (1 runs)
[0m00:47:49.859364 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.057475 (4 runs)
[0m00:47:49.860328 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.061042 (1 runs)
[0m00:47:49.861131 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005959 (1 runs)
[0m00:47:49.861990 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002498 (1 runs)
[0m00:47:49.862845 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.083394 (1 runs)
[0m00:47:49.863665 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.111924 (1 runs)
[0m00:47:49.864419 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m00:47:49.874802 [debug] [MainThread]: Elementary: Handling test results.
[0m00:47:49.905304 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.905944 [debug] [MainThread]: On master: BEGIN
[0m00:47:49.906805 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:49.907318 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.907804 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:47:49.912156 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m00:47:49.914902 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m00:47:49.966891 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:49.968046 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.968685 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_id.186948fd55',NULL,'5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_id.186948fd55','test.dbt_elsa.not_null_consumption_id.186948fd55','model.dbt_elsa.consumption','5bac047c-ccc7-478c-8aa4-b93077f9ae66',cast('2025-07-18 22:47:48' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','id','dbt_test','generic',NULL,'[]','[]','
    
    



select id
from "elsa"."bronze"."consumption"
where id is null


',NULL,'not_null_consumption_id','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_id',NULL,0),('5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_created_at.93906ad963',NULL,'5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_created_at.93906ad963','test.dbt_elsa.not_null_consumption_created_at.93906ad963','model.dbt_elsa.consumption','5bac047c-ccc7-478c-8aa4-b93077f9ae66',cast('2025-07-18 22:47:48' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','created_at','dbt_test','generic',NULL,'[]','[]','
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null


',NULL,'not_null_consumption_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_created_at',NULL,0),('5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_date.0e210070dc',NULL,'5bac047c-ccc7-478c-8aa4-b93077f9ae66.test.dbt_elsa.not_null_consumption_date.0e210070dc','test.dbt_elsa.not_null_consumption_date.0e210070dc','model.dbt_elsa.consumption','5bac047c-ccc7-478c-8aa4-b93077f9ae66',cast('2025-07-18 22:47:48' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze','consumption','date','dbt_test','generic',NULL,'[]','[]','
    
    



select date
from "elsa"."bronze"."consumption"
where date is null


',NULL,'not_null_consumption_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}','ERROR','pass',0,'not_null','not_null_consumption_date',NULL,0)
  
[0m00:47:49.969902 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m00:47:49.972334 [debug] [MainThread]: On master: COMMIT
[0m00:47:49.972784 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:49.973422 [debug] [MainThread]: On master: COMMIT
[0m00:47:49.974570 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:49.976564 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:47:49.992618 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m00:47:50.056789 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:50.057327 [debug] [MainThread]: On master: BEGIN
[0m00:47:50.058051 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:50.058504 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:50.059006 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:47:50.062973 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m00:47:50.065996 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m00:47:50.086920 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:50.088042 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:50.088609 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('5bac047c-ccc7-478c-8aa4-b93077f9ae66',NULL,NULL,NULL,'2025-07-18 22:47:41','2025-07-18 22:47:49','2025-07-18 22:47:49',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m00:47:50.089950 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m00:47:50.093151 [debug] [MainThread]: On master: COMMIT
[0m00:47:50.093586 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:50.093949 [debug] [MainThread]: On master: COMMIT
[0m00:47:50.095350 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:50.097219 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m00:47:50.104424 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:47:50.106895 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:47:50.107494 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.35s]
[0m00:47:50.107918 [debug] [MainThread]: On master: Close
[0m00:47:50.108399 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:47:50.108704 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m00:47:50.108988 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m00:47:50.109262 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m00:47:50.109728 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m00:47:50.110704 [info ] [MainThread]: 
[0m00:47:50.111329 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 2.42 seconds (2.42s).
[0m00:47:50.113629 [debug] [MainThread]: Command end result
[0m00:47:50.197319 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:47:50.199744 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:47:50.206473 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:47:50.206878 [info ] [MainThread]: 
[0m00:47:50.207361 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:47:50.207731 [info ] [MainThread]: 
[0m00:47:50.208100 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m00:47:50.208685 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m00:47:50.211333 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 8.485936, "process_in_blocks": "0", "process_kernel_time": 0.552271, "process_mem_max_rss": "146706432", "process_out_blocks": "0", "process_user_time": 9.318563}
[0m00:47:50.211903 [debug] [MainThread]: Command `dbt build` succeeded at 00:47:50.211782 after 8.49 seconds
[0m00:47:50.212397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136727b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113494710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128d4dd0>]}
[0m00:47:50.213021 [debug] [MainThread]: Flushing usage events
[0m00:47:50.646958 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:47:57.045601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d853770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef8b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef8b4d0>]}


============================== 00:47:57.050446 | c57bd252-dd52-4055-93ea-2ebd87d9f39b ==============================
[0m00:47:57.050446 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:47:57.051227 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build --select silver', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m00:47:57.268133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c57bd252-dd52-4055-93ea-2ebd87d9f39b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2d8510>]}
[0m00:47:57.344902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c57bd252-dd52-4055-93ea-2ebd87d9f39b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee0bdf0>]}
[0m00:47:57.345833 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:47:57.478035 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:47:57.737736 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:47:57.738220 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:47:57.746872 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m00:47:57.815156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c57bd252-dd52-4055-93ea-2ebd87d9f39b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef03350>]}
[0m00:47:58.064716 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:47:58.067707 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:47:58.102127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c57bd252-dd52-4055-93ea-2ebd87d9f39b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe93c50>]}
[0m00:47:58.102788 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1571 macros
[0m00:47:58.105473 [info ] [MainThread]: 
[0m00:47:58.106105 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:47:58.106643 [info ] [MainThread]: 
[0m00:47:58.107240 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:47:58.108100 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:47:58.169931 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:47:58.170394 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:47:58.170723 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:58.195237 [debug] [ThreadPool]: SQL status: SELECT 18 in 0.024 seconds
[0m00:47:58.196856 [debug] [ThreadPool]: On list_elsa: Close
[0m00:47:58.197762 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa_bronze_silver)
[0m00:47:58.199168 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "bronze_silver"
"
[0m00:47:58.207169 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_silver"
[0m00:47:58.207599 [debug] [ThreadPool]: On create_elsa_bronze_silver: BEGIN
[0m00:47:58.207906 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:47:58.213203 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m00:47:58.213623 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_silver"
[0m00:47:58.213944 [debug] [ThreadPool]: On create_elsa_bronze_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "create_elsa_bronze_silver"} */
create schema if not exists "bronze_silver"
[0m00:47:58.214894 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m00:47:58.215899 [debug] [ThreadPool]: On create_elsa_bronze_silver: COMMIT
[0m00:47:58.216270 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze_silver"
[0m00:47:58.216576 [debug] [ThreadPool]: On create_elsa_bronze_silver: COMMIT
[0m00:47:58.217457 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m00:47:58.217871 [debug] [ThreadPool]: On create_elsa_bronze_silver: Close
[0m00:47:58.224980 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa_bronze_silver, now list_elsa_bronze_tec_elsa)
[0m00:47:58.231115 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze_silver'
[0m00:47:58.232752 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:47:58.235595 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_silver"
[0m00:47:58.236151 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m00:47:58.236553 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: BEGIN
[0m00:47:58.236890 [debug] [ThreadPool]: On list_elsa_bronze_silver: BEGIN
[0m00:47:58.241084 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:47:58.241534 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:47:58.241852 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:58.242170 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:47:58.242819 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:58.248484 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:47:58.248926 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m00:47:58.249232 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m00:47:58.249526 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_silver"
[0m00:47:58.249849 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:47:58.250162 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze_tec_elsa"
[0m00:47:58.250504 [debug] [ThreadPool]: On list_elsa_bronze_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_silver'
  
[0m00:47:58.250877 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:47:58.251256 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze_tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze_tec_elsa'
  
[0m00:47:58.256021 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m00:47:58.256559 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.005 seconds
[0m00:47:58.257791 [debug] [ThreadPool]: On list_elsa_bronze_silver: ROLLBACK
[0m00:47:58.258105 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m00:47:58.259685 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: ROLLBACK
[0m00:47:58.261209 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:47:58.261663 [debug] [ThreadPool]: On list_elsa_bronze_silver: Close
[0m00:47:58.262211 [debug] [ThreadPool]: On list_elsa_bronze_tec_elsa: Close
[0m00:47:58.262731 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:47:58.284054 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.284601 [debug] [MainThread]: On master: BEGIN
[0m00:47:58.285010 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:47:58.290817 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:47:58.291390 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.292022 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:47:58.337207 [debug] [MainThread]: SQL status: SELECT 26 in 0.044 seconds
[0m00:47:58.361169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c57bd252-dd52-4055-93ea-2ebd87d9f39b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fed7150>]}
[0m00:47:58.362136 [debug] [MainThread]: On master: ROLLBACK
[0m00:47:58.363133 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.363751 [debug] [MainThread]: On master: BEGIN
[0m00:47:58.364720 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:58.365193 [debug] [MainThread]: On master: COMMIT
[0m00:47:58.365645 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.366071 [debug] [MainThread]: On master: COMMIT
[0m00:47:58.366705 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:47:58.410600 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:47:58.445675 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.446269 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'bronze_tec_elsa__tests'
  
[0m00:47:58.447329 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m00:47:58.450625 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:47:58.454554 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:47:58.455250 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m00:47:58.456208 [info ] [MainThread]: 
[0m00:47:58.456964 [debug] [MainThread]: On master: Close
[0m00:47:58.462056 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m00:47:58.462741 [info ] [Thread-1 (]: 1 of 3 START sql table model bronze_silver.consumption_history ................. [RUN]
[0m00:47:58.463774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze_tec_elsa, now model.dbt_elsa.consumption_history)
[0m00:47:58.464461 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m00:47:58.468503 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m00:47:58.469343 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m00:47:58.513648 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m00:47:58.514535 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:47:58.514924 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m00:47:58.515287 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:47:58.520523 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m00:47:58.520986 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:47:58.521386 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."bronze_silver"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."bronze_silver"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m00:47:58.523869 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze_silver.consumption_history" does not exist
LINE 13: FROM "elsa"."bronze_silver"."consumption_history"
              ^

[0m00:47:58.524368 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m00:47:58.525068 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m00:47:58.538212 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "bronze_silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."bronze_silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:47:58.540666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c57bd252-dd52-4055-93ea-2ebd87d9f39b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107342c0>]}
[0m00:47:58.541605 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model bronze_silver.consumption_history ........ [[31mERROR[0m in 0.08s]
[0m00:47:58.542311 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m00:47:58.542936 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "bronze_silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."bronze_silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m00:47:58.544172 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:47:58.544621 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:47:58.545101 [info ] [Thread-2 (]: 2 of 3 SKIP test not_null_consumption_history_created_at ....................... [[33mSKIP[0m]
[0m00:47:58.545598 [info ] [Thread-3 (]: 3 of 3 SKIP test not_null_consumption_history_date ............................. [[33mSKIP[0m]
[0m00:47:58.546079 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:47:58.546505 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:47:58.546960 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' to be skipped because of status 'skipped'. 
[0m00:47:58.547370 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' to be skipped because of status 'skipped'. 
[0m00:47:58.549345 [info ] [MainThread]: 
[0m00:47:58.549871 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.550313 [debug] [MainThread]: On master: BEGIN
[0m00:47:58.550807 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:47:58.557190 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:47:58.557624 [debug] [MainThread]: On master: COMMIT
[0m00:47:58.557956 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.558267 [debug] [MainThread]: On master: COMMIT
[0m00:47:58.558664 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:47:58.603890 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:58.604413 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."bronze_tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m00:47:58.608166 [debug] [MainThread]: SQL status: SELECT 126 in 0.003 seconds
[0m00:47:58.611305 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:47:58.642957 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m00:47:58.726681 [debug] [MainThread]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m00:47:58.734317 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m00:47:58.735228 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m00:47:58.736453 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m00:47:58.737291 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.082490 (1 runs)
[0m00:47:58.738130 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.093464 (1 runs)
[0m00:47:58.744309 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m00:47:58.866598 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m00:47:58.867992 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m00:47:58.868790 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m00:47:58.870299 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m00:47:58.871150 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.121011 (1 runs)
[0m00:47:58.872017 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.125981 (1 runs)
[0m00:47:58.877313 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m00:47:58.897812 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m00:47:58.899486 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m00:47:58.900270 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m00:47:58.901442 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m00:47:58.902295 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.019287 (1 runs)
[0m00:47:58.903110 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.024083 (1 runs)
[0m00:47:58.908368 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m00:47:58.909876 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m00:47:58.911293 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m00:47:58.912200 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m00:47:58.913795 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m00:47:58.914652 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000410 (1 runs)
[0m00:47:58.915483 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.005403 (1 runs)
[0m00:47:58.920118 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m00:47:58.921457 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m00:47:58.923059 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m00:47:58.924095 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m00:47:58.925327 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m00:47:58.926498 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000351 (1 runs)
[0m00:47:58.927467 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.005136 (1 runs)
[0m00:47:58.932305 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m00:47:58.933649 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m00:47:58.934830 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m00:47:58.935562 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m00:47:58.936814 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m00:47:58.937635 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000346 (1 runs)
[0m00:47:58.938472 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.004461 (1 runs)
[0m00:47:58.944232 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m00:47:58.945730 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m00:47:58.946940 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m00:47:58.947683 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m00:47:58.948856 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m00:47:58.949713 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000408 (1 runs)
[0m00:47:58.950548 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.004596 (1 runs)
[0m00:47:58.955102 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m00:47:58.957440 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m00:47:58.958785 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m00:47:58.959522 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m00:47:58.960906 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m00:47:58.961810 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000392 (1 runs)
[0m00:47:58.962639 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.005660 (1 runs)
[0m00:47:58.967543 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m00:47:59.135759 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 87 artifacts.
[0m00:47:59.137074 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m00:47:59.138033 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m00:47:59.139467 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m00:47:59.140662 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.167104 (1 runs)
[0m00:47:59.141594 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.171733 (1 runs)
[0m00:47:59.142481 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:47:59.146654 [debug] [MainThread]: Elementary: Uploading run results.
[0m00:47:59.147600 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m00:47:59.175387 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 3 artifacts.
[0m00:47:59.197814 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.198288 [debug] [MainThread]: On master: BEGIN
[0m00:47:59.198928 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:59.199309 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.199681 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:47:59.209279 [debug] [MainThread]: SQL status: SELECT 23 in 0.009 seconds
[0m00:47:59.214225 [debug] [MainThread]: Elementary: Inserting 3 rows to table "elsa"."bronze_tec_elsa"."dbt_run_results"
[0m00:47:59.319611 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:59.320830 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.321312 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('c57bd252-dd52-4055-93ea-2ebd87d9f39b.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','c57bd252-dd52-4055-93ea-2ebd87d9f39b','2025-07-18 22:47:59',
    current_timestamp::timestamp
,'consumption_history','Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "bronze_silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."bronze_silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql','error','model',0.07529592514038086,'2025-07-18T22:47:58.469781Z','2025-07-18T22:47:58.524920Z','2025-07-18T22:47:58.464779Z','2025-07-18T22:47:58.469169Z',NULL,False,'SELECT *
FROM "elsa"."bronze_silver"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    (''gaz'', consumption.gaz),
    (''nucleaire'', consumption.nucleaire),
    (''charbon'', consumption.charbon),
    (''solaire'', consumption.solaire),
    (''eolien'', consumption.eolien),
    (''hydraulique'', consumption.hydraulique),
    (''bioenergies'', consumption.bioenergies),
    (''autres'', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('c57bd252-dd52-4055-93ea-2ebd87d9f39b.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','c57bd252-dd52-4055-93ea-2ebd87d9f39b','2025-07-18 22:47:59',
    current_timestamp::timestamp
,'not_null_consumption_history_created_at',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)','test','{}',NULL),('c57bd252-dd52-4055-93ea-2ebd87d9f39b.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','c57bd252-dd52-4055-93ea-2ebd87d9f39b','2025-07-18 22:47:59',
    current_timestamp::timestamp
,'not_null_consumption_history_date',NULL,'skipped','test',0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-3 (worker)','test','{}',NULL)
  
[0m00:47:59.323342 [debug] [MainThread]: SQL status: INSERT 0 3 in 0.001 seconds
[0m00:47:59.325686 [debug] [MainThread]: On master: COMMIT
[0m00:47:59.326082 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.326427 [debug] [MainThread]: On master: COMMIT
[0m00:47:59.327542 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:59.329882 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m00:47:59.330626 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.026801 (1 runs)
[0m00:47:59.331341 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.023691 (1 runs)
[0m00:47:59.332072 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000649 (1 runs)
[0m00:47:59.332773 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.073741 (3 runs)
[0m00:47:59.333917 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.084417 (1 runs)
[0m00:47:59.334630 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.004789 (1 runs)
[0m00:47:59.335335 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.002883 (1 runs)
[0m00:47:59.336086 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.138950 (1 runs)
[0m00:47:59.336781 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.182066 (1 runs)
[0m00:47:59.337586 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m00:47:59.347772 [debug] [MainThread]: Elementary: Handling test results.
[0m00:47:59.400217 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.400750 [debug] [MainThread]: On master: BEGIN
[0m00:47:59.401491 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:59.401897 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.402352 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'elementary_test_results'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:47:59.407269 [debug] [MainThread]: SQL status: SELECT 28 in 0.004 seconds
[0m00:47:59.410375 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."bronze_tec_elsa"."elementary_test_results"
[0m00:47:59.450535 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:59.451739 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.452315 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."elementary_test_results"
         (id,data_issue_id,test_execution_id,test_unique_id,model_unique_id,invocation_id,detected_at,created_at,database_name,schema_name,table_name,column_name,test_type,test_sub_type,test_results_description,owners,tags,test_results_query,other,test_name,test_params,severity,status,failures,test_short_name,test_alias,result_rows,failed_row_count) values
    ('c57bd252-dd52-4055-93ea-2ebd87d9f39b.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9',NULL,'c57bd252-dd52-4055-93ea-2ebd87d9f39b.test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','model.dbt_elsa.consumption_history','c57bd252-dd52-4055-93ea-2ebd87d9f39b',cast('2025-07-18 22:47:59' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze_silver','consumption_history','created_at','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_created_at','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_created_at',NULL,NULL),('c57bd252-dd52-4055-93ea-2ebd87d9f39b.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4',NULL,'c57bd252-dd52-4055-93ea-2ebd87d9f39b.test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','model.dbt_elsa.consumption_history','c57bd252-dd52-4055-93ea-2ebd87d9f39b',cast('2025-07-18 22:47:59' as timestamp),
    current_timestamp::timestamp
,'elsa','bronze_silver','consumption_history','date','dbt_test','generic',NULL,'[]','[]',NULL,NULL,'not_null_consumption_history_date','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}','ERROR','skipped',NULL,'not_null','not_null_consumption_history_date',NULL,NULL)
  
[0m00:47:59.453631 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m00:47:59.456118 [debug] [MainThread]: On master: COMMIT
[0m00:47:59.456786 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.457380 [debug] [MainThread]: On master: COMMIT
[0m00:47:59.459128 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:59.461406 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:47:59.477585 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m00:47:59.561518 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.562046 [debug] [MainThread]: On master: BEGIN
[0m00:47:59.562731 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:47:59.563176 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.563671 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'bronze_tec_elsa'
        
      order by ordinal_position

  
[0m00:47:59.567656 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m00:47:59.570619 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."bronze_tec_elsa"."dbt_invocations"
[0m00:47:59.593029 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m00:47:59.594583 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.596338 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    
       insert into "elsa"."bronze_tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('c57bd252-dd52-4055-93ea-2ebd87d9f39b',NULL,NULL,NULL,'2025-07-18 22:47:57','2025-07-18 22:47:59','2025-07-18 22:47:59',
    current_timestamp::timestamp
,'build','1.10.4','0.19.0',False,'{}','{}','dev_live','elsa','bronze','dbt_elsa',16,'["silver"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{"user": "elsalebihan"}')
  
[0m00:47:59.600184 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m00:47:59.603308 [debug] [MainThread]: On master: COMMIT
[0m00:47:59.603775 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:59.604144 [debug] [MainThread]: On master: COMMIT
[0m00:47:59.605449 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:47:59.607373 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m00:47:59.614414 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:47:59.615644 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:47:59.616205 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.06s]
[0m00:47:59.616602 [debug] [MainThread]: On master: Close
[0m00:47:59.617077 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:47:59.617372 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m00:47:59.617647 [debug] [MainThread]: Connection 'list_elsa_bronze_silver' was properly closed.
[0m00:47:59.617915 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m00:47:59.618295 [info ] [MainThread]: 
[0m00:47:59.618651 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.51 seconds (1.51s).
[0m00:47:59.619823 [debug] [MainThread]: Command end result
[0m00:47:59.704695 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:47:59.707495 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:47:59.713860 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:47:59.714302 [info ] [MainThread]: 
[0m00:47:59.714726 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m00:47:59.715232 [info ] [MainThread]: 
[0m00:47:59.715820 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m00:47:59.716368 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "bronze_silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."bronze_silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:47:59.716750 [info ] [MainThread]: 
[0m00:47:59.717199 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m00:47:59.717584 [info ] [MainThread]: 
[0m00:47:59.717943 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=5
[0m00:47:59.720744 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.7644887, "process_in_blocks": "0", "process_kernel_time": 0.479323, "process_mem_max_rss": "137117696", "process_out_blocks": "0", "process_user_time": 3.844062}
[0m00:47:59.721525 [debug] [MainThread]: Command `dbt build` failed at 00:47:59.721350 after 2.77 seconds
[0m00:47:59.722139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed7ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106c7cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106c7c20>]}
[0m00:47:59.722646 [debug] [MainThread]: Flushing usage events
[0m00:48:00.117578 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:54:30.610205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088d3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a00b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a00b4d0>]}


============================== 00:54:30.618671 | 353fcb85-17e8-4b9c-97bd-7354b469b114 ==============================
[0m00:54:30.618671 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:54:30.619892 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select silver', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m00:54:30.945715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '353fcb85-17e8-4b9c-97bd-7354b469b114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109358510>]}
[0m00:54:31.026684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '353fcb85-17e8-4b9c-97bd-7354b469b114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e8bdf0>]}
[0m00:54:31.028150 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:54:31.186754 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:54:31.358552 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m00:54:31.359505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '353fcb85-17e8-4b9c-97bd-7354b469b114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b29c450>]}
[0m00:54:36.710329 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m00:54:36.726471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '353fcb85-17e8-4b9c-97bd-7354b469b114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac80c80>]}
[0m00:54:36.898377 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:54:36.904453 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:54:36.989523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '353fcb85-17e8-4b9c-97bd-7354b469b114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b020130>]}
[0m00:54:36.990096 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m00:54:36.993158 [info ] [MainThread]: 
[0m00:54:36.993811 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:54:36.994178 [info ] [MainThread]: 
[0m00:54:36.994730 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:54:36.995624 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:54:37.071907 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:54:37.072412 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:54:37.072842 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:54:37.119651 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.047 seconds
[0m00:54:37.121896 [debug] [ThreadPool]: On list_elsa: Close
[0m00:54:37.131548 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m00:54:37.132200 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_silver'
[0m00:54:37.139457 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_tec_elsa'
[0m00:54:37.140100 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:54:37.143846 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:54:37.146455 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:54:37.146816 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:54:37.147160 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m00:54:37.147510 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m00:54:37.147828 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:54:37.148132 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:54:37.148433 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:54:37.155968 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:54:37.156394 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m00:54:37.156705 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:54:37.156996 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m00:54:37.157310 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:54:37.157653 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m00:54:37.158028 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:54:37.158534 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:54:37.159174 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m00:54:37.164396 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m00:54:37.164840 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m00:54:37.165146 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m00:54:37.166383 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m00:54:37.167684 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:54:37.168802 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m00:54:37.169325 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m00:54:37.169700 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:54:37.170052 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m00:54:37.180180 [debug] [MainThread]: Using postgres connection "master"
[0m00:54:37.180688 [debug] [MainThread]: On master: BEGIN
[0m00:54:37.180984 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:54:37.186257 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m00:54:37.186666 [debug] [MainThread]: Using postgres connection "master"
[0m00:54:37.187066 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:54:37.237062 [debug] [MainThread]: SQL status: SELECT 26 in 0.050 seconds
[0m00:54:37.239222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '353fcb85-17e8-4b9c-97bd-7354b469b114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7fda50>]}
[0m00:54:37.239832 [debug] [MainThread]: On master: ROLLBACK
[0m00:54:37.240493 [debug] [MainThread]: Using postgres connection "master"
[0m00:54:37.240917 [debug] [MainThread]: On master: BEGIN
[0m00:54:37.241638 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:54:37.242138 [debug] [MainThread]: On master: COMMIT
[0m00:54:37.242566 [debug] [MainThread]: Using postgres connection "master"
[0m00:54:37.242901 [debug] [MainThread]: On master: COMMIT
[0m00:54:37.243441 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:54:37.265901 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:54:37.302475 [debug] [MainThread]: Using postgres connection "master"
[0m00:54:37.303084 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'tec_elsa__tests'
  
[0m00:54:37.304131 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m00:54:37.307748 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:54:37.312360 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:54:37.312981 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.07s]
[0m00:54:37.313324 [info ] [MainThread]: 
[0m00:54:37.313743 [debug] [MainThread]: On master: Close
[0m00:54:37.318219 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m00:54:37.319192 [info ] [Thread-1 (]: 1 of 3 START sql table model silver.consumption_history ........................ [RUN]
[0m00:54:37.319998 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption_history)
[0m00:54:37.320551 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m00:54:37.326404 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m00:54:37.328191 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m00:54:37.382559 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m00:54:37.383813 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:54:37.384208 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m00:54:37.384567 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:54:37.389950 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m00:54:37.390400 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:54:37.390805 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."silver"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."silver"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m00:54:37.392029 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "silver.consumption_history" does not exist
LINE 13: FROM "elsa"."silver"."consumption_history"
              ^

[0m00:54:37.392605 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m00:54:37.393441 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m00:54:37.408544 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:54:37.410693 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '353fcb85-17e8-4b9c-97bd-7354b469b114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b02b7d0>]}
[0m00:54:37.411400 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model silver.consumption_history ............... [[31mERROR[0m in 0.09s]
[0m00:54:37.412067 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m00:54:37.412644 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m00:54:37.414232 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:54:37.414708 [info ] [Thread-2 (]: 2 of 3 SKIP test not_null_consumption_history_created_at ....................... [[33mSKIP[0m]
[0m00:54:37.415198 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:54:37.415613 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:54:37.416035 [info ] [Thread-3 (]: 3 of 3 SKIP test not_null_consumption_history_date ............................. [[33mSKIP[0m]
[0m00:54:37.416686 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' to be skipped because of status 'skipped'. 
[0m00:54:37.417146 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:54:37.417700 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' to be skipped because of status 'skipped'. 
[0m00:54:37.419882 [info ] [MainThread]: 
[0m00:54:37.420470 [debug] [MainThread]: Using postgres connection "master"
[0m00:54:37.420829 [debug] [MainThread]: On master: BEGIN
[0m00:54:37.421250 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:54:37.427195 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:54:37.427605 [debug] [MainThread]: On master: COMMIT
[0m00:54:37.428017 [debug] [MainThread]: Using postgres connection "master"
[0m00:54:37.428330 [debug] [MainThread]: On master: COMMIT
[0m00:54:37.428831 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:54:37.454008 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:54:37.460151 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:54:37.473257 [debug] [MainThread]: Elementary: Handling test results.
[0m00:54:37.697101 [warn ] [MainThread]: Missing Elementary models in 'elsa.tec_elsa'. Please run 'dbt run -s elementary --target dev_live'.
[0m00:54:37.730391 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:54:37.752767 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:54:37.754875 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:54:37.755622 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.33s]
[0m00:54:37.756157 [debug] [MainThread]: On master: Close
[0m00:54:37.756798 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:54:37.757267 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m00:54:37.757665 [debug] [MainThread]: Connection 'list_elsa_silver' was properly closed.
[0m00:54:37.758122 [debug] [MainThread]: Connection 'list_elsa_tec_elsa' was properly closed.
[0m00:54:37.758686 [info ] [MainThread]: 
[0m00:54:37.759895 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 0.76 seconds (0.76s).
[0m00:54:37.761695 [debug] [MainThread]: Command end result
[0m00:54:37.851682 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:54:37.854320 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:54:37.862201 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:54:37.862655 [info ] [MainThread]: 
[0m00:54:37.863099 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m00:54:37.863518 [info ] [MainThread]: 
[0m00:54:37.864205 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m00:54:37.865039 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:54:37.865489 [info ] [MainThread]: 
[0m00:54:37.865913 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m00:54:37.866257 [info ] [MainThread]: 
[0m00:54:37.866637 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=5
[0m00:54:37.870549 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 7.366949, "process_in_blocks": "0", "process_kernel_time": 0.899415, "process_mem_max_rss": "145317888", "process_out_blocks": "0", "process_user_time": 8.622473}
[0m00:54:37.871277 [debug] [MainThread]: Command `dbt build` failed at 00:54:37.871122 after 7.37 seconds
[0m00:54:37.871831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b437c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bab2ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bab0730>]}
[0m00:54:37.872310 [debug] [MainThread]: Flushing usage events
[0m00:54:38.331879 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:55:05.625271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0ef770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f82b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f82b4d0>]}


============================== 00:55:05.633128 | 64a80718-c515-4639-8a9e-9874d90f600a ==============================
[0m00:55:05.633128 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:55:05.633969 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:55:05.897835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb78510>]}
[0m00:55:05.979044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6abdf0>]}
[0m00:55:05.980509 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:55:06.133429 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:55:06.541204 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:55:06.541698 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:55:06.550374 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m00:55:06.623022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f79f450>]}
[0m00:55:06.878986 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:55:06.882252 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:55:06.943431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11077fc50>]}
[0m00:55:06.944107 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m00:55:06.946694 [info ] [MainThread]: 
[0m00:55:06.947125 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:55:06.947609 [info ] [MainThread]: 
[0m00:55:06.948229 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:55:06.949140 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:55:07.020069 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:55:07.020517 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:55:07.020834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:55:07.057947 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.037 seconds
[0m00:55:07.060050 [debug] [ThreadPool]: On list_elsa: Close
[0m00:55:07.067086 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_tec_elsa)
[0m00:55:07.067703 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m00:55:07.080053 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_silver'
[0m00:55:07.081392 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:55:07.084510 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:55:07.079525 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:55:07.084982 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m00:55:07.085319 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m00:55:07.085642 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:55:07.085963 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:55:07.086281 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:55:07.086594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:55:07.096117 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m00:55:07.096575 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m00:55:07.096885 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m00:55:07.097185 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:55:07.097564 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:55:07.097895 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:55:07.098375 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:55:07.098824 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m00:55:07.099209 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m00:55:07.105038 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m00:55:07.105674 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m00:55:07.106169 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.007 seconds
[0m00:55:07.107960 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m00:55:07.109984 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m00:55:07.111510 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:55:07.112212 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m00:55:07.112645 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:55:07.112993 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m00:55:07.122988 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:07.123726 [debug] [MainThread]: On master: BEGIN
[0m00:55:07.124217 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:55:07.130279 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:55:07.130685 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:07.131080 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:55:07.171331 [debug] [MainThread]: SQL status: SELECT 26 in 0.040 seconds
[0m00:55:07.173758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110777150>]}
[0m00:55:07.174335 [debug] [MainThread]: On master: ROLLBACK
[0m00:55:07.175622 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:07.176798 [debug] [MainThread]: On master: BEGIN
[0m00:55:07.177793 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:55:07.178217 [debug] [MainThread]: On master: COMMIT
[0m00:55:07.178559 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:07.178863 [debug] [MainThread]: On master: COMMIT
[0m00:55:07.179452 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:55:07.233412 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:55:07.270115 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:07.270722 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'tec_elsa__tests'
  
[0m00:55:07.272030 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m00:55:07.275307 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:55:07.279758 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:55:07.280464 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.10s]
[0m00:55:07.280857 [info ] [MainThread]: 
[0m00:55:07.281284 [debug] [MainThread]: On master: Close
[0m00:55:07.286266 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m00:55:07.286933 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m00:55:07.287587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now model.dbt_elsa.consumption)
[0m00:55:07.288050 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m00:55:07.293088 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m00:55:07.295203 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m00:55:07.339307 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m00:55:07.341388 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.342290 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m00:55:07.342842 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:55:07.348451 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m00:55:07.348992 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.349409 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m00:55:07.355709 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.006 seconds
[0m00:55:07.367568 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.368027 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m00:55:07.368935 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:55:07.372880 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.373316 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m00:55:07.374235 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:55:07.399744 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.400217 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m00:55:07.401129 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m00:55:07.414570 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.415118 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m00:55:07.427020 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.011 seconds
[0m00:55:07.432332 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.432880 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m00:55:07.433786 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m00:55:07.435090 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m00:55:07.435511 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.435897 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m00:55:07.436940 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m00:55:07.445185 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m00:55:07.450721 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:07.451173 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m00:55:07.453336 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m00:55:07.455913 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m00:55:07.458376 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115074d50>]}
[0m00:55:07.459272 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.17s]
[0m00:55:07.459986 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m00:55:07.460872 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:07.461306 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m00:55:07.461801 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m00:55:07.462190 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:07.468528 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:07.475460 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m00:55:07.476348 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:07.478907 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:07.479351 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_elsa_silver, now test.dbt_elsa.not_null_consumption_date.0e210070dc)
[0m00:55:07.479782 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m00:55:07.480337 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:07.480895 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m00:55:07.486620 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:07.487108 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:07.487631 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:07.497244 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:07.500041 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:55:07.500584 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:07.501057 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151184d0>]}
[0m00:55:07.504024 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:55:07.504690 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:07.521366 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '64a80718-c515-4639-8a9e-9874d90f600a', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fccb50>]}
[0m00:55:07.911253 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:07.913093 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:07.913518 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:07.915624 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:07.916339 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:07.916796 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:07.917184 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m00:55:07.917581 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m00:55:07.917960 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m00:55:07.918343 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:55:07.918719 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m00:55:07.919090 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:55:07.926191 [debug] [Thread-3 (]: SQL status: BEGIN in 0.007 seconds
[0m00:55:07.926945 [debug] [Thread-2 (]: SQL status: BEGIN in 0.009 seconds
[0m00:55:07.927426 [debug] [Thread-4 (]: SQL status: BEGIN in 0.009 seconds
[0m00:55:07.927983 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:07.928438 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:07.928970 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:07.929635 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m00:55:07.930376 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m00:55:07.931222 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m00:55:07.934135 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m00:55:07.934900 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.003 seconds
[0m00:55:07.935590 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.004 seconds
[0m00:55:08.052305 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m00:55:08.053641 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m00:55:08.055942 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m00:55:08.056578 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m00:55:08.056992 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m00:55:08.057413 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m00:55:08.058093 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.60s]
[0m00:55:08.062376 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:08.059184 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.58s]
[0m00:55:08.063603 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.58s]
[0m00:55:08.064510 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:08.065146 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:08.067753 [info ] [MainThread]: 
[0m00:55:08.068270 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:08.068595 [debug] [MainThread]: On master: BEGIN
[0m00:55:08.068899 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:55:08.075242 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:55:08.076154 [debug] [MainThread]: On master: COMMIT
[0m00:55:08.076758 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:08.077109 [debug] [MainThread]: On master: COMMIT
[0m00:55:08.077671 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:55:08.115945 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:55:08.122723 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:55:08.139235 [debug] [MainThread]: Elementary: Handling test results.
[0m00:55:08.203921 [warn ] [MainThread]: Missing Elementary models in 'elsa.tec_elsa'. Please run 'dbt run -s elementary --target dev_live'.
[0m00:55:08.231675 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:55:08.256287 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:55:08.257346 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:55:08.257962 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.18s]
[0m00:55:08.258382 [debug] [MainThread]: On master: Close
[0m00:55:08.258943 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:55:08.259438 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m00:55:08.260068 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m00:55:08.260394 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m00:55:08.260677 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m00:55:08.261055 [info ] [MainThread]: 
[0m00:55:08.261408 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 1.31 seconds (1.31s).
[0m00:55:08.262947 [debug] [MainThread]: Command end result
[0m00:55:08.354884 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:55:08.357560 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:55:08.364784 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:55:08.365237 [info ] [MainThread]: 
[0m00:55:08.365650 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:55:08.366023 [info ] [MainThread]: 
[0m00:55:08.366424 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m00:55:08.367008 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m00:55:08.370651 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 2.8469899, "process_in_blocks": "0", "process_kernel_time": 0.70692, "process_mem_max_rss": "136994816", "process_out_blocks": "0", "process_user_time": 4.158226}
[0m00:55:08.371416 [debug] [MainThread]: Command `dbt build` succeeded at 00:55:08.371173 after 2.85 seconds
[0m00:55:08.371911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115080b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115019ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11092c750>]}
[0m00:55:08.372518 [debug] [MainThread]: Flushing usage events
[0m00:55:08.860691 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:55:46.846924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105067770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10679b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10679b4d0>]}


============================== 00:55:46.851913 | 852eb8df-87cd-48f2-9c26-431f3c5b616e ==============================
[0m00:55:46.851913 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:55:46.852582 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'invocation_command': 'dbt build --select bronze', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:55:47.076627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ae8510>]}
[0m00:55:47.174272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661bdf0>]}
[0m00:55:47.175725 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:55:47.396869 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:55:47.565297 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m00:55:47.565986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a34450>]}
[0m00:55:53.013236 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m00:55:53.028352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107414320>]}
[0m00:55:53.223592 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:55:53.227341 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:55:53.281426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074bc130>]}
[0m00:55:53.282080 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m00:55:53.284911 [info ] [MainThread]: 
[0m00:55:53.285369 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:55:53.285746 [info ] [MainThread]: 
[0m00:55:53.286301 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:55:53.287153 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:55:53.349244 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:55:53.349742 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:55:53.350076 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:55:53.374498 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.024 seconds
[0m00:55:53.375982 [debug] [ThreadPool]: On list_elsa: Close
[0m00:55:53.383088 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m00:55:53.383715 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_tec_elsa'
[0m00:55:53.390826 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:55:53.393937 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:55:53.394505 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_silver'
[0m00:55:53.394926 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:55:53.395266 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m00:55:53.398080 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:55:53.398447 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:55:53.398819 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:55:53.399146 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m00:55:53.399816 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:55:53.405802 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:55:53.406237 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:55:53.406557 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m00:55:53.406856 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:55:53.407178 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:55:53.407496 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:55:53.407846 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:55:53.408214 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m00:55:53.408580 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m00:55:53.413139 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m00:55:53.413580 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m00:55:53.414846 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m00:55:53.415185 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m00:55:53.416347 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m00:55:53.417721 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:55:53.418082 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m00:55:53.418547 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m00:55:53.419049 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:55:53.428510 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:53.428910 [debug] [MainThread]: On master: BEGIN
[0m00:55:53.429207 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:55:53.434471 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m00:55:53.434859 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:53.435256 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:55:53.478201 [debug] [MainThread]: SQL status: SELECT 26 in 0.042 seconds
[0m00:55:53.480062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f89a50>]}
[0m00:55:53.480573 [debug] [MainThread]: On master: ROLLBACK
[0m00:55:53.481093 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:53.481433 [debug] [MainThread]: On master: BEGIN
[0m00:55:53.482067 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:55:53.482427 [debug] [MainThread]: On master: COMMIT
[0m00:55:53.482761 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:53.483199 [debug] [MainThread]: On master: COMMIT
[0m00:55:53.483711 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:55:53.507312 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:55:53.544541 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:53.545173 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'tec_elsa__tests'
  
[0m00:55:53.546249 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m00:55:53.549546 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:55:53.553368 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:55:53.554050 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.07s]
[0m00:55:53.554509 [info ] [MainThread]: 
[0m00:55:53.554900 [debug] [MainThread]: On master: Close
[0m00:55:53.559198 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m00:55:53.560037 [info ] [Thread-1 (]: 1 of 4 START sql table model bronze.consumption ................................ [RUN]
[0m00:55:53.560724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption)
[0m00:55:53.561254 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m00:55:53.565738 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m00:55:53.566512 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m00:55:53.616912 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m00:55:53.617832 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.618335 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m00:55:53.618711 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:55:53.624809 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m00:55:53.625642 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.626249 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "elsa"."bronze"."rte_eco2mix"
  );
  
[0m00:55:53.630758 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.004 seconds
[0m00:55:53.643578 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.644207 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption" rename to "consumption__dbt_backup"
[0m00:55:53.645043 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m00:55:53.649413 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.649879 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
alter table "elsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m00:55:53.650845 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:55:53.676884 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.677373 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "elsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m00:55:53.678262 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m00:55:53.691970 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.692671 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m00:55:53.700629 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.007 seconds
[0m00:55:53.705932 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.706505 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "elsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m00:55:53.707554 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m00:55:53.708922 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m00:55:53.709431 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.709923 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m00:55:53.711477 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m00:55:53.719596 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."consumption__dbt_backup"
[0m00:55:53.726587 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m00:55:53.727041 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "elsa"."bronze"."consumption__dbt_backup" cascade
[0m00:55:53.729674 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m00:55:53.732348 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m00:55:53.734615 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a6bf50>]}
[0m00:55:53.735591 [info ] [Thread-1 (]: 1 of 4 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.17s]
[0m00:55:53.736351 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m00:55:53.737113 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:53.737559 [debug] [Thread-4 (]: Began running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:53.738169 [info ] [Thread-2 (]: 2 of 4 START test not_null_consumption_created_at .............................. [RUN]
[0m00:55:53.738768 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:53.739163 [info ] [Thread-4 (]: 4 of 4 START test not_null_consumption_id ...................................... [RUN]
[0m00:55:53.739726 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now test.dbt_elsa.not_null_consumption_created_at.93906ad963)
[0m00:55:53.740171 [info ] [Thread-3 (]: 3 of 4 START test not_null_consumption_date .................................... [RUN]
[0m00:55:53.740718 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_elsa.not_null_consumption_id.186948fd55'
[0m00:55:53.741115 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:53.741527 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_elsa_silver, now test.dbt_elsa.not_null_consumption_date.0e210070dc)
[0m00:55:53.742392 [debug] [Thread-4 (]: Began compiling node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:53.755093 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:53.757442 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:53.762589 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:53.767587 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:53.768508 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:53.771177 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:55:53.771764 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:53.772084 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107abafc0>]}
[0m00:55:53.772445 [debug] [Thread-4 (]: Began executing node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:53.775295 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:55:53.805489 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '852eb8df-87cd-48f2-9c26-431f3c5b616e', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083e5db0>]}
[0m00:55:54.197942 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:54.198831 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:54.199459 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:54.200289 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:54.200682 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: BEGIN
[0m00:55:54.201044 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:55:54.201717 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:54.202120 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: BEGIN
[0m00:55:54.202522 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m00:55:54.203246 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:54.203710 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: BEGIN
[0m00:55:54.204160 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:55:54.207817 [debug] [Thread-2 (]: SQL status: BEGIN in 0.007 seconds
[0m00:55:54.208270 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_created_at.93906ad963"
[0m00:55:54.208882 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_created_at.93906ad963"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."bronze"."consumption"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m00:55:54.209483 [debug] [Thread-4 (]: SQL status: BEGIN in 0.007 seconds
[0m00:55:54.210121 [debug] [Thread-4 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_id.186948fd55"
[0m00:55:54.210565 [debug] [Thread-3 (]: SQL status: BEGIN in 0.006 seconds
[0m00:55:54.210987 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_id.186948fd55"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from "elsa"."bronze"."consumption"
where id is null



  
  
      
    ) dbt_internal_test
[0m00:55:54.211401 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m00:55:54.211818 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_date.0e210070dc"
[0m00:55:54.217723 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.005 seconds
[0m00:55:54.234616 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_date.0e210070dc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."bronze"."consumption"
where date is null



  
  
      
    ) dbt_internal_test
[0m00:55:54.279398 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.006 seconds
[0m00:55:54.324987 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: ROLLBACK
[0m00:55:54.324100 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: ROLLBACK
[0m00:55:54.330843 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: ROLLBACK
[0m00:55:54.331871 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_date.0e210070dc: Close
[0m00:55:54.332430 [debug] [Thread-4 (]: On test.dbt_elsa.not_null_consumption_id.186948fd55: Close
[0m00:55:54.332854 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_created_at.93906ad963: Close
[0m00:55:54.333990 [info ] [Thread-3 (]: 3 of 4 PASS not_null_consumption_date .......................................... [[32mPASS[0m in 0.59s]
[0m00:55:54.335128 [info ] [Thread-4 (]: 4 of 4 PASS not_null_consumption_id ............................................ [[32mPASS[0m in 0.59s]
[0m00:55:54.336798 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_date.0e210070dc
[0m00:55:54.335986 [info ] [Thread-2 (]: 2 of 4 PASS not_null_consumption_created_at .................................... [[32mPASS[0m in 0.60s]
[0m00:55:54.337858 [debug] [Thread-4 (]: Finished running node test.dbt_elsa.not_null_consumption_id.186948fd55
[0m00:55:54.338717 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_created_at.93906ad963
[0m00:55:54.341067 [info ] [MainThread]: 
[0m00:55:54.341735 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:54.342563 [debug] [MainThread]: On master: BEGIN
[0m00:55:54.343196 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:55:54.348702 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m00:55:54.349114 [debug] [MainThread]: On master: COMMIT
[0m00:55:54.349456 [debug] [MainThread]: Using postgres connection "master"
[0m00:55:54.349769 [debug] [MainThread]: On master: COMMIT
[0m00:55:54.350240 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:55:54.371552 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:55:54.379148 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:55:54.395342 [debug] [MainThread]: Elementary: Handling test results.
[0m00:55:54.463677 [warn ] [MainThread]: Missing Elementary models in 'elsa.tec_elsa'. Please run 'dbt run -s elementary --target dev_live'.
[0m00:55:54.490221 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:55:54.512964 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:55:54.513926 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:55:54.514563 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.16s]
[0m00:55:54.515004 [debug] [MainThread]: On master: Close
[0m00:55:54.515654 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:55:54.516007 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m00:55:54.516300 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_created_at.93906ad963' was properly closed.
[0m00:55:54.516579 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_date.0e210070dc' was properly closed.
[0m00:55:54.516852 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_id.186948fd55' was properly closed.
[0m00:55:54.517230 [info ] [MainThread]: 
[0m00:55:54.517588 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 3 data tests in 0 hours 0 minutes and 1.23 seconds (1.23s).
[0m00:55:54.519225 [debug] [MainThread]: Command end result
[0m00:55:54.719146 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:55:54.721780 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:55:54.729643 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:55:54.730020 [info ] [MainThread]: 
[0m00:55:54.730408 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:55:54.730763 [info ] [MainThread]: 
[0m00:55:54.731212 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m00:55:54.731930 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 3 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m00:55:54.736705 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 7.982184, "process_in_blocks": "0", "process_kernel_time": 0.573011, "process_mem_max_rss": "149336064", "process_out_blocks": "0", "process_user_time": 8.761868}
[0m00:55:54.737272 [debug] [MainThread]: Command `dbt build` succeeded at 00:55:54.737150 after 7.98 seconds
[0m00:55:54.737851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10763a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074903d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101eb6040>]}
[0m00:55:54.738353 [debug] [MainThread]: Flushing usage events
[0m00:55:55.135137 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:56:32.336050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089e7770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a11b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a11b4d0>]}


============================== 00:56:32.344413 | bee19619-2d19-4688-9431-7e33766e1346 ==============================
[0m00:56:32.344413 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:56:32.345277 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --select silver', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:56:32.616526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bee19619-2d19-4688-9431-7e33766e1346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109464510>]}
[0m00:56:32.699335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bee19619-2d19-4688-9431-7e33766e1346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f97df0>]}
[0m00:56:32.700805 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:56:32.860112 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:56:33.284459 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:56:33.284923 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:56:33.293246 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m00:56:33.365400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bee19619-2d19-4688-9431-7e33766e1346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a08b350>]}
[0m00:56:33.628384 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:56:33.632833 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:56:33.701389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bee19619-2d19-4688-9431-7e33766e1346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afc7c50>]}
[0m00:56:33.701950 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m00:56:33.704656 [info ] [MainThread]: 
[0m00:56:33.705085 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:56:33.705428 [info ] [MainThread]: 
[0m00:56:33.706019 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:56:33.706961 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:56:33.782761 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:56:33.783185 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:56:33.783507 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:56:33.817246 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.034 seconds
[0m00:56:33.818718 [debug] [ThreadPool]: On list_elsa: Close
[0m00:56:33.825317 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m00:56:33.826044 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_tec_elsa'
[0m00:56:33.832575 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_silver'
[0m00:56:33.833882 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:56:33.836793 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:56:33.839719 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:56:33.840151 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:56:33.840495 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m00:56:33.840833 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m00:56:33.841228 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:56:33.841568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:56:33.841923 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:56:33.850408 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m00:56:33.850837 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:56:33.851181 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:56:33.851648 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m00:56:33.852002 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m00:56:33.852394 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:56:33.852750 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:56:33.853105 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m00:56:33.853479 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m00:56:33.857908 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m00:56:33.858348 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m00:56:33.859832 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m00:56:33.860519 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m00:56:33.862003 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:56:33.863267 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m00:56:33.863646 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m00:56:33.864009 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:56:33.864348 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m00:56:33.873295 [debug] [MainThread]: Using postgres connection "master"
[0m00:56:33.873810 [debug] [MainThread]: On master: BEGIN
[0m00:56:33.874174 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:56:33.880386 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:56:33.880803 [debug] [MainThread]: Using postgres connection "master"
[0m00:56:33.881255 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:56:33.924107 [debug] [MainThread]: SQL status: SELECT 26 in 0.042 seconds
[0m00:56:33.925908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bee19619-2d19-4688-9431-7e33766e1346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b42a510>]}
[0m00:56:33.926421 [debug] [MainThread]: On master: ROLLBACK
[0m00:56:33.927270 [debug] [MainThread]: Using postgres connection "master"
[0m00:56:33.927786 [debug] [MainThread]: On master: BEGIN
[0m00:56:33.928914 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:56:33.929325 [debug] [MainThread]: On master: COMMIT
[0m00:56:33.929684 [debug] [MainThread]: Using postgres connection "master"
[0m00:56:33.929987 [debug] [MainThread]: On master: COMMIT
[0m00:56:33.930470 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:56:33.974814 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:56:34.013641 [debug] [MainThread]: Using postgres connection "master"
[0m00:56:34.014249 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'tec_elsa__tests'
  
[0m00:56:34.015270 [debug] [MainThread]: SQL status: SELECT 1 in 0.000 seconds
[0m00:56:34.018488 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:56:34.023934 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:56:34.024549 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m00:56:34.024903 [info ] [MainThread]: 
[0m00:56:34.025304 [debug] [MainThread]: On master: Close
[0m00:56:34.030655 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m00:56:34.031456 [info ] [Thread-1 (]: 1 of 3 START sql table model silver.consumption_history ........................ [RUN]
[0m00:56:34.032085 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption_history)
[0m00:56:34.032648 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m00:56:34.036214 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m00:56:34.037428 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m00:56:34.084833 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m00:56:34.085730 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:56:34.086110 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m00:56:34.086462 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:56:34.092760 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m00:56:34.093313 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:56:34.094140 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."silver"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."silver"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m00:56:34.096039 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "silver.consumption_history" does not exist
LINE 13: FROM "elsa"."silver"."consumption_history"
              ^

[0m00:56:34.096475 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m00:56:34.097110 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m00:56:34.115544 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:56:34.117889 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bee19619-2d19-4688-9431-7e33766e1346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7c7860>]}
[0m00:56:34.118743 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model silver.consumption_history ............... [[31mERROR[0m in 0.08s]
[0m00:56:34.119779 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m00:56:34.120444 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m00:56:34.121814 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:56:34.122495 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:56:34.122990 [info ] [Thread-2 (]: 2 of 3 SKIP test not_null_consumption_history_created_at ....................... [[33mSKIP[0m]
[0m00:56:34.123839 [info ] [Thread-3 (]: 3 of 3 SKIP test not_null_consumption_history_date ............................. [[33mSKIP[0m]
[0m00:56:34.125241 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:56:34.126225 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:56:34.126841 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' to be skipped because of status 'skipped'. 
[0m00:56:34.127657 [debug] [Thread-19 ]: Marking all children of 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' to be skipped because of status 'skipped'. 
[0m00:56:34.129411 [info ] [MainThread]: 
[0m00:56:34.130000 [debug] [MainThread]: Using postgres connection "master"
[0m00:56:34.130605 [debug] [MainThread]: On master: BEGIN
[0m00:56:34.130952 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:56:34.137305 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m00:56:34.137744 [debug] [MainThread]: On master: COMMIT
[0m00:56:34.138083 [debug] [MainThread]: Using postgres connection "master"
[0m00:56:34.138390 [debug] [MainThread]: On master: COMMIT
[0m00:56:34.138825 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:56:34.176398 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:56:34.182530 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:56:34.196460 [debug] [MainThread]: Elementary: Handling test results.
[0m00:56:34.426486 [warn ] [MainThread]: Missing Elementary models in 'elsa.tec_elsa'. Please run 'dbt run -s elementary --target dev_live'.
[0m00:56:34.452808 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:56:34.474659 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:56:34.475830 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:56:34.476642 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.34s]
[0m00:56:34.477290 [debug] [MainThread]: On master: Close
[0m00:56:34.477808 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:56:34.478119 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m00:56:34.478401 [debug] [MainThread]: Connection 'list_elsa_tec_elsa' was properly closed.
[0m00:56:34.478674 [debug] [MainThread]: Connection 'list_elsa_silver' was properly closed.
[0m00:56:34.479169 [info ] [MainThread]: 
[0m00:56:34.479742 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 0.77 seconds (0.77s).
[0m00:56:34.481032 [debug] [MainThread]: Command end result
[0m00:56:34.574097 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:56:34.576837 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:56:34.584455 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:56:34.584875 [info ] [MainThread]: 
[0m00:56:34.585432 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m00:56:34.585816 [info ] [MainThread]: 
[0m00:56:34.586378 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m00:56:34.586825 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m00:56:34.587163 [info ] [MainThread]: 
[0m00:56:34.587557 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m00:56:34.587892 [info ] [MainThread]: 
[0m00:56:34.588262 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=5
[0m00:56:34.592701 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 2.355049, "process_in_blocks": "0", "process_kernel_time": 0.526945, "process_mem_max_rss": "135499776", "process_out_blocks": "0", "process_user_time": 3.334715}
[0m00:56:34.593526 [debug] [MainThread]: Command `dbt build` failed at 00:56:34.593296 after 2.36 seconds
[0m00:56:34.594247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f0ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b827d80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b827ee0>]}
[0m00:56:34.594872 [debug] [MainThread]: Flushing usage events
[0m00:56:35.007085 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:58:13.015077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f7f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10567b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10567b4d0>]}


============================== 00:58:13.022990 | d2af7fcb-8a52-4683-8652-5569b481b236 ==============================
[0m00:58:13.022990 [info ] [MainThread]: Running with dbt=1.10.4
[0m00:58:13.024034 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt build --select silver', 'send_anonymous_usage_stats': 'True'}
[0m00:58:13.337999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049f8510>]}
[0m00:58:13.425340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054ffdf0>]}
[0m00:58:13.427209 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:58:13.592501 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m00:58:14.003606 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m00:58:14.004457 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m00:58:14.635341 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m00:58:14.655911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690cc50>]}
[0m00:58:14.829113 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:58:14.833493 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:58:14.896901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d725d0>]}
[0m00:58:14.897442 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m00:58:14.900780 [info ] [MainThread]: 
[0m00:58:14.901538 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m00:58:14.902359 [info ] [MainThread]: 
[0m00:58:14.903180 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:58:14.904157 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m00:58:14.984069 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m00:58:14.984547 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m00:58:14.984905 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:58:15.025484 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.041 seconds
[0m00:58:15.027408 [debug] [ThreadPool]: On list_elsa: Close
[0m00:58:15.035983 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m00:58:15.041883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_silver'
[0m00:58:15.044439 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:58:15.047265 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:58:15.047766 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_tec_elsa'
[0m00:58:15.048164 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m00:58:15.048498 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m00:58:15.051749 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:58:15.052184 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:58:15.052522 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:58:15.052844 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m00:58:15.053490 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:58:15.062744 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m00:58:15.063286 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m00:58:15.063591 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m00:58:15.063896 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m00:58:15.064234 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m00:58:15.064753 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m00:58:15.065310 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m00:58:15.065978 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m00:58:15.066743 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m00:58:15.071989 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m00:58:15.072421 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m00:58:15.072836 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m00:58:15.074243 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m00:58:15.075582 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m00:58:15.076994 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m00:58:15.077655 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m00:58:15.078036 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m00:58:15.078454 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m00:58:15.087716 [debug] [MainThread]: Using postgres connection "master"
[0m00:58:15.088227 [debug] [MainThread]: On master: BEGIN
[0m00:58:15.088654 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:58:15.094109 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m00:58:15.094545 [debug] [MainThread]: Using postgres connection "master"
[0m00:58:15.094970 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:58:15.137538 [debug] [MainThread]: SQL status: SELECT 26 in 0.042 seconds
[0m00:58:15.139387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c14ad0>]}
[0m00:58:15.139956 [debug] [MainThread]: On master: ROLLBACK
[0m00:58:15.140565 [debug] [MainThread]: Using postgres connection "master"
[0m00:58:15.140905 [debug] [MainThread]: On master: BEGIN
[0m00:58:15.141632 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m00:58:15.142077 [debug] [MainThread]: On master: COMMIT
[0m00:58:15.142427 [debug] [MainThread]: Using postgres connection "master"
[0m00:58:15.142826 [debug] [MainThread]: On master: COMMIT
[0m00:58:15.143584 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:58:15.185006 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m00:58:15.224556 [debug] [MainThread]: Using postgres connection "master"
[0m00:58:15.225293 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'tec_elsa__tests'
  
[0m00:58:15.226610 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m00:58:15.230277 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m00:58:15.235378 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m00:58:15.236001 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m00:58:15.236467 [info ] [MainThread]: 
[0m00:58:15.236872 [debug] [MainThread]: On master: Close
[0m00:58:15.242089 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m00:58:15.243087 [info ] [Thread-1 (]: 1 of 3 START sql table model silver.consumption_history ........................ [RUN]
[0m00:58:15.243935 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption_history)
[0m00:58:15.244574 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m00:58:15.248756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m00:58:15.250914 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m00:58:15.306006 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m00:58:15.307111 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.307583 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m00:58:15.308056 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:58:15.314502 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m00:58:15.314960 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.315414 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."silver"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    /*
SELECT *
FROM "elsa"."silver"."consumption_history"
UNION
*/
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM "elsa"."bronze"."consumption"
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m00:58:15.321582 [debug] [Thread-1 (]: SQL status: SELECT 16 in 0.006 seconds
[0m00:58:15.334665 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.335125 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."silver"."consumption_history__dbt_tmp" rename to "consumption_history"
[0m00:58:15.336195 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:58:15.362605 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.363090 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  comment on table "elsa"."silver"."consumption_history" is $dbt_comment_literal_block$The aim of this table is to consolidate history data for consumption
$dbt_comment_literal_block$;

  
[0m00:58:15.364012 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m00:58:15.378116 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.378682 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption_history'
        
        and table_schema = 'silver'
        
      order by ordinal_position

  
[0m00:58:15.386424 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.007 seconds
[0m00:58:15.390822 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.391511 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  
    
    
    comment on column "elsa"."silver"."consumption_history".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".filiere is $dbt_comment_literal_block$filiere$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".volume is $dbt_comment_literal_block$volume$dbt_comment_literal_block$;
  

  
[0m00:58:15.392310 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m00:58:15.393886 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m00:58:15.394366 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.394793 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m00:58:15.395806 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m00:58:15.403398 [debug] [Thread-1 (]: Applying DROP to: "elsa"."silver"."consumption_history__dbt_backup"
[0m00:58:15.409299 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m00:58:15.409760 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
drop table if exists "elsa"."silver"."consumption_history__dbt_backup" cascade
[0m00:58:15.410499 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m00:58:15.413273 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m00:58:15.415700 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107127930>]}
[0m00:58:15.416566 [info ] [Thread-1 (]: 1 of 3 OK created sql table model silver.consumption_history ................... [[32mSELECT 16[0m in 0.17s]
[0m00:58:15.417256 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m00:58:15.418638 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:58:15.419090 [info ] [Thread-2 (]: 2 of 3 START test not_null_consumption_history_created_at ...................... [RUN]
[0m00:58:15.419535 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:58:15.420310 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_silver, now test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9)
[0m00:58:15.420740 [info ] [Thread-3 (]: 3 of 3 START test not_null_consumption_history_date ............................ [RUN]
[0m00:58:15.421298 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:58:15.421784 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4)
[0m00:58:15.432584 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:58:15.443146 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:58:15.438273 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:58:15.444866 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:58:15.445551 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:58:15.448249 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:58:15.451434 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m00:58:15.451937 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071910d0>]}
[0m00:58:15.452288 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'd2af7fcb-8a52-4683-8652-5569b481b236', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bda570>]}
[0m00:58:15.779577 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:58:15.778110 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:58:15.780605 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:58:15.781001 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: BEGIN
[0m00:58:15.781370 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:58:15.781936 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:58:15.782525 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: BEGIN
[0m00:58:15.783049 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:58:15.787282 [debug] [Thread-2 (]: SQL status: BEGIN in 0.006 seconds
[0m00:58:15.787732 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m00:58:15.788123 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."silver"."consumption_history"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m00:58:15.788997 [debug] [Thread-3 (]: SQL status: BEGIN in 0.006 seconds
[0m00:58:15.789385 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m00:58:15.789825 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m00:58:15.790286 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."silver"."consumption_history"
where date is null



  
  
      
    ) dbt_internal_test
[0m00:58:15.803330 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.007 seconds
[0m00:58:15.882356 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: ROLLBACK
[0m00:58:15.882940 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: ROLLBACK
[0m00:58:15.883562 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: Close
[0m00:58:15.884006 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: Close
[0m00:58:15.884683 [info ] [Thread-3 (]: 3 of 3 PASS not_null_consumption_history_date .................................. [[32mPASS[0m in 0.46s]
[0m00:58:15.885313 [info ] [Thread-2 (]: 2 of 3 PASS not_null_consumption_history_created_at ............................ [[32mPASS[0m in 0.47s]
[0m00:58:15.886063 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m00:58:15.886663 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m00:58:15.888471 [info ] [MainThread]: 
[0m00:58:15.888906 [debug] [MainThread]: Using postgres connection "master"
[0m00:58:15.889233 [debug] [MainThread]: On master: BEGIN
[0m00:58:15.889532 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:58:15.896859 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m00:58:15.897278 [debug] [MainThread]: On master: COMMIT
[0m00:58:15.897605 [debug] [MainThread]: Using postgres connection "master"
[0m00:58:15.897911 [debug] [MainThread]: On master: COMMIT
[0m00:58:15.898409 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:58:15.930757 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m00:58:15.937292 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m00:58:15.952470 [debug] [MainThread]: Elementary: Handling test results.
[0m00:58:16.016731 [warn ] [MainThread]: Missing Elementary models in 'elsa.tec_elsa'. Please run 'dbt run -s elementary --target dev_live'.
[0m00:58:16.042150 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m00:58:16.064351 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m00:58:16.066195 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m00:58:16.066768 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.17s]
[0m00:58:16.067269 [debug] [MainThread]: On master: Close
[0m00:58:16.067759 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:58:16.068062 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m00:58:16.068340 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' was properly closed.
[0m00:58:16.068613 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' was properly closed.
[0m00:58:16.068973 [info ] [MainThread]: 
[0m00:58:16.069434 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.17 seconds (1.17s).
[0m00:58:16.070831 [debug] [MainThread]: Command end result
[0m00:58:16.158302 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m00:58:16.161021 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m00:58:16.167767 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m00:58:16.168214 [info ] [MainThread]: 
[0m00:58:16.168604 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:58:16.168942 [info ] [MainThread]: 
[0m00:58:16.169310 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m00:58:16.169877 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m00:58:16.174150 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.276178, "process_in_blocks": "0", "process_kernel_time": 0.770372, "process_mem_max_rss": "144486400", "process_out_blocks": "0", "process_user_time": 4.436843}
[0m00:58:16.174896 [debug] [MainThread]: Command `dbt build` succeeded at 00:58:16.174762 after 3.28 seconds
[0m00:58:16.175323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071bc870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bd3260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106416550>]}
[0m00:58:16.175811 [debug] [MainThread]: Flushing usage events
[0m00:58:16.632284 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:46:52.103248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104507770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bff610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bff4d0>]}


============================== 10:46:52.115311 | 179a8322-d089-4f6f-b49e-45cff5b6464f ==============================
[0m10:46:52.115311 [info ] [MainThread]: Running with dbt=1.10.4
[0m10:46:52.116617 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build --select silver', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:46:52.832209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '179a8322-d089-4f6f-b49e-45cff5b6464f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f80510>]}
[0m10:46:52.905207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '179a8322-d089-4f6f-b49e-45cff5b6464f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a83df0>]}
[0m10:46:52.907394 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m10:46:53.087987 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m10:46:53.602612 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:46:53.603556 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m10:46:54.178808 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m10:46:54.197851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '179a8322-d089-4f6f-b49e-45cff5b6464f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e90c50>]}
[0m10:46:54.380757 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m10:46:54.384590 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m10:46:54.470443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '179a8322-d089-4f6f-b49e-45cff5b6464f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10714a5d0>]}
[0m10:46:54.471056 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m10:46:54.473798 [info ] [MainThread]: 
[0m10:46:54.474211 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m10:46:54.474541 [info ] [MainThread]: 
[0m10:46:54.475097 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:46:54.476004 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m10:46:54.642023 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m10:46:54.642918 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m10:46:54.643637 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:46:54.692608 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.049 seconds
[0m10:46:54.694395 [debug] [ThreadPool]: On list_elsa: Close
[0m10:46:54.701880 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_silver)
[0m10:46:54.702549 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_tec_elsa'
[0m10:46:54.709032 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m10:46:54.710217 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m10:46:54.712875 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m10:46:54.715427 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m10:46:54.715839 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m10:46:54.716181 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m10:46:54.716509 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m10:46:54.716866 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:46:54.717233 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:46:54.717560 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:46:54.724208 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m10:46:54.724612 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m10:46:54.724947 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m10:46:54.725324 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m10:46:54.725678 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m10:46:54.725985 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m10:46:54.726300 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m10:46:54.726638 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m10:46:54.726997 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m10:46:54.738304 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.011 seconds
[0m10:46:54.738758 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.013 seconds
[0m10:46:54.739075 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.012 seconds
[0m10:46:54.740351 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m10:46:54.741708 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m10:46:54.742902 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m10:46:54.743436 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m10:46:54.743797 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m10:46:54.744165 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m10:46:54.753008 [debug] [MainThread]: Using postgres connection "master"
[0m10:46:54.753378 [debug] [MainThread]: On master: BEGIN
[0m10:46:54.753658 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:46:54.758783 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m10:46:54.759193 [debug] [MainThread]: Using postgres connection "master"
[0m10:46:54.759596 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:46:54.812348 [debug] [MainThread]: SQL status: SELECT 26 in 0.052 seconds
[0m10:46:54.814275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '179a8322-d089-4f6f-b49e-45cff5b6464f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10719c4b0>]}
[0m10:46:54.814821 [debug] [MainThread]: On master: ROLLBACK
[0m10:46:54.815393 [debug] [MainThread]: Using postgres connection "master"
[0m10:46:54.815733 [debug] [MainThread]: On master: BEGIN
[0m10:46:54.816325 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m10:46:54.816655 [debug] [MainThread]: On master: COMMIT
[0m10:46:54.816970 [debug] [MainThread]: Using postgres connection "master"
[0m10:46:54.817275 [debug] [MainThread]: On master: COMMIT
[0m10:46:54.817710 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:46:54.856229 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m10:46:54.894226 [debug] [MainThread]: Using postgres connection "master"
[0m10:46:54.894817 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'tec_elsa__tests'
  
[0m10:46:54.899298 [debug] [MainThread]: SQL status: SELECT 1 in 0.004 seconds
[0m10:46:54.902484 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m10:46:54.907392 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m10:46:54.908162 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.09s]
[0m10:46:54.908603 [info ] [MainThread]: 
[0m10:46:54.909043 [debug] [MainThread]: On master: Close
[0m10:46:54.915911 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m10:46:54.916869 [info ] [Thread-1 (]: 1 of 3 START sql table model silver.consumption_history ........................ [RUN]
[0m10:46:54.918055 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_silver, now model.dbt_elsa.consumption_history)
[0m10:46:54.918840 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m10:46:54.926904 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m10:46:54.928067 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m10:46:54.998682 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m10:46:54.999599 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.000289 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m10:46:55.000849 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:46:55.007078 [debug] [Thread-1 (]: SQL status: BEGIN in 0.006 seconds
[0m10:46:55.007542 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.008175 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."silver"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."silver"."consumption_history"
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM "elsa"."bronze"."consumption"
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m10:46:55.036385 [debug] [Thread-1 (]: SQL status: SELECT 16 in 0.028 seconds
[0m10:46:55.047302 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.047799 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."silver"."consumption_history" rename to "consumption_history__dbt_backup"
[0m10:46:55.049579 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:46:55.053682 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.054146 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."silver"."consumption_history__dbt_tmp" rename to "consumption_history"
[0m10:46:55.055090 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:46:55.081626 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.082188 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  comment on table "elsa"."silver"."consumption_history" is $dbt_comment_literal_block$The aim of this table is to consolidate history data for consumption
$dbt_comment_literal_block$;

  
[0m10:46:55.084135 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m10:46:55.098221 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.098847 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption_history'
        
        and table_schema = 'silver'
        
      order by ordinal_position

  
[0m10:46:55.118378 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.019 seconds
[0m10:46:55.122754 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.123224 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  
    
    
    comment on column "elsa"."silver"."consumption_history".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".filiere is $dbt_comment_literal_block$filiere$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".volume is $dbt_comment_literal_block$volume$dbt_comment_literal_block$;
  

  
[0m10:46:55.124011 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m10:46:55.125256 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m10:46:55.125641 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.125993 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m10:46:55.127159 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m10:46:55.134882 [debug] [Thread-1 (]: Applying DROP to: "elsa"."silver"."consumption_history__dbt_backup"
[0m10:46:55.140548 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:46:55.141004 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
drop table if exists "elsa"."silver"."consumption_history__dbt_backup" cascade
[0m10:46:55.149122 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m10:46:55.151958 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m10:46:55.154173 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '179a8322-d089-4f6f-b49e-45cff5b6464f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8d0050>]}
[0m10:46:55.155040 [info ] [Thread-1 (]: 1 of 3 OK created sql table model silver.consumption_history ................... [[32mSELECT 16[0m in 0.23s]
[0m10:46:55.155761 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m10:46:55.156550 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:46:55.156958 [info ] [Thread-2 (]: 2 of 3 START test not_null_consumption_history_created_at ...................... [RUN]
[0m10:46:55.157400 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:46:55.157936 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9)
[0m10:46:55.158332 [info ] [Thread-3 (]: 3 of 3 START test not_null_consumption_history_date ............................ [RUN]
[0m10:46:55.158860 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:46:55.159282 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4)
[0m10:46:55.171834 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:46:55.174372 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:46:55.178917 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:46:55.180272 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:46:55.183322 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m10:46:55.183777 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '179a8322-d089-4f6f-b49e-45cff5b6464f', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107209010>]}
[0m10:46:55.190756 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:46:55.489792 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:46:55.491105 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:46:55.491994 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:46:55.492453 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:46:55.492840 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: BEGIN
[0m10:46:55.493228 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: BEGIN
[0m10:46:55.493627 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:46:55.494232 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:46:55.500080 [debug] [Thread-2 (]: SQL status: BEGIN in 0.006 seconds
[0m10:46:55.500532 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:46:55.500909 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."silver"."consumption_history"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m10:46:55.501385 [debug] [Thread-3 (]: SQL status: BEGIN in 0.008 seconds
[0m10:46:55.501771 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:46:55.502140 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."silver"."consumption_history"
where date is null



  
  
      
    ) dbt_internal_test
[0m10:46:55.502654 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.001 seconds
[0m10:46:55.509468 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.007 seconds
[0m10:46:55.597132 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: ROLLBACK
[0m10:46:55.598526 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: ROLLBACK
[0m10:46:55.599320 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: Close
[0m10:46:55.599729 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: Close
[0m10:46:55.600445 [info ] [Thread-3 (]: 3 of 3 PASS not_null_consumption_history_date .................................. [[32mPASS[0m in 0.44s]
[0m10:46:55.601349 [info ] [Thread-2 (]: 2 of 3 PASS not_null_consumption_history_created_at ............................ [[32mPASS[0m in 0.44s]
[0m10:46:55.602192 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:46:55.602922 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:46:55.605239 [info ] [MainThread]: 
[0m10:46:55.605744 [debug] [MainThread]: Using postgres connection "master"
[0m10:46:55.606422 [debug] [MainThread]: On master: BEGIN
[0m10:46:55.606851 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:46:55.613543 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m10:46:55.613947 [debug] [MainThread]: On master: COMMIT
[0m10:46:55.614265 [debug] [MainThread]: Using postgres connection "master"
[0m10:46:55.614554 [debug] [MainThread]: On master: COMMIT
[0m10:46:55.615000 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:46:55.645517 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m10:46:55.651317 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m10:46:55.664209 [debug] [MainThread]: Elementary: Handling test results.
[0m10:46:55.719855 [warn ] [MainThread]: Missing Elementary models in 'elsa.tec_elsa'. Please run 'dbt run -s elementary --target dev_live'.
[0m10:46:55.745673 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m10:46:55.766875 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m10:46:55.767933 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m10:46:55.768697 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.15s]
[0m10:46:55.769167 [debug] [MainThread]: On master: Close
[0m10:46:55.769853 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:46:55.770163 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m10:46:55.770447 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' was properly closed.
[0m10:46:55.770701 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' was properly closed.
[0m10:46:55.771053 [info ] [MainThread]: 
[0m10:46:55.771514 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.30 seconds (1.30s).
[0m10:46:55.772952 [debug] [MainThread]: Command end result
[0m10:46:55.857942 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m10:46:55.860525 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m10:46:55.866693 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m10:46:55.867234 [info ] [MainThread]: 
[0m10:46:55.867652 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:46:55.868015 [info ] [MainThread]: 
[0m10:46:55.868435 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m10:46:55.869083 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m10:46:55.901192 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.9173152, "process_in_blocks": "0", "process_kernel_time": 0.969667, "process_mem_max_rss": "146464768", "process_out_blocks": "0", "process_user_time": 4.571852}
[0m10:46:55.901816 [debug] [MainThread]: Command `dbt build` succeeded at 10:46:55.901696 after 3.92 seconds
[0m10:46:55.902365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072e94f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b85bed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b85be30>]}
[0m10:46:55.902849 [debug] [MainThread]: Flushing usage events
[0m10:46:56.364033 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:48:30.989286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f7b770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6b3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6b34d0>]}


============================== 10:48:30.995792 | b412fccc-a18c-42b8-bf09-1277f2a74c9f ==============================
[0m10:48:30.995792 [info ] [MainThread]: Running with dbt=1.10.4
[0m10:48:30.996589 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/elsalebihan/dev/ellebihan/test/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build --select silver', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:48:31.242019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa00510>]}
[0m10:48:31.319074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b533df0>]}
[0m10:48:31.320520 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m10:48:31.465865 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m10:48:31.988427 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:48:31.989328 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m10:48:32.570902 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m10:48:32.594345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c948c50>]}
[0m10:48:32.760836 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m10:48:32.764959 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m10:48:32.836144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbfe5d0>]}
[0m10:48:32.836771 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m10:48:32.839598 [info ] [MainThread]: 
[0m10:48:32.840042 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m10:48:32.840385 [info ] [MainThread]: 
[0m10:48:32.840949 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:48:32.841845 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m10:48:32.914807 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m10:48:32.926162 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m10:48:32.927166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:32.997508 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.070 seconds
[0m10:48:32.999611 [debug] [ThreadPool]: On list_elsa: Close
[0m10:48:33.008174 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_silver)
[0m10:48:33.008905 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_tec_elsa'
[0m10:48:33.014831 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m10:48:33.017235 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m10:48:33.020291 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m10:48:33.023104 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m10:48:33.023497 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m10:48:33.023834 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m10:48:33.024156 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m10:48:33.024481 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:48:33.024796 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:33.025106 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:33.032552 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m10:48:33.033063 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m10:48:33.033446 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m10:48:33.033770 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m10:48:33.034100 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m10:48:33.034405 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m10:48:33.034739 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m10:48:33.035100 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m10:48:33.035457 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m10:48:33.039652 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m10:48:33.040079 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m10:48:33.041323 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m10:48:33.041621 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.006 seconds
[0m10:48:33.042822 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m10:48:33.044148 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m10:48:33.044517 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m10:48:33.044917 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m10:48:33.045575 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m10:48:33.054147 [debug] [MainThread]: Using postgres connection "master"
[0m10:48:33.054534 [debug] [MainThread]: On master: BEGIN
[0m10:48:33.054829 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:48:33.060000 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m10:48:33.060399 [debug] [MainThread]: Using postgres connection "master"
[0m10:48:33.060792 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:48:33.100651 [debug] [MainThread]: SQL status: SELECT 26 in 0.039 seconds
[0m10:48:33.102564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce0add0>]}
[0m10:48:33.103084 [debug] [MainThread]: On master: ROLLBACK
[0m10:48:33.103619 [debug] [MainThread]: Using postgres connection "master"
[0m10:48:33.103956 [debug] [MainThread]: On master: BEGIN
[0m10:48:33.104541 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m10:48:33.104897 [debug] [MainThread]: On master: COMMIT
[0m10:48:33.105227 [debug] [MainThread]: Using postgres connection "master"
[0m10:48:33.105541 [debug] [MainThread]: On master: COMMIT
[0m10:48:33.105991 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:48:33.143578 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m10:48:33.181791 [debug] [MainThread]: Using postgres connection "master"
[0m10:48:33.182386 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */

    select count(*) from pg_namespace where nspname = 'tec_elsa__tests'
  
[0m10:48:33.183456 [debug] [MainThread]: SQL status: SELECT 1 in 0.001 seconds
[0m10:48:33.186513 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m10:48:33.190346 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m10:48:33.190932 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.08s]
[0m10:48:33.191277 [info ] [MainThread]: 
[0m10:48:33.191641 [debug] [MainThread]: On master: Close
[0m10:48:33.196530 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m10:48:33.197164 [info ] [Thread-1 (]: 1 of 3 START sql table model silver.consumption_history ........................ [RUN]
[0m10:48:33.197772 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_silver, now model.dbt_elsa.consumption_history)
[0m10:48:33.198871 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m10:48:33.203742 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m10:48:33.204587 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m10:48:33.249758 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m10:48:33.250658 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.251086 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m10:48:33.251465 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:33.256943 [debug] [Thread-1 (]: SQL status: BEGIN in 0.005 seconds
[0m10:48:33.257399 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.257795 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."silver"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."silver"."consumption_history"
WHERE DATE(created_at) < CURRENT_DATE
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM "elsa"."bronze"."consumption"
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m10:48:33.265380 [debug] [Thread-1 (]: SQL status: SELECT 16 in 0.007 seconds
[0m10:48:33.277118 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.277858 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."silver"."consumption_history" rename to "consumption_history__dbt_backup"
[0m10:48:33.278775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m10:48:33.282938 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.283417 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "elsa"."silver"."consumption_history__dbt_tmp" rename to "consumption_history"
[0m10:48:33.284424 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:48:33.310723 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.311216 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  comment on table "elsa"."silver"."consumption_history" is $dbt_comment_literal_block$The aim of this table is to consolidate history data for consumption
$dbt_comment_literal_block$;

  
[0m10:48:33.312139 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m10:48:33.325717 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.326257 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption_history'
        
        and table_schema = 'silver'
        
      order by ordinal_position

  
[0m10:48:33.333616 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.007 seconds
[0m10:48:33.338273 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.338783 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  
    
    
    comment on column "elsa"."silver"."consumption_history".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".filiere is $dbt_comment_literal_block$filiere$dbt_comment_literal_block$;
  
    
    
    comment on column "elsa"."silver"."consumption_history".volume is $dbt_comment_literal_block$volume$dbt_comment_literal_block$;
  

  
[0m10:48:33.339533 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m10:48:33.340834 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m10:48:33.341269 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.341644 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m10:48:33.342872 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m10:48:33.351378 [debug] [Thread-1 (]: Applying DROP to: "elsa"."silver"."consumption_history__dbt_backup"
[0m10:48:33.358237 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m10:48:33.358834 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption_history"} */
drop table if exists "elsa"."silver"."consumption_history__dbt_backup" cascade
[0m10:48:33.361459 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m10:48:33.364211 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m10:48:33.366629 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d258050>]}
[0m10:48:33.367451 [info ] [Thread-1 (]: 1 of 3 OK created sql table model silver.consumption_history ................... [[32mSELECT 16[0m in 0.17s]
[0m10:48:33.368330 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m10:48:33.369519 [debug] [Thread-2 (]: Began running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:48:33.369972 [debug] [Thread-3 (]: Began running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:48:33.370483 [info ] [Thread-2 (]: 2 of 3 START test not_null_consumption_history_created_at ...................... [RUN]
[0m10:48:33.370953 [info ] [Thread-3 (]: 3 of 3 START test not_null_consumption_history_date ............................ [RUN]
[0m10:48:33.371499 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9)
[0m10:48:33.372042 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4)
[0m10:48:33.372482 [debug] [Thread-2 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:48:33.372901 [debug] [Thread-3 (]: Began compiling node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:48:33.390282 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:48:33.395046 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:48:33.395910 [debug] [Thread-2 (]: Began executing node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:48:33.399174 [debug] [Thread-3 (]: Began executing node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:48:33.398733 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m10:48:33.401944 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Installed package 'elementary' is overriding the built-in
materialization 'test'. Overrides of built-in materializations from installed
packages will be deprecated in future versions of dbt. For more information:
https://docs.getdbt.com/reference/global-configs/legacy-behaviors
[0m10:48:33.402527 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce653d0>]}
[0m10:48:33.402862 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b412fccc-a18c-42b8-bf09-1277f2a74c9f', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce6e2b0>]}
[0m10:48:33.692798 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:48:33.694458 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:48:33.695359 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:48:33.695740 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: BEGIN
[0m10:48:33.696086 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:48:33.696741 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:48:33.697193 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: BEGIN
[0m10:48:33.697582 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:48:33.702563 [debug] [Thread-3 (]: SQL status: BEGIN in 0.006 seconds
[0m10:48:33.703028 [debug] [Thread-3 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"
[0m10:48:33.703396 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from "elsa"."silver"."consumption_history"
where date is null



  
  
      
    ) dbt_internal_test
[0m10:48:33.704288 [debug] [Thread-2 (]: SQL status: BEGIN in 0.007 seconds
[0m10:48:33.704676 [debug] [Thread-2 (]: Using postgres connection "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"
[0m10:48:33.705091 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select created_at
from "elsa"."silver"."consumption_history"
where created_at is null



  
  
      
    ) dbt_internal_test
[0m10:48:33.705576 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m10:48:33.712944 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.007 seconds
[0m10:48:33.797161 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: ROLLBACK
[0m10:48:33.795129 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: ROLLBACK
[0m10:48:33.798020 [debug] [Thread-3 (]: On test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4: Close
[0m10:48:33.798428 [debug] [Thread-2 (]: On test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9: Close
[0m10:48:33.799086 [info ] [Thread-3 (]: 3 of 3 PASS not_null_consumption_history_date .................................. [[32mPASS[0m in 0.43s]
[0m10:48:33.799736 [info ] [Thread-2 (]: 2 of 3 PASS not_null_consumption_history_created_at ............................ [[32mPASS[0m in 0.43s]
[0m10:48:33.800530 [debug] [Thread-3 (]: Finished running node test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4
[0m10:48:33.801138 [debug] [Thread-2 (]: Finished running node test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9
[0m10:48:33.802966 [info ] [MainThread]: 
[0m10:48:33.803389 [debug] [MainThread]: Using postgres connection "master"
[0m10:48:33.803738 [debug] [MainThread]: On master: BEGIN
[0m10:48:33.804038 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:48:33.810186 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m10:48:33.810632 [debug] [MainThread]: On master: COMMIT
[0m10:48:33.810979 [debug] [MainThread]: Using postgres connection "master"
[0m10:48:33.811293 [debug] [MainThread]: On master: COMMIT
[0m10:48:33.811750 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m10:48:33.842572 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m10:48:33.847991 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m10:48:33.860979 [debug] [MainThread]: Elementary: Handling test results.
[0m10:48:33.916203 [warn ] [MainThread]: Missing Elementary models in 'elsa.tec_elsa'. Please run 'dbt run -s elementary --target dev_live'.
[0m10:48:33.941149 [debug] [MainThread]: Elementary: Handled test results successfully.
[0m10:48:33.962638 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m10:48:33.963682 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m10:48:33.964212 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.15s]
[0m10:48:33.964606 [debug] [MainThread]: On master: Close
[0m10:48:33.965107 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:33.965408 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m10:48:33.965685 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9' was properly closed.
[0m10:48:33.965957 [debug] [MainThread]: Connection 'test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4' was properly closed.
[0m10:48:33.966339 [info ] [MainThread]: 
[0m10:48:33.966779 [info ] [MainThread]: Finished running 2 project hooks, 1 table model, 2 data tests in 0 hours 0 minutes and 1.13 seconds (1.13s).
[0m10:48:33.968176 [debug] [MainThread]: Command end result
[0m10:48:34.051879 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/manifest.json
[0m10:48:34.054407 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/semantic_manifest.json
[0m10:48:34.060733 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/elsalebihan/dev/ellebihan/test/dbt_elsa/target/run_results.json
[0m10:48:34.061300 [info ] [MainThread]: 
[0m10:48:34.061731 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:34.062239 [info ] [MainThread]: 
[0m10:48:34.062747 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m10:48:34.063454 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- PackageMaterializationOverrideDeprecation: 2 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m10:48:34.069512 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 3.1706703, "process_in_blocks": "0", "process_kernel_time": 0.639721, "process_mem_max_rss": "145387520", "process_out_blocks": "0", "process_user_time": 4.150439}
[0m10:48:34.070190 [debug] [MainThread]: Command `dbt build` succeeded at 10:48:34.070057 after 3.17 seconds
[0m10:48:34.070621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1dbbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1d39b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c66ec50>]}
[0m10:48:34.071022 [debug] [MainThread]: Flushing usage events
[0m10:48:34.523040 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:50:36.055581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db4f2d570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db35b0280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db35b0220>]}


============================== 19:50:36.063294 | c1a35cd3-6338-40c0-b869-7935ecdb3f8a ==============================
[0m19:50:36.063294 [info ] [MainThread]: Running with dbt=1.10.4
[0m19:50:36.065213 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:50:36.276554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c1a35cd3-6338-40c0-b869-7935ecdb3f8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db7683f10>]}
[0m19:50:36.884629 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-sbk9napg'
[0m19:50:36.885770 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:50:37.075758 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:50:37.081109 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m19:50:37.233661 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m19:50:37.247392 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json
[0m19:50:37.380285 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/metaplane/dbt_expectations.json 200
[0m19:50:37.392188 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m19:50:37.558431 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m19:50:37.574574 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json
[0m19:50:37.704224 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/godatadriven/dbt_date.json 200
[0m19:50:37.713471 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m19:50:39.118446 [info ] [MainThread]: Installed from version 1.3.0
[0m19:50:39.119803 [info ] [MainThread]: Up to date!
[0m19:50:39.121315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'c1a35cd3-6338-40c0-b869-7935ecdb3f8a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db4c2fbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db34fc7f0>]}
[0m19:50:39.122806 [info ] [MainThread]: Installing metaplane/dbt_expectations
[0m19:50:40.258851 [info ] [MainThread]: Installed from version 0.10.9
[0m19:50:40.260005 [info ] [MainThread]: Up to date!
[0m19:50:40.261309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'c1a35cd3-6338-40c0-b869-7935ecdb3f8a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db4c2fbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db33e13f0>]}
[0m19:50:40.262639 [info ] [MainThread]: Installing elementary-data/elementary
[0m19:50:42.076086 [info ] [MainThread]: Installed from version 0.19.0
[0m19:50:42.077957 [info ] [MainThread]: Updated version available: 0.19.1
[0m19:50:42.080429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'c1a35cd3-6338-40c0-b869-7935ecdb3f8a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db4c2fbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db33e2440>]}
[0m19:50:42.082142 [info ] [MainThread]: Installing godatadriven/dbt_date
[0m19:50:42.752700 [info ] [MainThread]: Installed from version 0.14.2
[0m19:50:42.754138 [info ] [MainThread]: Up to date!
[0m19:50:42.755842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'c1a35cd3-6338-40c0-b869-7935ecdb3f8a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db33e22c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db33e1f90>]}
[0m19:50:42.757088 [info ] [MainThread]: 
[0m19:50:42.758322 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m19:50:42.763255 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 6.798944, "process_in_blocks": "0", "process_kernel_time": 0.556298, "process_mem_max_rss": "110868", "process_out_blocks": "23556", "process_user_time": 4.192992}
[0m19:50:42.766761 [debug] [MainThread]: Command `dbt deps` succeeded at 19:50:42.765938 after 6.80 seconds
[0m19:50:42.768338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db4f2d570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db4a5d6f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7db4a5da20>]}
[0m19:50:42.769438 [debug] [MainThread]: Flushing usage events
[0m19:50:43.281859 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:50:52.911059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2169b4a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2153d8250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2153d81f0>]}


============================== 19:50:52.918848 | f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc ==============================
[0m19:50:52.918848 [info ] [MainThread]: Running with dbt=1.10.4
[0m19:50:52.920151 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'profiles_dir': '/opt/airflow/dbt_elsa', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:50:53.245100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2155e9c60>]}
[0m19:50:53.340147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff217c99e40>]}
[0m19:50:53.341724 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m19:50:53.515177 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m19:50:53.840531 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m19:50:53.842110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2161a22c0>]}
[0m19:51:02.062251 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m19:51:02.087886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2152d5090>]}
[0m19:51:02.434807 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m19:51:02.440968 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m19:51:02.473952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff21396f850>]}
[0m19:51:02.475156 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m19:51:02.476366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff21396faf0>]}
[0m19:51:02.479743 [info ] [MainThread]: 
[0m19:51:02.481279 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m19:51:02.483871 [info ] [MainThread]: 
[0m19:51:02.486208 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:51:02.488185 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m19:51:02.541748 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m19:51:02.542894 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m19:51:02.543810 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:51:02.554603 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.011 seconds
[0m19:51:02.556771 [debug] [ThreadPool]: On list_airflow: Close
[0m19:51:02.558420 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_bronze)
[0m19:51:02.559963 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "bronze"
"
[0m19:51:02.570908 [debug] [ThreadPool]: Using postgres connection "create_airflow_bronze"
[0m19:51:02.571898 [debug] [ThreadPool]: On create_airflow_bronze: BEGIN
[0m19:51:02.572648 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:51:02.582334 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m19:51:02.583445 [debug] [ThreadPool]: Using postgres connection "create_airflow_bronze"
[0m19:51:02.584325 [debug] [ThreadPool]: On create_airflow_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "create_airflow_bronze"} */
create schema if not exists "bronze"
[0m19:51:02.585902 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m19:51:02.587323 [debug] [ThreadPool]: On create_airflow_bronze: COMMIT
[0m19:51:02.588143 [debug] [ThreadPool]: Using postgres connection "create_airflow_bronze"
[0m19:51:02.588825 [debug] [ThreadPool]: On create_airflow_bronze: COMMIT
[0m19:51:02.590459 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m19:51:02.591553 [debug] [ThreadPool]: On create_airflow_bronze: Close
[0m19:51:02.602114 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_bronze, now list_airflow_bronze)
[0m19:51:02.603271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_tec_elsa'
[0m19:51:02.610245 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_silver'
[0m19:51:02.617939 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m19:51:02.624934 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m19:51:02.711330 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m19:51:02.712641 [debug] [ThreadPool]: On list_airflow_bronze: BEGIN
[0m19:51:02.714314 [debug] [ThreadPool]: On list_airflow_tec_elsa: BEGIN
[0m19:51:02.716180 [debug] [ThreadPool]: On list_airflow_silver: BEGIN
[0m19:51:02.717590 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:51:02.718777 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:51:02.719893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:51:02.733497 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m19:51:02.734472 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m19:51:02.735388 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m19:51:02.736046 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m19:51:02.737091 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m19:51:02.738169 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m19:51:02.739319 [debug] [ThreadPool]: On list_airflow_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_bronze"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m19:51:02.740686 [debug] [ThreadPool]: On list_airflow_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_tec_elsa"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m19:51:02.741939 [debug] [ThreadPool]: On list_airflow_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_silver"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m19:51:02.746467 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m19:51:02.747416 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m19:51:02.749646 [debug] [ThreadPool]: On list_airflow_tec_elsa: ROLLBACK
[0m19:51:02.751762 [debug] [ThreadPool]: On list_airflow_bronze: ROLLBACK
[0m19:51:02.752409 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m19:51:02.753503 [debug] [ThreadPool]: On list_airflow_tec_elsa: Close
[0m19:51:02.754273 [debug] [ThreadPool]: On list_airflow_bronze: Close
[0m19:51:02.755768 [debug] [ThreadPool]: On list_airflow_silver: ROLLBACK
[0m19:51:02.759919 [debug] [ThreadPool]: On list_airflow_silver: Close
[0m19:51:02.776553 [debug] [MainThread]: Using postgres connection "master"
[0m19:51:02.777858 [debug] [MainThread]: On master: BEGIN
[0m19:51:02.778698 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:51:02.788251 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m19:51:02.789657 [debug] [MainThread]: Using postgres connection "master"
[0m19:51:02.790913 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:51:02.796707 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m19:51:02.799918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff21467bc70>]}
[0m19:51:02.801912 [debug] [MainThread]: On master: ROLLBACK
[0m19:51:02.803217 [debug] [MainThread]: Using postgres connection "master"
[0m19:51:02.804407 [debug] [MainThread]: On master: BEGIN
[0m19:51:02.805937 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m19:51:02.807772 [debug] [MainThread]: On master: COMMIT
[0m19:51:02.808886 [debug] [MainThread]: Using postgres connection "master"
[0m19:51:02.809789 [debug] [MainThread]: On master: COMMIT
[0m19:51:02.810926 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:51:02.846361 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m19:51:02.856823 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m19:51:02.866002 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m19:51:02.867735 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.06s]
[0m19:51:02.868852 [info ] [MainThread]: 
[0m19:51:02.870048 [debug] [MainThread]: On master: Close
[0m19:51:02.884168 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m19:51:02.885444 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m19:51:02.886919 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_silver, now model.dbt_elsa.consumption)
[0m19:51:02.887946 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m19:51:02.896484 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m19:51:02.901655 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m19:51:02.966221 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m19:51:02.970152 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m19:51:02.971135 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m19:51:02.971957 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:51:02.982107 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m19:51:02.983251 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m19:51:02.984269 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "airflow"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "airflow"."bronze"."rte_eco2mix"
  );
  
[0m19:51:02.985819 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
              ^

[0m19:51:02.986715 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m19:51:02.987949 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m19:51:02.991766 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m19:51:02.994374 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ec24d2-6fd8-4a17-95a8-5b14b4ae33bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2141367a0>]}
[0m19:51:02.996045 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.11s]
[0m19:51:02.997934 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m19:51:02.999234 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m19:51:03.004127 [info ] [MainThread]: 
[0m19:51:03.006411 [debug] [MainThread]: Using postgres connection "master"
[0m19:51:03.007669 [debug] [MainThread]: On master: BEGIN
[0m19:51:03.008605 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:51:03.018655 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m19:51:03.019552 [debug] [MainThread]: On master: COMMIT
[0m19:51:03.020400 [debug] [MainThread]: Using postgres connection "master"
[0m19:51:03.021222 [debug] [MainThread]: On master: COMMIT
[0m19:51:03.022209 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:51:03.060358 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m19:51:03.068877 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m19:51:03.105965 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m19:51:03.109129 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m19:51:03.110915 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.09s]
[0m19:51:03.112013 [debug] [MainThread]: On master: Close
[0m19:51:03.113183 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:51:03.114229 [debug] [MainThread]: Connection 'list_airflow_bronze' was properly closed.
[0m19:51:03.115422 [debug] [MainThread]: Connection 'list_airflow_tec_elsa' was properly closed.
[0m19:51:03.116257 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m19:51:03.117319 [info ] [MainThread]: 
[0m19:51:03.118802 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.63 seconds (0.63s).
[0m19:51:03.121946 [debug] [MainThread]: Command end result
[0m19:51:03.333078 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m19:51:03.336757 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m19:51:03.347652 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m19:51:03.348460 [info ] [MainThread]: 
[0m19:51:03.349400 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:51:03.350452 [info ] [MainThread]: 
[0m19:51:03.351767 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m19:51:03.352817 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m19:51:03.353871 [info ] [MainThread]: 
[0m19:51:03.354958 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m19:51:03.356178 [info ] [MainThread]: 
[0m19:51:03.358607 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m19:51:03.361076 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.535316, "process_in_blocks": "0", "process_kernel_time": 0.373296, "process_mem_max_rss": "138180", "process_out_blocks": "12363", "process_user_time": 12.027546}
[0m19:51:03.362348 [debug] [MainThread]: Command `dbt run` failed at 19:51:03.362205 after 10.54 seconds
[0m19:51:03.365131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2169b4a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2168483d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff213525960>]}
[0m19:51:03.366214 [debug] [MainThread]: Flushing usage events
[0m19:51:04.902068 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:58:57.550786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88f0a14ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88ef4c8250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88ef4c81f0>]}


============================== 19:58:57.557776 | 80c5d59d-15ce-4883-bb62-e1735b9088ee ==============================
[0m19:58:57.557776 [info ] [MainThread]: Running with dbt=1.10.4
[0m19:58:57.559093 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m19:58:57.837057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '80c5d59d-15ce-4883-bb62-e1735b9088ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88f2066080>]}
[0m19:58:57.934050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '80c5d59d-15ce-4883-bb62-e1735b9088ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88ef480e20>]}
[0m19:58:57.935630 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m19:58:58.113327 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m19:58:58.425256 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:58:58.426616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '80c5d59d-15ce-4883-bb62-e1735b9088ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88f0200460>]}
[0m19:59:07.100621 [error] [MainThread]: Encountered an error:
can not serialize 'Undefined' object
[0m19:59:07.104861 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 161, in wrapper
    result, success = func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 111, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 254, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 285, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 355, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 332, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 371, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/cli/requires.py", line 398, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/parser/manifest.py", line 2115, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/parser/manifest.py", line 315, in get_full_manifest
    manifest = loader.load()
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/parser/manifest.py", line 513, in load
    self.write_manifest_for_partial_parse()
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/parser/manifest.py", line 821, in write_manifest_for_partial_parse
    manifest_msgpack = self.manifest.to_msgpack(extended_mashumaro_encoder)
  File "<string>", line 3, in __mashumaro_to_msgpack__
  File "<string>", line 91, in __mashumaro_to_msgpack__
  File "/home/airflow/.local/lib/python3.10/site-packages/dbt/parser/manifest.py", line 136, in extended_mashumaro_encoder
    return msgpack.packb(data, default=extended_msgpack_encoder, use_bin_type=True)
  File "/home/airflow/.local/lib/python3.10/site-packages/msgpack/__init__.py", line 36, in packb
    return Packer(**kwargs).pack(o)
  File "msgpack/_packer.pyx", line 279, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 276, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 270, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 257, in msgpack._cmsgpack.Packer._pack_inner
TypeError: can not serialize 'Undefined' object

[0m19:59:07.107537 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.643444, "process_in_blocks": "0", "process_kernel_time": 0.291375, "process_mem_max_rss": "129020", "process_out_blocks": "11", "process_user_time": 11.452818}
[0m19:59:07.108842 [debug] [MainThread]: Command `dbt run` failed at 19:59:07.108675 after 9.65 seconds
[0m19:59:07.109808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88f0a14ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88ed36b910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88ed36ba90>]}
[0m19:59:07.112023 [debug] [MainThread]: Flushing usage events
[0m19:59:07.667591 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:59:59.698216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4440c30ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443f6e4250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443f6e41f0>]}


============================== 19:59:59.704732 | e95ba9ce-1d03-4e52-af55-85445c86a90c ==============================
[0m19:59:59.704732 [info ] [MainThread]: Running with dbt=1.10.4
[0m19:59:59.706063 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:00:00.004626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443f5b7dc0>]}
[0m20:00:00.102789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443f52e500>]}
[0m20:00:00.104266 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:00:00.272960 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:00:00.685062 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:00:00.686271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f444041c460>]}
[0m20:00:08.608085 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:00:08.633900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443db0d5d0>]}
[0m20:00:08.976903 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:00:08.981808 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:00:09.014232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443db66c20>]}
[0m20:00:09.015582 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:00:09.016795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443db67df0>]}
[0m20:00:09.020178 [info ] [MainThread]: 
[0m20:00:09.021287 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m20:00:09.022948 [info ] [MainThread]: 
[0m20:00:09.025147 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:00:09.029734 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:00:09.085198 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:00:09.086270 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:00:09.087174 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:00:09.098156 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.011 seconds
[0m20:00:09.100331 [debug] [ThreadPool]: On list_airflow: Close
[0m20:00:09.110456 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_silver)
[0m20:00:09.112326 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_bronze'
[0m20:00:09.118990 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_tec_elsa'
[0m20:00:09.125024 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:00:09.133871 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:00:09.140011 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:00:09.141012 [debug] [ThreadPool]: On list_airflow_silver: BEGIN
[0m20:00:09.141985 [debug] [ThreadPool]: On list_airflow_bronze: BEGIN
[0m20:00:09.143210 [debug] [ThreadPool]: On list_airflow_tec_elsa: BEGIN
[0m20:00:09.144793 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:00:09.145867 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:00:09.146730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:00:09.156599 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m20:00:09.157465 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m20:00:09.158103 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:00:09.158700 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:00:09.159742 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:00:09.161234 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:00:09.162539 [debug] [ThreadPool]: On list_airflow_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_silver"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m20:00:09.163608 [debug] [ThreadPool]: On list_airflow_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_bronze"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:00:09.164599 [debug] [ThreadPool]: On list_airflow_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_tec_elsa"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:00:09.168508 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:00:09.169155 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:00:09.169773 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:00:09.171558 [debug] [ThreadPool]: On list_airflow_silver: ROLLBACK
[0m20:00:09.173300 [debug] [ThreadPool]: On list_airflow_bronze: ROLLBACK
[0m20:00:09.175011 [debug] [ThreadPool]: On list_airflow_tec_elsa: ROLLBACK
[0m20:00:09.176151 [debug] [ThreadPool]: On list_airflow_silver: Close
[0m20:00:09.177811 [debug] [ThreadPool]: On list_airflow_bronze: Close
[0m20:00:09.178751 [debug] [ThreadPool]: On list_airflow_tec_elsa: Close
[0m20:00:09.263870 [debug] [MainThread]: Using postgres connection "master"
[0m20:00:09.265149 [debug] [MainThread]: On master: BEGIN
[0m20:00:09.266470 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:00:09.278656 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m20:00:09.279724 [debug] [MainThread]: Using postgres connection "master"
[0m20:00:09.281042 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:00:09.285901 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m20:00:09.288001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4442682650>]}
[0m20:00:09.289067 [debug] [MainThread]: On master: ROLLBACK
[0m20:00:09.290228 [debug] [MainThread]: Using postgres connection "master"
[0m20:00:09.291143 [debug] [MainThread]: On master: BEGIN
[0m20:00:09.292492 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:00:09.293546 [debug] [MainThread]: On master: COMMIT
[0m20:00:09.294864 [debug] [MainThread]: Using postgres connection "master"
[0m20:00:09.295708 [debug] [MainThread]: On master: COMMIT
[0m20:00:09.296792 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:00:09.328864 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:00:09.337056 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:00:09.343612 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:00:09.345774 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m20:00:09.346976 [info ] [MainThread]: 
[0m20:00:09.348045 [debug] [MainThread]: On master: Close
[0m20:00:09.361956 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m20:00:09.363882 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m20:00:09.365775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_tec_elsa, now model.dbt_elsa.consumption)
[0m20:00:09.366995 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m20:00:09.382006 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m20:00:09.385285 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m20:00:09.452203 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m20:00:09.455037 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:00:09.455987 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m20:00:09.456922 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:00:09.467535 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m20:00:09.468575 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:00:09.469626 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "airflow"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "airflow"."bronze"."rte_eco2mix"
  );
  
[0m20:00:09.471193 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
              ^

[0m20:00:09.472323 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m20:00:09.473706 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m20:00:09.477579 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:00:09.480475 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e95ba9ce-1d03-4e52-af55-85445c86a90c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443d18a320>]}
[0m20:00:09.481964 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.11s]
[0m20:00:09.483328 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m20:00:09.484786 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m20:00:09.490280 [info ] [MainThread]: 
[0m20:00:09.492607 [debug] [MainThread]: Using postgres connection "master"
[0m20:00:09.494966 [debug] [MainThread]: On master: BEGIN
[0m20:00:09.495968 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:00:09.505674 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:00:09.506679 [debug] [MainThread]: On master: COMMIT
[0m20:00:09.507546 [debug] [MainThread]: Using postgres connection "master"
[0m20:00:09.508440 [debug] [MainThread]: On master: COMMIT
[0m20:00:09.509646 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:00:09.551619 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:00:09.560082 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:00:09.597078 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:00:09.599785 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:00:09.601182 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.09s]
[0m20:00:09.602501 [debug] [MainThread]: On master: Close
[0m20:00:09.603658 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:00:09.604485 [debug] [MainThread]: Connection 'list_airflow_silver' was properly closed.
[0m20:00:09.605271 [debug] [MainThread]: Connection 'list_airflow_bronze' was properly closed.
[0m20:00:09.606293 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m20:00:09.607748 [info ] [MainThread]: 
[0m20:00:09.609112 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m20:00:09.613804 [debug] [MainThread]: Command end result
[0m20:00:09.852870 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:00:09.856731 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:00:09.867678 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:00:09.868546 [info ] [MainThread]: 
[0m20:00:09.869561 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:00:09.870774 [info ] [MainThread]: 
[0m20:00:09.871937 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m20:00:09.873176 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:00:09.874327 [info ] [MainThread]: 
[0m20:00:09.876127 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m20:00:09.879267 [info ] [MainThread]: 
[0m20:00:09.880981 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m20:00:09.883713 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.277704, "process_in_blocks": "0", "process_kernel_time": 0.34882, "process_mem_max_rss": "139748", "process_out_blocks": "12360", "process_user_time": 11.943778}
[0m20:00:09.884931 [debug] [MainThread]: Command `dbt run` failed at 20:00:09.884783 after 10.28 seconds
[0m20:00:09.885930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4440c30ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443f5b6920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4440aed4b0>]}
[0m20:00:09.887104 [debug] [MainThread]: Flushing usage events
[0m20:00:10.357479 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:01:02.977112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f001079cac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f000f1bc250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f000f1bc1f0>]}


============================== 20:01:02.984548 | ce601547-ee16-4f2c-8ca1-b411c4bf8225 ==============================
[0m20:01:02.984548 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:01:02.986083 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m20:01:03.282678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ce601547-ee16-4f2c-8ca1-b411c4bf8225', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0011e22080>]}
[0m20:01:03.385566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ce601547-ee16-4f2c-8ca1-b411c4bf8225', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f000f3d15d0>]}
[0m20:01:03.388571 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:01:03.561623 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:01:03.874999 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:01:03.877469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ce601547-ee16-4f2c-8ca1-b411c4bf8225', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f000ff88460>]}
[0m20:01:10.149889 [error] [MainThread]: Encountered an error:
Parsing Error
  at path ['schema']: {'generate_schema_name': None} is not valid under any of the given schemas
[0m20:01:10.151848 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.264097, "process_in_blocks": "0", "process_kernel_time": 0.235283, "process_mem_max_rss": "118044", "process_out_blocks": "5", "process_user_time": 9.125205}
[0m20:01:10.153244 [debug] [MainThread]: Command `dbt run` failed at 20:01:10.153089 after 7.27 seconds
[0m20:01:10.154227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f001079cac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f000e997e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f000eb233d0>]}
[0m20:01:10.155176 [debug] [MainThread]: Flushing usage events
[0m20:01:10.685432 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:08:17.259277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a17a30af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a164d0280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a164d0220>]}


============================== 20:08:17.266780 | db2dd20d-36a9-431b-9389-9ef04c7f4294 ==============================
[0m20:08:17.266780 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:08:17.268743 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:08:17.605487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'db2dd20d-36a9-431b-9389-9ef04c7f4294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a16322b00>]}
[0m20:08:17.717868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'db2dd20d-36a9-431b-9389-9ef04c7f4294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a164cf0d0>]}
[0m20:08:17.719342 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:08:17.888876 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:08:18.187785 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:08:18.189006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'db2dd20d-36a9-431b-9389-9ef04c7f4294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a17223ca0>]}
[0m20:08:24.278327 [error] [MainThread]: Encountered an error:
Parsing Error
  at path ['schema']: Undefined is not valid under any of the given schemas
[0m20:08:24.280802 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.203768, "process_in_blocks": "0", "process_kernel_time": 0.269228, "process_mem_max_rss": "118004", "process_out_blocks": "5", "process_user_time": 9.319983}
[0m20:08:24.281977 [debug] [MainThread]: Command `dbt run` failed at 20:08:24.281824 after 7.21 seconds
[0m20:08:24.282955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a17a30af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a15c25660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a15d86ef0>]}
[0m20:08:24.283805 [debug] [MainThread]: Flushing usage events
[0m20:08:24.820779 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:11:53.598271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c4b74a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c35d4250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c35d41f0>]}


============================== 20:11:53.606791 | 307cbe73-b321-4858-bf05-34a52de5cf2b ==============================
[0m20:11:53.606791 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:11:53.608018 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m20:11:53.989551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '307cbe73-b321-4858-bf05-34a52de5cf2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c6375810>]}
[0m20:11:54.089000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '307cbe73-b321-4858-bf05-34a52de5cf2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c5e5de40>]}
[0m20:11:54.090510 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:11:54.261656 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:11:54.571820 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:11:54.573266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '307cbe73-b321-4858-bf05-34a52de5cf2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c43622c0>]}
[0m20:11:55.173362 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two macros named "generate_schema_name" in the project "dbt_elsa".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/generate_schema_name.sql
[0m20:11:55.175261 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.668053, "process_in_blocks": "0", "process_kernel_time": 0.269115, "process_mem_max_rss": "117920", "process_out_blocks": "5", "process_user_time": 3.983124}
[0m20:11:55.176506 [debug] [MainThread]: Command `dbt run` failed at 20:11:55.176300 after 1.67 seconds
[0m20:11:55.177354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c4b74a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c2288f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c228a890>]}
[0m20:11:55.178240 [debug] [MainThread]: Flushing usage events
[0m20:11:55.712366 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:12:22.431427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefde134ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdcbd0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdcbd01f0>]}


============================== 20:12:22.442566 | 503609d5-be2b-4003-a251-0fea1b5b0c5d ==============================
[0m20:12:22.442566 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:12:22.444039 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select bronze', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:12:22.751504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdf7aa080>]}
[0m20:12:22.848912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdcbc4f40>]}
[0m20:12:22.851133 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:12:23.023041 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:12:23.323730 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:12:23.325073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdd924460>]}
[0m20:12:31.966524 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:12:31.993236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdc3113f0>]}
[0m20:12:32.344506 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:12:32.349186 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:12:32.390570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdb1bdf90>]}
[0m20:12:32.391857 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:12:32.393353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdb1bd8d0>]}
[0m20:12:32.396491 [info ] [MainThread]: 
[0m20:12:32.398032 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m20:12:32.402687 [info ] [MainThread]: 
[0m20:12:32.404532 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:12:32.406807 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:12:32.462459 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:12:32.463476 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:12:32.464387 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:12:32.475585 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.011 seconds
[0m20:12:32.477685 [debug] [ThreadPool]: On list_airflow: Close
[0m20:12:32.489584 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_bronze)
[0m20:12:32.541390 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_silver'
[0m20:12:32.492263 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_tec_elsa'
[0m20:12:32.554126 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:12:32.562137 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:12:32.570362 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:12:32.571495 [debug] [ThreadPool]: On list_airflow_bronze: BEGIN
[0m20:12:32.572563 [debug] [ThreadPool]: On list_airflow_silver: BEGIN
[0m20:12:32.573607 [debug] [ThreadPool]: On list_airflow_tec_elsa: BEGIN
[0m20:12:32.574620 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:12:32.575606 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:12:32.576801 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:12:32.589521 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m20:12:32.590298 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m20:12:32.591388 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:12:32.592288 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m20:12:32.593331 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:12:32.594519 [debug] [ThreadPool]: On list_airflow_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_silver"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m20:12:32.595374 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:12:32.596304 [debug] [ThreadPool]: On list_airflow_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_bronze"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:12:32.597604 [debug] [ThreadPool]: On list_airflow_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_tec_elsa"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:12:32.601571 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:12:32.602568 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:12:32.603161 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m20:12:32.605133 [debug] [ThreadPool]: On list_airflow_silver: ROLLBACK
[0m20:12:32.607013 [debug] [ThreadPool]: On list_airflow_tec_elsa: ROLLBACK
[0m20:12:32.608902 [debug] [ThreadPool]: On list_airflow_bronze: ROLLBACK
[0m20:12:32.610292 [debug] [ThreadPool]: On list_airflow_silver: Close
[0m20:12:32.610893 [debug] [ThreadPool]: On list_airflow_tec_elsa: Close
[0m20:12:32.611906 [debug] [ThreadPool]: On list_airflow_bronze: Close
[0m20:12:32.705388 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:32.706826 [debug] [MainThread]: On master: BEGIN
[0m20:12:32.708169 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:12:32.721243 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m20:12:32.722439 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:32.723893 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:12:32.728761 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m20:12:32.730910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdb1a1d80>]}
[0m20:12:32.732302 [debug] [MainThread]: On master: ROLLBACK
[0m20:12:32.734160 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:32.735191 [debug] [MainThread]: On master: BEGIN
[0m20:12:32.736674 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:12:32.737634 [debug] [MainThread]: On master: COMMIT
[0m20:12:32.738537 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:32.739287 [debug] [MainThread]: On master: COMMIT
[0m20:12:32.740248 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:12:32.773183 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:12:32.781332 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:12:32.788945 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:12:32.790414 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m20:12:32.791520 [info ] [MainThread]: 
[0m20:12:32.792611 [debug] [MainThread]: On master: Close
[0m20:12:32.806323 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m20:12:32.807591 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m20:12:32.808785 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_bronze, now model.dbt_elsa.consumption)
[0m20:12:32.809929 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m20:12:32.821563 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m20:12:32.823895 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m20:12:32.887346 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m20:12:32.889988 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:12:32.891018 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m20:12:32.891919 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:12:32.902404 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m20:12:32.903616 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:12:32.904653 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "airflow"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "airflow"."bronze"."rte_eco2mix"
  );
  
[0m20:12:32.906383 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
              ^

[0m20:12:32.907418 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m20:12:32.908674 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m20:12:32.912221 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:12:32.914926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '503609d5-be2b-4003-a251-0fea1b5b0c5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdb1f5540>]}
[0m20:12:32.917466 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.10s]
[0m20:12:32.919431 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m20:12:32.920804 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m20:12:32.927050 [info ] [MainThread]: 
[0m20:12:32.928673 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:32.929577 [debug] [MainThread]: On master: BEGIN
[0m20:12:32.930461 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:12:32.941602 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:12:32.942612 [debug] [MainThread]: On master: COMMIT
[0m20:12:32.943365 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:32.944129 [debug] [MainThread]: On master: COMMIT
[0m20:12:32.945141 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:12:32.987973 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:12:32.997879 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:12:33.048345 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:12:33.052567 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:12:33.054634 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.11s]
[0m20:12:33.056620 [debug] [MainThread]: On master: Close
[0m20:12:33.058454 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:12:33.059494 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m20:12:33.060697 [debug] [MainThread]: Connection 'list_airflow_tec_elsa' was properly closed.
[0m20:12:33.061964 [debug] [MainThread]: Connection 'list_airflow_silver' was properly closed.
[0m20:12:33.063737 [info ] [MainThread]: 
[0m20:12:33.064981 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.66 seconds (0.66s).
[0m20:12:33.069251 [debug] [MainThread]: Command end result
[0m20:12:33.285637 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:12:33.289549 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:12:33.301055 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:12:33.302272 [info ] [MainThread]: 
[0m20:12:33.303366 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:12:33.304591 [info ] [MainThread]: 
[0m20:12:33.305870 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m20:12:33.307044 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:12:33.308178 [info ] [MainThread]: 
[0m20:12:33.309832 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m20:12:33.311641 [info ] [MainThread]: 
[0m20:12:33.313232 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m20:12:33.315559 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.985857, "process_in_blocks": "0", "process_kernel_time": 0.343841, "process_mem_max_rss": "139640", "process_out_blocks": "12353", "process_user_time": 12.74626}
[0m20:12:33.319441 [debug] [MainThread]: Command `dbt run` failed at 20:12:33.319220 after 10.99 seconds
[0m20:12:33.320631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefde134ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefddfc6bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fefdc346380>]}
[0m20:12:33.321964 [debug] [MainThread]: Flushing usage events
[0m20:12:33.807029 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:12:38.693256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2a7f8b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb291c8280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb291c8220>]}


============================== 20:12:38.702678 | 203c8bce-f68c-4bcd-b697-81b35b2263d7 ==============================
[0m20:12:38.702678 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:12:38.704238 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select path:models/bronze', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m20:12:38.997130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '203c8bce-f68c-4bcd-b697-81b35b2263d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb29099450>]}
[0m20:12:39.095785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '203c8bce-f68c-4bcd-b697-81b35b2263d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb293d17b0>]}
[0m20:12:39.097316 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:12:39.263614 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:12:40.071035 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:12:40.072105 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:12:40.085366 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:12:40.199485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '203c8bce-f68c-4bcd-b697-81b35b2263d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2793a410>]}
[0m20:12:40.598477 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:12:40.603234 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:12:40.635278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '203c8bce-f68c-4bcd-b697-81b35b2263d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb279ca530>]}
[0m20:12:40.636361 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:12:40.637205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '203c8bce-f68c-4bcd-b697-81b35b2263d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb279c9090>]}
[0m20:12:40.641684 [info ] [MainThread]: 
[0m20:12:40.642793 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m20:12:40.644303 [info ] [MainThread]: 
[0m20:12:40.646233 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:12:40.648022 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:12:40.710600 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:12:40.711699 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:12:40.712701 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:12:40.725613 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.013 seconds
[0m20:12:40.727942 [debug] [ThreadPool]: On list_airflow: Close
[0m20:12:40.740411 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_tec_elsa)
[0m20:12:40.741777 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_bronze'
[0m20:12:40.749287 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_silver'
[0m20:12:40.755475 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:12:40.762970 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:12:40.834504 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:12:40.835266 [debug] [ThreadPool]: On list_airflow_tec_elsa: BEGIN
[0m20:12:40.836525 [debug] [ThreadPool]: On list_airflow_bronze: BEGIN
[0m20:12:40.837736 [debug] [ThreadPool]: On list_airflow_silver: BEGIN
[0m20:12:40.839119 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:12:40.840412 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:12:40.841686 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:12:40.853817 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m20:12:40.854581 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m20:12:40.855163 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m20:12:40.856106 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:12:40.857138 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:12:40.858107 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:12:40.859146 [debug] [ThreadPool]: On list_airflow_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_tec_elsa"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:12:40.860258 [debug] [ThreadPool]: On list_airflow_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_bronze"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:12:40.861274 [debug] [ThreadPool]: On list_airflow_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_silver"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m20:12:40.865172 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:12:40.865854 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:12:40.867283 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:12:40.869231 [debug] [ThreadPool]: On list_airflow_tec_elsa: ROLLBACK
[0m20:12:40.871010 [debug] [ThreadPool]: On list_airflow_bronze: ROLLBACK
[0m20:12:40.872813 [debug] [ThreadPool]: On list_airflow_silver: ROLLBACK
[0m20:12:40.873906 [debug] [ThreadPool]: On list_airflow_tec_elsa: Close
[0m20:12:40.874656 [debug] [ThreadPool]: On list_airflow_bronze: Close
[0m20:12:40.875541 [debug] [ThreadPool]: On list_airflow_silver: Close
[0m20:12:40.890444 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:40.891448 [debug] [MainThread]: On master: BEGIN
[0m20:12:40.892251 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:12:40.902112 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:12:40.903150 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:40.904275 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:12:40.908589 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m20:12:40.910698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '203c8bce-f68c-4bcd-b697-81b35b2263d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb279e1630>]}
[0m20:12:40.911701 [debug] [MainThread]: On master: ROLLBACK
[0m20:12:40.912814 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:40.913723 [debug] [MainThread]: On master: BEGIN
[0m20:12:40.914939 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:12:40.915876 [debug] [MainThread]: On master: COMMIT
[0m20:12:40.917624 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:40.918522 [debug] [MainThread]: On master: COMMIT
[0m20:12:40.919556 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:12:40.977313 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:12:40.986598 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:12:40.993276 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:12:40.994870 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.07s]
[0m20:12:40.995922 [info ] [MainThread]: 
[0m20:12:40.997209 [debug] [MainThread]: On master: Close
[0m20:12:41.010211 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m20:12:41.011431 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m20:12:41.012486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_silver, now model.dbt_elsa.consumption)
[0m20:12:41.013429 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m20:12:41.023046 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m20:12:41.025294 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m20:12:41.091262 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m20:12:41.093673 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:12:41.094584 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m20:12:41.095411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:12:41.104918 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m20:12:41.106152 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:12:41.107155 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "airflow"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "airflow"."bronze"."rte_eco2mix"
  );
  
[0m20:12:41.108576 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
              ^

[0m20:12:41.109507 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m20:12:41.110702 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m20:12:41.114026 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:12:41.117973 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '203c8bce-f68c-4bcd-b697-81b35b2263d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb272e60b0>]}
[0m20:12:41.119390 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.10s]
[0m20:12:41.120780 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m20:12:41.122126 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m20:12:41.128101 [info ] [MainThread]: 
[0m20:12:41.130176 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:41.131123 [debug] [MainThread]: On master: BEGIN
[0m20:12:41.132142 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:12:41.143182 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:12:41.144089 [debug] [MainThread]: On master: COMMIT
[0m20:12:41.144882 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:41.145609 [debug] [MainThread]: On master: COMMIT
[0m20:12:41.146725 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:12:41.204940 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:12:41.213095 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:12:41.251651 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:12:41.254648 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:12:41.256102 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.11s]
[0m20:12:41.257382 [debug] [MainThread]: On master: Close
[0m20:12:41.258518 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:12:41.259240 [debug] [MainThread]: Connection 'list_airflow_tec_elsa' was properly closed.
[0m20:12:41.259897 [debug] [MainThread]: Connection 'list_airflow_bronze' was properly closed.
[0m20:12:41.260598 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m20:12:41.261533 [info ] [MainThread]: 
[0m20:12:41.262752 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.62 seconds (0.62s).
[0m20:12:41.267681 [debug] [MainThread]: Command end result
[0m20:12:41.477526 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:12:41.481142 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:12:41.494968 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:12:41.495963 [info ] [MainThread]: 
[0m20:12:41.497178 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:12:41.499250 [info ] [MainThread]: 
[0m20:12:41.501409 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m20:12:41.503163 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:12:41.504448 [info ] [MainThread]: 
[0m20:12:41.505986 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m20:12:41.507296 [info ] [MainThread]: 
[0m20:12:41.508728 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m20:12:41.510711 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9133925, "process_in_blocks": "0", "process_kernel_time": 0.3142, "process_mem_max_rss": "131148", "process_out_blocks": "8257", "process_user_time": 4.616243}
[0m20:12:41.511887 [debug] [MainThread]: Command `dbt run` failed at 20:12:41.511751 after 2.91 seconds
[0m20:12:41.512879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2a7f8b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb293d17b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb2715cee0>]}
[0m20:12:41.514249 [debug] [MainThread]: Flushing usage events
[0m20:12:41.994365 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:13:14.324573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa755080b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa753ac4280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa753ac4220>]}


============================== 20:13:14.331234 | feaaac59-5b1a-4951-ba08-bc5e624147a8 ==============================
[0m20:13:14.331234 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:13:14.332713 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt_elsa', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select path:models/bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:13:14.659014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa75399c0d0>]}
[0m20:13:14.771578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa753cd57b0>]}
[0m20:13:14.773174 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:13:14.939181 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:13:15.263579 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:13:15.265181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa75486edd0>]}
[0m20:13:23.512028 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:13:23.540251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7520ef190>]}
[0m20:13:23.896373 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:13:23.900548 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:13:23.932824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa752151780>]}
[0m20:13:23.934023 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:13:23.935293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa752151ab0>]}
[0m20:13:23.941390 [info ] [MainThread]: 
[0m20:13:23.942803 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m20:13:23.944777 [info ] [MainThread]: 
[0m20:13:23.946446 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:13:23.948886 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:13:24.004220 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:13:24.005329 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:13:24.006332 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:24.017121 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.011 seconds
[0m20:13:24.019909 [debug] [ThreadPool]: On list_airflow: Close
[0m20:13:24.030344 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_bronze)
[0m20:13:24.031592 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_tec_elsa'
[0m20:13:24.044763 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_silver'
[0m20:13:24.045880 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:13:24.053348 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:13:24.059949 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:13:24.061070 [debug] [ThreadPool]: On list_airflow_bronze: BEGIN
[0m20:13:24.062068 [debug] [ThreadPool]: On list_airflow_tec_elsa: BEGIN
[0m20:13:24.063030 [debug] [ThreadPool]: On list_airflow_silver: BEGIN
[0m20:13:24.064032 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:13:24.065020 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:24.065869 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:24.076601 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m20:13:24.077769 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:13:24.078483 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m20:13:24.079080 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m20:13:24.079937 [debug] [ThreadPool]: On list_airflow_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_bronze"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:13:24.080899 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:13:24.081827 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:13:24.083144 [debug] [ThreadPool]: On list_airflow_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_silver"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m20:13:24.084128 [debug] [ThreadPool]: On list_airflow_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_tec_elsa"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:13:24.086266 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:13:24.088907 [debug] [ThreadPool]: On list_airflow_bronze: ROLLBACK
[0m20:13:24.089622 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:13:24.090386 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:13:24.091182 [debug] [ThreadPool]: On list_airflow_bronze: Close
[0m20:13:24.092758 [debug] [ThreadPool]: On list_airflow_silver: ROLLBACK
[0m20:13:24.094690 [debug] [ThreadPool]: On list_airflow_tec_elsa: ROLLBACK
[0m20:13:24.096385 [debug] [ThreadPool]: On list_airflow_silver: Close
[0m20:13:24.097185 [debug] [ThreadPool]: On list_airflow_tec_elsa: Close
[0m20:13:24.176619 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:24.177646 [debug] [MainThread]: On master: BEGIN
[0m20:13:24.178617 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:13:24.188541 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:13:24.189580 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:24.190658 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:13:24.195078 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m20:13:24.197088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa752cb1e10>]}
[0m20:13:24.198187 [debug] [MainThread]: On master: ROLLBACK
[0m20:13:24.199380 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:24.200203 [debug] [MainThread]: On master: BEGIN
[0m20:13:24.201455 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:13:24.202748 [debug] [MainThread]: On master: COMMIT
[0m20:13:24.203793 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:24.204929 [debug] [MainThread]: On master: COMMIT
[0m20:13:24.206055 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:13:24.238844 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:13:24.247161 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:13:24.254325 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:13:24.255712 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m20:13:24.256908 [info ] [MainThread]: 
[0m20:13:24.258125 [debug] [MainThread]: On master: Close
[0m20:13:24.269729 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m20:13:24.271295 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m20:13:24.272456 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_tec_elsa, now model.dbt_elsa.consumption)
[0m20:13:24.273449 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m20:13:24.282888 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m20:13:24.286083 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m20:13:24.351155 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m20:13:24.355266 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:13:24.356390 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m20:13:24.357389 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:13:24.367420 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m20:13:24.368625 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:13:24.370537 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "airflow"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM "airflow"."bronze"."rte_eco2mix"
  );
  
[0m20:13:24.372444 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
              ^

[0m20:13:24.373588 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m20:13:24.375065 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m20:13:24.378645 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:13:24.381401 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'feaaac59-5b1a-4951-ba08-bc5e624147a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7525d7340>]}
[0m20:13:24.382799 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.11s]
[0m20:13:24.384552 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m20:13:24.386553 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m20:13:24.392310 [info ] [MainThread]: 
[0m20:13:24.393835 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:24.394873 [debug] [MainThread]: On master: BEGIN
[0m20:13:24.395814 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:13:24.406988 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:13:24.408100 [debug] [MainThread]: On master: COMMIT
[0m20:13:24.408983 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:24.409749 [debug] [MainThread]: On master: COMMIT
[0m20:13:24.410859 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:13:24.450035 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:13:24.459215 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:13:24.498096 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:13:24.500568 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:13:24.501805 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.09s]
[0m20:13:24.504537 [debug] [MainThread]: On master: Close
[0m20:13:24.505822 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:13:24.506758 [debug] [MainThread]: Connection 'list_airflow_bronze' was properly closed.
[0m20:13:24.507629 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m20:13:24.508705 [debug] [MainThread]: Connection 'list_airflow_silver' was properly closed.
[0m20:13:24.509887 [info ] [MainThread]: 
[0m20:13:24.511764 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m20:13:24.513991 [debug] [MainThread]: Command end result
[0m20:13:24.801905 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:13:24.806871 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:13:24.818070 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:13:24.819153 [info ] [MainThread]: 
[0m20:13:24.820685 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:13:24.821752 [info ] [MainThread]: 
[0m20:13:24.823055 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m20:13:24.824198 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM "airflow"."bronze"."rte_eco2mix"
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:13:24.825171 [info ] [MainThread]: 
[0m20:13:24.826303 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m20:13:24.827782 [info ] [MainThread]: 
[0m20:13:24.829814 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m20:13:24.831957 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.598877, "process_in_blocks": "0", "process_kernel_time": 0.336266, "process_mem_max_rss": "139876", "process_out_blocks": "12353", "process_user_time": 12.248106}
[0m20:13:24.833518 [debug] [MainThread]: Command `dbt run` failed at 20:13:24.833335 after 10.60 seconds
[0m20:13:24.834610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa755080b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa754f3f700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa752bbe7d0>]}
[0m20:13:24.835597 [debug] [MainThread]: Flushing usage events
[0m20:13:25.382858 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:13:56.769713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2465734ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24641c8250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24641c81f0>]}


============================== 20:13:56.777224 | 48081040-bbfc-416a-b90c-fa4fcfe8b31b ==============================
[0m20:13:56.777224 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:13:56.778417 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select path:models/bronze', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m20:13:57.067936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '48081040-bbfc-416a-b90c-fa4fcfe8b31b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2466daa080>]}
[0m20:13:57.166922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '48081040-bbfc-416a-b90c-fa4fcfe8b31b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24641c4f40>]}
[0m20:13:57.169296 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:13:57.364606 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:13:58.291352 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:13:58.292730 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/bronze/consumption.sql
[0m20:13:59.043303 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:13:59.175310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48081040-bbfc-416a-b90c-fa4fcfe8b31b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2462b9e470>]}
[0m20:13:59.546055 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:13:59.550128 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:13:59.580427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48081040-bbfc-416a-b90c-fa4fcfe8b31b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246311fd90>]}
[0m20:13:59.581559 [info ] [MainThread]: Found 32 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:13:59.582559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48081040-bbfc-416a-b90c-fa4fcfe8b31b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f246311de40>]}
[0m20:13:59.589924 [info ] [MainThread]: 
[0m20:13:59.591827 [info ] [MainThread]: Concurrency: 16 threads (target='dev_live')
[0m20:13:59.593071 [info ] [MainThread]: 
[0m20:13:59.594528 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:13:59.596428 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:13:59.654597 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:13:59.655864 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:13:59.656887 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:59.739907 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.083 seconds
[0m20:13:59.742498 [debug] [ThreadPool]: On list_airflow: Close
[0m20:13:59.755968 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_bronze)
[0m20:13:59.757568 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_silver'
[0m20:13:59.770650 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_tec_elsa'
[0m20:13:59.774109 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:13:59.781433 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:13:59.789740 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:13:59.790796 [debug] [ThreadPool]: On list_airflow_bronze: BEGIN
[0m20:13:59.791932 [debug] [ThreadPool]: On list_airflow_silver: BEGIN
[0m20:13:59.793091 [debug] [ThreadPool]: On list_airflow_tec_elsa: BEGIN
[0m20:13:59.794135 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:13:59.795097 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:59.796094 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:59.811704 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m20:13:59.812867 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m20:13:59.813777 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m20:13:59.815122 [debug] [ThreadPool]: Using postgres connection "list_airflow_silver"
[0m20:13:59.816510 [debug] [ThreadPool]: Using postgres connection "list_airflow_bronze"
[0m20:13:59.818378 [debug] [ThreadPool]: Using postgres connection "list_airflow_tec_elsa"
[0m20:13:59.820420 [debug] [ThreadPool]: On list_airflow_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_silver"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m20:13:59.821737 [debug] [ThreadPool]: On list_airflow_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_bronze"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:13:59.822853 [debug] [ThreadPool]: On list_airflow_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "list_airflow_tec_elsa"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:13:59.827183 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:13:59.827827 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:13:59.828449 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:13:59.830264 [debug] [ThreadPool]: On list_airflow_silver: ROLLBACK
[0m20:13:59.832012 [debug] [ThreadPool]: On list_airflow_bronze: ROLLBACK
[0m20:13:59.833860 [debug] [ThreadPool]: On list_airflow_tec_elsa: ROLLBACK
[0m20:13:59.835955 [debug] [ThreadPool]: On list_airflow_silver: Close
[0m20:13:59.837181 [debug] [ThreadPool]: On list_airflow_bronze: Close
[0m20:13:59.837967 [debug] [ThreadPool]: On list_airflow_tec_elsa: Close
[0m20:13:59.853949 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:59.855028 [debug] [MainThread]: On master: BEGIN
[0m20:13:59.855827 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:13:59.864840 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m20:13:59.866028 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:59.867147 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:13:59.872457 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m20:13:59.874449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48081040-bbfc-416a-b90c-fa4fcfe8b31b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2464ee3e50>]}
[0m20:13:59.875515 [debug] [MainThread]: On master: ROLLBACK
[0m20:13:59.876666 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:59.877500 [debug] [MainThread]: On master: BEGIN
[0m20:13:59.878770 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:13:59.879579 [debug] [MainThread]: On master: COMMIT
[0m20:13:59.880351 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:59.881108 [debug] [MainThread]: On master: COMMIT
[0m20:13:59.882065 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:13:59.940296 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:13:59.948382 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:13:59.955485 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:13:59.956815 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.07s]
[0m20:13:59.957967 [info ] [MainThread]: 
[0m20:13:59.959234 [debug] [MainThread]: On master: Close
[0m20:13:59.973248 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m20:13:59.974639 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption ................................ [RUN]
[0m20:13:59.975988 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_tec_elsa, now model.dbt_elsa.consumption)
[0m20:13:59.977073 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m20:13:59.986512 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m20:13:59.989538 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m20:14:00.056269 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m20:14:00.058845 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:14:00.059873 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m20:14:00.060779 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:14:00.070866 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m20:14:00.071984 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:14:00.072978 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_live", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "airflow"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m20:14:00.074518 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM bronze.rte_eco2mix
              ^

[0m20:14:00.075444 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m20:14:00.076661 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m20:14:00.080120 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:14:00.082877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48081040-bbfc-416a-b90c-fa4fcfe8b31b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2461f21c60>]}
[0m20:14:00.084271 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.11s]
[0m20:14:00.086538 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m20:14:00.088168 [debug] [Thread-19 ]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m20:14:00.094925 [info ] [MainThread]: 
[0m20:14:00.096469 [debug] [MainThread]: Using postgres connection "master"
[0m20:14:00.097317 [debug] [MainThread]: On master: BEGIN
[0m20:14:00.098162 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:14:00.108849 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:14:00.109907 [debug] [MainThread]: On master: COMMIT
[0m20:14:00.110763 [debug] [MainThread]: Using postgres connection "master"
[0m20:14:00.111516 [debug] [MainThread]: On master: COMMIT
[0m20:14:00.112425 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:14:00.167970 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:14:00.176434 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:14:00.213865 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:14:00.216578 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:14:00.218271 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.10s]
[0m20:14:00.219957 [debug] [MainThread]: On master: Close
[0m20:14:00.221415 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:14:00.222338 [debug] [MainThread]: Connection 'list_airflow_bronze' was properly closed.
[0m20:14:00.223283 [debug] [MainThread]: Connection 'list_airflow_silver' was properly closed.
[0m20:14:00.224357 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m20:14:00.226203 [info ] [MainThread]: 
[0m20:14:00.227728 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.63 seconds (0.63s).
[0m20:14:00.229911 [debug] [MainThread]: Command end result
[0m20:14:00.587385 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:14:00.591388 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:14:00.604421 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:14:00.605382 [info ] [MainThread]: 
[0m20:14:00.606619 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:14:00.608244 [info ] [MainThread]: 
[0m20:14:00.610125 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m20:14:00.612362 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:14:00.614732 [info ] [MainThread]: 
[0m20:14:00.616676 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m20:14:00.618336 [info ] [MainThread]: 
[0m20:14:00.622264 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m20:14:00.624299 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.9546974, "process_in_blocks": "0", "process_kernel_time": 0.32617, "process_mem_max_rss": "138304", "process_out_blocks": "12372", "process_user_time": 5.663217}
[0m20:14:00.625545 [debug] [MainThread]: Command `dbt run` failed at 20:14:00.625402 after 3.96 seconds
[0m20:14:00.626481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2465734ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24655f3b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24626cdea0>]}
[0m20:14:00.627520 [debug] [MainThread]: Flushing usage events
[0m20:14:01.132920 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:19:28.187251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbfca14a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbfb4cc280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbfb4cc220>]}


============================== 20:19:28.193942 | 5689962c-5893-4769-9e82-d8ed06da0aef ==============================
[0m20:19:28.193942 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:19:28.195242 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug --target dev_main', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m20:19:28.206926 [info ] [MainThread]: dbt version: 1.10.4
[0m20:19:28.208498 [info ] [MainThread]: python version: 3.10.14
[0m20:19:28.209841 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:19:28.210970 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:19:28.301467 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:19:28.302648 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:19:28.304513 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:19:28.306790 [info ] [MainThread]: adapter type: postgres
[0m20:19:28.307832 [info ] [MainThread]: adapter version: 1.9.0
[0m20:19:28.482356 [info ] [MainThread]: Configuration:
[0m20:19:28.483544 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:19:28.484651 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:19:28.485784 [info ] [MainThread]: Required dependencies:
[0m20:19:28.487588 [debug] [MainThread]: Executing "git --help"
[0m20:19:28.491684 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:19:28.493052 [debug] [MainThread]: STDERR: "b''"
[0m20:19:28.494189 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:19:28.495301 [info ] [MainThread]: Connection:
[0m20:19:28.496958 [info ] [MainThread]:   host: db
[0m20:19:28.498124 [info ] [MainThread]:   port: 5432
[0m20:19:28.499827 [info ] [MainThread]:   user: elsalebihan
[0m20:19:28.501623 [info ] [MainThread]:   database: dbelsa
[0m20:19:28.502794 [info ] [MainThread]:   schema: bronze
[0m20:19:28.506037 [info ] [MainThread]:   connect_timeout: 10
[0m20:19:28.507521 [info ] [MainThread]:   role: None
[0m20:19:28.508748 [info ] [MainThread]:   search_path: None
[0m20:19:28.509822 [info ] [MainThread]:   keepalives_idle: 0
[0m20:19:28.510796 [info ] [MainThread]:   sslmode: None
[0m20:19:28.511705 [info ] [MainThread]:   sslcert: None
[0m20:19:28.513077 [info ] [MainThread]:   sslkey: None
[0m20:19:28.514109 [info ] [MainThread]:   sslrootcert: None
[0m20:19:28.515439 [info ] [MainThread]:   application_name: dbt
[0m20:19:28.516544 [info ] [MainThread]:   retries: 1
[0m20:19:28.518149 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:19:28.629362 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:19:28.663374 [debug] [MainThread]: Using postgres connection "debug"
[0m20:19:28.664392 [debug] [MainThread]: On debug: select 1 as id
[0m20:19:28.665267 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:19:28.674840 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "db" to address: Name or service not known

[0m20:19:28.680148 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:19:28.681306 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:19:28.682215 [debug] [MainThread]: On debug: No close available on handle
[0m20:19:28.683057 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:19:28.683942 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:19:28.685116 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  could not translate host name "db" to address: Name or service not known
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:19:28.687504 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.58596164, "process_in_blocks": "0", "process_kernel_time": 0.179605, "process_mem_max_rss": "110728", "process_out_blocks": "14", "process_user_time": 3.132145}
[0m20:19:28.689005 [debug] [MainThread]: Command `dbt debug` failed at 20:19:28.688822 after 0.59 seconds
[0m20:19:28.689890 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:19:28.691117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbfca14a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbfb4bf370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbfc8e3d00>]}
[0m20:19:28.692274 [debug] [MainThread]: Flushing usage events
[0m20:19:29.213432 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:21:07.315304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fd834af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fc2bc280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fc2bc220>]}


============================== 20:21:07.323275 | 5ef4c1e5-fe03-4501-9a94-9f4082ffef16 ==============================
[0m20:21:07.323275 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:21:07.324483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s test_connection', 'send_anonymous_usage_stats': 'True'}
[0m20:21:07.672025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ef4c1e5-fe03-4501-9a94-9f4082ffef16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fefb90c0>]}
[0m20:21:07.765132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ef4c1e5-fe03-4501-9a94-9f4082ffef16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29feb02c80>]}
[0m20:21:07.766652 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:21:07.934440 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:21:08.262045 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:21:08.263369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5ef4c1e5-fe03-4501-9a94-9f4082ffef16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fead3ca0>]}
[0m20:21:16.419830 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:21:16.447463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ef4c1e5-fe03-4501-9a94-9f4082ffef16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fa339ea0>]}
[0m20:21:16.801259 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:21:16.806450 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:21:16.841349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ef4c1e5-fe03-4501-9a94-9f4082ffef16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fa700be0>]}
[0m20:21:16.842782 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:21:16.844255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ef4c1e5-fe03-4501-9a94-9f4082ffef16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fa702770>]}
[0m20:21:16.846843 [warn ] [MainThread]: The selection criterion 'test_connection' does not match any enabled nodes
[0m20:21:16.849468 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m20:21:16.851384 [debug] [MainThread]: Command end result
[0m20:21:17.145473 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:21:17.149434 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:21:17.156232 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:21:17.158027 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.93015, "process_in_blocks": "0", "process_kernel_time": 0.320449, "process_mem_max_rss": "134240", "process_out_blocks": "12324", "process_user_time": 11.548377}
[0m20:21:17.159300 [debug] [MainThread]: Command `dbt run` succeeded at 20:21:17.159082 after 9.93 seconds
[0m20:21:17.160279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fc283220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fc2834c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29fc283fa0>]}
[0m20:21:17.161282 [debug] [MainThread]: Flushing usage events
[0m20:21:17.712729 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:21:48.958227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13ac77caf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13ab1cc280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13ab1cc220>]}


============================== 20:21:48.964692 | af2720a1-95bd-4c56-b2b4-61b0989606a4 ==============================
[0m20:21:48.964692 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:21:48.966260 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s test_connection', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m20:21:49.262150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'af2720a1-95bd-4c56-b2b4-61b0989606a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13aded50c0>]}
[0m20:21:49.361310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'af2720a1-95bd-4c56-b2b4-61b0989606a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13abf9ac80>]}
[0m20:21:49.362865 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:21:49.526816 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:21:50.358783 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m20:21:50.360174 [debug] [MainThread]: Partial parsing: added file: dbt_elsa://models/bronze/test_connection.sql
[0m20:21:50.361019 [debug] [MainThread]: Partial parsing: deleted file: dbt_elsa://models/bronze/test_connexion.sql
[0m20:21:50.837727 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:21:50.871833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af2720a1-95bd-4c56-b2b4-61b0989606a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13a98ae9b0>]}
[0m20:21:51.320807 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:21:51.325094 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:21:51.357717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af2720a1-95bd-4c56-b2b4-61b0989606a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13ab0d78e0>]}
[0m20:21:51.358929 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:21:51.360600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'af2720a1-95bd-4c56-b2b4-61b0989606a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13aab3b940>]}
[0m20:21:51.364720 [info ] [MainThread]: 
[0m20:21:51.366209 [info ] [MainThread]: Concurrency: 4 threads (target='dev_main')
[0m20:21:51.368324 [info ] [MainThread]: 
[0m20:21:51.372281 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:21:51.375343 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:21:51.432860 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:21:51.434010 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_main", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:21:51.434872 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:21:51.445403 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "db" to address: Name or service not known

[0m20:21:51.451661 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_main", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:21:51.453161 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:21:51.454258 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:21:51.455219 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:21:51.456147 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:21:51.457471 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:21:51.458374 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:21:51.459293 [info ] [MainThread]: 
[0m20:21:51.460370 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.09 seconds (0.09s).
[0m20:21:51.462193 [error] [MainThread]: Encountered an error:
Database Error
  could not translate host name "db" to address: Name or service not known
  
[0m20:21:51.464223 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.5930517, "process_in_blocks": "0", "process_kernel_time": 0.289786, "process_mem_max_rss": "128756", "process_out_blocks": "8339", "process_user_time": 4.693264}
[0m20:21:51.465426 [debug] [MainThread]: Command `dbt run` failed at 20:21:51.465261 after 2.59 seconds
[0m20:21:51.466674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13ac77caf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13aab3bca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13a9901a20>]}
[0m20:21:51.467904 [debug] [MainThread]: Flushing usage events
[0m20:21:51.970272 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:22:27.583105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9356c8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9340b4250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9340b41f0>]}


============================== 20:22:27.593401 | f67a18b9-87f3-4627-86ea-2314095b99da ==============================
[0m20:22:27.593401 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:22:27.595168 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s test_connection', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:22:27.947704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f67a18b9-87f3-4627-86ea-2314095b99da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa936cb2050>]}
[0m20:22:28.049773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f67a18b9-87f3-4627-86ea-2314095b99da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa935640490>]}
[0m20:22:28.051233 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:22:28.274123 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:22:28.623213 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:22:28.624973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f67a18b9-87f3-4627-86ea-2314095b99da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa936964460>]}
[0m20:22:39.114539 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:22:39.161999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f67a18b9-87f3-4627-86ea-2314095b99da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93214f7c0>]}
[0m20:22:39.682120 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:22:39.686454 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:22:39.718955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f67a18b9-87f3-4627-86ea-2314095b99da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93267e530>]}
[0m20:22:39.720374 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:22:39.722019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f67a18b9-87f3-4627-86ea-2314095b99da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93267eaa0>]}
[0m20:22:39.725367 [info ] [MainThread]: 
[0m20:22:39.726566 [info ] [MainThread]: Concurrency: 4 threads (target='dev_main')
[0m20:22:39.728358 [info ] [MainThread]: 
[0m20:22:39.730036 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:22:39.732083 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:22:39.784933 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:22:39.785990 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_main", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:22:39.787510 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:22:39.797011 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "dbelse" to address: Name or service not known

[0m20:22:39.802262 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_main", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:22:39.803249 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:22:39.804527 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:22:39.805684 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:22:39.806438 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:22:39.807585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:22:39.808392 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:22:39.809186 [info ] [MainThread]: 
[0m20:22:39.810116 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.08 seconds (0.08s).
[0m20:22:39.811417 [error] [MainThread]: Encountered an error:
Database Error
  could not translate host name "dbelse" to address: Name or service not known
  
[0m20:22:39.813148 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.352235, "process_in_blocks": "0", "process_kernel_time": 0.337598, "process_mem_max_rss": "133200", "process_out_blocks": "8312", "process_user_time": 14.193434}
[0m20:22:39.814324 [debug] [MainThread]: Command `dbt run` failed at 20:22:39.814179 after 12.35 seconds
[0m20:22:39.815183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9356c8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93267fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9325e59f0>]}
[0m20:22:39.816306 [debug] [MainThread]: Flushing usage events
[0m20:22:40.373624 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:22:44.988876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9571e24b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95707bc280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95707bc220>]}


============================== 20:22:44.995583 | dddd97f5-6c1c-42b2-aab5-6c19b32003e5 ==============================
[0m20:22:44.995583 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:22:44.996903 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run -s test_connection', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:22:45.316068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dddd97f5-6c1c-42b2-aab5-6c19b32003e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f957060eb30>]}
[0m20:22:45.410992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dddd97f5-6c1c-42b2-aab5-6c19b32003e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95707b8160>]}
[0m20:22:45.412438 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:22:45.585123 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:22:45.889780 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:22:45.891126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'dddd97f5-6c1c-42b2-aab5-6c19b32003e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95715f6dd0>]}
[0m20:22:54.272661 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:22:54.300572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dddd97f5-6c1c-42b2-aab5-6c19b32003e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956e94a080>]}
[0m20:22:54.657016 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:22:54.661264 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:22:54.693441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dddd97f5-6c1c-42b2-aab5-6c19b32003e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956f33c700>]}
[0m20:22:54.694844 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:22:54.696146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dddd97f5-6c1c-42b2-aab5-6c19b32003e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956f3bfb50>]}
[0m20:22:54.699702 [info ] [MainThread]: 
[0m20:22:54.701389 [info ] [MainThread]: Concurrency: 4 threads (target='dev_main')
[0m20:22:54.706983 [info ] [MainThread]: 
[0m20:22:54.709012 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:22:54.711089 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:22:54.767447 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:22:54.768683 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_main", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:22:54.769966 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:22:54.790532 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "dbelsa" to address: Name or service not known

[0m20:22:54.799225 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_main", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:22:54.801855 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:22:54.803231 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:22:54.805633 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:22:54.807059 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:22:54.808641 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:22:54.809867 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:22:54.810864 [info ] [MainThread]: 
[0m20:22:54.812192 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.10 seconds (0.10s).
[0m20:22:54.813869 [error] [MainThread]: Encountered an error:
Database Error
  could not translate host name "dbelsa" to address: Name or service not known
  
[0m20:22:54.815898 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.9125, "process_in_blocks": "0", "process_kernel_time": 0.320847, "process_mem_max_rss": "133084", "process_out_blocks": "8312", "process_user_time": 11.740558}
[0m20:22:54.817335 [debug] [MainThread]: Command `dbt run` failed at 20:22:54.817127 after 9.91 seconds
[0m20:22:54.818600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9571e24b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956ed03760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f956e933fd0>]}
[0m20:22:54.821007 [debug] [MainThread]: Flushing usage events
[0m20:22:55.302588 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:27:23.807411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fe150a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fcbcc280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fcbcc220>]}


============================== 20:27:23.814287 | 534b0768-6e2f-4d33-a44f-9fec78bce40e ==============================
[0m20:27:23.814287 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:27:23.815750 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run -s test_connection', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:27:24.113810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '534b0768-6e2f-4d33-a44f-9fec78bce40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fd93dab0>]}
[0m20:27:24.212980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '534b0768-6e2f-4d33-a44f-9fec78bce40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fd96e020>]}
[0m20:27:24.214519 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:27:24.387339 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:27:24.729067 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:27:24.730420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '534b0768-6e2f-4d33-a44f-9fec78bce40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fd93fa60>]}
[0m20:27:33.131735 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:27:33.161541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '534b0768-6e2f-4d33-a44f-9fec78bce40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67faf57130>]}
[0m20:27:33.515497 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:27:33.519928 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:27:33.557636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '534b0768-6e2f-4d33-a44f-9fec78bce40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fb083370>]}
[0m20:27:33.559055 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:27:33.560464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '534b0768-6e2f-4d33-a44f-9fec78bce40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fb082380>]}
[0m20:27:33.565931 [info ] [MainThread]: 
[0m20:27:33.569877 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m20:27:33.574101 [info ] [MainThread]: 
[0m20:27:33.576067 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:27:33.578299 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:27:33.634215 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:27:33.635270 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:27:33.636119 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:27:33.652906 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "db" to address: Name or service not known

[0m20:27:33.658767 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:27:33.659714 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:27:33.660553 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:27:33.661329 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:27:33.662094 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:27:33.663198 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:27:33.663961 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:27:33.664757 [info ] [MainThread]: 
[0m20:27:33.665566 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.09 seconds (0.09s).
[0m20:27:33.666993 [error] [MainThread]: Encountered an error:
Database Error
  could not translate host name "db" to address: Name or service not known
  
[0m20:27:33.668804 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.951394, "process_in_blocks": "0", "process_kernel_time": 0.293874, "process_mem_max_rss": "133020", "process_out_blocks": "8312", "process_user_time": 11.774313}
[0m20:27:33.669962 [debug] [MainThread]: Command `dbt run` failed at 20:27:33.669814 after 9.95 seconds
[0m20:27:33.671133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fe150a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67fb080f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67faf003d0>]}
[0m20:27:33.672770 [debug] [MainThread]: Flushing usage events
[0m20:27:34.516072 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:27:48.431130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fcc2c8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fcacb0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fcacb01f0>]}


============================== 20:27:48.437514 | be831be4-0369-4373-8621-11b9ba114015 ==============================
[0m20:27:48.437514 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:27:48.439719 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'log_path': '/opt/airflow/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s test_connection', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:27:48.744577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be831be4-0369-4373-8621-11b9ba114015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fcd8a6050>]}
[0m20:27:48.843263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be831be4-0369-4373-8621-11b9ba114015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fcd576c20>]}
[0m20:27:48.845551 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:27:49.019855 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:27:49.344809 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:27:49.346361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'be831be4-0369-4373-8621-11b9ba114015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fcd544460>]}
[0m20:27:57.623771 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:27:57.652020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be831be4-0369-4373-8621-11b9ba114015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc9141930>]}
[0m20:27:58.003543 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:27:58.008619 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:27:58.041792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be831be4-0369-4373-8621-11b9ba114015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc917f370>]}
[0m20:27:58.042982 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:27:58.044550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be831be4-0369-4373-8621-11b9ba114015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc917cc10>]}
[0m20:27:58.047809 [info ] [MainThread]: 
[0m20:27:58.049029 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m20:27:58.050514 [info ] [MainThread]: 
[0m20:27:58.052611 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:27:58.056647 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:27:58.110329 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:27:58.111365 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:27:58.112204 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:27:58.127787 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "elsa" to address: Name or service not known

[0m20:27:58.133330 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:27:58.134310 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:27:58.135101 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:27:58.135850 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:27:58.136583 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:27:58.137729 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:27:58.139485 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:27:58.140440 [info ] [MainThread]: 
[0m20:27:58.141497 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.09 seconds (0.09s).
[0m20:27:58.142779 [error] [MainThread]: Encountered an error:
Database Error
  could not translate host name "elsa" to address: Name or service not known
  
[0m20:27:58.144702 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.803749, "process_in_blocks": "0", "process_kernel_time": 0.302961, "process_mem_max_rss": "133172", "process_out_blocks": "8312", "process_user_time": 11.732859}
[0m20:27:58.145848 [debug] [MainThread]: Command `dbt run` failed at 20:27:58.145698 after 9.81 seconds
[0m20:27:58.146698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fcc2c8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc917c640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc92fb0d0>]}
[0m20:27:58.147728 [debug] [MainThread]: Flushing usage events
[0m20:27:58.620191 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:29:22.117252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f078683cb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07852a0280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07852a0220>]}


============================== 20:29:22.126302 | 5dc5e4c7-a012-4c0c-b053-e090c7138d17 ==============================
[0m20:29:22.126302 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:29:22.128010 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'log_path': '/opt/airflow/dbt_elsa/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug --target dev_airflow', 'send_anonymous_usage_stats': 'True'}
[0m20:29:22.142877 [info ] [MainThread]: dbt version: 1.10.4
[0m20:29:22.144122 [info ] [MainThread]: python version: 3.10.14
[0m20:29:22.145483 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:29:22.146983 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:29:22.238413 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:29:22.240957 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:29:22.242035 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:29:22.243396 [info ] [MainThread]: adapter type: postgres
[0m20:29:22.245026 [info ] [MainThread]: adapter version: 1.9.0
[0m20:29:22.425047 [info ] [MainThread]: Configuration:
[0m20:29:22.426157 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:29:22.427436 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:29:22.428567 [info ] [MainThread]: Required dependencies:
[0m20:29:22.429741 [debug] [MainThread]: Executing "git --help"
[0m20:29:22.434091 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:29:22.435653 [debug] [MainThread]: STDERR: "b''"
[0m20:29:22.436505 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:29:22.437417 [info ] [MainThread]: Connection:
[0m20:29:22.440140 [info ] [MainThread]:   host: db_airflow
[0m20:29:22.441252 [info ] [MainThread]:   port: 5432
[0m20:29:22.442250 [info ] [MainThread]:   user: airflow
[0m20:29:22.443176 [info ] [MainThread]:   database: airflow
[0m20:29:22.444521 [info ] [MainThread]:   schema: bronze
[0m20:29:22.445900 [info ] [MainThread]:   connect_timeout: 10
[0m20:29:22.446860 [info ] [MainThread]:   role: None
[0m20:29:22.447889 [info ] [MainThread]:   search_path: None
[0m20:29:22.448871 [info ] [MainThread]:   keepalives_idle: 0
[0m20:29:22.449838 [info ] [MainThread]:   sslmode: None
[0m20:29:22.451148 [info ] [MainThread]:   sslcert: None
[0m20:29:22.452255 [info ] [MainThread]:   sslkey: None
[0m20:29:22.453270 [info ] [MainThread]:   sslrootcert: None
[0m20:29:22.454236 [info ] [MainThread]:   application_name: dbt
[0m20:29:22.458139 [info ] [MainThread]:   retries: 1
[0m20:29:22.459391 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:29:22.642666 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:29:22.678112 [debug] [MainThread]: Using postgres connection "debug"
[0m20:29:22.679076 [debug] [MainThread]: On debug: select 1 as id
[0m20:29:22.679914 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:29:22.690517 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m20:29:22.692279 [debug] [MainThread]: On debug: Close
[0m20:29:22.693304 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m20:29:22.694839 [info ] [MainThread]: [32mAll checks passed![0m
[0m20:29:22.697216 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.6666824, "process_in_blocks": "0", "process_kernel_time": 0.180581, "process_mem_max_rss": "112596", "process_out_blocks": "12", "process_user_time": 3.102135}
[0m20:29:22.698530 [debug] [MainThread]: Command `dbt debug` succeeded at 20:29:22.698380 after 0.67 seconds
[0m20:29:22.699443 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:29:22.700372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f078683cb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07866fad40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0784b11000>]}
[0m20:29:22.701298 [debug] [MainThread]: Flushing usage events
[0m20:29:23.248275 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:29:45.381372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ebe08af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ea7d4280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ea7d4220>]}


============================== 20:29:45.387994 | 3e7f0507-d62f-4489-a5e1-65a669d55b4b ==============================
[0m20:29:45.387994 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:29:45.389718 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt debug --target dev_elsa', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:29:45.401609 [info ] [MainThread]: dbt version: 1.10.4
[0m20:29:45.402817 [info ] [MainThread]: python version: 3.10.14
[0m20:29:45.403935 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:29:45.405466 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:29:45.499286 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:29:45.500459 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:29:45.501710 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:29:45.503039 [info ] [MainThread]: adapter type: postgres
[0m20:29:45.504127 [info ] [MainThread]: adapter version: 1.9.0
[0m20:29:45.676591 [info ] [MainThread]: Configuration:
[0m20:29:45.677959 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:29:45.679219 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:29:45.680348 [info ] [MainThread]: Required dependencies:
[0m20:29:45.681640 [debug] [MainThread]: Executing "git --help"
[0m20:29:45.685766 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:29:45.686954 [debug] [MainThread]: STDERR: "b''"
[0m20:29:45.687997 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:29:45.690323 [info ] [MainThread]: Connection:
[0m20:29:45.691750 [info ] [MainThread]:   host: elsa
[0m20:29:45.693029 [info ] [MainThread]:   port: 5432
[0m20:29:45.694275 [info ] [MainThread]:   user: elsalebihan
[0m20:29:45.695405 [info ] [MainThread]:   database: dbelsa
[0m20:29:45.696352 [info ] [MainThread]:   schema: bronze
[0m20:29:45.697712 [info ] [MainThread]:   connect_timeout: 10
[0m20:29:45.698702 [info ] [MainThread]:   role: None
[0m20:29:45.699730 [info ] [MainThread]:   search_path: None
[0m20:29:45.700664 [info ] [MainThread]:   keepalives_idle: 0
[0m20:29:45.701603 [info ] [MainThread]:   sslmode: None
[0m20:29:45.702729 [info ] [MainThread]:   sslcert: None
[0m20:29:45.704074 [info ] [MainThread]:   sslkey: None
[0m20:29:45.705372 [info ] [MainThread]:   sslrootcert: None
[0m20:29:45.707427 [info ] [MainThread]:   application_name: dbt
[0m20:29:45.708725 [info ] [MainThread]:   retries: 1
[0m20:29:45.710240 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:29:45.819041 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:29:45.852605 [debug] [MainThread]: Using postgres connection "debug"
[0m20:29:45.853687 [debug] [MainThread]: On debug: select 1 as id
[0m20:29:45.854523 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:29:45.873527 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "elsa" to address: Name or service not known

[0m20:29:45.878906 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:29:45.879921 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:29:45.880813 [debug] [MainThread]: On debug: No close available on handle
[0m20:29:45.881706 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:29:45.882679 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:29:45.883964 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  could not translate host name "elsa" to address: Name or service not known
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:29:45.885660 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.5953207, "process_in_blocks": "0", "process_kernel_time": 0.159009, "process_mem_max_rss": "110584", "process_out_blocks": "14", "process_user_time": 2.817885}
[0m20:29:45.886878 [debug] [MainThread]: Command `dbt debug` failed at 20:29:45.886746 after 0.60 seconds
[0m20:29:45.887655 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:29:45.888382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ebe08af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ebcc55a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6ea093ca0>]}
[0m20:29:45.890839 [debug] [MainThread]: Flushing usage events
[0m20:29:46.379095 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:30:41.893414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb66b7a0ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb66a1ac280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb66a1ac220>]}


============================== 20:30:41.899928 | aae323c5-b9ce-412b-baf9-d4b6e3c33ba7 ==============================
[0m20:30:41.899928 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:30:41.901540 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug --target dev_elsa', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m20:30:41.914489 [info ] [MainThread]: dbt version: 1.10.4
[0m20:30:41.916157 [info ] [MainThread]: python version: 3.10.14
[0m20:30:41.918245 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:30:41.919639 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:30:42.014086 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:30:42.015476 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:30:42.016488 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:30:42.017863 [info ] [MainThread]: adapter type: postgres
[0m20:30:42.019040 [info ] [MainThread]: adapter version: 1.9.0
[0m20:30:42.193831 [info ] [MainThread]: Configuration:
[0m20:30:42.195166 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:30:42.196441 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:30:42.197638 [info ] [MainThread]: Required dependencies:
[0m20:30:42.198810 [debug] [MainThread]: Executing "git --help"
[0m20:30:42.202638 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:30:42.204430 [debug] [MainThread]: STDERR: "b''"
[0m20:30:42.207367 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:30:42.208725 [info ] [MainThread]: Connection:
[0m20:30:42.209938 [info ] [MainThread]:   host: db
[0m20:30:42.211050 [info ] [MainThread]:   port: 5432
[0m20:30:42.212164 [info ] [MainThread]:   user: elsalebihan
[0m20:30:42.213324 [info ] [MainThread]:   database: dbelsa
[0m20:30:42.214622 [info ] [MainThread]:   schema: bronze
[0m20:30:42.215762 [info ] [MainThread]:   connect_timeout: 10
[0m20:30:42.217011 [info ] [MainThread]:   role: None
[0m20:30:42.218004 [info ] [MainThread]:   search_path: None
[0m20:30:42.219057 [info ] [MainThread]:   keepalives_idle: 0
[0m20:30:42.220705 [info ] [MainThread]:   sslmode: None
[0m20:30:42.224843 [info ] [MainThread]:   sslcert: None
[0m20:30:42.226796 [info ] [MainThread]:   sslkey: None
[0m20:30:42.227981 [info ] [MainThread]:   sslrootcert: None
[0m20:30:42.229187 [info ] [MainThread]:   application_name: dbt
[0m20:30:42.230200 [info ] [MainThread]:   retries: 1
[0m20:30:42.231698 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:30:42.348992 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:30:42.383662 [debug] [MainThread]: Using postgres connection "debug"
[0m20:30:42.384589 [debug] [MainThread]: On debug: select 1 as id
[0m20:30:42.385319 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:30:42.403189 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "db" to address: Name or service not known

[0m20:30:42.410166 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:30:42.411198 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:30:42.412012 [debug] [MainThread]: On debug: No close available on handle
[0m20:30:42.412936 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:30:42.413984 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:30:42.415244 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  could not translate host name "db" to address: Name or service not known
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:30:42.417124 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.6094637, "process_in_blocks": "0", "process_kernel_time": 0.176476, "process_mem_max_rss": "110688", "process_out_blocks": "14", "process_user_time": 2.810514}
[0m20:30:42.418314 [debug] [MainThread]: Command `dbt debug` failed at 20:30:42.418166 after 0.61 seconds
[0m20:30:42.419041 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:30:42.419835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb66b7a0ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb66d5f09a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb66b637b80>]}
[0m20:30:42.420961 [debug] [MainThread]: Flushing usage events
[0m20:30:43.013641 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:30:58.496201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3b8b0a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3a298280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3a298220>]}


============================== 20:30:58.505976 | da176b1e-fb78-4327-9f96-ec7134398d11 ==============================
[0m20:30:58.505976 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:30:58.508056 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug --target dev_elsa', 'send_anonymous_usage_stats': 'True'}
[0m20:30:58.526324 [info ] [MainThread]: dbt version: 1.10.4
[0m20:30:58.527504 [info ] [MainThread]: python version: 3.10.14
[0m20:30:58.528880 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:30:58.530322 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:30:58.631222 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:30:58.632355 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:30:58.633416 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:30:58.634782 [info ] [MainThread]: adapter type: postgres
[0m20:30:58.635935 [info ] [MainThread]: adapter version: 1.9.0
[0m20:30:58.804968 [info ] [MainThread]: Configuration:
[0m20:30:58.807919 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:30:58.809205 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:30:58.810260 [info ] [MainThread]: Required dependencies:
[0m20:30:58.811367 [debug] [MainThread]: Executing "git --help"
[0m20:30:58.815295 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:30:58.816684 [debug] [MainThread]: STDERR: "b''"
[0m20:30:58.817790 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:30:58.818833 [info ] [MainThread]: Connection:
[0m20:30:58.820166 [info ] [MainThread]:   host: localhost
[0m20:30:58.821687 [info ] [MainThread]:   port: 5432
[0m20:30:58.824428 [info ] [MainThread]:   user: elsalebihan
[0m20:30:58.826416 [info ] [MainThread]:   database: dbelsa
[0m20:30:58.827601 [info ] [MainThread]:   schema: bronze
[0m20:30:58.828689 [info ] [MainThread]:   connect_timeout: 10
[0m20:30:58.829712 [info ] [MainThread]:   role: None
[0m20:30:58.830810 [info ] [MainThread]:   search_path: None
[0m20:30:58.832090 [info ] [MainThread]:   keepalives_idle: 0
[0m20:30:58.833439 [info ] [MainThread]:   sslmode: None
[0m20:30:58.834603 [info ] [MainThread]:   sslcert: None
[0m20:30:58.835693 [info ] [MainThread]:   sslkey: None
[0m20:30:58.836764 [info ] [MainThread]:   sslrootcert: None
[0m20:30:58.839841 [info ] [MainThread]:   application_name: dbt
[0m20:30:58.841795 [info ] [MainThread]:   retries: 1
[0m20:30:58.843167 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:30:58.954648 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:30:58.990749 [debug] [MainThread]: Using postgres connection "debug"
[0m20:30:58.991921 [debug] [MainThread]: On debug: select 1 as id
[0m20:30:58.992838 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:30:58.994528 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

[0m20:30:58.996021 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:30:58.996956 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:30:58.997926 [debug] [MainThread]: On debug: No close available on handle
[0m20:30:58.998862 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:30:58.999895 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:30:59.001285 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:30:59.003346 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.60482234, "process_in_blocks": "0", "process_kernel_time": 0.167118, "process_mem_max_rss": "110652", "process_out_blocks": "15", "process_user_time": 2.841022}
[0m20:30:59.004944 [debug] [MainThread]: Command `dbt debug` failed at 20:30:59.004542 after 0.61 seconds
[0m20:30:59.006884 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:30:59.008426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3b8b0a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3cdb6740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc39b0bf40>]}
[0m20:30:59.011069 [debug] [MainThread]: Flushing usage events
[0m20:30:59.492553 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:31:11.766905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ff0368ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9feedcc280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9feedcc220>]}


============================== 20:31:11.774784 | 0e15f4a4-bf89-49d2-8586-ae56b5126aed ==============================
[0m20:31:11.774784 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:31:11.776530 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt debug --target dev_elsa', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m20:31:11.791007 [info ] [MainThread]: dbt version: 1.10.4
[0m20:31:11.793449 [info ] [MainThread]: python version: 3.10.14
[0m20:31:11.796437 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:31:11.798381 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:31:11.897154 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:31:11.898558 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:31:11.899762 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:31:11.901251 [info ] [MainThread]: adapter type: postgres
[0m20:31:11.902178 [info ] [MainThread]: adapter version: 1.9.0
[0m20:31:12.071785 [info ] [MainThread]: Configuration:
[0m20:31:12.073848 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:31:12.075506 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:31:12.076838 [info ] [MainThread]: Required dependencies:
[0m20:31:12.078206 [debug] [MainThread]: Executing "git --help"
[0m20:31:12.082452 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:31:12.084107 [debug] [MainThread]: STDERR: "b''"
[0m20:31:12.084849 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:31:12.085991 [info ] [MainThread]: Connection:
[0m20:31:12.087140 [info ] [MainThread]:   host: db
[0m20:31:12.089830 [info ] [MainThread]:   port: 5432
[0m20:31:12.091076 [info ] [MainThread]:   user: elsalebihan
[0m20:31:12.092583 [info ] [MainThread]:   database: dbelsa
[0m20:31:12.093748 [info ] [MainThread]:   schema: bronze
[0m20:31:12.094836 [info ] [MainThread]:   connect_timeout: 10
[0m20:31:12.097413 [info ] [MainThread]:   role: None
[0m20:31:12.099255 [info ] [MainThread]:   search_path: None
[0m20:31:12.100366 [info ] [MainThread]:   keepalives_idle: 0
[0m20:31:12.101368 [info ] [MainThread]:   sslmode: None
[0m20:31:12.102364 [info ] [MainThread]:   sslcert: None
[0m20:31:12.103318 [info ] [MainThread]:   sslkey: None
[0m20:31:12.106440 [info ] [MainThread]:   sslrootcert: None
[0m20:31:12.108544 [info ] [MainThread]:   application_name: dbt
[0m20:31:12.109781 [info ] [MainThread]:   retries: 1
[0m20:31:12.111067 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:31:12.223111 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:31:12.262477 [debug] [MainThread]: Using postgres connection "debug"
[0m20:31:12.263505 [debug] [MainThread]: On debug: select 1 as id
[0m20:31:12.264388 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:31:12.270321 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "db" to address: Name or service not known

[0m20:31:12.277419 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:31:12.278471 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:31:12.279370 [debug] [MainThread]: On debug: No close available on handle
[0m20:31:12.280392 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:31:12.281673 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:31:12.283136 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  could not translate host name "db" to address: Name or service not known
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:31:12.285131 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.60393125, "process_in_blocks": "0", "process_kernel_time": 0.159325, "process_mem_max_rss": "110644", "process_out_blocks": "14", "process_user_time": 2.851617}
[0m20:31:12.286586 [debug] [MainThread]: Command `dbt debug` failed at 20:31:12.286433 after 0.61 seconds
[0m20:31:12.287935 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:31:12.291363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ff0368ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ff21989a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9ff01ffb80>]}
[0m20:31:12.292675 [debug] [MainThread]: Flushing usage events
[0m20:31:12.775292 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:32:26.519490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d48814ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d472d0280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d472d0220>]}


============================== 20:32:26.527474 | a59e651b-c6df-495e-b621-cf9a8c23415b ==============================
[0m20:32:26.527474 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:32:26.528853 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug --target dev_elsa', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:32:26.545416 [info ] [MainThread]: dbt version: 1.10.4
[0m20:32:26.547339 [info ] [MainThread]: python version: 3.10.14
[0m20:32:26.548717 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:32:26.550609 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:32:26.645124 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:32:26.646218 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:32:26.647422 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:32:26.648791 [info ] [MainThread]: adapter type: postgres
[0m20:32:26.649836 [info ] [MainThread]: adapter version: 1.9.0
[0m20:32:26.823326 [info ] [MainThread]: Configuration:
[0m20:32:26.824570 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:32:26.825805 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:32:26.827080 [info ] [MainThread]: Required dependencies:
[0m20:32:26.828239 [debug] [MainThread]: Executing "git --help"
[0m20:32:26.831995 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:32:26.833736 [debug] [MainThread]: STDERR: "b''"
[0m20:32:26.834631 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:32:26.835960 [info ] [MainThread]: Connection:
[0m20:32:26.838101 [info ] [MainThread]:   host: db
[0m20:32:26.840173 [info ] [MainThread]:   port: 5432
[0m20:32:26.841327 [info ] [MainThread]:   user: elsalebihan
[0m20:32:26.842856 [info ] [MainThread]:   database: dbelsa
[0m20:32:26.844061 [info ] [MainThread]:   schema: bronze
[0m20:32:26.845631 [info ] [MainThread]:   connect_timeout: 10
[0m20:32:26.846739 [info ] [MainThread]:   role: None
[0m20:32:26.847764 [info ] [MainThread]:   search_path: None
[0m20:32:26.849241 [info ] [MainThread]:   keepalives_idle: 0
[0m20:32:26.850365 [info ] [MainThread]:   sslmode: None
[0m20:32:26.851436 [info ] [MainThread]:   sslcert: None
[0m20:32:26.852571 [info ] [MainThread]:   sslkey: None
[0m20:32:26.853630 [info ] [MainThread]:   sslrootcert: None
[0m20:32:26.857697 [info ] [MainThread]:   application_name: dbt
[0m20:32:26.858805 [info ] [MainThread]:   retries: 1
[0m20:32:26.860117 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:32:26.973439 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:32:27.008004 [debug] [MainThread]: Using postgres connection "debug"
[0m20:32:27.009040 [debug] [MainThread]: On debug: select 1 as id
[0m20:32:27.009970 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:32:27.026867 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "db" to address: Name or service not known

[0m20:32:27.032860 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:32:27.033828 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:32:27.034558 [debug] [MainThread]: On debug: No close available on handle
[0m20:32:27.035283 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:32:27.036195 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:32:27.038019 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  could not translate host name "db" to address: Name or service not known
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:32:27.040406 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.6123391, "process_in_blocks": "0", "process_kernel_time": 0.186277, "process_mem_max_rss": "110608", "process_out_blocks": "14", "process_user_time": 2.88068}
[0m20:32:27.041602 [debug] [MainThread]: Command `dbt debug` failed at 20:32:27.041413 after 0.61 seconds
[0m20:32:27.042337 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:32:27.043663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d48814ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d4a5f3070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d486abb80>]}
[0m20:32:27.044912 [debug] [MainThread]: Flushing usage events
[0m20:32:27.594249 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:34:23.174766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d6d88af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d57b0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d57b01f0>]}


============================== 20:34:23.181445 | 192d82d2-452f-479b-8e8f-d0fcd69ccead ==============================
[0m20:34:23.181445 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:34:23.182684 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --target dev_elsa', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:34:23.475222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '192d82d2-452f-479b-8e8f-d0fcd69ccead', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d5602aa0>]}
[0m20:34:23.570329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '192d82d2-452f-479b-8e8f-d0fcd69ccead', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d56031c0>]}
[0m20:34:23.572146 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:34:23.751044 [debug] [MainThread]: checksum: 0af36a85d50777368bfad96f7b079454a784073d22eee9066924278f802a5ad5, vars: {}, profile: , target: dev_elsa, version: 1.10.4
[0m20:34:24.067246 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m20:34:24.068479 [debug] [MainThread]: previous checksum: 0af36a85d50777368bfad96f7b079454a784073d22eee9066924278f802a5ad5, current checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2
[0m20:34:24.069463 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:34:24.070632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '192d82d2-452f-479b-8e8f-d0fcd69ccead', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d8093ca0>]}
[0m20:34:32.029663 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:34:32.058042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '192d82d2-452f-479b-8e8f-d0fcd69ccead', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d3dea290>]}
[0m20:34:32.404484 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:34:32.409766 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:34:32.442407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '192d82d2-452f-479b-8e8f-d0fcd69ccead', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d393e7a0>]}
[0m20:34:32.443836 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:34:32.445002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '192d82d2-452f-479b-8e8f-d0fcd69ccead', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d393ead0>]}
[0m20:34:32.450120 [info ] [MainThread]: 
[0m20:34:32.451595 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m20:34:32.453554 [info ] [MainThread]: 
[0m20:34:32.455751 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:34:32.469422 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:34:32.470764 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:34:32.483392 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m20:34:32.550746 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:34:32.551453 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:34:32.552066 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m20:34:32.552894 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:34:32.553848 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:34:32.554801 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:34:32.556021 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:34:32.557585 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:34:32.558620 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:34:32.567844 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "db" (172.18.0.2), port 5432 failed: FATAL:  database "dbelsa" does not exist

[0m20:34:32.568917 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "db" (172.18.0.2), port 5432 failed: FATAL:  database "dbelsa" does not exist

[0m20:34:32.569937 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "db" (172.18.0.2), port 5432 failed: FATAL:  database "dbelsa" does not exist

[0m20:34:32.579339 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:34:32.580416 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:34:32.581801 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m20:34:32.582612 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:34:32.583759 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:34:32.584480 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:34:32.585450 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:34:32.586640 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:34:32.587541 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m20:34:32.588407 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:34:32.590008 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:34:32.591096 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m20:34:32.592010 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:34:32.592848 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:34:32.593564 [debug] [ThreadPool]: On list_dbelsa: No close available on handle
[0m20:34:32.595998 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:34:32.596779 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:34:32.597438 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:34:32.598304 [debug] [MainThread]: Connection 'list_dbelsa' was properly closed.
[0m20:34:32.599042 [info ] [MainThread]: 
[0m20:34:32.599988 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.14 seconds (0.14s).
[0m20:34:32.601249 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "db" (172.18.0.2), port 5432 failed: FATAL:  database "dbelsa" does not exist
  
[0m20:34:32.603165 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.518305, "process_in_blocks": "0", "process_kernel_time": 0.280547, "process_mem_max_rss": "136088", "process_out_blocks": "8317", "process_user_time": 11.24822}
[0m20:34:32.604307 [debug] [MainThread]: Command `dbt run` failed at 20:34:32.604168 after 9.52 seconds
[0m20:34:32.605138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d6d88af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d393e1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d3da9ed0>]}
[0m20:34:32.607811 [debug] [MainThread]: Flushing usage events
[0m20:34:33.084505 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:35:34.189841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc094cb0a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0936e0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0936e01f0>]}


============================== 20:35:34.196582 | b63bef1c-f249-4ff7-abf5-212ebea01119 ==============================
[0m20:35:34.196582 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:35:34.197831 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --target dev_elsa', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:35:34.491116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0938e5c60>]}
[0m20:35:34.598204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0936cf280>]}
[0m20:35:34.599629 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:35:34.770247 [debug] [MainThread]: checksum: 0af36a85d50777368bfad96f7b079454a784073d22eee9066924278f802a5ad5, vars: {}, profile: , target: dev_elsa, version: 1.10.4
[0m20:35:35.090573 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m20:35:35.091957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09449e2c0>]}
[0m20:35:43.441919 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:35:43.469028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091bbc1c0>]}
[0m20:35:43.817484 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:35:43.821698 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:35:43.853680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0917126b0>]}
[0m20:35:43.854780 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:35:43.855697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091711c60>]}
[0m20:35:43.861457 [info ] [MainThread]: 
[0m20:35:43.863030 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m20:35:43.865125 [info ] [MainThread]: 
[0m20:35:43.867299 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:35:43.879589 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m20:35:43.880775 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m20:35:43.888200 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m20:35:43.954277 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m20:35:43.955019 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m20:35:43.955560 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m20:35:43.956726 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m20:35:43.958405 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m20:35:43.959451 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m20:35:43.960427 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:35:43.961321 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:35:43.962243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:35:43.977119 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.017 seconds
[0m20:35:43.977855 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.017 seconds
[0m20:35:43.978393 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.016 seconds
[0m20:35:43.980347 [debug] [ThreadPool]: On list_elsa: Close
[0m20:35:43.982200 [debug] [ThreadPool]: On list_elsa: Close
[0m20:35:43.984129 [debug] [ThreadPool]: On list_elsa: Close
[0m20:35:43.987560 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa_tec_elsa)
[0m20:35:43.988400 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa_bronze)
[0m20:35:43.989130 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now create_elsa_silver)
[0m20:35:43.991333 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "tec_elsa"
"
[0m20:35:43.992671 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "bronze"
"
[0m20:35:43.993724 [debug] [ThreadPool]: Creating schema "database: "elsa"
schema: "silver"
"
[0m20:35:44.004642 [debug] [ThreadPool]: Using postgres connection "create_elsa_tec_elsa"
[0m20:35:44.082166 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze"
[0m20:35:44.091008 [debug] [ThreadPool]: Using postgres connection "create_elsa_silver"
[0m20:35:44.092141 [debug] [ThreadPool]: On create_elsa_tec_elsa: BEGIN
[0m20:35:44.093406 [debug] [ThreadPool]: On create_elsa_bronze: BEGIN
[0m20:35:44.094636 [debug] [ThreadPool]: On create_elsa_silver: BEGIN
[0m20:35:44.095723 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:35:44.096866 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:35:44.097901 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:35:44.108932 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m20:35:44.109610 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m20:35:44.110441 [debug] [ThreadPool]: Using postgres connection "create_elsa_tec_elsa"
[0m20:35:44.111113 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m20:35:44.111972 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze"
[0m20:35:44.112934 [debug] [ThreadPool]: On create_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "create_elsa_tec_elsa"} */
create schema if not exists "tec_elsa"
[0m20:35:44.113730 [debug] [ThreadPool]: Using postgres connection "create_elsa_silver"
[0m20:35:44.114588 [debug] [ThreadPool]: On create_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "create_elsa_bronze"} */
create schema if not exists "bronze"
[0m20:35:44.115690 [debug] [ThreadPool]: On create_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "create_elsa_silver"} */
create schema if not exists "silver"
[0m20:35:44.116275 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m20:35:44.117539 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.000 seconds
[0m20:35:44.118134 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m20:35:44.119610 [debug] [ThreadPool]: On create_elsa_tec_elsa: COMMIT
[0m20:35:44.121227 [debug] [ThreadPool]: On create_elsa_bronze: COMMIT
[0m20:35:44.122923 [debug] [ThreadPool]: On create_elsa_silver: COMMIT
[0m20:35:44.124177 [debug] [ThreadPool]: Using postgres connection "create_elsa_tec_elsa"
[0m20:35:44.125250 [debug] [ThreadPool]: Using postgres connection "create_elsa_bronze"
[0m20:35:44.126073 [debug] [ThreadPool]: Using postgres connection "create_elsa_silver"
[0m20:35:44.126874 [debug] [ThreadPool]: On create_elsa_tec_elsa: COMMIT
[0m20:35:44.127711 [debug] [ThreadPool]: On create_elsa_bronze: COMMIT
[0m20:35:44.128400 [debug] [ThreadPool]: On create_elsa_silver: COMMIT
[0m20:35:44.130587 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m20:35:44.131186 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m20:35:44.131769 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m20:35:44.132547 [debug] [ThreadPool]: On create_elsa_tec_elsa: Close
[0m20:35:44.133267 [debug] [ThreadPool]: On create_elsa_silver: Close
[0m20:35:44.134142 [debug] [ThreadPool]: On create_elsa_bronze: Close
[0m20:35:44.142107 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa_bronze, now list_elsa_tec_elsa)
[0m20:35:44.143258 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa_silver, now list_elsa_bronze)
[0m20:35:44.151428 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_elsa_tec_elsa, now list_elsa_silver)
[0m20:35:44.158398 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m20:35:44.165322 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m20:35:44.171936 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m20:35:44.172842 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m20:35:44.174115 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m20:35:44.175213 [debug] [ThreadPool]: On list_elsa_silver: BEGIN
[0m20:35:44.176246 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:35:44.177191 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:35:44.178065 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:35:44.187319 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:35:44.188445 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m20:35:44.189148 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:35:44.189921 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m20:35:44.191232 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:35:44.192236 [debug] [ThreadPool]: Using postgres connection "list_elsa_silver"
[0m20:35:44.193150 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m20:35:44.194337 [debug] [ThreadPool]: On list_elsa_silver: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa_silver"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m20:35:44.195351 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:35:44.197185 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:35:44.199175 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:35:44.201297 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m20:35:44.203318 [debug] [ThreadPool]: On list_elsa_silver: ROLLBACK
[0m20:35:44.203983 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:35:44.205244 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m20:35:44.206037 [debug] [ThreadPool]: On list_elsa_silver: Close
[0m20:35:44.208237 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m20:35:44.211981 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m20:35:44.227229 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:44.228198 [debug] [MainThread]: On master: BEGIN
[0m20:35:44.229152 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:35:44.238055 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m20:35:44.238975 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:44.240802 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:35:44.245530 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m20:35:44.247525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09289c520>]}
[0m20:35:44.248520 [debug] [MainThread]: On master: ROLLBACK
[0m20:35:44.249729 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:44.250611 [debug] [MainThread]: On master: BEGIN
[0m20:35:44.251785 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:35:44.252568 [debug] [MainThread]: On master: COMMIT
[0m20:35:44.253288 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:44.254113 [debug] [MainThread]: On master: COMMIT
[0m20:35:44.255075 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:35:44.288394 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:35:44.297862 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:35:44.304762 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:35:44.306083 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m20:35:44.308012 [info ] [MainThread]: 
[0m20:35:44.309267 [debug] [MainThread]: On master: Close
[0m20:35:44.318061 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m20:35:44.318872 [debug] [Thread-2 (]: Began running node model.dbt_elsa.consumption_history
[0m20:35:44.319632 [debug] [Thread-3 (]: Began running node model.dbt_elsa.test_connection
[0m20:35:44.320487 [debug] [Thread-4 (]: Began running node model.elementary.data_monitoring_metrics
[0m20:35:44.321704 [info ] [Thread-1 (]: 1 of 33 START sql table model bronze.consumption ............................... [RUN]
[0m20:35:44.324888 [info ] [Thread-2 (]: 2 of 33 START sql table model silver.consumption_history ....................... [RUN]
[0m20:35:44.326629 [info ] [Thread-3 (]: 3 of 33 START sql table model bronze.test_connection ........................... [RUN]
[0m20:35:44.328243 [info ] [Thread-4 (]: 4 of 33 START sql incremental model tec_elsa.data_monitoring_metrics ........... [RUN]
[0m20:35:44.330235 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.consumption)
[0m20:35:44.331620 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_silver, now model.dbt_elsa.consumption_history)
[0m20:35:44.332693 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now model.dbt_elsa.test_connection)
[0m20:35:44.333921 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.elementary.data_monitoring_metrics'
[0m20:35:44.334993 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m20:35:44.336373 [debug] [Thread-2 (]: Began compiling node model.dbt_elsa.consumption_history
[0m20:35:44.337616 [debug] [Thread-3 (]: Began compiling node model.dbt_elsa.test_connection
[0m20:35:44.338742 [debug] [Thread-4 (]: Began compiling node model.elementary.data_monitoring_metrics
[0m20:35:44.349148 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m20:35:44.359010 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m20:35:44.366879 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_elsa.test_connection"
[0m20:35:44.383159 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.data_monitoring_metrics"
[0m20:35:44.387675 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m20:35:44.388408 [debug] [Thread-2 (]: Began executing node model.dbt_elsa.consumption_history
[0m20:35:44.389100 [debug] [Thread-3 (]: Began executing node model.dbt_elsa.test_connection
[0m20:35:44.451051 [debug] [Thread-4 (]: Began executing node model.elementary.data_monitoring_metrics
[0m20:35:44.468369 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m20:35:44.482350 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m20:35:44.486348 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_elsa.test_connection"
[0m20:35:44.549755 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.data_monitoring_metrics"
[0m20:35:44.550864 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:35:44.552789 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m20:35:44.554693 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m20:35:44.555450 [debug] [Thread-3 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:35:44.556377 [debug] [Thread-2 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m20:35:44.557956 [debug] [Thread-4 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m20:35:44.558932 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:35:44.560949 [debug] [Thread-3 (]: On model.dbt_elsa.test_connection: BEGIN
[0m20:35:44.562661 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:44.563783 [debug] [Thread-4 (]: On model.elementary.data_monitoring_metrics: BEGIN
[0m20:35:44.565430 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:44.568006 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:35:44.575249 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m20:35:44.576598 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:35:44.578027 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m20:35:44.579018 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m20:35:44.580751 [debug] [Thread-4 (]: SQL status: BEGIN in 0.013 seconds
[0m20:35:44.581651 [debug] [Thread-3 (]: SQL status: BEGIN in 0.016 seconds
[0m20:35:44.582480 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM bronze.rte_eco2mix
              ^

[0m20:35:44.583770 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m20:35:44.585004 [debug] [Thread-4 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m20:35:44.586087 [debug] [Thread-3 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:35:44.587186 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m20:35:44.588356 [debug] [Thread-2 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "elsa"."silver"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "elsa"."silver"."consumption_history"
WHERE DATE(created_at) < CURRENT_DATE
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM "elsa"."bronze"."consumption"
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m20:35:44.590271 [debug] [Thread-4 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.data_monitoring_metrics"} */

      
  
    

  create  table "elsa"."tec_elsa"."data_monitoring_metrics"
  
  
    as
  
  (
    


    
    
        
    
    select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as id

,
                
        cast('dummy_string' as varchar(4096)) as full_table_name

,
                
        cast('dummy_string' as varchar(4096)) as column_name

,
                
        cast('dummy_string' as varchar(4096)) as metric_name

,
                
        cast('dummy_string' as varchar(4096)) as metric_type

,
                
        cast(123456789.99 as float) as metric_value

,
                
        cast('dummy_string' as varchar(4096)) as source_value

,
                cast('2091-02-17' as timestamp) as bucket_start

,
                cast('2091-02-17' as timestamp) as bucket_end

,
                
        cast(123456789 as integer) as bucket_duration_hours

,
                cast('2091-02-17' as timestamp) as updated_at

,
                
        cast('dummy_string' as varchar(4096)) as dimension

,
                
        cast('dummy_string' as varchar(4096)) as dimension_value

,
                
        cast('dummy_string' as varchar(4096)) as metric_properties

,
                cast('2091-02-17' as timestamp) as created_at


        ) as empty_table
        where 1 = 0

  );
  
  
[0m20:35:44.591858 [debug] [Thread-3 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */

  
    

  create  table "elsa"."bronze"."test_connection__dbt_tmp"
  
  
    as
  
  (
    select current_database() as db, current_schema() as schema;
  );
  
[0m20:35:44.593428 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m20:35:44.594719 [debug] [Thread-2 (]: Postgres adapter: Postgres error: relation "silver.consumption_history" does not exist
LINE 13: FROM "elsa"."silver"."consumption_history"
              ^

[0m20:35:44.596261 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 12: ...select current_database() as db, current_schema() as schema;
                                                                       ^

[0m20:35:44.598954 [debug] [Thread-2 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m20:35:44.599851 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.004 seconds
[0m20:35:44.601426 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:35:44.602369 [debug] [Thread-3 (]: On model.dbt_elsa.test_connection: ROLLBACK
[0m20:35:44.603761 [debug] [Thread-2 (]: On model.dbt_elsa.consumption_history: Close
[0m20:35:44.632198 [debug] [Thread-4 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m20:35:44.633053 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09298e800>]}
[0m20:35:44.634076 [debug] [Thread-3 (]: On model.dbt_elsa.test_connection: Close
[0m20:35:44.636102 [debug] [Thread-2 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m20:35:44.636913 [debug] [Thread-4 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.data_monitoring_metrics"} */

    create  index if not exists
  "7b66d232c39e51c03cbf1f2345464baf"
  on "elsa"."tec_elsa"."data_monitoring_metrics" 
  (full_table_name, column_name, metric_name)
  
[0m20:35:44.638567 [error] [Thread-1 (]: 1 of 33 ERROR creating sql table model bronze.consumption ...................... [[31mERROR[0m in 0.29s]
[0m20:35:44.642145 [debug] [Thread-3 (]: Database Error in model test_connection (models/bronze/test_connection.sql)
  syntax error at or near ";"
  LINE 12: ...select current_database() as db, current_schema() as schema;
                                                                         ^
  compiled code at target/run/dbt_elsa/models/bronze/test_connection.sql
[0m20:35:44.643383 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090f63a90>]}
[0m20:35:44.645369 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m20:35:44.646376 [debug] [Thread-4 (]: SQL status: CREATE INDEX in 0.002 seconds
[0m20:35:44.648038 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090f68550>]}
[0m20:35:44.650187 [error] [Thread-2 (]: 2 of 33 ERROR creating sql table model silver.consumption_history .............. [[31mERROR[0m in 0.31s]
[0m20:35:44.651620 [debug] [Thread-1 (]: Began running node model.elementary.dbt_columns
[0m20:35:44.652807 [debug] [Thread-7 (]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m20:35:44.672200 [error] [Thread-3 (]: 3 of 33 ERROR creating sql table model bronze.test_connection .................. [[31mERROR[0m in 0.32s]
[0m20:35:44.681092 [debug] [Thread-4 (]: On model.elementary.data_monitoring_metrics: COMMIT
[0m20:35:44.682355 [debug] [Thread-2 (]: Finished running node model.dbt_elsa.consumption_history
[0m20:35:44.683709 [info ] [Thread-1 (]: 5 of 33 START sql incremental model tec_elsa.dbt_columns ....................... [RUN]
[0m20:35:44.686172 [debug] [Thread-3 (]: Finished running node model.dbt_elsa.test_connection
[0m20:35:44.687272 [debug] [Thread-4 (]: Using postgres connection "model.elementary.data_monitoring_metrics"
[0m20:35:44.688447 [debug] [Thread-2 (]: Began running node model.elementary.dbt_exposures
[0m20:35:44.689346 [debug] [Thread-7 (]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m20:35:44.692855 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_elsa.consumption, now model.elementary.dbt_columns)
[0m20:35:44.694103 [debug] [Thread-3 (]: Began running node model.elementary.dbt_groups
[0m20:35:44.695331 [debug] [Thread-4 (]: On model.elementary.data_monitoring_metrics: COMMIT
[0m20:35:44.696636 [info ] [Thread-2 (]: 6 of 33 START sql incremental model tec_elsa.dbt_exposures ..................... [RUN]
[0m20:35:44.697959 [debug] [Thread-7 (]: Marking all children of 'model.dbt_elsa.test_connection' to be skipped because of status 'error'.  Reason: Database Error in model test_connection (models/bronze/test_connection.sql)
  syntax error at or near ";"
  LINE 12: ...select current_database() as db, current_schema() as schema;
                                                                         ^
  compiled code at target/run/dbt_elsa/models/bronze/test_connection.sql.
[0m20:35:44.699138 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_columns
[0m20:35:44.700294 [info ] [Thread-3 (]: 7 of 33 START sql incremental model tec_elsa.dbt_groups ........................ [RUN]
[0m20:35:44.701831 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.dbt_elsa.consumption_history, now model.elementary.dbt_exposures)
[0m20:35:44.702596 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:44.718616 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_columns"
[0m20:35:44.719308 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.dbt_elsa.test_connection, now model.elementary.dbt_groups)
[0m20:35:44.720792 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_exposures
[0m20:35:44.725785 [debug] [Thread-4 (]: On model.elementary.data_monitoring_metrics: Close
[0m20:35:44.727697 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_groups
[0m20:35:44.742246 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_columns
[0m20:35:44.747413 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_exposures"
[0m20:35:44.749387 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0961cfd00>]}
[0m20:35:44.764186 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_groups"
[0m20:35:44.775723 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_columns"
[0m20:35:44.777987 [info ] [Thread-4 (]: 4 of 33 OK created sql incremental model tec_elsa.data_monitoring_metrics ...... [[32mSELECT 0[0m in 0.42s]
[0m20:35:44.779610 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_exposures
[0m20:35:44.782170 [debug] [Thread-4 (]: Finished running node model.elementary.data_monitoring_metrics
[0m20:35:44.782945 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_groups
[0m20:35:44.797340 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_exposures"
[0m20:35:44.798615 [debug] [Thread-4 (]: Began running node model.elementary.dbt_invocations
[0m20:35:44.799800 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:44.810534 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_groups"
[0m20:35:44.813987 [info ] [Thread-4 (]: 8 of 33 START sql incremental model tec_elsa.dbt_invocations ................... [RUN]
[0m20:35:44.815774 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m20:35:44.816430 [debug] [Thread-1 (]: On model.elementary.dbt_columns: BEGIN
[0m20:35:44.818104 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.data_monitoring_metrics, now model.elementary.dbt_invocations)
[0m20:35:44.819139 [debug] [Thread-2 (]: On model.elementary.dbt_exposures: BEGIN
[0m20:35:44.820013 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_groups"
[0m20:35:44.820952 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:35:44.822277 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_invocations
[0m20:35:44.824437 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:44.825903 [debug] [Thread-3 (]: On model.elementary.dbt_groups: BEGIN
[0m20:35:44.845189 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m20:35:44.847100 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_invocations"
[0m20:35:44.848191 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:44.849254 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:44.851470 [debug] [Thread-1 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_columns"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_columns"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as parent_unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as data_type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as table_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as resource_type

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:44.853204 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_invocations
[0m20:35:44.854191 [debug] [Thread-2 (]: SQL status: BEGIN in 0.030 seconds
[0m20:35:44.955152 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.101 seconds
[0m20:35:44.959143 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_invocations"
[0m20:35:44.960698 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m20:35:44.961732 [debug] [Thread-3 (]: SQL status: BEGIN in 0.113 seconds
[0m20:35:45.007019 [debug] [Thread-1 (]: Elementary: [dbt_columns] Flattening the artifacts.
[0m20:35:45.008055 [debug] [Thread-2 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_exposures"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_exposures"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as maturity

,
                
        cast('dummy_string' as varchar(4096)) as type

,
                
        cast('dummy_string' as varchar(4096)) as owner_email

,
                
        cast('dummy_string' as varchar(4096)) as owner_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as url

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_columns

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as label

,
                
        cast('this_is_just_a_long_dummy_string' as text) as raw_queries


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:45.009426 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_invocations"
[0m20:35:45.010407 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_groups"
[0m20:35:45.035945 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.006 seconds
[0m20:35:45.059888 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: BEGIN
[0m20:35:45.084086 [debug] [Thread-3 (]: On model.elementary.dbt_groups: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_groups"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_groups"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as owner_email

,
                
        cast('dummy_string' as varchar(4096)) as owner_name

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:45.110744 [debug] [Thread-2 (]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m20:35:45.131980 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:45.168062 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.012 seconds
[0m20:35:45.244200 [debug] [Thread-2 (]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m20:35:45.265273 [debug] [Thread-1 (]: Elementary: [dbt_columns] Flattened 87 artifacts.
[0m20:35:45.269698 [debug] [Thread-3 (]: Elementary: [dbt_groups] Flattening the artifacts.
[0m20:35:45.284110 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m20:35:45.286734 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:45.287626 [debug] [Thread-4 (]: SQL status: BEGIN in 0.156 seconds
[0m20:35:45.290880 [debug] [Thread-3 (]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m20:35:45.292173 [debug] [Thread-2 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_exposures"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_exposures"
    order by metadata_hash
    
  
[0m20:35:45.293277 [debug] [Thread-1 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_columns"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_columns"
    order by metadata_hash
    
  
[0m20:35:45.294389 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_invocations"
[0m20:35:45.296888 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_groups"
[0m20:35:45.298736 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:45.299619 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:45.300664 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_invocations"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_invocations"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as invocation_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as job_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as job_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as job_run_id

,
                
        cast('dummy_string' as varchar(4096)) as run_started_at

,
                
        cast('dummy_string' as varchar(4096)) as run_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast('dummy_string' as varchar(4096)) as command

,
                
        cast('dummy_string' as varchar(4096)) as dbt_version

,
                
        cast('dummy_string' as varchar(4096)) as elementary_version

,
                
        cast (True as boolean) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as text) as invocation_vars

,
                
        cast('this_is_just_a_long_dummy_string' as text) as vars

,
                
        cast('dummy_string' as varchar(4096)) as target_name

,
                
        cast('dummy_string' as varchar(4096)) as target_database

,
                
        cast('dummy_string' as varchar(4096)) as target_schema

,
                
        cast('dummy_string' as varchar(4096)) as target_profile_name

,
                
        cast(123456789 as integer) as threads

,
                
        cast('this_is_just_a_long_dummy_string' as text) as selected

,
                
        cast('this_is_just_a_long_dummy_string' as text) as yaml_selector

,
                
        cast('dummy_string' as varchar(4096)) as project_id

,
                
        cast('dummy_string' as varchar(4096)) as project_name

,
                
        cast('dummy_string' as varchar(4096)) as env

,
                
        cast('dummy_string' as varchar(4096)) as env_id

,
                
        cast('dummy_string' as varchar(4096)) as cause_category

,
                
        cast('this_is_just_a_long_dummy_string' as text) as cause

,
                
        cast('dummy_string' as varchar(4096)) as pull_request_id

,
                
        cast('dummy_string' as varchar(4096)) as git_sha

,
                
        cast('dummy_string' as varchar(4096)) as orchestrator

,
                
        cast('dummy_string' as varchar(4096)) as dbt_user

,
                
        cast('dummy_string' as varchar(4096)) as job_url

,
                
        cast('dummy_string' as varchar(4096)) as job_run_url

,
                
        cast('dummy_string' as varchar(4096)) as account_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as target_adapter_specific_fields


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:45.302148 [debug] [Thread-3 (]: On model.elementary.dbt_groups: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_groups"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_groups"
    order by metadata_hash
    
  
[0m20:35:45.304795 [debug] [Thread-2 (]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m20:35:45.308203 [debug] [Thread-1 (]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m20:35:45.311030 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:45.312433 [debug] [Thread-2 (]: Elementary: [dbt_exposures] Artifacts did not change.
[0m20:35:45.313347 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.004 seconds
[0m20:35:45.315256 [debug] [Thread-1 (]: Elementary: [dbt_columns] Artifacts changed.
[0m20:35:45.317886 [debug] [Thread-3 (]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m20:35:45.320699 [debug] [Thread-2 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m20:35:45.323364 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: COMMIT
[0m20:35:45.336305 [debug] [Thread-1 (]: Elementary: Deleting from and inserting to: "elsa"."tec_elsa"."dbt_columns"
[0m20:35:45.338330 [debug] [Thread-3 (]: Elementary: [dbt_groups] Artifacts did not change.
[0m20:35:45.340964 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.051378 (1 runs)
[0m20:35:45.342269 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_invocations"
[0m20:35:45.363135 [debug] [Thread-3 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m20:35:45.372085 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:45.374852 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.209853 (1 runs)
[0m20:35:45.376184 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: COMMIT
[0m20:35:45.377776 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.001115 (1 runs)
[0m20:35:45.378826 [debug] [Thread-1 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_columns"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250720203545356234203545364701"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m20:35:45.380282 [debug] [Thread-2 (]: On model.elementary.dbt_exposures: COMMIT
[0m20:35:45.382365 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.093410 (1 runs)
[0m20:35:45.383217 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:45.384577 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_exposures"
[0m20:35:45.385289 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:45.386867 [debug] [Thread-3 (]: On model.elementary.dbt_groups: COMMIT
[0m20:35:45.388584 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: Close
[0m20:35:45.390073 [debug] [Thread-2 (]: On model.elementary.dbt_exposures: COMMIT
[0m20:35:45.409479 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_groups"
[0m20:35:45.436242 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:45.437667 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09289eaa0>]}
[0m20:35:45.440209 [debug] [Thread-3 (]: On model.elementary.dbt_groups: COMMIT
[0m20:35:45.441384 [debug] [Thread-2 (]: SQL status: COMMIT in 0.003 seconds
[0m20:35:45.442440 [debug] [Thread-1 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_columns"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250720203545356234203545364701'
        
      order by ordinal_position

  
[0m20:35:45.444083 [info ] [Thread-4 (]: 8 of 33 OK created sql incremental model tec_elsa.dbt_invocations .............. [[32mSELECT 0[0m in 0.62s]
[0m20:35:45.447075 [debug] [Thread-2 (]: On model.elementary.dbt_exposures: Close
[0m20:35:45.447802 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:45.449371 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_invocations
[0m20:35:45.450908 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090f62140>]}
[0m20:35:45.453516 [debug] [Thread-3 (]: On model.elementary.dbt_groups: Close
[0m20:35:45.454916 [debug] [Thread-4 (]: Began running node model.elementary.dbt_metrics
[0m20:35:45.458924 [info ] [Thread-2 (]: 6 of 33 OK created sql incremental model tec_elsa.dbt_exposures ................ [[32mSELECT 0[0m in 0.75s]
[0m20:35:45.460236 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.011 seconds
[0m20:35:45.462637 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090f62440>]}
[0m20:35:45.464102 [info ] [Thread-4 (]: 9 of 33 START sql incremental model tec_elsa.dbt_metrics ....................... [RUN]
[0m20:35:45.465912 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_exposures
[0m20:35:45.475187 [debug] [Thread-1 (]: Elementary: Inserting 87 rows to table "dbt_columns__tmp_20250720203545356234203545364701"
[0m20:35:45.477139 [info ] [Thread-3 (]: 7 of 33 OK created sql incremental model tec_elsa.dbt_groups ................... [[32mSELECT 0[0m in 0.74s]
[0m20:35:45.478955 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_invocations, now model.elementary.dbt_metrics)
[0m20:35:45.480208 [debug] [Thread-2 (]: Began running node model.elementary.dbt_models
[0m20:35:45.499297 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_groups
[0m20:35:45.522994 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_metrics
[0m20:35:45.537088 [info ] [Thread-2 (]: 10 of 33 START sql incremental model tec_elsa.dbt_models ....................... [RUN]
[0m20:35:45.562131 [debug] [Thread-3 (]: Began running node model.elementary.dbt_run_results
[0m20:35:45.637231 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_exposures, now model.elementary.dbt_models)
[0m20:35:45.644401 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_metrics"
[0m20:35:45.658496 [info ] [Thread-3 (]: 11 of 33 START sql incremental model tec_elsa.dbt_run_results .................. [RUN]
[0m20:35:45.676987 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_models
[0m20:35:45.714273 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_groups, now model.elementary.dbt_run_results)
[0m20:35:45.738293 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_metrics
[0m20:35:45.776385 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_models"
[0m20:35:45.787040 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_run_results
[0m20:35:45.832813 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_metrics"
[0m20:35:45.895547 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_run_results"
[0m20:35:45.908726 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_models
[0m20:35:45.975025 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m20:35:45.988073 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_run_results
[0m20:35:46.010654 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_models"
[0m20:35:46.025016 [debug] [Thread-4 (]: On model.elementary.dbt_metrics: BEGIN
[0m20:35:46.063785 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_run_results"
[0m20:35:46.094896 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:46.125419 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:46.168015 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m20:35:46.200184 [debug] [Thread-2 (]: On model.elementary.dbt_models: BEGIN
[0m20:35:46.201002 [debug] [Thread-4 (]: SQL status: BEGIN in 0.106 seconds
[0m20:35:46.220091 [debug] [Thread-3 (]: On model.elementary.dbt_run_results: BEGIN
[0m20:35:46.243979 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:46.269021 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m20:35:46.292887 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:46.327930 [debug] [Thread-1 (]: Elementary: [1/1] Running insert query.
[0m20:35:46.329325 [debug] [Thread-4 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_metrics"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_metrics"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as label

,
                
        cast('dummy_string' as varchar(4096)) as model

,
                
        cast('dummy_string' as varchar(4096)) as type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as sql

,
                
        cast('dummy_string' as varchar(4096)) as timestamp

,
                
        cast('this_is_just_a_long_dummy_string' as text) as filters

,
                
        cast('this_is_just_a_long_dummy_string' as text) as time_grains

,
                
        cast('this_is_just_a_long_dummy_string' as text) as dimensions

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:46.332710 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:46.334234 [debug] [Thread-2 (]: SQL status: BEGIN in 0.090 seconds
[0m20:35:46.345887 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.008 seconds
[0m20:35:46.342399 [debug] [Thread-1 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_columns"} */

    
       insert into "dbt_columns__tmp_20250720203545356234203545364701"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.dbt_elsa.consumption.id','model.dbt_elsa.consumption','id','integer','[]','{}','elsa','bronze','consumption','ID','model','2025-07-20 20:35:45','1b339d8bc84c2644c964b35d2efcaebb'),('column.model.dbt_elsa.consumption.created_at','model.dbt_elsa.consumption','created_at','datetime','[]','{}','elsa','bronze','consumption','datetime','model','2025-07-20 20:35:45','4f5046ce89934f74491d7499868f6aff'),('column.model.dbt_elsa.consumption.date','model.dbt_elsa.consumption','date','date','[]','{}','elsa','bronze','consumption','date','model','2025-07-20 20:35:45','933f56a529e08b007b899618c489a5b7'),('column.model.dbt_elsa.consumption.time','model.dbt_elsa.consumption','time','time','[]','{}','elsa','bronze','consumption','time','model','2025-07-20 20:35:45','9a430aa16d9a208634bbf5b03e472797'),('column.model.dbt_elsa.consumption.gaz','model.dbt_elsa.consumption','gaz','integer','[]','{}','elsa','bronze','consumption','Production for gaz energy in TWH','model','2025-07-20 20:35:45','c1381ba8bc7d677af0f60682093b014a'),('column.model.dbt_elsa.consumption.nucleaire','model.dbt_elsa.consumption','nucleaire','integer','[]','{}','elsa','bronze','consumption','Production for nuclear energy in TWH','model','2025-07-20 20:35:45','6477b04956e409ee3e1e3a33599fd7ce'),('column.model.dbt_elsa.consumption.charbon','model.dbt_elsa.consumption','charbon','integer','[]','{}','elsa','bronze','consumption','Production for coal energy in TWH','model','2025-07-20 20:35:45','73015f45e474a2f472eac8a0b8bec6ca'),('column.model.dbt_elsa.consumption.solaire','model.dbt_elsa.consumption','solaire','integer','[]','{}','elsa','bronze','consumption','Production for solar energy in TWH','model','2025-07-20 20:35:45','b7ebd61d6e15c578e58c04dcf3f9aab8'),('column.model.dbt_elsa.consumption.eolien','model.dbt_elsa.consumption','eolien','integer','[]','{}','elsa','bronze','consumption','Production for eolian energy in TWH','model','2025-07-20 20:35:45','bfe4d991806cb107fe21daf8a76f88ec'),('column.model.dbt_elsa.consumption.hydraulique','model.dbt_elsa.consumption','hydraulique','integer','[]','{}','elsa','bronze','consumption','Production for hydrolic energy in TWH','model','2025-07-20 20:35:45','e9dd011749620cabab33fc53fd12d90e'),('column.model.dbt_elsa.consumption.bioenergies','model.dbt_elsa.consumption','bioenergies','integer','[]','{}','elsa','bronze','consumption','Production for bioenergy energy in TWH','model','2025-07-20 20:35:45','aee8888eb22af332c4d6cc954e0305e7'),('column.model.dbt_elsa.consumption.autres','model.dbt_elsa.consumption','autres','integer','[]','{}','elsa','bronze','consumption','Production for other energy in TWH','model','2025-07-20 20:35:45','bf60a317f0d62f814c35af46cd70442a'),('column.model.dbt_elsa.consumption.prevision_j','model.dbt_elsa.consumption','prevision_j','integer','[]','{}','elsa','bronze','consumption','Pprevision_j','model','2025-07-20 20:35:45','15b304ac3e18ec9865268b2a711ad58b'),('column.model.dbt_elsa.consumption.prevision_j1','model.dbt_elsa.consumption','prevision_j1','integer','[]','{}','elsa','bronze','consumption','prevision_j1','model','2025-07-20 20:35:45','2cf20940ce3473fdaa10c880d022986e'),('column.model.dbt_elsa.consumption_history.created_at','model.dbt_elsa.consumption_history','created_at','datetime','[]','{}','elsa','silver','consumption_history','datetime','model','2025-07-20 20:35:45','f032746724353f98be0936d4943034da'),('column.model.dbt_elsa.consumption_history.date','model.dbt_elsa.consumption_history','date','date','[]','{}','elsa','silver','consumption_history','date','model','2025-07-20 20:35:45','9e50ce5a1027a44e7a7d1fb64e5c0d20'),('column.model.dbt_elsa.consumption_history.filiere','model.dbt_elsa.consumption_history','filiere','text','[]','{}','elsa','silver','consumption_history','filiere','model','2025-07-20 20:35:45','243c9f9e7e825164d98ad7608783b7f2'),('column.model.dbt_elsa.consumption_history.volume','model.dbt_elsa.consumption_history','volume','integer','[]','{}','elsa','silver','consumption_history','volume','model','2025-07-20 20:35:45','1749add022cd7cb8f4ef00d9fb52962b'),('column.model.elementary.dbt_tests.unique_id','model.elementary.dbt_tests','unique_id','string','[]','{}','elsa','tec_elsa','dbt_tests','The unique id of the test.','model','2025-07-20 20:35:45','4fc471d8cfa2adc8fce0d7733426dfbe'),('column.model.elementary.dbt_tests.database_name','model.elementary.dbt_tests','database_name','string','[]','{}','elsa','tec_elsa','dbt_tests','The tested model database name.','model','2025-07-20 20:35:45','73dfe0c122465b05947bc9fd7b781c5a'),('column.model.elementary.dbt_tests.schema_name','model.elementary.dbt_tests','schema_name','string','[]','{}','elsa','tec_elsa','dbt_tests','The tested model schema name.','model','2025-07-20 20:35:45','ffeeff728f24c52a7e04a03a0740d199'),('column.model.elementary.dbt_tests.name','model.elementary.dbt_tests','name','string','[]','{}','elsa','tec_elsa','dbt_tests','The test name.','model','2025-07-20 20:35:45','f31f4dc9cf26f0cf09b0a230cded7737'),('column.model.elementary.dbt_tests.test_column_name','model.elementary.dbt_tests','test_column_name','string','[]','{}','elsa','tec_elsa','dbt_tests','The name of the tested column.','model','2025-07-20 20:35:45','01b02ab958e15bd02892e50b4227a1c0'),('column.model.elementary.dbt_models.unique_id','model.elementary.dbt_models','unique_id','string','[]','{}','elsa','tec_elsa','dbt_models','The unique id of the model.','model','2025-07-20 20:35:45','a38664996d28b7c5051fe11954f2b7e0'),('column.model.elementary.dbt_models.checksum','model.elementary.dbt_models','checksum','string','[]','{}','elsa','tec_elsa','dbt_models','Model file checksum.','model','2025-07-20 20:35:45','2ec8fa2ea8d1136d93415cd367a15860'),('column.model.elementary.dbt_models.materialization','model.elementary.dbt_models','materialization','string','[]','{}','elsa','tec_elsa','dbt_models','The model materialization config.','model','2025-07-20 20:35:45','1efd0531f1752e5333a88ed398d769fc'),('column.model.elementary.dbt_models.tags','model.elementary.dbt_models','tags','string','[]','{}','elsa','tec_elsa','dbt_models','Model tags property.','model','2025-07-20 20:35:45','b08d6749e7f9b23ef68ba76364eaf7c1'),('column.model.elementary.dbt_models.meta','model.elementary.dbt_models','meta','string','[]','{}','elsa','tec_elsa','dbt_models','The content of ''meta'' property key.','model','2025-07-20 20:35:45','fde24feda9c545177f5f5de6b11cf270'),('column.model.elementary.dbt_models.owner','model.elementary.dbt_models','owner','string','[]','{}','elsa','tec_elsa','dbt_models','Model owner property (configured under ''meta'' key).','model','2025-07-20 20:35:45','8fc09d8fb0e23f0dd0902b4e098184ae'),('column.model.elementary.dbt_models.database_name','model.elementary.dbt_models','database_name','string','[]','{}','elsa','tec_elsa','dbt_models','The model database name.','model','2025-07-20 20:35:45','f9d21eb103bc741a636a39e9f39fd403'),('column.model.elementary.dbt_models.schema_name','model.elementary.dbt_models','schema_name','string','[]','{}','elsa','tec_elsa','dbt_models','The model schema name.','model','2025-07-20 20:35:45','d40cef5456b11e24720f2f158990c387'),('column.model.elementary.dbt_models.depends_on_macros','model.elementary.dbt_models','depends_on_macros','string','[]','{}','elsa','tec_elsa','dbt_models','The macros the model directly depends on.','model','2025-07-20 20:35:45','f5c661731ed9fb68aea8d408110323c3'),('column.model.elementary.dbt_models.depends_on_nodes','model.elementary.dbt_models','depends_on_nodes','string','[]','{}','elsa','tec_elsa','dbt_models','The nodes the model directly depends on.','model','2025-07-20 20:35:45','c74b99c87907899320d3b52252054b0b'),('column.model.elementary.dbt_models.description','model.elementary.dbt_models','description','string','[]','{}','elsa','tec_elsa','dbt_models','Model description.','model','2025-07-20 20:35:45','12c57ed2863e2e7748e425cdff12b9c1'),('column.model.elementary.dbt_models.name','model.elementary.dbt_models','name','string','[]','{}','elsa','tec_elsa','dbt_models','Model name.','model','2025-07-20 20:35:45','0b012e1dbcf88205bc815efb20ba9f25'),('column.model.elementary.dbt_models.package_name','model.elementary.dbt_models','package_name','string','[]','{}','elsa','tec_elsa','dbt_models','Package name of the model.','model','2025-07-20 20:35:45','be73fa4db6dfd03af9a0e79d67f826c2'),('column.model.elementary.dbt_models.original_path','model.elementary.dbt_models','original_path','string','[]','{}','elsa','tec_elsa','dbt_models','Full path of the model file.','model','2025-07-20 20:35:45','bf46b7d8a7a6c2a596f692930b881240'),('column.model.elementary.dbt_models.path','model.elementary.dbt_models','path','string','[]','{}','elsa','tec_elsa','dbt_models','Short path of the model file.','model','2025-07-20 20:35:45','c4e12afa4c182a1ff5e05f4865189e3e'),('column.model.elementary.dbt_models.generated_at','model.elementary.dbt_models','generated_at','string','[]','{}','elsa','tec_elsa','dbt_models','Update time of the table.','model','2025-07-20 20:35:45','b3a6ac900d6cf6538a54a3e82634327e'),('column.model.elementary.dbt_invocations.invocation_id','model.elementary.dbt_invocations','invocation_id','string','[]','{}','elsa','tec_elsa','dbt_invocations','Primary key of this table.','model','2025-07-20 20:35:45','96bbae4091571a0e9927e233fe669790'),('column.model.elementary.dbt_invocations.run_started_at','model.elementary.dbt_invocations','run_started_at','string','[]','{}','elsa','tec_elsa','dbt_invocations','Timestamp the invocation was started.','model','2025-07-20 20:35:45','63717fbc18160b83a87006c7c4cfcd03'),('column.model.elementary.dbt_invocations.run_completed_at','model.elementary.dbt_invocations','run_completed_at','string','[]','{}','elsa','tec_elsa','dbt_invocations','Timestamp the invocation was completed','model','2025-07-20 20:35:45','ba20dac9d7d6835557cc7961be42a337'),('column.model.elementary.dbt_invocations.generated_at','model.elementary.dbt_invocations','generated_at','string','[]','{}','elsa','tec_elsa','dbt_invocations','The time this invocation was uploaded to the database.','model','2025-07-20 20:35:45','8ece522a5bacb563fb7824c516eadceb'),('column.model.elementary.dbt_invocations.command','model.elementary.dbt_invocations','command','string','[]','{}','elsa','tec_elsa','dbt_invocations','dbt command that was used. For example, run.','model','2025-07-20 20:35:45','0f3d332a608cac193a80aface79a8cf3'),('column.model.elementary.dbt_invocations.dbt_version','model.elementary.dbt_invocations','dbt_version','string','[]','{}','elsa','tec_elsa','dbt_invocations','Version of dbt that was used in this invocation.','model','2025-07-20 20:35:45','c89e3210319751876be7bc7d2056cf6c'),('column.model.elementary.dbt_invocations.elementary_version','model.elementary.dbt_invocations','elementary_version','string','[]','{}','elsa','tec_elsa','dbt_invocations','Version of the elementary package that was used in this invocation.','model','2025-07-20 20:35:45','981bc7c3238bb8b11bcb34f416de3fbd'),('column.model.elementary.dbt_invocations.full_refresh','model.elementary.dbt_invocations','full_refresh','boolean','[]','{}','elsa','tec_elsa','dbt_invocations','Whether or not this invocation was executed as a full-refresh.','model','2025-07-20 20:35:45','92cf6b9a2ca8f88842e5801ac96570e5'),('column.model.elementary.dbt_invocations.invocation_vars','model.elementary.dbt_invocations','invocation_vars','string','[]','{}','elsa','tec_elsa','dbt_invocations','Dictionary of the variables (and values) that were declared in the invocation.','model','2025-07-20 20:35:45','49a8d0f08de143b45eb1992c1f13f73e'),('column.model.elementary.dbt_invocations.vars','model.elementary.dbt_invocations','vars','string','[]','{}','elsa','tec_elsa','dbt_invocations','Dictionary of all variables (and values) in the dbt project. If none were declared at runtime, these are the variables declared in dbt_project yml','model','2025-07-20 20:35:45','f7ac4d977ea2a6556d306f24d42f7c80'),('column.model.elementary.dbt_invocations.target_name','model.elementary.dbt_invocations','target_name','string','[]','{}','elsa','tec_elsa','dbt_invocations','Name of the target used in this invocation.','model','2025-07-20 20:35:45','2b52a6d5562ed5e0bf1184a8f412344c'),('column.model.elementary.dbt_invocations.target_database','model.elementary.dbt_invocations','target_database','string','[]','{}','elsa','tec_elsa','dbt_invocations','Name of the target database that was used in this invocation.','model','2025-07-20 20:35:45','145d321193261d41f4669f8fcda1e73b'),('column.model.elementary.dbt_invocations.target_schema','model.elementary.dbt_invocations','target_schema','string','[]','{}','elsa','tec_elsa','dbt_invocations','Name of the target schema that was used in this invocation.','model','2025-07-20 20:35:45','c8ded46563f462339acf6c8179377eda'),('column.model.elementary.dbt_invocations.target_profile_name','model.elementary.dbt_invocations','target_profile_name','string','[]','{}','elsa','tec_elsa','dbt_invocations','Name of the dbt profile that was used in this invocation.','model','2025-07-20 20:35:45','cf19d8055bde387c30e67d2ed6c9a909'),('column.model.elementary.dbt_invocations.threads','model.elementary.dbt_invocations','threads','integer','[]','{}','elsa','tec_elsa','dbt_invocations','Number of threads that were used to run this dbt invocation. (This number could impact the performance of a dbt invocation).','model','2025-07-20 20:35:45','ad3d1a0a42378c3496db97bcab2efb2c'),('column.model.elementary.dbt_invocations.selected','model.elementary.dbt_invocations','selected','string','[]','{}','elsa','tec_elsa','dbt_invocations','The selected resources in the dbt command. While this is a string in the database, this can easily be converted to an array.','model','2025-07-20 20:35:45','f4f8b23f7a112f08fa334ee0d7702b7a'),('column.model.elementary.dbt_invocations.yaml_selector','model.elementary.dbt_invocations','yaml_selector','string','[]','{}','elsa','tec_elsa','dbt_invocations','The yaml selector that was passed in this invocation.','model','2025-07-20 20:35:45','0a960ea0ca4f45e52ed977f818ead385'),('column.model.elementary.dbt_invocations.job_id','model.elementary.dbt_invocations','job_id','string','[]','{}','elsa','tec_elsa','dbt_invocations','The ID of a job, defined in the `job_id` var or in the `JOB_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-20 20:35:45','adb998a2f5b942fba3c91e9aa21f64b0'),('column.model.elementary.dbt_invocations.job_name','model.elementary.dbt_invocations','job_name','string','[]','{}','elsa','tec_elsa','dbt_invocations','The name of a job, defined in the `job_name` var or in the `JOB_NAME` env var.','model','2025-07-20 20:35:45','f71bccfb75d5fee3274b2ed7647e4f11'),('column.model.elementary.dbt_invocations.job_run_id','model.elementary.dbt_invocations','job_run_id','string','[]','{}','elsa','tec_elsa','dbt_invocations','The run ID of a job, defined in the `job_run_id` var or in the `DBT_JOB_RUN_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-20 20:35:45','f9b165cccb705b2a3260cd3b84ee035b'),('column.model.elementary.dbt_invocations.env','model.elementary.dbt_invocations','env','string','[]','{}','elsa','tec_elsa','dbt_invocations','The environment''s name, defined in the `DBT_ENV` env var.','model','2025-07-20 20:35:45','fa00629d5d8a05b247d0067bb094c8a8'),('column.model.elementary.dbt_invocations.env_id','model.elementary.dbt_invocations','env_id','string','[]','{}','elsa','tec_elsa','dbt_invocations','The ID of an environment, defined in the `DBT_ENV_ID` env var.','model','2025-07-20 20:35:45','7645e211e1c376cccff6398109f14fca'),('column.model.elementary.dbt_invocations.project_id','model.elementary.dbt_invocations','project_id','string','[]','{}','elsa','tec_elsa','dbt_invocations','The ID of a project, defined in the `DBT_PROJECT_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-20 20:35:45','aa6cb2f30bcd79c1d09baf01de9632fd'),('column.model.elementary.dbt_invocations.cause_category','model.elementary.dbt_invocations','cause_category','string','[]','{}','elsa','tec_elsa','dbt_invocations','The category of the cause of the invocation. For example, if the invocation was triggered by a schedule, the cause category would be schedule.
Defined in the `DBT_CAUSE_CATEGORY` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).
','model','2025-07-20 20:35:45','3e9a787829ecc055f09d8b6895aee58f'),('column.model.elementary.dbt_invocations.cause','model.elementary.dbt_invocations','cause','string','[]','{}','elsa','tec_elsa','dbt_invocations','The cause of the invocation. For example, if the invocation was triggered by a manual run, the cause would be _"Kicked off by Joe."_.
Defined in the `DBT_CAUSE` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).
','model','2025-07-20 20:35:45','3b3aa36b977edf73f2dc521adee758d6'),('column.model.elementary.dbt_invocations.pull_request_id','model.elementary.dbt_invocations','pull_request_id','string','[]','{}','elsa','tec_elsa','dbt_invocations','The ID of a pull request, defined in the `DBT_PULL_REQUEST_ID` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-20 20:35:45','75bcb70600f90969570b88d6df36adc3'),('column.model.elementary.dbt_invocations.git_sha','model.elementary.dbt_invocations','git_sha','string','[]','{}','elsa','tec_elsa','dbt_invocations','The git SHA of the commit that was used in this invocation, defined in the `DBT_GIT_SHA` env var or by the orchestrator (dbt Cloud, GitHub Actions, etc).','model','2025-07-20 20:35:45','64e2c450653242b2f8b247db482132ae'),('column.model.elementary.dbt_invocations.orchestrator','model.elementary.dbt_invocations','orchestrator','string','[]','{}','elsa','tec_elsa','dbt_invocations','The orchestrator that was used to run this invocation, defined in the `orchestrator` var or in the `ORCHESTRATOR` env var or by the orchestrator env vars. For example, dbt Cloud, GitHub Actions, etc.','model','2025-07-20 20:35:45','7acf7fdcff0bfda624494811e2013d38'),('column.model.elementary.dbt_invocations.job_url','model.elementary.dbt_invocations','job_url','string','[]','{}','elsa','tec_elsa','dbt_invocations','The name of a job, defined in the `job_url` var or in the `JOB_URL` env var or by the orchestrator. For GitHub Actions orchestrator, the value is calculated.','model','2025-07-20 20:35:45','6ce2eaff8cdb3107e4acb5c7d32df0dc'),('column.model.elementary.dbt_invocations.account_id','model.elementary.dbt_invocations','account_id','string','[]','{}','elsa','tec_elsa','dbt_invocations','The ID of the account, defined in the `account_id` var or in the `ACCOUNT_ID` env var or by the orchestrator.','model','2025-07-20 20:35:45','b4ac5ebd38d7db736f2f7430c26480c6'),('column.model.elementary.dbt_run_results.model_execution_id','model.elementary.dbt_run_results','model_execution_id','string','[]','{}','elsa','tec_elsa','dbt_run_results','Execution id generated by joining the unique_id of the resource and the invocation_id. This is the unique key of each row in this model.','model','2025-07-20 20:35:45','371661573c18492ef43ea74bd73ee020'),('column.model.elementary.dbt_run_results.unique_id','model.elementary.dbt_run_results','unique_id','string','[]','{}','elsa','tec_elsa','dbt_run_results','The unique id of the resource (would be similar for all executions of the same resource).','model','2025-07-20 20:35:45','326634d85bc0c6d48f6c648fc84ac17f'),('column.model.elementary.dbt_run_results.invocation_id','model.elementary.dbt_run_results','invocation_id','string','[]','{}','elsa','tec_elsa','dbt_run_results','The unique id of the invocation (would be similar for all resources executed on the same invocation). FK to dbt_invocations.','model','2025-07-20 20:35:45','19c8c9aa38ff5fef8ebd0d02482c2365'),('column.model.elementary.dbt_run_results.name','model.elementary.dbt_run_results','name','string','[]','{}','elsa','tec_elsa','dbt_run_results','Resource name.','model','2025-07-20 20:35:45','aa1e96992f7782c56e7d813c05944444'),('column.model.elementary.dbt_run_results.message','model.elementary.dbt_run_results','message','string','[]','{}','elsa','tec_elsa','dbt_run_results','Execution results message returned by dbt.','model','2025-07-20 20:35:45','4e12dad5e9a823e14304f0823db1227d'),('column.model.elementary.dbt_run_results.status','model.elementary.dbt_run_results','status','string','[]','{}','elsa','tec_elsa','dbt_run_results','Execution result status (success, error, pass, fail)','model','2025-07-20 20:35:45','04e7c959ca1518cf17f6358deaeb6498'),('column.model.elementary.dbt_run_results.resource_type','model.elementary.dbt_run_results','resource_type','string','[]','{}','elsa','tec_elsa','dbt_run_results','Resource type (model, test, snapshot, seed, etc)','model','2025-07-20 20:35:45','a2fb29dfd0784c2aa2de375c89d886a2'),('column.model.elementary.dbt_run_results.execution_time','model.elementary.dbt_run_results','execution_time','float','[]','{}','elsa','tec_elsa','dbt_run_results','Resource execution duration in seconds.','model','2025-07-20 20:35:45','e599babcdfa28f35546c45d6c7f89e0b'),('column.model.elementary.dbt_run_results.execute_started_at','model.elementary.dbt_run_results','execute_started_at','string','[]','{}','elsa','tec_elsa','dbt_run_results','Start time of the execution.','model','2025-07-20 20:35:45','eb7f5a624b2bd831637700cfac29588c'),('column.model.elementary.dbt_run_results.execute_completed_at','model.elementary.dbt_run_results','execute_completed_at','string','[]','{}','elsa','tec_elsa','dbt_run_results','End time of the execution.','model','2025-07-20 20:35:45','8842286ab03756d09988364c43ab304b'),('column.model.elementary.dbt_run_results.compile_started_at','model.elementary.dbt_run_results','compile_started_at','string','[]','{}','elsa','tec_elsa','dbt_run_results','Start time of resource compile action.','model','2025-07-20 20:35:45','a3055e9e5e3bc78c4f3daf2b461d2ae6'),('column.model.elementary.dbt_run_results.compile_completed_at','model.elementary.dbt_run_results','compile_completed_at','string','[]','{}','elsa','tec_elsa','dbt_run_results','End time of resource compile action.','model','2025-07-20 20:35:45','46ed96b0160f568778b9187ca6646582'),('column.model.elementary.dbt_run_results.full_refresh','model.elementary.dbt_run_results','full_refresh','boolean','[]','{}','elsa','tec_elsa','dbt_run_results','Was this a full refresh execution.','model','2025-07-20 20:35:45','7a19498bde49d1c114e7739dc4269f67'),('column.model.elementary.dbt_run_results.compiled_code','model.elementary.dbt_run_results','compiled_code','string','[]','{}','elsa','tec_elsa','dbt_run_results','The compiled code (SQL / Python) executed against the database.','model','2025-07-20 20:35:45','97d039b28e5864a45f4e9d1aef484e6e'),('column.model.elementary.dbt_run_results.failures','model.elementary.dbt_run_results','failures','int','[]','{}','elsa','tec_elsa','dbt_run_results','Number of failures in this run.','model','2025-07-20 20:35:45','91e3d4b64914b79e400a511dbdf19816'),('column.model.elementary.dbt_run_results.query_id','model.elementary.dbt_run_results','query_id','string','[]','{}','elsa','tec_elsa','dbt_run_results','Query ID in the data warehouse, if returned by the adapter (currently only supported in Snowflake, is null for any other adapter).','model','2025-07-20 20:35:45','0a0f070aba6c66e86bc082bbea3e14c2'),('column.model.elementary.dbt_run_results.thread_id','model.elementary.dbt_run_results','thread_id','string','[]','{}','elsa','tec_elsa','dbt_run_results','Id of the thread of this resource run.','model','2025-07-20 20:35:45','78cd87a0d98cfc1ba2860a16fe9978ef'),('column.model.elementary.dbt_run_results.adapter_response','model.elementary.dbt_run_results','adapter_response','string','[]','{}','elsa','tec_elsa','dbt_run_results','Response returned by the adapter (Fields will be different for each adapters).','model','2025-07-20 20:35:45','84f3a781faa64ae121beaf94d0d3fd19')
  
[0m20:35:46.348058 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:46.349355 [debug] [Thread-3 (]: SQL status: BEGIN in 0.056 seconds
[0m20:35:46.353830 [debug] [Thread-4 (]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m20:35:46.356069 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_models"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_models"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as checksum

,
                
        cast('dummy_string' as varchar(4096)) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as patch_path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as unique_key

,
                
        cast('dummy_string' as varchar(4096)) as incremental_strategy

,
                
        cast('dummy_string' as varchar(4096)) as group_name

,
                
        cast('dummy_string' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:46.359062 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m20:35:46.360000 [debug] [Thread-1 (]: SQL status: INSERT 0 87 in 0.005 seconds
[0m20:35:46.362616 [debug] [Thread-4 (]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m20:35:46.365190 [debug] [Thread-3 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_run_results"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_run_results"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as model_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as invocation_id

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast('this_is_just_a_long_dummy_string' as text) as name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as message

,
                
        cast('dummy_string' as varchar(4096)) as status

,
                
        cast('dummy_string' as varchar(4096)) as resource_type

,
                
        cast(123456789.99 as float) as execution_time

,
                
        cast('dummy_string' as varchar(4096)) as execute_started_at

,
                
        cast('dummy_string' as varchar(4096)) as execute_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as compile_started_at

,
                
        cast('dummy_string' as varchar(4096)) as compile_completed_at

,
                
        cast(31474836478 as bigint) as rows_affected

,
                
        cast (True as boolean) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as text) as compiled_code

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as varchar(4096)) as query_id

,
                
        cast('dummy_string' as varchar(4096)) as thread_id

,
                
        cast('dummy_string' as varchar(4096)) as materialization

,
                
        cast('dummy_string' as varchar(4096)) as adapter_response

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:46.374543 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.009 seconds
[0m20:35:46.378594 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:46.381541 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m20:35:46.386505 [debug] [Thread-2 (]: Elementary: [dbt_models] Flattening the artifacts.
[0m20:35:46.387387 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.004 seconds
[0m20:35:46.388437 [debug] [Thread-1 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_columns"} */

    
        begin transaction;
        
        
            insert into "elsa"."tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250720203545356234203545364701";
        
        commit;
    
  
[0m20:35:46.391794 [debug] [Thread-4 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_metrics"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_metrics"
    order by metadata_hash
    
  
[0m20:35:46.414280 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m20:35:46.454207 [debug] [Thread-1 (]: SQL status: COMMIT in 0.012 seconds
[0m20:35:46.468170 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.007 seconds
[0m20:35:46.473026 [debug] [Thread-2 (]: Elementary: [dbt_models] Flattened 33 artifacts.
[0m20:35:46.474994 [debug] [Thread-3 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_run_results"} */

    create  index if not exists
  "d34afd11f9742d7e55f72c7620f9cb5d"
  on "elsa"."tec_elsa"."dbt_run_results" 
  (unique_id)
  
[0m20:35:46.492116 [debug] [Thread-1 (]: Applying DROP to: "dbt_columns__tmp_20250720203545356234203545364701"
[0m20:35:46.494901 [debug] [Thread-4 (]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m20:35:46.497693 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:46.507413 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:46.509635 [debug] [Thread-3 (]: SQL status: CREATE INDEX in 0.010 seconds
[0m20:35:46.511298 [debug] [Thread-4 (]: Elementary: [dbt_metrics] Artifacts did not change.
[0m20:35:46.512412 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_models"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_models"
    order by metadata_hash
    
  
[0m20:35:46.513634 [debug] [Thread-1 (]: On model.elementary.dbt_columns: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_columns"} */
drop table if exists "dbt_columns__tmp_20250720203545356234203545364701" cascade
[0m20:35:46.516924 [debug] [Thread-3 (]: On model.elementary.dbt_run_results: COMMIT
[0m20:35:46.520647 [debug] [Thread-4 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m20:35:46.524730 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:46.525836 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_run_results"
[0m20:35:46.526756 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m20:35:46.528347 [debug] [Thread-4 (]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000679 (1 runs)
[0m20:35:46.531044 [debug] [Thread-2 (]: Elementary: [dbt_models] Comparing the artifacts state.
[0m20:35:46.533327 [debug] [Thread-3 (]: On model.elementary.dbt_run_results: COMMIT
[0m20:35:46.536233 [debug] [Thread-1 (]: Elementary: Finished deleting from and inserting to: "elsa"."tec_elsa"."dbt_columns"
[0m20:35:46.537842 [debug] [Thread-4 (]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.166789 (1 runs)
[0m20:35:46.540834 [debug] [Thread-2 (]: Elementary: [dbt_models] Artifacts changed.
[0m20:35:46.543982 [debug] [Thread-1 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m20:35:46.544812 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m20:35:46.546095 [debug] [Thread-4 (]: On model.elementary.dbt_metrics: COMMIT
[0m20:35:46.547880 [debug] [Thread-2 (]: Elementary: Deleting from and inserting to: "elsa"."tec_elsa"."dbt_models"
[0m20:35:46.549564 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.252867 (1 runs)
[0m20:35:46.551217 [debug] [Thread-3 (]: On model.elementary.dbt_run_results: Close
[0m20:35:46.552132 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_metrics"
[0m20:35:46.557149 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:46.559039 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.059010 (1 runs)
[0m20:35:46.560452 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090f62440>]}
[0m20:35:46.561375 [debug] [Thread-4 (]: On model.elementary.dbt_metrics: COMMIT
[0m20:35:46.562744 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_models"} */

    
  
    

  create temporary table "dbt_models__tmp_20250720203546553576203546553903"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m20:35:46.564485 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000865 (1 runs)
[0m20:35:46.566313 [info ] [Thread-3 (]: 11 of 33 OK created sql incremental model tec_elsa.dbt_run_results ............. [[32mSELECT 0[0m in 0.85s]
[0m20:35:46.568839 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:46.569958 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.002 seconds
[0m20:35:46.572105 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.754663 (87 runs)
[0m20:35:46.575299 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_run_results
[0m20:35:46.577811 [debug] [Thread-4 (]: On model.elementary.dbt_metrics: Close
[0m20:35:46.589034 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:46.592741 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.821689 (1 runs)
[0m20:35:46.595056 [debug] [Thread-3 (]: Began running node model.elementary.dbt_seeds
[0m20:35:46.597056 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc092ff9120>]}
[0m20:35:46.597874 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_models"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250720203546553576203546553903'
        
      order by ordinal_position

  
[0m20:35:46.599838 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.036534 (1 runs)
[0m20:35:46.601145 [info ] [Thread-3 (]: 12 of 33 START sql incremental model tec_elsa.dbt_seeds ........................ [RUN]
[0m20:35:46.602951 [info ] [Thread-4 (]: 9 of 33 OK created sql incremental model tec_elsa.dbt_metrics .................. [[32mSELECT 0[0m in 1.12s]
[0m20:35:46.608805 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.956182 (1 runs)
[0m20:35:46.610392 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_run_results, now model.elementary.dbt_seeds)
[0m20:35:46.612218 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_metrics
[0m20:35:46.613753 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:01.536884 (1 runs)
[0m20:35:46.614475 [debug] [Thread-2 (]: SQL status: SELECT 23 in 0.010 seconds
[0m20:35:46.615358 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_seeds
[0m20:35:46.616444 [debug] [Thread-4 (]: Began running node model.elementary.dbt_snapshots
[0m20:35:46.618084 [debug] [Thread-1 (]: On model.elementary.dbt_columns: COMMIT
[0m20:35:46.622498 [debug] [Thread-2 (]: Elementary: Inserting 33 rows to table "dbt_models__tmp_20250720203546553576203546553903"
[0m20:35:46.639628 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_seeds"
[0m20:35:46.641968 [info ] [Thread-4 (]: 13 of 33 START sql incremental model tec_elsa.dbt_snapshots .................... [RUN]
[0m20:35:46.643371 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_columns"
[0m20:35:46.687137 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_metrics, now model.elementary.dbt_snapshots)
[0m20:35:46.699928 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_seeds
[0m20:35:46.708312 [debug] [Thread-1 (]: On model.elementary.dbt_columns: COMMIT
[0m20:35:46.737808 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_snapshots
[0m20:35:46.782051 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_seeds"
[0m20:35:46.820863 [debug] [Thread-1 (]: SQL status: COMMIT in 0.024 seconds
[0m20:35:46.948940 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_snapshots"
[0m20:35:46.992143 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_seeds"
[0m20:35:46.999804 [debug] [Thread-1 (]: On model.elementary.dbt_columns: Close
[0m20:35:47.048048 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: BEGIN
[0m20:35:47.072033 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_snapshots
[0m20:35:47.085273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090519060>]}
[0m20:35:47.103840 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:47.145510 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_snapshots"
[0m20:35:47.172440 [info ] [Thread-1 (]: 5 of 33 OK created sql incremental model tec_elsa.dbt_columns .................. [[32mSELECT 0[0m in 2.39s]
[0m20:35:47.186709 [debug] [Thread-2 (]: Elementary: [1/1] Running insert query.
[0m20:35:47.193482 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_columns
[0m20:35:47.195616 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:47.196403 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_snapshots"
[0m20:35:47.197617 [debug] [Thread-1 (]: Began running node model.elementary.dbt_source_freshness_results
[0m20:35:47.201912 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_models"} */

    
       insert into "dbt_models__tmp_20250720203546553576203546553903"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.test_connection','test_connection','0ee739bacc39f8cdc57c2d0e3fd40dc7e59941c4af8e19d2f52dbe42b46b7af8','table','[]','{}','[]','elsa','bronze','[]','[]','','test_connection','dbt_elsa','models/bronze/test_connection.sql','bronze/test_connection.sql',NULL,'2025-07-20 20:35:46','3c23b8007b2c67ebb72075573a369c6b',NULL,NULL,NULL,'protected'),('model.dbt_elsa.consumption','consumption','591e13565539e5fff150e2695a9b9da1e2ec7a2725e6213d40f25320f29ce98a','table','[]','{}','[]','elsa','bronze','[]','[]','The aim of this table is to track houtly energy consumption for a given day
','consumption','dbt_elsa','models/bronze/consumption.sql','bronze/consumption.sql','dbt_elsa://models/bronze/_elsa_bronze__models.yml','2025-07-20 20:35:46','cfd24d72976d2470aec1485d6e928fb6',NULL,NULL,NULL,'protected'),('model.dbt_elsa.consumption_history','consumption_history','1d9ced1588ca5e6e8daa9d71d5a0afc6da9569a46c0e2e6fd0beaf3de6ff9a62','table','[]','{}','[]','elsa','silver','[]','["source.dbt_elsa.bronze.consumption"]','The aim of this table is to consolidate history data for consumption
','consumption_history','dbt_elsa','models/silver/consumption_history.sql','silver/consumption_history.sql','dbt_elsa://models/silver/_elsa_bronze__models.yml','2025-07-20 20:35:46','7c94c6b43e2a60d4598ea1a65af26c41',NULL,NULL,NULL,'protected'),('model.elementary.snapshot_run_results','snapshot_run_results','eb2ce3c6a48f39b5654308c6ee10dce649e156abefe4d95a89402f497061f908','view','[]','{}','[]','elsa','tec_elsa','[]','["model.elementary.dbt_run_results", "model.elementary.dbt_snapshots"]','Run results of dbt snapshots, enriched with snapshots metadata. Each row is the result of a single snapshot. This is a view that joins data from `dbt_run_results` and `dbt_snapshots`.
','snapshot_run_results','elementary','models/edr/run_results/snapshot_run_results.sql','edr/run_results/snapshot_run_results.sql','elementary://models/run_results.yml','2025-07-20 20:35:46','fb51be8c1b13933e52d30d9172b4eecd',NULL,NULL,NULL,'protected'),('model.elementary.job_run_results','job_run_results','70fa0f75184f074237575d1146a8caf3048d0d0300a5da5013b7a88f137bc810','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.timediff"]','["model.elementary.dbt_invocations"]','Run results of dbt invocations, enriched with jobs metadata. Each row is the result of a single job. This is a view on `dbt_invocations`.','job_run_results','elementary','models/edr/run_results/job_run_results.sql','edr/run_results/job_run_results.sql','elementary://models/run_results.yml','2025-07-20 20:35:46','72a927c1ac4851e27b633f21aa7d1f26',NULL,NULL,NULL,'protected'),('model.elementary.model_run_results','model_run_results','437b57b32630844cde2f23de66531b56757f9ee23c0ffbbb7bec945823c50636','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.edr_time_trunc"]','["model.elementary.dbt_models", "model.elementary.dbt_run_results"]','Run results of dbt models, enriched with models metadata. Each row is the result of a single model. This is a view that joins data from `dbt_run_results` and `dbt_models`.
','model_run_results','elementary','models/edr/run_results/model_run_results.sql','edr/run_results/model_run_results.sql','elementary://models/run_results.yml','2025-07-20 20:35:46','da9ec33290d3cfdaf863af21dda01d12',NULL,NULL,NULL,'protected'),('model.elementary.test_result_rows','test_result_rows','30fb69b16af56c55748fcb347c94ff46981dc4bf76b9b6aa272aa5194aa32f96','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "detected_at"}','[]','elsa','tec_elsa','["macro.elementary.empty_table", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','["model.elementary.elementary_test_results"]','','test_result_rows','elementary','models/edr/run_results/test_result_rows.sql','edr/run_results/test_result_rows.sql',NULL,'2025-07-20 20:35:46','c63529acae031373e4e5efffbc248416','elementary_test_results_id',NULL,NULL,'protected'),('model.elementary.seed_run_results','seed_run_results','7f1ce3a11e8f228f1bdd1d9b73a525881b52bd93712575ab43a1c56c41d0f15c','view','[]','{}','[]','elsa','tec_elsa','[]','["model.elementary.dbt_run_results", "model.elementary.dbt_seeds"]','','seed_run_results','elementary','models/edr/run_results/seed_run_results.sql','edr/run_results/seed_run_results.sql',NULL,'2025-07-20 20:35:46','e8d855d8015e77c85cd150cd7c3e5bc7',NULL,NULL,NULL,'protected'),('model.elementary.elementary_test_results','elementary_test_results','df74ce864e711c45b8f20af4d3246257f95ef0735e17d83dce220bdd80bde93a','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "detected_at"}','[]','elsa','tec_elsa','["macro.elementary.empty_elementary_test_results", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Run results of all dbt tests, with fields and metadata needed to produce the Elementary report UI. Each row is the result of a single test, including native dbt tests, packages tests and elementary tests. New data is loaded to this model on an on-run-end hook named `elementary.handle_tests_results`.
','elementary_test_results','elementary','models/edr/run_results/elementary_test_results.sql','edr/run_results/elementary_test_results.sql','elementary://models/run_results.yml','2025-07-20 20:35:46','df6fbd9b51ea1d566ad1c2ae57cd0b25','id',NULL,NULL,'protected'),('model.elementary.dbt_source_freshness_results','dbt_source_freshness_results','fb063c8eb524356395464854c25d33038742ce2e0c3d4b3936ce8919a0ee27d6','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "generated_at"}','[]','elsa','tec_elsa','["macro.elementary.empty_dbt_source_freshness_results", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','','dbt_source_freshness_results','elementary','models/edr/run_results/dbt_source_freshness_results.sql','edr/run_results/dbt_source_freshness_results.sql',NULL,'2025-07-20 20:35:46','e9c1e4a4e2dd90ec99894d6872dc6b38','source_freshness_execution_id',NULL,NULL,'protected'),('model.elementary.alerts_dbt_tests','alerts_dbt_tests','d15f2b4a7ade165ad09b2b9f6d143d9d47ab0f080b2de5dce1c6fae9e30375ba','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate dbt tests alerts, including all the fields the alert will include such as owner, tags, error message, etc. This view includes data about all dbt tests except elementary tests. It filters alerts according to configuration.
','alerts_dbt_tests','elementary','models/edr/alerts/alerts_dbt_tests.sql','edr/alerts/alerts_dbt_tests.sql','elementary://models/alerts_views.yml','2025-07-20 20:35:46','87cfa36e7a3b325061e8f5e5d381e2a9',NULL,NULL,NULL,'protected'),('model.elementary.alerts_schema_changes','alerts_schema_changes','bad7007c54d8885efe0496bd6289998cfed84a250ada4899fb8e53765236db0b','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on schema changes detected using elementary tests. The view filters alerts according to configuration.','alerts_schema_changes','elementary','models/edr/alerts/alerts_schema_changes.sql','edr/alerts/alerts_schema_changes.sql','elementary://models/alerts_views.yml','2025-07-20 20:35:46','88b199312615ef0421e8b515d45c8e14',NULL,NULL,NULL,'protected'),('model.elementary.alerts_dbt_source_freshness','alerts_dbt_source_freshness','59b6900cf93ce1ac9e61f07c3358a21aecda80b7980e55e4387c80ea3463f012','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.get_config_var"]','["model.elementary.dbt_source_freshness_results", "model.elementary.dbt_sources"]','','alerts_dbt_source_freshness','elementary','models/edr/alerts/alerts_dbt_source_freshness.sql','edr/alerts/alerts_dbt_source_freshness.sql',NULL,'2025-07-20 20:35:46','6370e0e0ae736fa82ffe6305161983e0',NULL,NULL,NULL,'protected'),('model.elementary.alerts_anomaly_detection','alerts_anomaly_detection','0d2bb9c33ded81e6501643abeeacde1b21695f406b861f748923e4bd9ce0c4c8','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on data anomalies detected using the elementary anomaly detection tests. The view filters alerts according to configuration.
','alerts_anomaly_detection','elementary','models/edr/alerts/alerts_anomaly_detection.sql','edr/alerts/alerts_anomaly_detection.sql','elementary://models/alerts_views.yml','2025-07-20 20:35:46','62f802aaaa896a60039458531f416f15',NULL,NULL,NULL,'protected'),('model.elementary.alerts_dbt_models','alerts_dbt_models','6b76b9a7b5f40ef4f9ff316fe90b4d48451442cafac243dc5abf0ac10b4c67eb','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.get_config_var"]','["model.elementary.model_run_results", "model.elementary.snapshot_run_results"]','A view that is used by the Elementary CLI to generate models alerts, including all the fields the alert will include such as owner, tags, error message, etc. It joins data about models and snapshots run results, and filters alerts according to configuration.
','alerts_dbt_models','elementary','models/edr/alerts/alerts_dbt_models.sql','edr/alerts/alerts_dbt_models.sql','elementary://models/alerts_views.yml','2025-07-20 20:35:46','34bb769f2e34e0c71cf02265a9a638ac',NULL,NULL,NULL,'protected'),('model.elementary.monitors_runs','monitors_runs','3720e206635d4f2f95c193835727b0d533ec1a5fa56e5dec79331418d07e934f','view','[]','{}','[]','elsa','tec_elsa','[]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that is used to determine when a specific anomaly detection test was last executed. Each anomaly detection test queries this view to decide on a start time for collecting metrics.
','monitors_runs','elementary','models/edr/system/monitors_runs.sql','edr/system/monitors_runs.sql','elementary://models/elementary_tests.yml','2025-07-20 20:35:46','34110174dea2c37bacb05ef347519cae',NULL,NULL,NULL,'protected'),('model.elementary.metadata','metadata','7d06c726499b330d51c340d2dc2774ac95f958fd6824c09711b3881b39b76a84','table','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_elementary_package_version"]','[]','','metadata','elementary','models/edr/system/metadata.sql','edr/system/metadata.sql',NULL,'2025-07-20 20:35:46','b42b4ffce2d94cca958690b51a0de993',NULL,NULL,NULL,'protected'),('model.elementary.dbt_tests','dbt_tests','e3e387b5d7f7df8bdfdc358f4458dd69b8311803d989c7a0a571314bb1f1dfc2','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_tests_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_tests"]','[]','Metadata about tests in the project, including configuration and properties from the dbt graph. Each row contains information about a single test. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_tests','elementary','models/edr/dbt_artifacts/dbt_tests.sql','edr/dbt_artifacts/dbt_tests.sql','elementary://models/dbt_artifacts.yml','2025-07-20 20:35:46','089c68851fa3cf383b13b28428249855','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_models','dbt_models','3b137ff6fc5007c98c2cce8c57010d5a8386ed4f9d217b08506e9106ab9168fd','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_models"]','[]','Metadata about models in the project, including configuration and properties from the dbt graph. Each row contains information about a single model. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_models','elementary','models/edr/dbt_artifacts/dbt_models.sql','edr/dbt_artifacts/dbt_models.sql','elementary://models/dbt_artifacts.yml','2025-07-20 20:35:46','415d66f10f2422d2b4f32a578f734f34','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_sources','dbt_sources','1abd5241398ed596cf8fcf85b84a45835ae0a3e67069f00d7b519757b009cbb3','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_sources_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_sources"]','[]','Metadata about sources in the project, including configuration and properties from the dbt graph. Each row contains information about a single source. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_sources','elementary','models/edr/dbt_artifacts/dbt_sources.sql','edr/dbt_artifacts/dbt_sources.sql','elementary://models/dbt_artifacts.yml','2025-07-20 20:35:46','68585221989c649aa325d6d0aee6f37c','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_snapshots','dbt_snapshots','84129810bfd9a5181f3d1552ba85143966cd16d64b9fc9169c1b089eab0c6ac2','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_snapshots"]','[]','Metadata about snapshots in the project, including configuration and properties from the dbt graph. Each row contains information about a single snapshot. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_snapshots','elementary','models/edr/dbt_artifacts/dbt_snapshots.sql','edr/dbt_artifacts/dbt_snapshots.sql','elementary://models/dbt_artifacts.yml','2025-07-20 20:35:46','7fd9f74dca8d707e92d0c81cccc699b4','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_columns','dbt_columns','b8a1cdacc7886a9dc3c8595a28fe850e1c39090ca6da04e3431b6549b986dc99','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_columns_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_columns"]','[]','','dbt_columns','elementary','models/edr/dbt_artifacts/dbt_columns.sql','edr/dbt_artifacts/dbt_columns.sql',NULL,'2025-07-20 20:35:46','b8267703bdc95c83df71700e221b88d9','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_invocations','dbt_invocations','6ec0cb09a0a3991db91ebd8a52625cc508faa4aac958138022aeaa3abb960755','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "generated_at"}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_invocations_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Attributes associated with each dbt invocation. Inserted at the end of each invocation.
','dbt_invocations','elementary','models/edr/dbt_artifacts/dbt_invocations.sql','edr/dbt_artifacts/dbt_invocations.sql','elementary://models/run_results.yml','2025-07-20 20:35:46','a444a62f7dc918b68e8ebf7ad734ba8c','invocation_id',NULL,NULL,'protected'),('model.elementary.dbt_metrics','dbt_metrics','86136f6682874137b3f9277098edf419c918548c440e1cd03c29f930d13d6dca','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_metrics_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_metrics"]','[]','Metadata about metrics in the project, including configuration and properties from the dbt graph. Each row contains information about a single metric. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_metrics','elementary','models/edr/dbt_artifacts/dbt_metrics.sql','edr/dbt_artifacts/dbt_metrics.sql','elementary://models/dbt_artifacts.yml','2025-07-20 20:35:46','565a4e16022023bdd76eec04ce4032d2','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_seeds','dbt_seeds','e768cbfb8ca753297d627bc51d661b4d4278e48650f9479d6a64431cb291a551','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_seeds_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_seeds"]','[]','','dbt_seeds','elementary','models/edr/dbt_artifacts/dbt_seeds.sql','edr/dbt_artifacts/dbt_seeds.sql',NULL,'2025-07-20 20:35:46','875acdcdf38beaf2439e22828c3aee5b','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_artifacts_hashes','dbt_artifacts_hashes','ac875e63f33b65509c9c0a5bacb9ddf19955c4c395562a5d4424fc380f76e98f','view','[]','{}','[]','elsa','tec_elsa','[]','["model.elementary.dbt_columns", "model.elementary.dbt_exposures", "model.elementary.dbt_groups", "model.elementary.dbt_metrics", "model.elementary.dbt_models", "model.elementary.dbt_seeds", "model.elementary.dbt_snapshots", "model.elementary.dbt_sources", "model.elementary.dbt_tests"]','','dbt_artifacts_hashes','elementary','models/edr/dbt_artifacts/dbt_artifacts_hashes.sql','edr/dbt_artifacts/dbt_artifacts_hashes.sql',NULL,'2025-07-20 20:35:46','ff1b395c079f55dbe5bd02cb94a77fb4',NULL,NULL,NULL,'protected'),('model.elementary.dbt_run_results','dbt_run_results','997ce0c97d01170814d63bc24012c41911aa1666dd62b68c298adb156584ac65','incremental','[]','{"deprecated_columns": [{"name": "compiled_sql", "data_type": "string", "description": "The compiled SQL executed against the database."}], "dedup_by_column": "model_execution_id", "timestamp_column": "created_at", "prev_timestamp_column": "generated_at"}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_run_results_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Run results of dbt invocations, inserted at the end of each invocation. Each row is the invocation result of a single resource (model, test, snapshot, etc). New data is loaded to this model on an on-run-end hook named ''elementary.upload_run_results'' from each invocation that produces a result object. This is an incremental model.
','dbt_run_results','elementary','models/edr/dbt_artifacts/dbt_run_results.sql','edr/dbt_artifacts/dbt_run_results.sql','elementary://models/run_results.yml','2025-07-20 20:35:46','bbb2acb1eaf4bfc560b3fcb528ea97c0','model_execution_id',NULL,NULL,'protected'),('model.elementary.dbt_groups','dbt_groups','b2cbce8ffc59730649cc06cac4b70b4fb6fe36adf58ae162031c451b75ca908f','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_groups_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_groups"]','[]','','dbt_groups','elementary','models/edr/dbt_artifacts/dbt_groups.sql','edr/dbt_artifacts/dbt_groups.sql',NULL,'2025-07-20 20:35:46','b3bfc335b658d14a47a846b1f3ed1615','unique_id',NULL,NULL,'protected'),('model.elementary.dbt_exposures','dbt_exposures','11693171043651333132be14894b4b7acad2ce7f09dea0ae0f722cf7d2417bb0','incremental','[]','{}','[]','elsa','tec_elsa','["macro.elementary.get_config_var", "macro.elementary.get_dbt_exposures_empty_table_query", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type", "macro.elementary.upload_dbt_exposures"]','[]','Metadata about exposures in the project, including configuration and properties from the dbt graph. Each row contains information about a single exposure. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.
','dbt_exposures','elementary','models/edr/dbt_artifacts/dbt_exposures.sql','edr/dbt_artifacts/dbt_exposures.sql','elementary://models/dbt_artifacts.yml','2025-07-20 20:35:46','fadd99a1ea2a06f804e4017d414f1fcc','unique_id',NULL,NULL,'protected'),('model.elementary.metrics_anomaly_score','metrics_anomaly_score','081d8b024e9c3ee037a2b149ddf564350743575027240ed019deee27ae94b004','view','[]','{}','[]','elsa','tec_elsa','["macro.dbt_utils.group_by", "macro.elementary.edr_current_timestamp", "macro.elementary.edr_date_trunc", "macro.elementary.edr_timeadd", "macro.elementary.get_config_var", "macro.elementary.standard_deviation"]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that runs the same query the anomaly detection tests run to calculate anomaly scores. The purpose of this view is to provide visibility to the results of anomaly detection tests.
','metrics_anomaly_score','elementary','models/edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','elementary://models/elementary_tests.yml','2025-07-20 20:35:46','dfd84913977175a306cc6e875468ca4b',NULL,NULL,NULL,'protected'),('model.elementary.anomaly_threshold_sensitivity','anomaly_threshold_sensitivity','b0e4310abc62902b98a6ad6fd465713d5aeb5e884b52594e8a1b2ff6429b1b2d','view','[]','{}','[]','elsa','tec_elsa','["macro.elementary.edr_quote_column"]','["model.elementary.metrics_anomaly_score"]','This is a view on `metrics_anomaly_score` that calculates if values of metrics from latest runs would have been considered anomalies in different anomaly scores. This can help you decide if there is a need to adjust the `anomaly_score_threshold`.
','anomaly_threshold_sensitivity','elementary','models/edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','elementary://models/elementary_tests.yml','2025-07-20 20:35:46','3d745465e31f16a0b78b73f2eccbb057',NULL,NULL,NULL,'protected'),('model.elementary.schema_columns_snapshot','schema_columns_snapshot','91a98d3190bef02e47f763520b5443197e120ceb132a86b1d90608ca30c33374','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "detected_at"}','[]','elsa','tec_elsa','["macro.elementary.empty_schema_columns_snapshot", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Stores the schema details for tables that are monitored with elementary schema changes test. In order to compare current schema to previous state, we must store the previous state. The data is from a view that queries the data warehouse information schema. This is an incremental table.','schema_columns_snapshot','elementary','models/edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','elementary://models/elementary_tests.yml','2025-07-20 20:35:46','d067d4834fa088a5f7e820a680a5d1d4','column_state_id',NULL,NULL,'protected'),('model.elementary.data_monitoring_metrics','data_monitoring_metrics','39b2ef4821634e188a273316d5ad0ae780c42b5429b7313dcd385d4db64d613b','incremental','[]','{"timestamp_column": "created_at", "prev_timestamp_column": "updated_at"}','[]','elsa','tec_elsa','["macro.elementary.empty_data_monitoring_metrics", "macro.elementary.get_config_var", "macro.elementary.get_default_incremental_strategy", "macro.elementary.get_default_table_type"]','[]','Elementary anomaly detection tests monitor metrics such as volume, freshness and data quality metrics. This incremental table is used to store the metrics over time. On each anomaly detection test, the test queries this table for historical metrics, and compares to the latest values. The table is updated with new metrics on the on-run-end named handle_test_results that is executed at the end of dbt test invocations.
','data_monitoring_metrics','elementary','models/edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','elementary://models/elementary_tests.yml','2025-07-20 20:35:46','8c5ba7ab6169c4a21b206336dcd0ba3c','id',NULL,NULL,'protected')
  
[0m20:35:47.207246 [debug] [Thread-3 (]: SQL status: BEGIN in 0.103 seconds
[0m20:35:47.208608 [debug] [Thread-4 (]: On model.elementary.dbt_snapshots: BEGIN
[0m20:35:47.209973 [info ] [Thread-1 (]: 14 of 33 START sql incremental model tec_elsa.dbt_source_freshness_results ..... [RUN]
[0m20:35:47.214197 [debug] [Thread-2 (]: SQL status: INSERT 0 33 in 0.002 seconds
[0m20:35:47.215355 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_seeds"
[0m20:35:47.216684 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:47.218289 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_columns, now model.elementary.dbt_source_freshness_results)
[0m20:35:47.223321 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:47.226812 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_seeds"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_seeds"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as checksum

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:47.229478 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_source_freshness_results
[0m20:35:47.230774 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_models"} */

    
        begin transaction;
        
        
            insert into "elsa"."tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250720203546553576203546553903";
        
        commit;
    
  
[0m20:35:47.238039 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.006 seconds
[0m20:35:47.245067 [debug] [Thread-4 (]: SQL status: BEGIN in 0.028 seconds
[0m20:35:47.248561 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_source_freshness_results"
[0m20:35:47.253078 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m20:35:47.253927 [debug] [Thread-2 (]: SQL status: COMMIT in 0.004 seconds
[0m20:35:47.254835 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_snapshots"
[0m20:35:47.258840 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m20:35:47.267337 [debug] [Thread-2 (]: Applying DROP to: "dbt_models__tmp_20250720203546553576203546553903"
[0m20:35:47.268662 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_source_freshness_results
[0m20:35:47.270049 [debug] [Thread-4 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_snapshots"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_snapshots"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as checksum

,
                
        cast('dummy_string' as varchar(4096)) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as patch_path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as unique_key

,
                
        cast('dummy_string' as varchar(4096)) as incremental_strategy

,
                
        cast('dummy_string' as varchar(4096)) as group_name

,
                
        cast('dummy_string' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:47.275294 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_seeds"
[0m20:35:47.276949 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:47.287374 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_source_freshness_results"
[0m20:35:47.289087 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_seeds"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_seeds"
    order by metadata_hash
    
  
[0m20:35:47.290881 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_models"} */
drop table if exists "dbt_models__tmp_20250720203546553576203546553903" cascade
[0m20:35:47.291774 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.003 seconds
[0m20:35:47.294599 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:47.298409 [debug] [Thread-4 (]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m20:35:47.299363 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.005 seconds
[0m20:35:47.300338 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_source_freshness_results"
[0m20:35:47.302349 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m20:35:47.305004 [debug] [Thread-4 (]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m20:35:47.308121 [debug] [Thread-2 (]: Elementary: Finished deleting from and inserting to: "elsa"."tec_elsa"."dbt_models"
[0m20:35:47.309610 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: BEGIN
[0m20:35:47.311329 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Artifacts did not change.
[0m20:35:47.314216 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_snapshots"
[0m20:35:47.316992 [debug] [Thread-2 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m20:35:47.318090 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:35:47.320525 [debug] [Thread-3 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m20:35:47.321818 [debug] [Thread-4 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_snapshots"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_snapshots"
    order by metadata_hash
    
  
[0m20:35:47.323365 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.078647 (1 runs)
[0m20:35:47.326842 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000769 (1 runs)
[0m20:35:47.329292 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:47.330844 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.040475 (1 runs)
[0m20:35:47.332519 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.067365 (1 runs)
[0m20:35:47.335086 [debug] [Thread-4 (]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m20:35:47.335888 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m20:35:47.337236 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000693 (1 runs)
[0m20:35:47.338696 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: COMMIT
[0m20:35:47.340796 [debug] [Thread-4 (]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m20:35:47.342276 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_source_freshness_results"
[0m20:35:47.344432 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.524651 (33 runs)
[0m20:35:47.345674 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_seeds"
[0m20:35:47.347711 [debug] [Thread-4 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m20:35:47.348907 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_source_freshness_results"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_source_freshness_results"
  
  
    as
  
  (
    


    select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as source_freshness_execution_id

,
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as max_loaded_at

,
                
        cast('dummy_string' as varchar(4096)) as snapshotted_at

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast(123456789.99 as float) as max_loaded_at_time_ago_in_s

,
                
        cast('dummy_string' as varchar(4096)) as status

,
                
        cast('dummy_string' as varchar(4096)) as error

,
                
        cast('dummy_string' as varchar(4096)) as compile_started_at

,
                
        cast('dummy_string' as varchar(4096)) as compile_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as execute_started_at

,
                
        cast('dummy_string' as varchar(4096)) as execute_completed_at

,
                
        cast('dummy_string' as varchar(4096)) as invocation_id

,
                
        cast('dummy_string' as varchar(4096)) as warn_after

,
                
        cast('dummy_string' as varchar(4096)) as error_after

,
                
        cast('this_is_just_a_long_dummy_string' as text) as filter


        ) as empty_table
        where 1 = 0

  );
  
  
[0m20:35:47.350387 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.541041 (1 runs)
[0m20:35:47.351364 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: COMMIT
[0m20:35:47.353813 [debug] [Thread-4 (]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000565 (1 runs)
[0m20:35:47.355990 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.026695 (1 runs)
[0m20:35:47.358853 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.004 seconds
[0m20:35:47.359717 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:47.360919 [debug] [Thread-4 (]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.049229 (1 runs)
[0m20:35:47.362335 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.640997 (1 runs)
[0m20:35:47.364617 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: COMMIT
[0m20:35:47.366390 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: Close
[0m20:35:47.368085 [debug] [Thread-4 (]: On model.elementary.dbt_snapshots: COMMIT
[0m20:35:47.369403 [debug] [Thread-2 (]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.930189 (1 runs)
[0m20:35:47.370458 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_source_freshness_results"
[0m20:35:47.371991 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091704190>]}
[0m20:35:47.373653 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_snapshots"
[0m20:35:47.375955 [debug] [Thread-2 (]: On model.elementary.dbt_models: COMMIT
[0m20:35:47.377138 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: COMMIT
[0m20:35:47.378522 [info ] [Thread-3 (]: 12 of 33 OK created sql incremental model tec_elsa.dbt_seeds ................... [[32mSELECT 0[0m in 0.76s]
[0m20:35:47.379458 [debug] [Thread-4 (]: On model.elementary.dbt_snapshots: COMMIT
[0m20:35:47.380697 [debug] [Thread-2 (]: Using postgres connection "model.elementary.dbt_models"
[0m20:35:47.382437 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_seeds
[0m20:35:47.383213 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:47.384469 [debug] [Thread-2 (]: On model.elementary.dbt_models: COMMIT
[0m20:35:47.385219 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:47.386174 [debug] [Thread-3 (]: Began running node model.elementary.dbt_sources
[0m20:35:47.390830 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: Close
[0m20:35:47.392930 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:47.394683 [debug] [Thread-4 (]: On model.elementary.dbt_snapshots: Close
[0m20:35:47.396140 [info ] [Thread-3 (]: 15 of 33 START sql incremental model tec_elsa.dbt_sources ...................... [RUN]
[0m20:35:47.397962 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0909e1270>]}
[0m20:35:47.400383 [debug] [Thread-2 (]: On model.elementary.dbt_models: Close
[0m20:35:47.401680 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc092ff9120>]}
[0m20:35:47.403120 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_seeds, now model.elementary.dbt_sources)
[0m20:35:47.404688 [info ] [Thread-1 (]: 14 of 33 OK created sql incremental model tec_elsa.dbt_source_freshness_results  [[32mSELECT 0[0m in 0.18s]
[0m20:35:47.406212 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091c28eb0>]}
[0m20:35:47.409711 [info ] [Thread-4 (]: 13 of 33 OK created sql incremental model tec_elsa.dbt_snapshots ............... [[32mSELECT 0[0m in 0.71s]
[0m20:35:47.410856 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_sources
[0m20:35:47.412668 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_source_freshness_results
[0m20:35:47.414084 [info ] [Thread-2 (]: 10 of 33 OK created sql incremental model tec_elsa.dbt_models .................. [[32mSELECT 0[0m in 1.77s]
[0m20:35:47.416164 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_snapshots
[0m20:35:47.434127 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_sources"
[0m20:35:47.434980 [debug] [Thread-1 (]: Began running node model.elementary.dbt_tests
[0m20:35:47.436516 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_models
[0m20:35:47.437723 [debug] [Thread-4 (]: Began running node model.elementary.elementary_test_results
[0m20:35:47.441736 [info ] [Thread-1 (]: 16 of 33 START sql incremental model tec_elsa.dbt_tests ........................ [RUN]
[0m20:35:47.443417 [debug] [Thread-2 (]: Began running node model.elementary.metadata
[0m20:35:47.444774 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_sources
[0m20:35:47.445561 [info ] [Thread-4 (]: 17 of 33 START sql incremental model tec_elsa.elementary_test_results .......... [RUN]
[0m20:35:47.446883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_source_freshness_results, now model.elementary.dbt_tests)
[0m20:35:47.448277 [info ] [Thread-2 (]: 18 of 33 START sql table model tec_elsa.metadata ............................... [RUN]
[0m20:35:47.463970 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_sources"
[0m20:35:47.465193 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_snapshots, now model.elementary.elementary_test_results)
[0m20:35:47.466309 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_tests
[0m20:35:47.467435 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_models, now model.elementary.metadata)
[0m20:35:47.469006 [debug] [Thread-4 (]: Began compiling node model.elementary.elementary_test_results
[0m20:35:47.482025 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:47.487837 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_tests"
[0m20:35:47.488526 [debug] [Thread-2 (]: Began compiling node model.elementary.metadata
[0m20:35:47.508012 [debug] [Thread-3 (]: On model.elementary.dbt_sources: BEGIN
[0m20:35:47.508906 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.elementary_test_results"
[0m20:35:47.520260 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.metadata"
[0m20:35:47.521444 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:47.522381 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_tests
[0m20:35:47.526018 [debug] [Thread-4 (]: Began executing node model.elementary.elementary_test_results
[0m20:35:47.537600 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_tests"
[0m20:35:47.545128 [debug] [Thread-2 (]: Began executing node model.elementary.metadata
[0m20:35:47.545914 [debug] [Thread-3 (]: SQL status: BEGIN in 0.024 seconds
[0m20:35:47.551051 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.elementary_test_results"
[0m20:35:47.562867 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.metadata"
[0m20:35:47.564165 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:47.565051 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:47.567557 [debug] [Thread-1 (]: On model.elementary.dbt_tests: BEGIN
[0m20:35:47.568407 [debug] [Thread-4 (]: Using postgres connection "model.elementary.elementary_test_results"
[0m20:35:47.569741 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_sources"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_sources"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as source_name

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as identifier

,
                
        cast('dummy_string' as varchar(4096)) as loaded_at_field

,
                
        cast('dummy_string' as varchar(4096)) as freshness_warn_after

,
                
        cast('dummy_string' as varchar(4096)) as freshness_error_after

,
                
        cast('this_is_just_a_long_dummy_string' as text) as freshness_filter

,
                
        cast('this_is_just_a_long_dummy_string' as text) as freshness_description

,
                
        cast('dummy_string' as varchar(4096)) as relation_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('dummy_string' as varchar(4096)) as owner

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('this_is_just_a_long_dummy_string' as text) as source_description

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:47.571047 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metadata"
[0m20:35:47.571909 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:35:47.573250 [debug] [Thread-4 (]: On model.elementary.elementary_test_results: BEGIN
[0m20:35:47.575749 [debug] [Thread-2 (]: On model.elementary.metadata: BEGIN
[0m20:35:47.577970 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.003 seconds
[0m20:35:47.578669 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:47.579747 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:47.583811 [debug] [Thread-3 (]: Elementary: [dbt_sources] Flattening the artifacts.
[0m20:35:47.586198 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:35:47.611551 [debug] [Thread-2 (]: SQL status: BEGIN in 0.032 seconds
[0m20:35:47.616462 [debug] [Thread-3 (]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m20:35:47.617368 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:47.618215 [debug] [Thread-4 (]: SQL status: BEGIN in 0.040 seconds
[0m20:35:47.619140 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metadata"
[0m20:35:47.621714 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:47.623349 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_tests"} */

      
  
    

  create  table "elsa"."tec_elsa"."dbt_tests"
  
  
    as
  
  (
    

select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as unique_id

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as name

,
                
        cast('dummy_string' as varchar(4096)) as short_name

,
                
        cast('dummy_string' as varchar(4096)) as alias

,
                
        cast('dummy_string' as varchar(4096)) as test_column_name

,
                
        cast('dummy_string' as varchar(4096)) as severity

,
                
        cast('dummy_string' as varchar(4096)) as warn_if

,
                
        cast('dummy_string' as varchar(4096)) as error_if

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_params

,
                
        cast('dummy_string' as varchar(4096)) as test_namespace

,
                
        cast('dummy_string' as varchar(4096)) as test_original_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as model_tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as model_owners

,
                
        cast('this_is_just_a_long_dummy_string' as text) as meta

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as text) as depends_on_nodes

,
                
        cast('dummy_string' as varchar(4096)) as parent_model_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as description

,
                
        cast('dummy_string' as varchar(4096)) as package_name

,
                
        cast('dummy_string' as varchar(4096)) as type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as original_path

,
                
        cast('dummy_string' as varchar(4096)) as path

,
                
        cast('dummy_string' as varchar(4096)) as generated_at

,
                
        cast('dummy_string' as varchar(4096)) as metadata_hash

,
                
        cast('dummy_string' as varchar(4096)) as quality_dimension

,
                
        cast('dummy_string' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:47.625011 [debug] [Thread-4 (]: Using postgres connection "model.elementary.elementary_test_results"
[0m20:35:47.626140 [debug] [Thread-2 (]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.metadata"} */

  
    

  create  table "elsa"."tec_elsa"."metadata__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    '0.19.0' as dbt_pkg_version
  );
  
[0m20:35:47.627207 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_sources"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_sources"
    order by metadata_hash
    
  
[0m20:35:47.629207 [debug] [Thread-4 (]: On model.elementary.elementary_test_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.elementary_test_results"} */

      
  
    

  create  table "elsa"."tec_elsa"."elementary_test_results"
  
  
    as
  
  (
    


    select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as id

,
                
        cast('dummy_string' as varchar(4096)) as data_issue_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as model_unique_id

,
                
        cast('dummy_string' as varchar(4096)) as invocation_id

,
                cast('2091-02-17' as timestamp) as detected_at

,
                cast('2091-02-17' as timestamp) as created_at

,
                
        cast('dummy_string' as varchar(4096)) as database_name

,
                
        cast('dummy_string' as varchar(4096)) as schema_name

,
                
        cast('dummy_string' as varchar(4096)) as table_name

,
                
        cast('dummy_string' as varchar(4096)) as column_name

,
                
        cast('dummy_string' as varchar(4096)) as test_type

,
                
        cast('dummy_string' as varchar(4096)) as test_sub_type

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_results_description

,
                
        cast('dummy_string' as varchar(4096)) as owners

,
                
        cast('dummy_string' as varchar(4096)) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_results_query

,
                
        cast('dummy_string' as varchar(4096)) as other

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_name

,
                
        cast('this_is_just_a_long_dummy_string' as text) as test_params

,
                
        cast('dummy_string' as varchar(4096)) as severity

,
                
        cast('dummy_string' as varchar(4096)) as status

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as varchar(4096)) as test_short_name

,
                
        cast('dummy_string' as varchar(4096)) as test_alias

,
                
        cast('this_is_just_a_long_dummy_string' as text) as result_rows

,
                
        cast(31474836478 as bigint) as failed_row_count


        ) as empty_table
        where 1 = 0

  );
  
  
[0m20:35:47.630839 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.002 seconds
[0m20:35:47.632969 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.001 seconds
[0m20:35:47.633735 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.003 seconds
[0m20:35:47.637086 [debug] [Thread-1 (]: Elementary: [dbt_tests] Flattening the artifacts.
[0m20:35:47.637843 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.005 seconds
[0m20:35:47.640336 [debug] [Thread-3 (]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m20:35:47.653521 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metadata"
[0m20:35:47.680436 [debug] [Thread-4 (]: On model.elementary.elementary_test_results: COMMIT
[0m20:35:47.709045 [debug] [Thread-3 (]: Elementary: [dbt_sources] Artifacts changed.
[0m20:35:47.733058 [debug] [Thread-2 (]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.metadata"} */
alter table "elsa"."tec_elsa"."metadata__dbt_tmp" rename to "metadata"
[0m20:35:47.763096 [debug] [Thread-4 (]: Using postgres connection "model.elementary.elementary_test_results"
[0m20:35:47.787365 [debug] [Thread-3 (]: Elementary: Deleting from and inserting to: "elsa"."tec_elsa"."dbt_sources"
[0m20:35:47.816035 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.006 seconds
[0m20:35:47.826387 [debug] [Thread-1 (]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m20:35:47.827570 [debug] [Thread-4 (]: On model.elementary.elementary_test_results: COMMIT
[0m20:35:47.830660 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:47.832974 [debug] [Thread-2 (]: On model.elementary.metadata: COMMIT
[0m20:35:47.835482 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:47.837199 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_sources"} */

    
  
    

  create temporary table "dbt_sources__tmp_20250720203547829016203547829449"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."tec_elsa"."dbt_sources"
        WHERE 1 = 0
    
  );
  
  
[0m20:35:47.838105 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:47.838980 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metadata"
[0m20:35:47.840413 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_tests"} */

    
    select metadata_hash 
    from "elsa"."tec_elsa"."dbt_tests"
    order by metadata_hash
    
  
[0m20:35:47.842901 [debug] [Thread-4 (]: On model.elementary.elementary_test_results: Close
[0m20:35:47.843669 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.002 seconds
[0m20:35:47.844623 [debug] [Thread-2 (]: On model.elementary.metadata: COMMIT
[0m20:35:47.846758 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09173a140>]}
[0m20:35:47.847713 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.002 seconds
[0m20:35:47.857014 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:47.859199 [info ] [Thread-4 (]: 17 of 33 OK created sql incremental model tec_elsa.elementary_test_results ..... [[32mSELECT 0[0m in 0.38s]
[0m20:35:47.860070 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:47.862710 [debug] [Thread-1 (]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m20:35:47.863831 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_sources"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_sources__tmp_20250720203547829016203547829449'
        
      order by ordinal_position

  
[0m20:35:47.865168 [debug] [Thread-4 (]: Finished running node model.elementary.elementary_test_results
[0m20:35:47.873617 [debug] [Thread-2 (]: Applying DROP to: "elsa"."tec_elsa"."metadata__dbt_backup"
[0m20:35:47.875310 [debug] [Thread-1 (]: Elementary: [dbt_tests] Artifacts changed.
[0m20:35:47.876869 [debug] [Thread-4 (]: Began running node model.elementary.schema_columns_snapshot
[0m20:35:47.878744 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metadata"
[0m20:35:47.880307 [debug] [Thread-1 (]: Elementary: Deleting from and inserting to: "elsa"."tec_elsa"."dbt_tests"
[0m20:35:47.881835 [info ] [Thread-4 (]: 19 of 33 START sql incremental model tec_elsa.schema_columns_snapshot .......... [RUN]
[0m20:35:47.883377 [debug] [Thread-2 (]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.metadata"} */
drop table if exists "elsa"."tec_elsa"."metadata__dbt_backup" cascade
[0m20:35:47.884306 [debug] [Thread-3 (]: SQL status: SELECT 22 in 0.008 seconds
[0m20:35:47.887299 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:47.888415 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.elementary_test_results, now model.elementary.schema_columns_snapshot)
[0m20:35:47.891880 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m20:35:47.895464 [debug] [Thread-3 (]: Elementary: Inserting 2 rows to table "dbt_sources__tmp_20250720203547829016203547829449"
[0m20:35:47.897181 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_tests"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250720203547885797203547886097"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m20:35:47.898780 [debug] [Thread-4 (]: Began compiling node model.elementary.schema_columns_snapshot
[0m20:35:47.901395 [debug] [Thread-2 (]: On model.elementary.metadata: Close
[0m20:35:47.933254 [debug] [Thread-3 (]: Elementary: [1/1] Running insert query.
[0m20:35:47.934173 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.013 seconds
[0m20:35:47.947907 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.schema_columns_snapshot"
[0m20:35:47.948984 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0928d3a60>]}
[0m20:35:47.950861 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:47.960529 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:47.962770 [info ] [Thread-2 (]: 18 of 33 OK created sql table model tec_elsa.metadata .......................... [[32mSELECT 1[0m in 0.48s]
[0m20:35:47.964473 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_sources"} */

    
       insert into "dbt_sources__tmp_20250720203547829016203547829449"
         (unique_id,database_name,schema_name,source_name,name,identifier,loaded_at_field,freshness_warn_after,freshness_error_after,freshness_filter,freshness_description,relation_name,tags,meta,owner,package_name,original_path,path,source_description,description,generated_at,metadata_hash) values
    ('source.dbt_elsa.bronze.rte_eco2mix','elsa','bronze','bronze','rte_eco2mix','rte_eco2mix','created_at','{"count": null, "period": null}','{"count": null, "period": null}',NULL,'Source freshness validates if the time elapsed between the test execution to the latest record is above an acceptable SLA threshold.','"elsa"."bronze"."rte_eco2mix"','[]','{}','[]','dbt_elsa','models/bronze/_elsa_bronze__sources.yml','models/bronze/_elsa_bronze__sources.yml','','Source JSON loadée dans le champ data','2025-07-20 20:35:47','f4b31759d8110599123fad1e18fd43ac'),('source.dbt_elsa.bronze.consumption','elsa','bronze','bronze','consumption','consumption',NULL,'{"count": null, "period": null}','{"count": null, "period": null}',NULL,'Source freshness validates if the time elapsed between the test execution to the latest record is above an acceptable SLA threshold.','"elsa"."bronze"."consumption"','[]','{}','[]','dbt_elsa','models/silver/_elsa_silver__sources.yml','models/silver/_elsa_silver__sources.yml','','Données raw','2025-07-20 20:35:47','57e62e882484c591a0ce7597a6fcae35')
  
[0m20:35:47.965977 [debug] [Thread-4 (]: Began executing node model.elementary.schema_columns_snapshot
[0m20:35:47.966688 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_tests"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250720203547885797203547886097'
        
      order by ordinal_position

  
[0m20:35:47.968168 [debug] [Thread-2 (]: Finished running node model.elementary.metadata
[0m20:35:47.976978 [debug] [Thread-3 (]: SQL status: INSERT 0 2 in 0.008 seconds
[0m20:35:48.087980 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.schema_columns_snapshot"
[0m20:35:48.090035 [debug] [Thread-2 (]: Began running node model.elementary.metrics_anomaly_score
[0m20:35:48.095836 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:48.097835 [debug] [Thread-1 (]: SQL status: SELECT 29 in 0.010 seconds
[0m20:35:48.099250 [info ] [Thread-2 (]: 20 of 33 START sql view model tec_elsa.metrics_anomaly_score ................... [RUN]
[0m20:35:48.101074 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_sources"} */

    
        begin transaction;
        
        
            insert into "elsa"."tec_elsa"."dbt_sources" select * from "dbt_sources__tmp_20250720203547829016203547829449";
        
        commit;
    
  
[0m20:35:48.102638 [debug] [Thread-4 (]: Using postgres connection "model.elementary.schema_columns_snapshot"
[0m20:35:48.107521 [debug] [Thread-1 (]: Elementary: Inserting 5 rows to table "dbt_tests__tmp_20250720203547885797203547886097"
[0m20:35:48.109794 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.metadata, now model.elementary.metrics_anomaly_score)
[0m20:35:48.113120 [debug] [Thread-4 (]: On model.elementary.schema_columns_snapshot: BEGIN
[0m20:35:48.114078 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:48.133029 [debug] [Thread-2 (]: Began compiling node model.elementary.metrics_anomaly_score
[0m20:35:48.163896 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:48.193872 [debug] [Thread-1 (]: Elementary: [1/1] Running insert query.
[0m20:35:48.195586 [debug] [Thread-3 (]: Applying DROP to: "dbt_sources__tmp_20250720203547829016203547829449"
[0m20:35:48.210523 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.metrics_anomaly_score"
[0m20:35:48.212916 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:48.214401 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:48.216577 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_tests"} */

    
       insert into "dbt_tests__tmp_20250720203547885797203547886097"
         (unique_id,database_name,schema_name,name,short_name,alias,test_column_name,severity,warn_if,error_if,test_params,test_namespace,test_original_name,tags,model_tags,model_owners,meta,depends_on_macros,depends_on_nodes,parent_model_unique_id,description,package_name,type,original_path,path,generated_at,metadata_hash,quality_dimension,group_name) values
    ('test.dbt_elsa.not_null_consumption_id.186948fd55','elsa','bronze','not_null_consumption_id','not_null','not_null_consumption_id','id','ERROR','!= 0','!= 0','{"column_name": "id", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption"]','model.dbt_elsa.consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_consumption_id.sql','2025-07-20 20:35:47','f210eff676b62b5f5ad68760ba2f46c8','completeness',NULL),('test.dbt_elsa.not_null_consumption_created_at.93906ad963','elsa','bronze','not_null_consumption_created_at','not_null','not_null_consumption_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption"]','model.dbt_elsa.consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_consumption_created_at.sql','2025-07-20 20:35:47','37dd210f2b364de61791df38a93fff0a','completeness',NULL),('test.dbt_elsa.not_null_consumption_date.0e210070dc','elsa','bronze','not_null_consumption_date','not_null','not_null_consumption_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption"]','model.dbt_elsa.consumption','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/bronze/_elsa_bronze__models.yml','not_null_consumption_date.sql','2025-07-20 20:35:47','056167eee57e746a29aabb5e8ff038f0','completeness',NULL),('test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','elsa','silver','not_null_consumption_history_created_at','not_null','not_null_consumption_history_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_created_at.sql','2025-07-20 20:35:47','c8858dc73b90355aea9b16e1c9bd6770','completeness',NULL),('test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','elsa','silver','not_null_consumption_history_date','not_null','not_null_consumption_history_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_date.sql','2025-07-20 20:35:47','9244ab3196851fc590c004e833d6957a','completeness',NULL)
  
[0m20:35:48.218303 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_sources"} */
drop table if exists "dbt_sources__tmp_20250720203547829016203547829449" cascade
[0m20:35:48.219408 [debug] [Thread-2 (]: Began executing node model.elementary.metrics_anomaly_score
[0m20:35:48.220258 [debug] [Thread-4 (]: SQL status: BEGIN in 0.056 seconds
[0m20:35:48.221015 [debug] [Thread-1 (]: SQL status: INSERT 0 5 in 0.001 seconds
[0m20:35:48.233942 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.012 seconds
[0m20:35:48.241344 [debug] [Thread-4 (]: Using postgres connection "model.elementary.schema_columns_snapshot"
[0m20:35:48.256208 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.metrics_anomaly_score"
[0m20:35:48.260551 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:48.262563 [debug] [Thread-3 (]: Elementary: Finished deleting from and inserting to: "elsa"."tec_elsa"."dbt_sources"
[0m20:35:48.263930 [debug] [Thread-4 (]: On model.elementary.schema_columns_snapshot: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.schema_columns_snapshot"} */

      
  
    

  create  table "elsa"."tec_elsa"."schema_columns_snapshot"
  
  
    as
  
  (
    


    select * from (
            select
            
                
        cast('dummy_string' as varchar(4096)) as column_state_id

,
                
        cast('dummy_string' as varchar(4096)) as full_column_name

,
                
        cast('dummy_string' as varchar(4096)) as full_table_name

,
                
        cast('dummy_string' as varchar(4096)) as column_name

,
                
        cast('dummy_string' as varchar(4096)) as data_type

,
                
        cast (True as boolean) as is_new

,
                cast('2091-02-17' as timestamp) as detected_at

,
                cast('2091-02-17' as timestamp) as created_at


        ) as empty_table
        where 1 = 0

  );
  
  
[0m20:35:48.265781 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_tests"} */

    
        begin transaction;
        
        
            insert into "elsa"."tec_elsa"."dbt_tests" select * from "dbt_tests__tmp_20250720203547885797203547886097";
        
        commit;
    
  
[0m20:35:48.269506 [debug] [Thread-3 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m20:35:48.270763 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m20:35:48.273946 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.028250 (1 runs)
[0m20:35:48.274775 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:35:48.275463 [debug] [Thread-4 (]: SQL status: SELECT 0 in 0.004 seconds
[0m20:35:48.276453 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: BEGIN
[0m20:35:48.278718 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_columns_in_relation: 0:00:00.044953 (1 runs)
[0m20:35:48.287877 [debug] [Thread-1 (]: Applying DROP to: "dbt_tests__tmp_20250720203547885797203547886097"
[0m20:35:48.290951 [debug] [Thread-4 (]: On model.elementary.schema_columns_snapshot: COMMIT
[0m20:35:48.292193 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:48.293964 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000688 (1 runs)
[0m20:35:48.295355 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:48.296580 [debug] [Thread-4 (]: Using postgres connection "model.elementary.schema_columns_snapshot"
[0m20:35:48.298842 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.027112 (2 runs)
[0m20:35:48.299936 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_tests"} */
drop table if exists "dbt_tests__tmp_20250720203547885797203547886097" cascade
[0m20:35:48.300988 [debug] [Thread-4 (]: On model.elementary.schema_columns_snapshot: COMMIT
[0m20:35:48.302806 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.get_insert_rows_queries: 0:00:00.029582 (1 runs)
[0m20:35:48.305509 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows.run_insert_rows_query: 0:00:00.143647 (1 runs)
[0m20:35:48.306321 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:48.307633 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:35:48.309189 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources].insert_rows: 0:00:00.244803 (1 runs)
[0m20:35:48.309936 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m20:35:48.311331 [debug] [Thread-4 (]: On model.elementary.schema_columns_snapshot: Close
[0m20:35:48.313201 [debug] [Thread-1 (]: Elementary: Finished deleting from and inserting to: "elsa"."tec_elsa"."dbt_tests"
[0m20:35:48.314542 [debug] [Thread-3 (]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.685441 (1 runs)
[0m20:35:48.315628 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m20:35:48.316984 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091c66b30>]}
[0m20:35:48.319094 [debug] [Thread-1 (]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m20:35:48.320624 [debug] [Thread-3 (]: On model.elementary.dbt_sources: COMMIT
[0m20:35:48.322060 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.metrics_anomaly_score"} */

  create view "elsa"."tec_elsa"."metrics_anomaly_score__dbt_tmp"
    
    
  as (
    

with data_monitoring_metrics as (

    select * from "elsa"."tec_elsa"."data_monitoring_metrics"

),

time_window_aggregation as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        metric_value,
        source_value,
        bucket_start,
        bucket_end,
        bucket_duration_hours,
        updated_at,
        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,
        stddev(cast(metric_value as float)) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,
        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,
        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,
        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start
    from data_monitoring_metrics
    group by 1,2,3,4,5,6,7,8,9,10,11,12
),

metrics_anomaly_score as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        case
            when training_stddev is null then null
            when training_stddev = 0 then 0
            else (metric_value - training_avg) / (training_stddev)
        end as anomaly_score,
        metric_value as latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        max(updated_at) as updated_at
    from time_window_aggregation
        where
            metric_value is not null
            and training_avg is not null
            and bucket_end >= 
    cast(date_trunc('day', 
    current_timestamp::timestamp
) as timestamp) + cast(-7 as integer) * INTERVAL '1 day'

    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    order by bucket_end desc


),

final as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        anomaly_score,
        latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        updated_at,
        case
            when abs(anomaly_score) > 3 then true
            else false end
        as is_anomaly
    from metrics_anomaly_score
)

select * from final
  );
[0m20:35:48.324231 [info ] [Thread-4 (]: 19 of 33 OK created sql incremental model tec_elsa.schema_columns_snapshot ..... [[32mSELECT 0[0m in 0.43s]
[0m20:35:48.326948 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.171054 (1 runs)
[0m20:35:48.328187 [debug] [Thread-3 (]: Using postgres connection "model.elementary.dbt_sources"
[0m20:35:48.330069 [debug] [Thread-4 (]: Finished running node model.elementary.schema_columns_snapshot
[0m20:35:48.331584 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.153441 (1 runs)
[0m20:35:48.332957 [debug] [Thread-3 (]: On model.elementary.dbt_sources: COMMIT
[0m20:35:48.334894 [debug] [Thread-4 (]: Began running node model.elementary.monitors_runs
[0m20:35:48.336755 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000766 (1 runs)
[0m20:35:48.337815 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m20:35:48.342075 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m20:35:48.341273 [info ] [Thread-4 (]: 21 of 33 START sql view model tec_elsa.monitors_runs ........................... [RUN]
[0m20:35:48.345059 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.067450 (5 runs)
[0m20:35:48.354500 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m20:35:48.356161 [debug] [Thread-3 (]: On model.elementary.dbt_sources: Close
[0m20:35:48.360002 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.schema_columns_snapshot, now model.elementary.monitors_runs)
[0m20:35:48.362167 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.077734 (1 runs)
[0m20:35:48.363285 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.metrics_anomaly_score"} */
alter table "elsa"."tec_elsa"."metrics_anomaly_score__dbt_tmp" rename to "metrics_anomaly_score"
[0m20:35:48.364734 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090ac2680>]}
[0m20:35:48.365755 [debug] [Thread-4 (]: Began compiling node model.elementary.monitors_runs
[0m20:35:48.367170 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.046677 (1 runs)
[0m20:35:48.369699 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:48.369044 [info ] [Thread-3 (]: 15 of 33 OK created sql incremental model tec_elsa.dbt_sources ................. [[32mSELECT 0[0m in 0.96s]
[0m20:35:48.380568 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.monitors_runs"
[0m20:35:48.382067 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:00.306209 (1 runs)
[0m20:35:48.384282 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: COMMIT
[0m20:35:48.385762 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_sources
[0m20:35:48.387741 [debug] [Thread-1 (]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.681677 (1 runs)
[0m20:35:48.388787 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m20:35:48.389562 [debug] [Thread-4 (]: Began executing node model.elementary.monitors_runs
[0m20:35:48.392956 [debug] [Thread-3 (]: Began running node model.elementary.job_run_results
[0m20:35:48.394786 [debug] [Thread-1 (]: On model.elementary.dbt_tests: COMMIT
[0m20:35:48.395696 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: COMMIT
[0m20:35:48.405610 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.monitors_runs"
[0m20:35:48.409356 [info ] [Thread-3 (]: 22 of 33 START sql view model tec_elsa.job_run_results ......................... [RUN]
[0m20:35:48.411136 [debug] [Thread-1 (]: Using postgres connection "model.elementary.dbt_tests"
[0m20:35:48.413119 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:48.414131 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_sources, now model.elementary.job_run_results)
[0m20:35:48.415104 [debug] [Thread-1 (]: On model.elementary.dbt_tests: COMMIT
[0m20:35:48.415843 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m20:35:48.427505 [debug] [Thread-2 (]: Applying DROP to: "elsa"."tec_elsa"."metrics_anomaly_score__dbt_backup"
[0m20:35:48.428796 [debug] [Thread-3 (]: Began compiling node model.elementary.job_run_results
[0m20:35:48.430670 [debug] [Thread-1 (]: SQL status: COMMIT in 0.000 seconds
[0m20:35:48.431593 [debug] [Thread-4 (]: On model.elementary.monitors_runs: BEGIN
[0m20:35:48.435933 [debug] [Thread-2 (]: Using postgres connection "model.elementary.metrics_anomaly_score"
[0m20:35:48.450500 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.job_run_results"
[0m20:35:48.451781 [debug] [Thread-1 (]: On model.elementary.dbt_tests: Close
[0m20:35:48.452820 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:48.453989 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.metrics_anomaly_score"} */
drop view if exists "elsa"."tec_elsa"."metrics_anomaly_score__dbt_backup" cascade
[0m20:35:48.456241 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091c40250>]}
[0m20:35:48.459164 [debug] [Thread-3 (]: Began executing node model.elementary.job_run_results
[0m20:35:48.460880 [info ] [Thread-1 (]: 16 of 33 OK created sql incremental model tec_elsa.dbt_tests ................... [[32mSELECT 0[0m in 1.01s]
[0m20:35:48.461979 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.002 seconds
[0m20:35:48.475333 [debug] [Thread-4 (]: SQL status: BEGIN in 0.022 seconds
[0m20:35:48.478313 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.job_run_results"
[0m20:35:48.479535 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_tests
[0m20:35:48.481867 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: Close
[0m20:35:48.482907 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m20:35:48.484547 [debug] [Thread-1 (]: Began running node model.elementary.seed_run_results
[0m20:35:48.486451 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091c65a80>]}
[0m20:35:48.487338 [debug] [Thread-3 (]: Using postgres connection "model.elementary.job_run_results"
[0m20:35:48.488093 [debug] [Thread-4 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.monitors_runs"} */

  create view "elsa"."tec_elsa"."monitors_runs__dbt_tmp"
    
    
  as (
    

with data_monitoring_metrics as (

    select * from "elsa"."tec_elsa"."data_monitoring_metrics"

),

max_bucket_end as (

    select full_table_name,
           column_name,
           metric_name,
           metric_properties,
           max(bucket_end) as last_bucket_end,
           min(bucket_end) as first_bucket_end
    from data_monitoring_metrics
    group by 1,2,3,4

)

select * from max_bucket_end
  );
[0m20:35:48.489420 [info ] [Thread-1 (]: 23 of 33 START sql view model tec_elsa.seed_run_results ........................ [RUN]
[0m20:35:48.492159 [info ] [Thread-2 (]: 20 of 33 OK created sql view model tec_elsa.metrics_anomaly_score .............. [[32mCREATE VIEW[0m in 0.38s]
[0m20:35:48.493448 [debug] [Thread-3 (]: On model.elementary.job_run_results: BEGIN
[0m20:35:48.495397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.elementary.dbt_tests, now model.elementary.seed_run_results)
[0m20:35:48.497210 [debug] [Thread-2 (]: Finished running node model.elementary.metrics_anomaly_score
[0m20:35:48.498007 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m20:35:48.499227 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:48.500453 [debug] [Thread-1 (]: Began compiling node model.elementary.seed_run_results
[0m20:35:48.502194 [debug] [Thread-2 (]: Began running node model.elementary.snapshot_run_results
[0m20:35:48.513086 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m20:35:48.526407 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.seed_run_results"
[0m20:35:48.527838 [info ] [Thread-2 (]: 24 of 33 START sql view model tec_elsa.snapshot_run_results .................... [RUN]
[0m20:35:48.528801 [debug] [Thread-3 (]: SQL status: BEGIN in 0.029 seconds
[0m20:35:48.530084 [debug] [Thread-4 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.monitors_runs"} */
alter table "elsa"."tec_elsa"."monitors_runs__dbt_tmp" rename to "monitors_runs"
[0m20:35:48.531753 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.metrics_anomaly_score, now model.elementary.snapshot_run_results)
[0m20:35:48.532791 [debug] [Thread-3 (]: Using postgres connection "model.elementary.job_run_results"
[0m20:35:48.533486 [debug] [Thread-1 (]: Began executing node model.elementary.seed_run_results
[0m20:35:48.535081 [debug] [Thread-2 (]: Began compiling node model.elementary.snapshot_run_results
[0m20:35:48.535972 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m20:35:48.537483 [debug] [Thread-3 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.job_run_results"} */

  create view "elsa"."tec_elsa"."job_run_results__dbt_tmp"
    
    
  as (
    





with jobs as (
  select
    job_name,
    job_id,
    job_run_id,
    
min(cast(run_started_at as timestamp))
 as job_run_started_at,
    
max(cast(run_completed_at as timestamp))
 as job_run_completed_at,
    
    
        (
        (
        (
        ((
max(cast(run_completed_at as timestamp))
)::date - (
min(cast(run_started_at as timestamp))
)::date)
     * 24 + date_part('hour', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part('hour', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + date_part('minute', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part('minute', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + floor(date_part('second', (
max(cast(run_completed_at as timestamp))
)::timestamp)) - floor(date_part('second', (
min(cast(run_started_at as timestamp))
)::timestamp)))
    
 as job_run_execution_time
  from "elsa"."tec_elsa"."dbt_invocations"
  where job_id is not null
  group by job_name, job_id, job_run_id
)

select
  job_name as name,
  job_id as id,
  job_run_id as run_id,
  job_run_started_at as run_started_at,
  job_run_completed_at as run_completed_at,
  job_run_execution_time as run_execution_time
from jobs
  );
[0m20:35:48.549922 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.seed_run_results"
[0m20:35:48.560430 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.snapshot_run_results"
[0m20:35:48.562729 [debug] [Thread-4 (]: On model.elementary.monitors_runs: COMMIT
[0m20:35:48.565768 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m20:35:48.566838 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m20:35:48.567955 [debug] [Thread-1 (]: Using postgres connection "model.elementary.seed_run_results"
[0m20:35:48.568886 [debug] [Thread-4 (]: On model.elementary.monitors_runs: COMMIT
[0m20:35:48.569769 [debug] [Thread-2 (]: Began executing node model.elementary.snapshot_run_results
[0m20:35:48.580769 [debug] [Thread-3 (]: Using postgres connection "model.elementary.job_run_results"
[0m20:35:48.581789 [debug] [Thread-1 (]: On model.elementary.seed_run_results: BEGIN
[0m20:35:48.589053 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m20:35:48.593741 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.snapshot_run_results"
[0m20:35:48.594799 [debug] [Thread-3 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.job_run_results"} */
alter table "elsa"."tec_elsa"."job_run_results__dbt_tmp" rename to "job_run_results"
[0m20:35:48.595904 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:35:48.603786 [debug] [Thread-4 (]: Applying DROP to: "elsa"."tec_elsa"."monitors_runs__dbt_backup"
[0m20:35:48.606544 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:48.608662 [debug] [Thread-2 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m20:35:48.609690 [debug] [Thread-4 (]: Using postgres connection "model.elementary.monitors_runs"
[0m20:35:48.615422 [debug] [Thread-3 (]: On model.elementary.job_run_results: COMMIT
[0m20:35:48.617168 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: BEGIN
[0m20:35:48.618303 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m20:35:48.619498 [debug] [Thread-4 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.monitors_runs"} */
drop view if exists "elsa"."tec_elsa"."monitors_runs__dbt_backup" cascade
[0m20:35:48.620766 [debug] [Thread-3 (]: Using postgres connection "model.elementary.job_run_results"
[0m20:35:48.622143 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:48.623699 [debug] [Thread-1 (]: Using postgres connection "model.elementary.seed_run_results"
[0m20:35:48.625667 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:48.626316 [debug] [Thread-3 (]: On model.elementary.job_run_results: COMMIT
[0m20:35:48.628172 [debug] [Thread-1 (]: On model.elementary.seed_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.seed_run_results"} */

  create view "elsa"."tec_elsa"."seed_run_results__dbt_tmp"
    
    
  as (
    

with dbt_run_results as (
    select * from "elsa"."tec_elsa"."dbt_run_results"
),

dbt_seeds as (
    select * from "elsa"."tec_elsa"."dbt_seeds"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    seeds.database_name,
    seeds.schema_name,
    run_results.materialization,
    seeds.tags,
    seeds.package_name,
    seeds.path,
    seeds.original_path,
    seeds.owner,
    seeds.alias
FROM dbt_run_results run_results
JOIN dbt_seeds seeds ON run_results.unique_id = seeds.unique_id
  );
[0m20:35:48.631380 [debug] [Thread-4 (]: On model.elementary.monitors_runs: Close
[0m20:35:48.633636 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:48.635067 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090ac2ce0>]}
[0m20:35:48.642113 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.009 seconds
[0m20:35:48.644525 [debug] [Thread-3 (]: Applying DROP to: "elsa"."tec_elsa"."job_run_results__dbt_backup"
[0m20:35:48.645217 [debug] [Thread-2 (]: SQL status: BEGIN in 0.023 seconds
[0m20:35:48.646687 [info ] [Thread-4 (]: 21 of 33 OK created sql view model tec_elsa.monitors_runs ...................... [[32mCREATE VIEW[0m in 0.27s]
[0m20:35:48.657357 [debug] [Thread-1 (]: Using postgres connection "model.elementary.seed_run_results"
[0m20:35:48.754290 [debug] [Thread-3 (]: Using postgres connection "model.elementary.job_run_results"
[0m20:35:48.755806 [debug] [Thread-2 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m20:35:48.758172 [debug] [Thread-4 (]: Finished running node model.elementary.monitors_runs
[0m20:35:48.759797 [debug] [Thread-1 (]: On model.elementary.seed_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.seed_run_results"} */
alter table "elsa"."tec_elsa"."seed_run_results__dbt_tmp" rename to "seed_run_results"
[0m20:35:48.761221 [debug] [Thread-3 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.job_run_results"} */
drop view if exists "elsa"."tec_elsa"."job_run_results__dbt_backup" cascade
[0m20:35:48.763085 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.snapshot_run_results"} */

  create view "elsa"."tec_elsa"."snapshot_run_results__dbt_tmp"
    
    
  as (
    

with dbt_run_results as (
    select * from "elsa"."tec_elsa"."dbt_run_results"
),

dbt_snapshots as (
    select * from "elsa"."tec_elsa"."dbt_snapshots"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    snapshots.database_name,
    snapshots.schema_name,
    coalesce(run_results.materialization, snapshots.materialization) as materialization,
    snapshots.tags,
    snapshots.package_name,
    snapshots.path,
    snapshots.original_path,
    snapshots.owner,
    snapshots.alias
FROM dbt_run_results run_results
JOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id
  );
[0m20:35:48.764926 [debug] [Thread-4 (]: Began running node model.elementary.model_run_results
[0m20:35:48.767291 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:48.768161 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.001 seconds
[0m20:35:48.769692 [info ] [Thread-4 (]: 25 of 33 START sql view model tec_elsa.model_run_results ....................... [RUN]
[0m20:35:48.773287 [debug] [Thread-1 (]: On model.elementary.seed_run_results: COMMIT
[0m20:35:48.774332 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m20:35:48.777383 [debug] [Thread-3 (]: On model.elementary.job_run_results: Close
[0m20:35:48.778977 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.monitors_runs, now model.elementary.model_run_results)
[0m20:35:48.780537 [debug] [Thread-1 (]: Using postgres connection "model.elementary.seed_run_results"
[0m20:35:48.789638 [debug] [Thread-2 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m20:35:48.792403 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0909b1450>]}
[0m20:35:48.793601 [debug] [Thread-4 (]: Began compiling node model.elementary.model_run_results
[0m20:35:48.794938 [debug] [Thread-1 (]: On model.elementary.seed_run_results: COMMIT
[0m20:35:48.796386 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.snapshot_run_results"} */
alter table "elsa"."tec_elsa"."snapshot_run_results__dbt_tmp" rename to "snapshot_run_results"
[0m20:35:48.814948 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.model_run_results"
[0m20:35:48.817098 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:48.817779 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:48.826664 [debug] [Thread-1 (]: Applying DROP to: "elsa"."tec_elsa"."seed_run_results__dbt_backup"
[0m20:35:48.827686 [debug] [Thread-4 (]: Began executing node model.elementary.model_run_results
[0m20:35:48.829749 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: COMMIT
[0m20:35:48.831588 [debug] [Thread-1 (]: Using postgres connection "model.elementary.seed_run_results"
[0m20:35:48.842802 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.model_run_results"
[0m20:35:48.843876 [debug] [Thread-2 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m20:35:48.845008 [debug] [Thread-1 (]: On model.elementary.seed_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.seed_run_results"} */
drop view if exists "elsa"."tec_elsa"."seed_run_results__dbt_backup" cascade
[0m20:35:48.847717 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: COMMIT
[0m20:35:48.849381 [debug] [Thread-4 (]: Using postgres connection "model.elementary.model_run_results"
[0m20:35:48.850708 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:48.852100 [debug] [Thread-4 (]: On model.elementary.model_run_results: BEGIN
[0m20:35:48.853270 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:48.855819 [debug] [Thread-1 (]: On model.elementary.seed_run_results: Close
[0m20:35:48.858086 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:48.866681 [debug] [Thread-2 (]: Applying DROP to: "elsa"."tec_elsa"."snapshot_run_results__dbt_backup"
[0m20:35:48.868137 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090fdd660>]}
[0m20:35:48.870400 [debug] [Thread-2 (]: Using postgres connection "model.elementary.snapshot_run_results"
[0m20:35:48.872380 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.snapshot_run_results"} */
drop view if exists "elsa"."tec_elsa"."snapshot_run_results__dbt_backup" cascade
[0m20:35:48.874610 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.001 seconds
[0m20:35:48.877036 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: Close
[0m20:35:48.878419 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090a7a920>]}
[0m20:35:48.879206 [debug] [Thread-4 (]: SQL status: BEGIN in 0.021 seconds
[0m20:35:48.880838 [debug] [Thread-4 (]: Using postgres connection "model.elementary.model_run_results"
[0m20:35:48.882069 [debug] [Thread-4 (]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.model_run_results"} */

  create view "elsa"."tec_elsa"."model_run_results__dbt_tmp"
    
    
  as (
    

with dbt_run_results as (
    select * from "elsa"."tec_elsa"."dbt_run_results"
),

dbt_models as (
    select * from "elsa"."tec_elsa"."dbt_models"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    models.database_name,
    models.schema_name,
    coalesce(run_results.materialization, models.materialization) as materialization,
    models.tags,
    models.package_name,
    models.path,
    models.original_path,
    models.owner,
    models.alias,
    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,
    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc('day', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_first_invocation_of_the_day,
    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc('day', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_last_invocation_of_the_day
    
FROM dbt_run_results run_results
JOIN dbt_models models ON run_results.unique_id = models.unique_id
  );
[0m20:35:48.887226 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m20:35:48.895996 [debug] [Thread-4 (]: Using postgres connection "model.elementary.model_run_results"
[0m20:35:48.897109 [debug] [Thread-4 (]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.model_run_results"} */
alter table "elsa"."tec_elsa"."model_run_results__dbt_tmp" rename to "model_run_results"
[0m20:35:48.898929 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:48.901115 [debug] [Thread-4 (]: On model.elementary.model_run_results: COMMIT
[0m20:35:48.902231 [debug] [Thread-4 (]: Using postgres connection "model.elementary.model_run_results"
[0m20:35:48.903205 [debug] [Thread-4 (]: On model.elementary.model_run_results: COMMIT
[0m20:35:48.905313 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:48.914150 [debug] [Thread-4 (]: Applying DROP to: "elsa"."tec_elsa"."model_run_results__dbt_backup"
[0m20:35:48.915665 [debug] [Thread-4 (]: Using postgres connection "model.elementary.model_run_results"
[0m20:35:48.916738 [debug] [Thread-4 (]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.model_run_results"} */
drop view if exists "elsa"."tec_elsa"."model_run_results__dbt_backup" cascade
[0m20:35:48.918155 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:48.920640 [debug] [Thread-4 (]: On model.elementary.model_run_results: Close
[0m20:35:48.921959 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090949c60>]}
[0m20:35:49.421360 [debug] [Thread-3 (]: An error was encountered while trying to send an event
[0m20:35:49.423619 [info ] [Thread-1 (]: 23 of 33 OK created sql view model tec_elsa.seed_run_results ................... [[32mCREATE VIEW[0m in 0.37s]
[0m20:35:49.425925 [info ] [Thread-2 (]: 24 of 33 OK created sql view model tec_elsa.snapshot_run_results ............... [[32mCREATE VIEW[0m in 0.35s]
[0m20:35:49.427192 [info ] [Thread-4 (]: 25 of 33 OK created sql view model tec_elsa.model_run_results .................. [[32mCREATE VIEW[0m in 0.14s]
[0m20:35:49.436493 [debug] [Thread-1 (]: Finished running node model.elementary.seed_run_results
[0m20:35:49.432243 [info ] [Thread-3 (]: 22 of 33 OK created sql view model tec_elsa.job_run_results .................... [[32mCREATE VIEW[0m in 0.38s]
[0m20:35:49.439245 [debug] [Thread-2 (]: Finished running node model.elementary.snapshot_run_results
[0m20:35:49.443839 [debug] [Thread-4 (]: Finished running node model.elementary.model_run_results
[0m20:35:49.445659 [debug] [Thread-1 (]: Began running node model.elementary.alerts_anomaly_detection
[0m20:35:49.447270 [debug] [Thread-3 (]: Finished running node model.elementary.job_run_results
[0m20:35:49.449191 [debug] [Thread-2 (]: Began running node model.elementary.alerts_dbt_tests
[0m20:35:49.451108 [debug] [Thread-4 (]: Began running node model.elementary.alerts_schema_changes
[0m20:35:49.454092 [info ] [Thread-1 (]: 26 of 33 START sql view model tec_elsa.alerts_anomaly_detection ................ [RUN]
[0m20:35:49.458955 [debug] [Thread-3 (]: Began running node model.elementary.test_result_rows
[0m20:35:49.461448 [info ] [Thread-2 (]: 27 of 33 START sql view model tec_elsa.alerts_dbt_tests ........................ [RUN]
[0m20:35:49.464968 [info ] [Thread-4 (]: 28 of 33 START sql view model tec_elsa.alerts_schema_changes ................... [RUN]
[0m20:35:49.466809 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.elementary.seed_run_results, now model.elementary.alerts_anomaly_detection)
[0m20:35:49.469741 [info ] [Thread-3 (]: 29 of 33 START sql incremental model tec_elsa.test_result_rows ................. [RUN]
[0m20:35:49.472117 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.snapshot_run_results, now model.elementary.alerts_dbt_tests)
[0m20:35:49.479130 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.model_run_results, now model.elementary.alerts_schema_changes)
[0m20:35:49.481127 [debug] [Thread-1 (]: Began compiling node model.elementary.alerts_anomaly_detection
[0m20:35:49.483330 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.job_run_results, now model.elementary.test_result_rows)
[0m20:35:49.485024 [debug] [Thread-2 (]: Began compiling node model.elementary.alerts_dbt_tests
[0m20:35:49.486979 [debug] [Thread-4 (]: Began compiling node model.elementary.alerts_schema_changes
[0m20:35:49.507044 [debug] [Thread-3 (]: Began compiling node model.elementary.test_result_rows
[0m20:35:49.512455 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.alerts_anomaly_detection"
[0m20:35:49.531919 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.alerts_dbt_tests"
[0m20:35:49.552212 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.alerts_schema_changes"
[0m20:35:49.572771 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.test_result_rows"
[0m20:35:49.577632 [debug] [Thread-1 (]: Began executing node model.elementary.alerts_anomaly_detection
[0m20:35:49.579382 [debug] [Thread-2 (]: Began executing node model.elementary.alerts_dbt_tests
[0m20:35:49.581339 [debug] [Thread-4 (]: Began executing node model.elementary.alerts_schema_changes
[0m20:35:49.598528 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.alerts_anomaly_detection"
[0m20:35:49.606120 [debug] [Thread-3 (]: Began executing node model.elementary.test_result_rows
[0m20:35:49.615939 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.alerts_dbt_tests"
[0m20:35:49.630075 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.alerts_schema_changes"
[0m20:35:49.643625 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.test_result_rows"
[0m20:35:49.645223 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m20:35:49.647207 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m20:35:49.648503 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: BEGIN
[0m20:35:49.649246 [debug] [Thread-4 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m20:35:49.650135 [debug] [Thread-3 (]: Using postgres connection "model.elementary.test_result_rows"
[0m20:35:49.651049 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: BEGIN
[0m20:35:49.651988 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:35:49.652868 [debug] [Thread-4 (]: On model.elementary.alerts_schema_changes: BEGIN
[0m20:35:49.653760 [debug] [Thread-3 (]: On model.elementary.test_result_rows: BEGIN
[0m20:35:49.654651 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:49.657464 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:49.659494 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:49.668119 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m20:35:49.670138 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m20:35:49.671609 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_anomaly_detection"} */

  create view "elsa"."tec_elsa"."alerts_anomaly_detection__dbt_tmp"
    
    
  as (
    

with elementary_test_results as (
    select * from "elsa"."tec_elsa"."elementary_test_results"
),

alerts_anomaly_detection as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'anomaly_detection'
)

select * from alerts_anomaly_detection
  );
[0m20:35:49.674041 [debug] [Thread-4 (]: SQL status: BEGIN in 0.017 seconds
[0m20:35:49.675410 [debug] [Thread-2 (]: SQL status: BEGIN in 0.021 seconds
[0m20:35:49.676681 [debug] [Thread-4 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m20:35:49.677600 [debug] [Thread-3 (]: SQL status: BEGIN in 0.018 seconds
[0m20:35:49.678226 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m20:35:49.679073 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m20:35:49.680216 [debug] [Thread-4 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_schema_changes"} */

  create view "elsa"."tec_elsa"."alerts_schema_changes__dbt_tmp"
    
    
  as (
    


with elementary_test_results as (
    select * from "elsa"."tec_elsa"."elementary_test_results"
),

alerts_schema_changes as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'schema_change'
)

select * from alerts_schema_changes
  );
[0m20:35:49.681309 [debug] [Thread-3 (]: Using postgres connection "model.elementary.test_result_rows"
[0m20:35:49.689320 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m20:35:49.694795 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_anomaly_detection"} */
alter table "elsa"."tec_elsa"."alerts_anomaly_detection__dbt_tmp" rename to "alerts_anomaly_detection"
[0m20:35:49.693497 [debug] [Thread-3 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.test_result_rows"} */

      
  
    

  create  table "elsa"."tec_elsa"."test_result_rows"
  
  
    as
  
  (
    -- indexes are not supported in all warehouses, relevant to postgres only


-- depends_on: "elsa"."tec_elsa"."elementary_test_results"
select * from (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as text) as elementary_test_results_id

,
                
        cast('this_is_just_a_long_dummy_string' as text) as result_row

,
                cast('2091-02-17' as timestamp) as detected_at

,
                cast('2091-02-17' as timestamp) as created_at


        ) as empty_table
        where 1 = 0
  );
  
  
[0m20:35:49.691818 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_tests"} */

  create view "elsa"."tec_elsa"."alerts_dbt_tests__dbt_tmp"
    
    
  as (
    

with elementary_test_results as (
    select * from "elsa"."tec_elsa"."elementary_test_results"
),

alerts_dbt_tests as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'   and lower(status) != 'skipped'  and test_type = 'dbt_test'
)

select * from alerts_dbt_tests
  );
[0m20:35:49.696038 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m20:35:49.696839 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:49.704263 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m20:35:49.705335 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.009 seconds
[0m20:35:49.709361 [debug] [Thread-4 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m20:35:49.711372 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: COMMIT
[0m20:35:49.724863 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m20:35:49.721626 [debug] [Thread-3 (]: Using postgres connection "model.elementary.test_result_rows"
[0m20:35:49.723355 [debug] [Thread-4 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_schema_changes"} */
alter table "elsa"."tec_elsa"."alerts_schema_changes__dbt_tmp" rename to "alerts_schema_changes"
[0m20:35:49.719298 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m20:35:49.725956 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: COMMIT
[0m20:35:49.726888 [debug] [Thread-3 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.test_result_rows"} */

    create  index if not exists
  "9a3ba3a8c8f6b6f97aac42cd51885785"
  on "elsa"."tec_elsa"."test_result_rows" 
  (created_at)
  
[0m20:35:49.728305 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_tests"} */
alter table "elsa"."tec_elsa"."alerts_dbt_tests__dbt_tmp" rename to "alerts_dbt_tests"
[0m20:35:49.729027 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:49.732437 [debug] [Thread-4 (]: On model.elementary.alerts_schema_changes: COMMIT
[0m20:35:49.733378 [debug] [Thread-3 (]: SQL status: CREATE INDEX in 0.003 seconds
[0m20:35:49.734073 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.004 seconds
[0m20:35:49.734690 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m20:35:49.735641 [debug] [Thread-4 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m20:35:49.738047 [debug] [Thread-3 (]: Using postgres connection "model.elementary.test_result_rows"
[0m20:35:49.741043 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: COMMIT
[0m20:35:49.750190 [debug] [Thread-1 (]: Applying DROP to: "elsa"."tec_elsa"."alerts_anomaly_detection__dbt_backup"
[0m20:35:49.751300 [debug] [Thread-4 (]: On model.elementary.alerts_schema_changes: COMMIT
[0m20:35:49.752390 [debug] [Thread-3 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.test_result_rows"} */

    create  index if not exists
  "bd5738f928d5e432eaa2ab143eced1ba"
  on "elsa"."tec_elsa"."test_result_rows" 
  (elementary_test_results_id)
  
[0m20:35:49.753602 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m20:35:49.755107 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_anomaly_detection"
[0m20:35:49.758517 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:49.759373 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: COMMIT
[0m20:35:49.760182 [debug] [Thread-3 (]: SQL status: CREATE INDEX in 0.003 seconds
[0m20:35:49.761479 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_anomaly_detection"} */
drop view if exists "elsa"."tec_elsa"."alerts_anomaly_detection__dbt_backup" cascade
[0m20:35:49.769602 [debug] [Thread-4 (]: Applying DROP to: "elsa"."tec_elsa"."alerts_schema_changes__dbt_backup"
[0m20:35:49.774296 [debug] [Thread-3 (]: On model.elementary.test_result_rows: COMMIT
[0m20:35:49.775370 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m20:35:49.777206 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m20:35:49.778535 [debug] [Thread-4 (]: Using postgres connection "model.elementary.alerts_schema_changes"
[0m20:35:49.779840 [debug] [Thread-3 (]: Using postgres connection "model.elementary.test_result_rows"
[0m20:35:49.787731 [debug] [Thread-2 (]: Applying DROP to: "elsa"."tec_elsa"."alerts_dbt_tests__dbt_backup"
[0m20:35:49.791850 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: Close
[0m20:35:49.793116 [debug] [Thread-4 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_schema_changes"} */
drop view if exists "elsa"."tec_elsa"."alerts_schema_changes__dbt_backup" cascade
[0m20:35:49.794092 [debug] [Thread-3 (]: On model.elementary.test_result_rows: COMMIT
[0m20:35:49.795423 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_tests"
[0m20:35:49.796966 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090558190>]}
[0m20:35:49.798438 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:49.799444 [debug] [Thread-3 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:49.800614 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_tests"} */
drop view if exists "elsa"."tec_elsa"."alerts_dbt_tests__dbt_backup" cascade
[0m20:35:49.802144 [info ] [Thread-1 (]: 26 of 33 OK created sql view model tec_elsa.alerts_anomaly_detection ........... [[32mCREATE VIEW[0m in 0.33s]
[0m20:35:49.804848 [debug] [Thread-4 (]: On model.elementary.alerts_schema_changes: Close
[0m20:35:49.806512 [debug] [Thread-3 (]: On model.elementary.test_result_rows: Close
[0m20:35:49.810047 [debug] [Thread-1 (]: Finished running node model.elementary.alerts_anomaly_detection
[0m20:35:49.808884 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:49.812390 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090949c60>]}
[0m20:35:49.814461 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0909b1450>]}
[0m20:35:49.815932 [debug] [Thread-1 (]: Began running node model.elementary.alerts_dbt_source_freshness
[0m20:35:49.818639 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: Close
[0m20:35:49.820103 [info ] [Thread-4 (]: 28 of 33 OK created sql view model tec_elsa.alerts_schema_changes .............. [[32mCREATE VIEW[0m in 0.33s]
[0m20:35:49.821415 [info ] [Thread-3 (]: 29 of 33 OK created sql incremental model tec_elsa.test_result_rows ............ [[32mSELECT 0[0m in 0.33s]
[0m20:35:49.825144 [info ] [Thread-1 (]: 30 of 33 START sql view model tec_elsa.alerts_dbt_source_freshness ............. [RUN]
[0m20:35:49.827274 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09055a3e0>]}
[0m20:35:49.829570 [debug] [Thread-4 (]: Finished running node model.elementary.alerts_schema_changes
[0m20:35:49.830852 [debug] [Thread-3 (]: Finished running node model.elementary.test_result_rows
[0m20:35:49.832953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.elementary.alerts_anomaly_detection, now model.elementary.alerts_dbt_source_freshness)
[0m20:35:49.854622 [info ] [Thread-2 (]: 27 of 33 OK created sql view model tec_elsa.alerts_dbt_tests ................... [[32mCREATE VIEW[0m in 0.36s]
[0m20:35:49.860052 [debug] [Thread-4 (]: Began running node model.elementary.dbt_artifacts_hashes
[0m20:35:49.862466 [debug] [Thread-3 (]: Began running node model.elementary.anomaly_threshold_sensitivity
[0m20:35:49.864513 [debug] [Thread-1 (]: Began compiling node model.elementary.alerts_dbt_source_freshness
[0m20:35:49.866488 [debug] [Thread-2 (]: Finished running node model.elementary.alerts_dbt_tests
[0m20:35:49.868898 [info ] [Thread-4 (]: 31 of 33 START sql view model tec_elsa.dbt_artifacts_hashes .................... [RUN]
[0m20:35:49.870951 [info ] [Thread-3 (]: 32 of 33 START sql view model tec_elsa.anomaly_threshold_sensitivity ........... [RUN]
[0m20:35:49.887865 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.alerts_dbt_source_freshness"
[0m20:35:49.888686 [debug] [Thread-2 (]: Began running node model.elementary.alerts_dbt_models
[0m20:35:49.891909 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.elementary.alerts_schema_changes, now model.elementary.dbt_artifacts_hashes)
[0m20:35:49.893695 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.elementary.test_result_rows, now model.elementary.anomaly_threshold_sensitivity)
[0m20:35:49.898767 [debug] [Thread-3 (]: Began compiling node model.elementary.anomaly_threshold_sensitivity
[0m20:35:49.897047 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_artifacts_hashes
[0m20:35:49.897855 [debug] [Thread-1 (]: Began executing node model.elementary.alerts_dbt_source_freshness
[0m20:35:49.895702 [info ] [Thread-2 (]: 33 of 33 START sql view model tec_elsa.alerts_dbt_models ....................... [RUN]
[0m20:35:49.916071 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.anomaly_threshold_sensitivity"
[0m20:35:49.933410 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_artifacts_hashes"
[0m20:35:49.944418 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.alerts_dbt_source_freshness"
[0m20:35:49.945569 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.elementary.alerts_dbt_tests, now model.elementary.alerts_dbt_models)
[0m20:35:49.948336 [debug] [Thread-3 (]: Began executing node model.elementary.anomaly_threshold_sensitivity
[0m20:35:49.949670 [debug] [Thread-2 (]: Began compiling node model.elementary.alerts_dbt_models
[0m20:35:49.950267 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_artifacts_hashes
[0m20:35:49.951204 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m20:35:50.094214 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: BEGIN
[0m20:35:50.081036 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.alerts_dbt_models"
[0m20:35:50.093133 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_artifacts_hashes"
[0m20:35:50.066440 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.anomaly_threshold_sensitivity"
[0m20:35:50.095289 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:35:50.097946 [debug] [Thread-2 (]: Began executing node model.elementary.alerts_dbt_models
[0m20:35:50.099506 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m20:35:50.110843 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.alerts_dbt_models"
[0m20:35:50.111609 [debug] [Thread-3 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m20:35:50.112740 [debug] [Thread-4 (]: On model.elementary.dbt_artifacts_hashes: BEGIN
[0m20:35:50.113532 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m20:35:50.115183 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: BEGIN
[0m20:35:50.116085 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:35:50.116808 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m20:35:50.117797 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m20:35:50.118681 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:35:50.120123 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: BEGIN
[0m20:35:50.121311 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_source_freshness"} */

  create view "elsa"."tec_elsa"."alerts_dbt_source_freshness__dbt_tmp"
    
    
  as (
    

with results as (
  select * from "elsa"."tec_elsa"."dbt_source_freshness_results"
),

sources as (
  select * from "elsa"."tec_elsa"."dbt_sources"
)

select
  results.source_freshness_execution_id as alert_id,
  results.max_loaded_at,
  results.snapshotted_at,
  cast(results.generated_at as timestamp) as detected_at,
  results.max_loaded_at_time_ago_in_s,
  results.status,
  results.error,
  results.warn_after,
  results.error_after,
  results.filter,
  sources.unique_id,
  sources.database_name,
  sources.schema_name,
  sources.source_name,
  sources.identifier,
  sources.tags,
  sources.meta,
  sources.owner,
  sources.package_name,
  sources.path,
  -- These columns below are deprecated. We add them since this view
  -- was used to be loaded into an incremental model with those columns, their names were later changed
  -- and Databricks doesn't respect `on_schema_change = 'append_new_columns'` properly, as described here -
  -- https://docs.databricks.com/en/delta/update-schema.html#automatic-schema-evolution-for-delta-lake-merge
  results.error_after as freshness_error_after,
  results.warn_after as freshness_warn_after,
  results.filter as freshness_filter
from results
join sources on results.unique_id = sources.unique_id
where True and lower(status) != 'pass'
  );
[0m20:35:50.123293 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:35:50.129655 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m20:35:50.130447 [debug] [Thread-4 (]: SQL status: BEGIN in 0.014 seconds
[0m20:35:50.139172 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m20:35:50.141157 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m20:35:50.142040 [debug] [Thread-3 (]: SQL status: BEGIN in 0.023 seconds
[0m20:35:50.142706 [debug] [Thread-2 (]: SQL status: BEGIN in 0.019 seconds
[0m20:35:50.143713 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_source_freshness"} */
alter table "elsa"."tec_elsa"."alerts_dbt_source_freshness__dbt_tmp" rename to "alerts_dbt_source_freshness"
[0m20:35:50.144942 [debug] [Thread-4 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_artifacts_hashes"} */

  create view "elsa"."tec_elsa"."dbt_artifacts_hashes__dbt_tmp"
    
    
  as (
    




select
  'dbt_models' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_models"
 union all 

select
  'dbt_tests' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_tests"
 union all 

select
  'dbt_sources' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_sources"
 union all 

select
  'dbt_snapshots' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_snapshots"
 union all 

select
  'dbt_metrics' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_metrics"
 union all 

select
  'dbt_exposures' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_exposures"
 union all 

select
  'dbt_seeds' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_seeds"
 union all 

select
  'dbt_columns' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_columns"
 union all 

select
  'dbt_groups' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_groups"


order by metadata_hash
  );
[0m20:35:50.146120 [debug] [Thread-3 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m20:35:50.147148 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m20:35:50.148961 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:50.149961 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */

  create view "elsa"."tec_elsa"."anomaly_threshold_sensitivity__dbt_tmp"
    
    
  as (
    

with metrics_anomaly_score as (

    select * from "elsa"."tec_elsa"."metrics_anomaly_score"

),

score_sensitivity as (

    select
        full_table_name,
        column_name,
        metric_name,
        latest_metric_value,
        training_avg as metric_avg,
        training_stddev as metric_stddev,
        anomaly_score,
        case when abs(anomaly_score) >= 1.5 then true else false end as "is_anomaly_1_5",
        case when abs(anomaly_score) >= 2 then true else false end as "is_anomaly_2",
        case when abs(anomaly_score) >= 2.5 then true else false end as "is_anomaly_2_5",
        case when abs(anomaly_score) >= 3 then true else false end as "is_anomaly_3",
        case when abs(anomaly_score) >= 3.5 then true else false end as "is_anomaly_3_5",
        case when abs(anomaly_score) >= 4 then true else false end as "is_anomaly_4",
        case when abs(anomaly_score) >= 4.5 then true else false end as "is_anomaly_4_5"
    from metrics_anomaly_score
    where abs(anomaly_score) >= 1.5

)

select * from score_sensitivity
  );
[0m20:35:50.151192 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m20:35:50.152124 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_models"} */

  create view "elsa"."tec_elsa"."alerts_dbt_models__dbt_tmp"
    
    
  as (
    

with error_models as (
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias 
    from "elsa"."tec_elsa"."model_run_results"
  
    union all
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias  
  from "elsa"."tec_elsa"."snapshot_run_results"
)


select model_execution_id as alert_id,
       unique_id,
       cast(generated_at as timestamp) as detected_at,
       database_name,
       materialization,
       path,
       original_path,
       schema_name,
       message,
       owner as owners,
       tags,
       alias,
       status,
       full_refresh
from error_models
where True and lower(status) != 'success'and lower(status) != 'skipped'
  );
[0m20:35:50.154566 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: COMMIT
[0m20:35:50.262438 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m20:35:50.263361 [debug] [Thread-3 (]: SQL status: CREATE VIEW in 0.108 seconds
[0m20:35:50.266174 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m20:35:50.267580 [debug] [Thread-4 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_artifacts_hashes"} */
alter table "elsa"."tec_elsa"."dbt_artifacts_hashes__dbt_tmp" rename to "dbt_artifacts_hashes"
[0m20:35:50.276738 [debug] [Thread-3 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m20:35:50.277663 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.012 seconds
[0m20:35:50.278755 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: COMMIT
[0m20:35:50.280233 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */
alter table "elsa"."tec_elsa"."anomaly_threshold_sensitivity__dbt_tmp" rename to "anomaly_threshold_sensitivity"
[0m20:35:50.281121 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:35:50.289903 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m20:35:50.293177 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:50.294070 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m20:35:50.295931 [debug] [Thread-4 (]: On model.elementary.dbt_artifacts_hashes: COMMIT
[0m20:35:50.297140 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_models"} */
alter table "elsa"."tec_elsa"."alerts_dbt_models__dbt_tmp" rename to "alerts_dbt_models"
[0m20:35:50.304257 [debug] [Thread-1 (]: Applying DROP to: "elsa"."tec_elsa"."alerts_dbt_source_freshness__dbt_backup"
[0m20:35:50.308617 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: COMMIT
[0m20:35:50.310144 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m20:35:50.312099 [debug] [Thread-1 (]: Using postgres connection "model.elementary.alerts_dbt_source_freshness"
[0m20:35:50.312792 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m20:35:50.313739 [debug] [Thread-3 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m20:35:50.314707 [debug] [Thread-4 (]: On model.elementary.dbt_artifacts_hashes: COMMIT
[0m20:35:50.315737 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_source_freshness"} */
drop view if exists "elsa"."tec_elsa"."alerts_dbt_source_freshness__dbt_backup" cascade
[0m20:35:50.318536 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: COMMIT
[0m20:35:50.319641 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: COMMIT
[0m20:35:50.321878 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m20:35:50.323176 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m20:35:50.324387 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m20:35:50.333124 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m20:35:50.335310 [debug] [Thread-4 (]: Applying DROP to: "elsa"."tec_elsa"."dbt_artifacts_hashes__dbt_backup"
[0m20:35:50.337957 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: Close
[0m20:35:50.339076 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: COMMIT
[0m20:35:50.347167 [debug] [Thread-3 (]: Applying DROP to: "elsa"."tec_elsa"."anomaly_threshold_sensitivity__dbt_backup"
[0m20:35:50.348478 [debug] [Thread-4 (]: Using postgres connection "model.elementary.dbt_artifacts_hashes"
[0m20:35:50.350054 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091c647f0>]}
[0m20:35:50.351866 [debug] [Thread-3 (]: Using postgres connection "model.elementary.anomaly_threshold_sensitivity"
[0m20:35:50.352695 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m20:35:50.353647 [debug] [Thread-4 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.dbt_artifacts_hashes"} */
drop view if exists "elsa"."tec_elsa"."dbt_artifacts_hashes__dbt_backup" cascade
[0m20:35:50.355063 [info ] [Thread-1 (]: 30 of 33 OK created sql view model tec_elsa.alerts_dbt_source_freshness ........ [[32mCREATE VIEW[0m in 0.52s]
[0m20:35:50.356612 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */
drop view if exists "elsa"."tec_elsa"."anomaly_threshold_sensitivity__dbt_backup" cascade
[0m20:35:50.364944 [debug] [Thread-2 (]: Applying DROP to: "elsa"."tec_elsa"."alerts_dbt_models__dbt_backup"
[0m20:35:50.366534 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:50.367842 [debug] [Thread-1 (]: Finished running node model.elementary.alerts_dbt_source_freshness
[0m20:35:50.369164 [debug] [Thread-3 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:50.370305 [debug] [Thread-2 (]: Using postgres connection "model.elementary.alerts_dbt_models"
[0m20:35:50.372654 [debug] [Thread-4 (]: On model.elementary.dbt_artifacts_hashes: Close
[0m20:35:50.376818 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: Close
[0m20:35:50.378096 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.elementary.alerts_dbt_models"} */
drop view if exists "elsa"."tec_elsa"."alerts_dbt_models__dbt_backup" cascade
[0m20:35:50.379502 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090f56200>]}
[0m20:35:50.380833 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc091c35960>]}
[0m20:35:50.382188 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:35:50.383299 [info ] [Thread-4 (]: 31 of 33 OK created sql view model tec_elsa.dbt_artifacts_hashes ............... [[32mCREATE VIEW[0m in 0.49s]
[0m20:35:50.384722 [info ] [Thread-3 (]: 32 of 33 OK created sql view model tec_elsa.anomaly_threshold_sensitivity ...... [[32mCREATE VIEW[0m in 0.49s]
[0m20:35:50.387309 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: Close
[0m20:35:50.388648 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_artifacts_hashes
[0m20:35:50.390424 [debug] [Thread-3 (]: Finished running node model.elementary.anomaly_threshold_sensitivity
[0m20:35:50.392796 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b63bef1c-f249-4ff7-abf5-212ebea01119', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc090564ac0>]}
[0m20:35:50.395731 [info ] [Thread-2 (]: 33 of 33 OK created sql view model tec_elsa.alerts_dbt_models .................. [[32mCREATE VIEW[0m in 0.45s]
[0m20:35:50.397302 [debug] [Thread-2 (]: Finished running node model.elementary.alerts_dbt_models
[0m20:35:50.400848 [info ] [MainThread]: 
[0m20:35:50.401911 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:50.403018 [debug] [MainThread]: On master: BEGIN
[0m20:35:50.403848 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:35:50.414182 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:35:50.415303 [debug] [MainThread]: On master: COMMIT
[0m20:35:50.416218 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:50.416975 [debug] [MainThread]: On master: COMMIT
[0m20:35:50.417865 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:35:50.451678 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:50.452778 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m20:35:50.456094 [debug] [MainThread]: SQL status: SELECT 127 in 0.002 seconds
[0m20:35:50.461072 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:35:50.467953 [debug] [MainThread]: Elementary: [dbt_models] Artifacts already ran.
[0m20:35:50.469682 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts already ran.
[0m20:35:50.471184 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts already ran.
[0m20:35:50.472552 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts already ran.
[0m20:35:50.474735 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts already ran.
[0m20:35:50.476353 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts already ran.
[0m20:35:50.477884 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts already ran.
[0m20:35:50.479343 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts already ran.
[0m20:35:50.481101 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts already ran.
[0m20:35:50.482373 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:35:50.488402 [debug] [MainThread]: Elementary: Uploading run results.
[0m20:35:50.490899 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m20:35:50.564902 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 33 artifacts.
[0m20:35:50.573726 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:50.574933 [debug] [MainThread]: On master: BEGIN
[0m20:35:50.576251 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:35:50.577220 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:50.578236 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'tec_elsa'
        
      order by ordinal_position

  
[0m20:35:50.586884 [debug] [MainThread]: SQL status: SELECT 23 in 0.008 seconds
[0m20:35:50.591627 [debug] [MainThread]: Elementary: Inserting 33 rows to table "elsa"."tec_elsa"."dbt_run_results"
[0m20:35:50.963146 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:35:50.965004 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:50.974188 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "elsa"."tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('b63bef1c-f249-4ff7-abf5-212ebea01119.model.dbt_elsa.consumption','model.dbt_elsa.consumption','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'consumption','Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql','error','model',0.29200220108032227,'2025-07-20T20:35:44.390796Z','2025-07-20T20:35:44.593218Z','2025-07-20T20:35:44.339601Z','2025-07-20T20:35:44.387265Z',NULL,False,'SELECT
    id,
    created_at,
    (data->>''date'')::date AS date,
    (data->>''heure'')::time AS heure,   
    (data->>''gaz'')::int AS gaz,
    (data->>''nucleaire'')::int AS nucleaire,
    (data->>''charbon'')::int AS charbon,
    (data->>''solaire'')::int AS solaire,
    (data->>''eolien'')::int AS eolien,
    (data->>''hydraulique'')::int AS hydraulique,
    (data->>''bioenergies'')::int AS bioenergies,
    (data->>''autres'')::int AS autres,
    (data->>''prevision_j'')::int AS prevision_j,
    (data->>''prevision_j1'')::int AS prevision_j1
FROM bronze.rte_eco2mix',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.dbt_elsa.consumption_history','model.dbt_elsa.consumption_history','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'consumption_history','Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql','error','model',0.31179046630859375,'2025-07-20T20:35:44.438928Z','2025-07-20T20:35:44.603553Z','2025-07-20T20:35:44.350017Z','2025-07-20T20:35:44.388207Z',NULL,False,'SELECT *
FROM "elsa"."silver"."consumption_history"
WHERE DATE(created_at) < CURRENT_DATE
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM "elsa"."bronze"."consumption"
JOIN LATERAL(VALUES
    (''gaz'', consumption.gaz),
    (''nucleaire'', consumption.nucleaire),
    (''charbon'', consumption.charbon),
    (''solaire'', consumption.solaire),
    (''eolien'', consumption.eolien),
    (''hydraulique'', consumption.hydraulique),
    (''bioenergies'', consumption.bioenergies),
    (''autres'', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere',NULL,NULL,'Thread-2 (worker)','table','{}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.dbt_elsa.test_connection','model.dbt_elsa.test_connection','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'test_connection','Database Error in model test_connection (models/bronze/test_connection.sql)
  syntax error at or near ";"
  LINE 12: ...select current_database() as db, current_schema() as schema;
                                                                         ^
  compiled code at target/run/dbt_elsa/models/bronze/test_connection.sql','error','model',0.3151545524597168,'2025-07-20T20:35:44.475513Z','2025-07-20T20:35:44.633852Z','2025-07-20T20:35:44.360070Z','2025-07-20T20:35:44.388918Z',NULL,False,'select current_database() as db, current_schema() as schema;',NULL,NULL,'Thread-3 (worker)','table','{}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.data_monitoring_metrics','model.elementary.data_monitoring_metrics','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'data_monitoring_metrics','SELECT 0','success','model',0.41541528701782227,'2025-07-20T20:35:44.487391Z','2025-07-20T20:35:44.725454Z','2025-07-20T20:35:44.367786Z','2025-07-20T20:35:44.450771Z',0,False,'


    
    
        
    
    select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as id

,
                
        cast(''dummy_string'' as varchar(4096)) as full_table_name

,
                
        cast(''dummy_string'' as varchar(4096)) as column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as metric_name

,
                
        cast(''dummy_string'' as varchar(4096)) as metric_type

,
                
        cast(123456789.99 as float) as metric_value

,
                
        cast(''dummy_string'' as varchar(4096)) as source_value

,
                cast(''2091-02-17'' as timestamp) as bucket_start

,
                cast(''2091-02-17'' as timestamp) as bucket_end

,
                
        cast(123456789 as integer) as bucket_duration_hours

,
                cast(''2091-02-17'' as timestamp) as updated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as dimension

,
                
        cast(''dummy_string'' as varchar(4096)) as dimension_value

,
                
        cast(''dummy_string'' as varchar(4096)) as metric_properties

,
                cast(''2091-02-17'' as timestamp) as created_at


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-4 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_invocations','model.elementary.dbt_invocations','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_invocations','SELECT 0','success','model',0.6194300651550293,'2025-07-20T20:35:44.855182Z','2025-07-20T20:35:45.388383Z','2025-07-20T20:35:44.827289Z','2025-07-20T20:35:44.852901Z',0,False,'

select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as invocation_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as job_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as job_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as job_run_id

,
                
        cast(''dummy_string'' as varchar(4096)) as run_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as run_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(''dummy_string'' as varchar(4096)) as command

,
                
        cast(''dummy_string'' as varchar(4096)) as dbt_version

,
                
        cast(''dummy_string'' as varchar(4096)) as elementary_version

,
                
        cast (True as boolean) as full_refresh

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as invocation_vars

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as vars

,
                
        cast(''dummy_string'' as varchar(4096)) as target_name

,
                
        cast(''dummy_string'' as varchar(4096)) as target_database

,
                
        cast(''dummy_string'' as varchar(4096)) as target_schema

,
                
        cast(''dummy_string'' as varchar(4096)) as target_profile_name

,
                
        cast(123456789 as integer) as threads

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as selected

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as yaml_selector

,
                
        cast(''dummy_string'' as varchar(4096)) as project_id

,
                
        cast(''dummy_string'' as varchar(4096)) as project_name

,
                
        cast(''dummy_string'' as varchar(4096)) as env

,
                
        cast(''dummy_string'' as varchar(4096)) as env_id

,
                
        cast(''dummy_string'' as varchar(4096)) as cause_category

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as cause

,
                
        cast(''dummy_string'' as varchar(4096)) as pull_request_id

,
                
        cast(''dummy_string'' as varchar(4096)) as git_sha

,
                
        cast(''dummy_string'' as varchar(4096)) as orchestrator

,
                
        cast(''dummy_string'' as varchar(4096)) as dbt_user

,
                
        cast(''dummy_string'' as varchar(4096)) as job_url

,
                
        cast(''dummy_string'' as varchar(4096)) as job_run_url

,
                
        cast(''dummy_string'' as varchar(4096)) as account_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as target_adapter_specific_fields


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-4 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_exposures','model.elementary.dbt_exposures','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_exposures','SELECT 0','success','model',0.7489850521087646,'2025-07-20T20:35:44.783760Z','2025-07-20T20:35:45.446882Z','2025-07-20T20:35:44.728800Z','2025-07-20T20:35:44.779236Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as maturity

,
                
        cast(''dummy_string'' as varchar(4096)) as type

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_email

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as url

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_columns

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as label

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as raw_queries


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-2 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_groups','model.elementary.dbt_groups','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_groups','SELECT 0','success','model',0.7429749965667725,'2025-07-20T20:35:44.800653Z','2025-07-20T20:35:45.453290Z','2025-07-20T20:35:44.750030Z','2025-07-20T20:35:44.782740Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_email

,
                
        cast(''dummy_string'' as varchar(4096)) as owner_name

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-3 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_run_results','model.elementary.dbt_run_results','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_run_results','SELECT 0','success','model',0.8462216854095459,'2025-07-20T20:35:46.048708Z','2025-07-20T20:35:46.551000Z','2025-07-20T20:35:45.871692Z','2025-07-20T20:35:45.987806Z',0,False,'

select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_execution_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as invocation_id

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as message

,
                
        cast(''dummy_string'' as varchar(4096)) as status

,
                
        cast(''dummy_string'' as varchar(4096)) as resource_type

,
                
        cast(123456789.99 as float) as execution_time

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_completed_at

,
                
        cast(31474836478 as bigint) as rows_affected

,
                
        cast (True as boolean) as full_refresh

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as compiled_code

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast(''dummy_string'' as varchar(4096)) as query_id

,
                
        cast(''dummy_string'' as varchar(4096)) as thread_id

,
                
        cast(''dummy_string'' as varchar(4096)) as materialization

,
                
        cast(''dummy_string'' as varchar(4096)) as adapter_response

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-3 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_metrics','model.elementary.dbt_metrics','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_metrics','SELECT 0','success','model',1.1183042526245117,'2025-07-20T20:35:45.816711Z','2025-07-20T20:35:46.577531Z','2025-07-20T20:35:45.587725Z','2025-07-20T20:35:45.738036Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as label

,
                
        cast(''dummy_string'' as varchar(4096)) as model

,
                
        cast(''dummy_string'' as varchar(4096)) as type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as sql

,
                
        cast(''dummy_string'' as varchar(4096)) as timestamp

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as filters

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as time_grains

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as dimensions

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-4 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_columns','model.elementary.dbt_columns','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_columns','SELECT 0','success','model',2.392930030822754,'2025-07-20T20:35:44.765011Z','2025-07-20T20:35:46.999540Z','2025-07-20T20:35:44.704023Z','2025-07-20T20:35:44.741969Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as parent_unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as data_type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as table_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as resource_type

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-1 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_seeds','model.elementary.dbt_seeds','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_seeds','SELECT 0','success','model',0.7616708278656006,'2025-07-20T20:35:46.760729Z','2025-07-20T20:35:47.366207Z','2025-07-20T20:35:46.624612Z','2025-07-20T20:35:46.699661Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as checksum

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-3 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_source_freshness_results','model.elementary.dbt_source_freshness_results','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_source_freshness_results','SELECT 0','success','model',0.1796128749847412,'2025-07-20T20:35:47.277936Z','2025-07-20T20:35:47.388975Z','2025-07-20T20:35:47.232227Z','2025-07-20T20:35:47.268307Z',0,False,'


    select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as source_freshness_execution_id

,
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as max_loaded_at

,
                
        cast(''dummy_string'' as varchar(4096)) as snapshotted_at

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(123456789.99 as float) as max_loaded_at_time_ago_in_s

,
                
        cast(''dummy_string'' as varchar(4096)) as status

,
                
        cast(''dummy_string'' as varchar(4096)) as error

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as compile_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_started_at

,
                
        cast(''dummy_string'' as varchar(4096)) as execute_completed_at

,
                
        cast(''dummy_string'' as varchar(4096)) as invocation_id

,
                
        cast(''dummy_string'' as varchar(4096)) as warn_after

,
                
        cast(''dummy_string'' as varchar(4096)) as error_after

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as filter


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-1 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_snapshots','model.elementary.dbt_snapshots','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_snapshots','SELECT 0','success','model',0.7145516872406006,'2025-07-20T20:35:47.127705Z','2025-07-20T20:35:47.394363Z','2025-07-20T20:35:46.814768Z','2025-07-20T20:35:47.071786Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as checksum

,
                
        cast(''dummy_string'' as varchar(4096)) as materialization

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as patch_path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as unique_key

,
                
        cast(''dummy_string'' as varchar(4096)) as incremental_strategy

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name

,
                
        cast(''dummy_string'' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-4 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_models','model.elementary.dbt_models','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_models','SELECT 0','success','model',1.76908540725708,'2025-07-20T20:35:45.994729Z','2025-07-20T20:35:47.400196Z','2025-07-20T20:35:45.749876Z','2025-07-20T20:35:45.908372Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as checksum

,
                
        cast(''dummy_string'' as varchar(4096)) as materialization

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as patch_path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as unique_key

,
                
        cast(''dummy_string'' as varchar(4096)) as incremental_strategy

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name

,
                
        cast(''dummy_string'' as varchar(4096)) as access


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-2 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.elementary_test_results','model.elementary.elementary_test_results','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'elementary_test_results','SELECT 0','success','model',0.3814566135406494,'2025-07-20T20:35:47.538615Z','2025-07-20T20:35:47.842615Z','2025-07-20T20:35:47.489682Z','2025-07-20T20:35:47.525764Z',0,False,'


    select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as id

,
                
        cast(''dummy_string'' as varchar(4096)) as data_issue_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_execution_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_unique_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as invocation_id

,
                cast(''2091-02-17'' as timestamp) as detected_at

,
                cast(''2091-02-17'' as timestamp) as created_at

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as table_name

,
                
        cast(''dummy_string'' as varchar(4096)) as column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as test_type

,
                
        cast(''dummy_string'' as varchar(4096)) as test_sub_type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_results_description

,
                
        cast(''dummy_string'' as varchar(4096)) as owners

,
                
        cast(''dummy_string'' as varchar(4096)) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_results_query

,
                
        cast(''dummy_string'' as varchar(4096)) as other

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_params

,
                
        cast(''dummy_string'' as varchar(4096)) as severity

,
                
        cast(''dummy_string'' as varchar(4096)) as status

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast(''dummy_string'' as varchar(4096)) as test_short_name

,
                
        cast(''dummy_string'' as varchar(4096)) as test_alias

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as result_rows

,
                
        cast(31474836478 as bigint) as failed_row_count


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-4 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.metadata','model.elementary.metadata','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'metadata','SELECT 1','success','model',0.4814908504486084,'2025-07-20T20:35:47.552612Z','2025-07-20T20:35:47.901169Z','2025-07-20T20:35:47.510554Z','2025-07-20T20:35:47.544902Z',1,False,'

SELECT
    ''0.19.0'' as dbt_pkg_version',NULL,NULL,'Thread-2 (worker)','table','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.schema_columns_snapshot','model.elementary.schema_columns_snapshot','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'schema_columns_snapshot','SELECT 0','success','model',0.4285094738006592,'2025-07-20T20:35:47.969560Z','2025-07-20T20:35:48.311131Z','2025-07-20T20:35:47.934800Z','2025-07-20T20:35:47.965743Z',0,False,'


    select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as column_state_id

,
                
        cast(''dummy_string'' as varchar(4096)) as full_column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as full_table_name

,
                
        cast(''dummy_string'' as varchar(4096)) as column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as data_type

,
                
        cast (True as boolean) as is_new

,
                cast(''2091-02-17'' as timestamp) as detected_at

,
                cast(''2091-02-17'' as timestamp) as created_at


        ) as empty_table
        where 1 = 0
',NULL,NULL,'Thread-4 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_sources','model.elementary.dbt_sources','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_sources','SELECT 0','success','model',0.9615480899810791,'2025-07-20T20:35:47.449670Z','2025-07-20T20:35:48.355977Z','2025-07-20T20:35:47.417182Z','2025-07-20T20:35:47.444574Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as source_name

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as identifier

,
                
        cast(''dummy_string'' as varchar(4096)) as loaded_at_field

,
                
        cast(''dummy_string'' as varchar(4096)) as freshness_warn_after

,
                
        cast(''dummy_string'' as varchar(4096)) as freshness_error_after

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as freshness_filter

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as freshness_description

,
                
        cast(''dummy_string'' as varchar(4096)) as relation_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''dummy_string'' as varchar(4096)) as owner

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as source_description

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-3 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_tests','model.elementary.dbt_tests','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_tests','SELECT 0','success','model',1.0093841552734375,'2025-07-20T20:35:47.526877Z','2025-07-20T20:35:48.451557Z','2025-07-20T20:35:47.469760Z','2025-07-20T20:35:47.522150Z',0,False,'

select * from (
            select
            
                
        cast(''dummy_string'' as varchar(4096)) as unique_id

,
                
        cast(''dummy_string'' as varchar(4096)) as database_name

,
                
        cast(''dummy_string'' as varchar(4096)) as schema_name

,
                
        cast(''dummy_string'' as varchar(4096)) as name

,
                
        cast(''dummy_string'' as varchar(4096)) as short_name

,
                
        cast(''dummy_string'' as varchar(4096)) as alias

,
                
        cast(''dummy_string'' as varchar(4096)) as test_column_name

,
                
        cast(''dummy_string'' as varchar(4096)) as severity

,
                
        cast(''dummy_string'' as varchar(4096)) as warn_if

,
                
        cast(''dummy_string'' as varchar(4096)) as error_if

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as test_params

,
                
        cast(''dummy_string'' as varchar(4096)) as test_namespace

,
                
        cast(''dummy_string'' as varchar(4096)) as test_original_name

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_tags

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as model_owners

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as meta

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_macros

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as depends_on_nodes

,
                
        cast(''dummy_string'' as varchar(4096)) as parent_model_unique_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as description

,
                
        cast(''dummy_string'' as varchar(4096)) as package_name

,
                
        cast(''dummy_string'' as varchar(4096)) as type

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as original_path

,
                
        cast(''dummy_string'' as varchar(4096)) as path

,
                
        cast(''dummy_string'' as varchar(4096)) as generated_at

,
                
        cast(''dummy_string'' as varchar(4096)) as metadata_hash

,
                
        cast(''dummy_string'' as varchar(4096)) as quality_dimension

,
                
        cast(''dummy_string'' as varchar(4096)) as group_name


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-1 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.metrics_anomaly_score','model.elementary.metrics_anomaly_score','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'metrics_anomaly_score','CREATE VIEW','success','model',0.37696361541748047,'2025-07-20T20:35:48.222270Z','2025-07-20T20:35:48.481673Z','2025-07-20T20:35:48.196384Z','2025-07-20T20:35:48.219185Z',-1,False,'

with data_monitoring_metrics as (

    select * from "elsa"."tec_elsa"."data_monitoring_metrics"

),

time_window_aggregation as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        metric_value,
        source_value,
        bucket_start,
        bucket_end,
        bucket_duration_hours,
        updated_at,
        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,
        stddev(cast(metric_value as float)) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,
        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,
        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,
        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start
    from data_monitoring_metrics
    group by 1,2,3,4,5,6,7,8,9,10,11,12
),

metrics_anomaly_score as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        case
            when training_stddev is null then null
            when training_stddev = 0 then 0
            else (metric_value - training_avg) / (training_stddev)
        end as anomaly_score,
        metric_value as latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        max(updated_at) as updated_at
    from time_window_aggregation
        where
            metric_value is not null
            and training_avg is not null
            and bucket_end >= 
    cast(date_trunc(''day'', 
    current_timestamp::timestamp
) as timestamp) + cast(-7 as integer) * INTERVAL ''1 day''

    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    order by bucket_end desc


),

final as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        anomaly_score,
        latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        updated_at,
        case
            when abs(anomaly_score) > 3 then true
            else false end
        as is_anomaly
    from metrics_anomaly_score
)

select * from final',NULL,NULL,'Thread-2 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.monitors_runs','model.elementary.monitors_runs','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'monitors_runs','CREATE VIEW','success','model',0.2749321460723877,'2025-07-20T20:35:48.396493Z','2025-07-20T20:35:48.631040Z','2025-07-20T20:35:48.370632Z','2025-07-20T20:35:48.389319Z',-1,False,'

with data_monitoring_metrics as (

    select * from "elsa"."tec_elsa"."data_monitoring_metrics"

),

max_bucket_end as (

    select full_table_name,
           column_name,
           metric_name,
           metric_properties,
           max(bucket_end) as last_bucket_end,
           min(bucket_end) as first_bucket_end
    from data_monitoring_metrics
    group by 1,2,3,4

)

select * from max_bucket_end',NULL,NULL,'Thread-4 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.seed_run_results','model.elementary.seed_run_results','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'seed_run_results','CREATE VIEW','success','model',0.3727457523345947,'2025-07-20T20:35:48.538664Z','2025-07-20T20:35:48.855544Z','2025-07-20T20:35:48.514534Z','2025-07-20T20:35:48.533288Z',-1,False,'

with dbt_run_results as (
    select * from "elsa"."tec_elsa"."dbt_run_results"
),

dbt_seeds as (
    select * from "elsa"."tec_elsa"."dbt_seeds"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    seeds.database_name,
    seeds.schema_name,
    run_results.materialization,
    seeds.tags,
    seeds.package_name,
    seeds.path,
    seeds.original_path,
    seeds.owner,
    seeds.alias
FROM dbt_run_results run_results
JOIN dbt_seeds seeds ON run_results.unique_id = seeds.unique_id',NULL,NULL,'Thread-1 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.snapshot_run_results','model.elementary.snapshot_run_results','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'snapshot_run_results','CREATE VIEW','success','model',0.34670114517211914,'2025-07-20T20:35:48.583308Z','2025-07-20T20:35:48.876842Z','2025-07-20T20:35:48.550795Z','2025-07-20T20:35:48.569549Z',-1,False,'

with dbt_run_results as (
    select * from "elsa"."tec_elsa"."dbt_run_results"
),

dbt_snapshots as (
    select * from "elsa"."tec_elsa"."dbt_snapshots"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    snapshots.database_name,
    snapshots.schema_name,
    coalesce(run_results.materialization, snapshots.materialization) as materialization,
    snapshots.tags,
    snapshots.package_name,
    snapshots.path,
    snapshots.original_path,
    snapshots.owner,
    snapshots.alias
FROM dbt_run_results run_results
JOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id',NULL,NULL,'Thread-2 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.model_run_results','model.elementary.model_run_results','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'model_run_results','CREATE VIEW','success','model',0.1431431770324707,'2025-07-20T20:35:48.832559Z','2025-07-20T20:35:48.920445Z','2025-07-20T20:35:48.803550Z','2025-07-20T20:35:48.827485Z',-1,False,'

with dbt_run_results as (
    select * from "elsa"."tec_elsa"."dbt_run_results"
),

dbt_models as (
    select * from "elsa"."tec_elsa"."dbt_models"
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.adapter_response,
    run_results.thread_id,
    run_results.group_name,
    models.database_name,
    models.schema_name,
    coalesce(run_results.materialization, models.materialization) as materialization,
    models.tags,
    models.package_name,
    models.path,
    models.original_path,
    models.owner,
    models.alias,
    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,
    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc(''day'', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_first_invocation_of_the_day,
    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY 
    date_trunc(''day'', cast(run_results.generated_at as timestamp))
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_last_invocation_of_the_day
    
FROM dbt_run_results run_results
JOIN dbt_models models ON run_results.unique_id = models.unique_id',NULL,NULL,'Thread-4 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.job_run_results','model.elementary.job_run_results','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'job_run_results','CREATE VIEW','success','model',0.3782069683074951,'2025-07-20T20:35:48.462924Z','2025-07-20T20:35:48.777076Z','2025-07-20T20:35:48.436889Z','2025-07-20T20:35:48.458787Z',-1,False,'





with jobs as (
  select
    job_name,
    job_id,
    job_run_id,
    
min(cast(run_started_at as timestamp))
 as job_run_started_at,
    
max(cast(run_completed_at as timestamp))
 as job_run_completed_at,
    
    
        (
        (
        (
        ((
max(cast(run_completed_at as timestamp))
)::date - (
min(cast(run_started_at as timestamp))
)::date)
     * 24 + date_part(''hour'', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part(''hour'', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + date_part(''minute'', (
max(cast(run_completed_at as timestamp))
)::timestamp) - date_part(''minute'', (
min(cast(run_started_at as timestamp))
)::timestamp))
     * 60 + floor(date_part(''second'', (
max(cast(run_completed_at as timestamp))
)::timestamp)) - floor(date_part(''second'', (
min(cast(run_started_at as timestamp))
)::timestamp)))
    
 as job_run_execution_time
  from "elsa"."tec_elsa"."dbt_invocations"
  where job_id is not null
  group by job_name, job_id, job_run_id
)

select
  job_name as name,
  job_id as id,
  job_run_id as run_id,
  job_run_started_at as run_started_at,
  job_run_completed_at as run_completed_at,
  job_run_execution_time as run_execution_time
from jobs',NULL,NULL,'Thread-3 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.alerts_anomaly_detection','model.elementary.alerts_anomaly_detection','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'alerts_anomaly_detection','CREATE VIEW','success','model',0.3303828239440918,'2025-07-20T20:35:49.582224Z','2025-07-20T20:35:49.791574Z','2025-07-20T20:35:49.488609Z','2025-07-20T20:35:49.577083Z',-1,False,'

with elementary_test_results as (
    select * from "elsa"."tec_elsa"."elementary_test_results"
),

alerts_anomaly_detection as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != ''pass''and lower(status) != ''skipped''and test_type = ''anomaly_detection''
)

select * from alerts_anomaly_detection',NULL,NULL,'Thread-1 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.alerts_schema_changes','model.elementary.alerts_schema_changes','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'alerts_schema_changes','CREATE VIEW','success','model',0.33335065841674805,'2025-07-20T20:35:49.616868Z','2025-07-20T20:35:49.804565Z','2025-07-20T20:35:49.532645Z','2025-07-20T20:35:49.581036Z',-1,False,'


with elementary_test_results as (
    select * from "elsa"."tec_elsa"."elementary_test_results"
),

alerts_schema_changes as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != ''pass''and lower(status) != ''skipped''and test_type = ''schema_change''
)

select * from alerts_schema_changes',NULL,NULL,'Thread-4 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.test_result_rows','model.elementary.test_result_rows','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'test_result_rows','SELECT 0','success','model',0.3309335708618164,'2025-07-20T20:35:49.632227Z','2025-07-20T20:35:49.806322Z','2025-07-20T20:35:49.552860Z','2025-07-20T20:35:49.605682Z',0,False,'-- indexes are not supported in all warehouses, relevant to postgres only


-- depends_on: "elsa"."tec_elsa"."elementary_test_results"
select * from (
            select
            
                
        cast(''this_is_just_a_long_dummy_string'' as text) as elementary_test_results_id

,
                
        cast(''this_is_just_a_long_dummy_string'' as text) as result_row

,
                cast(''2091-02-17'' as timestamp) as detected_at

,
                cast(''2091-02-17'' as timestamp) as created_at


        ) as empty_table
        where 1 = 0',NULL,NULL,'Thread-3 (worker)','incremental','{"_message": "SELECT 0", "code": "SELECT", "rows_affected": 0}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.alerts_dbt_tests','model.elementary.alerts_dbt_tests','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'alerts_dbt_tests','CREATE VIEW','success','model',0.35537147521972656,'2025-07-20T20:35:49.599487Z','2025-07-20T20:35:49.818439Z','2025-07-20T20:35:49.514064Z','2025-07-20T20:35:49.579053Z',-1,False,'

with elementary_test_results as (
    select * from "elsa"."tec_elsa"."elementary_test_results"
),

alerts_dbt_tests as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != ''pass''   and lower(status) != ''skipped''  and test_type = ''dbt_test''
)

select * from alerts_dbt_tests',NULL,NULL,'Thread-2 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.alerts_dbt_source_freshness','model.elementary.alerts_dbt_source_freshness','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'alerts_dbt_source_freshness','CREATE VIEW','success','model',0.5177962779998779,'2025-07-20T20:35:49.934310Z','2025-07-20T20:35:50.337756Z','2025-07-20T20:35:49.874390Z','2025-07-20T20:35:49.897638Z',-1,False,'

with results as (
  select * from "elsa"."tec_elsa"."dbt_source_freshness_results"
),

sources as (
  select * from "elsa"."tec_elsa"."dbt_sources"
)

select
  results.source_freshness_execution_id as alert_id,
  results.max_loaded_at,
  results.snapshotted_at,
  cast(results.generated_at as timestamp) as detected_at,
  results.max_loaded_at_time_ago_in_s,
  results.status,
  results.error,
  results.warn_after,
  results.error_after,
  results.filter,
  sources.unique_id,
  sources.database_name,
  sources.schema_name,
  sources.source_name,
  sources.identifier,
  sources.tags,
  sources.meta,
  sources.owner,
  sources.package_name,
  sources.path,
  -- These columns below are deprecated. We add them since this view
  -- was used to be loaded into an incremental model with those columns, their names were later changed
  -- and Databricks doesn''t respect `on_schema_change = ''append_new_columns''` properly, as described here -
  -- https://docs.databricks.com/en/delta/update-schema.html#automatic-schema-evolution-for-delta-lake-merge
  results.error_after as freshness_error_after,
  results.warn_after as freshness_warn_after,
  results.filter as freshness_filter
from results
join sources on results.unique_id = sources.unique_id
where True and lower(status) != ''pass''',NULL,NULL,'Thread-1 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.dbt_artifacts_hashes','model.elementary.dbt_artifacts_hashes','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'dbt_artifacts_hashes','CREATE VIEW','success','model',0.4876852035522461,'2025-07-20T20:35:50.081722Z','2025-07-20T20:35:50.372432Z','2025-07-20T20:35:49.917066Z','2025-07-20T20:35:49.950086Z',-1,False,'




select
  ''dbt_models'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_models"
 union all 

select
  ''dbt_tests'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_tests"
 union all 

select
  ''dbt_sources'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_sources"
 union all 

select
  ''dbt_snapshots'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_snapshots"
 union all 

select
  ''dbt_metrics'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_metrics"
 union all 

select
  ''dbt_exposures'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_exposures"
 union all 

select
  ''dbt_seeds'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_seeds"
 union all 

select
  ''dbt_columns'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_columns"
 union all 

select
  ''dbt_groups'' as artifacts_model,
   metadata_hash
from "elsa"."tec_elsa"."dbt_groups"


order by metadata_hash',NULL,NULL,'Thread-4 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.anomaly_threshold_sensitivity','model.elementary.anomaly_threshold_sensitivity','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'anomaly_threshold_sensitivity','CREATE VIEW','success','model',0.4872314929962158,'2025-07-20T20:35:49.951810Z','2025-07-20T20:35:50.376535Z','2025-07-20T20:35:49.899549Z','2025-07-20T20:35:49.948109Z',-1,False,'

with metrics_anomaly_score as (

    select * from "elsa"."tec_elsa"."metrics_anomaly_score"

),

score_sensitivity as (

    select
        full_table_name,
        column_name,
        metric_name,
        latest_metric_value,
        training_avg as metric_avg,
        training_stddev as metric_stddev,
        anomaly_score,
        case when abs(anomaly_score) >= 1.5 then true else false end as "is_anomaly_1_5",
        case when abs(anomaly_score) >= 2 then true else false end as "is_anomaly_2",
        case when abs(anomaly_score) >= 2.5 then true else false end as "is_anomaly_2_5",
        case when abs(anomaly_score) >= 3 then true else false end as "is_anomaly_3",
        case when abs(anomaly_score) >= 3.5 then true else false end as "is_anomaly_3_5",
        case when abs(anomaly_score) >= 4 then true else false end as "is_anomaly_4",
        case when abs(anomaly_score) >= 4.5 then true else false end as "is_anomaly_4_5"
    from metrics_anomaly_score
    where abs(anomaly_score) >= 1.5

)

select * from score_sensitivity',NULL,NULL,'Thread-3 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL),('b63bef1c-f249-4ff7-abf5-212ebea01119.model.elementary.alerts_dbt_models','model.elementary.alerts_dbt_models','b63bef1c-f249-4ff7-abf5-212ebea01119','2025-07-20 20:35:50',
    current_timestamp::timestamp
,'alerts_dbt_models','CREATE VIEW','success','model',0.4468839168548584,'2025-07-20T20:35:50.100081Z','2025-07-20T20:35:50.387119Z','2025-07-20T20:35:50.067121Z','2025-07-20T20:35:50.097733Z',-1,False,'

with error_models as (
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias 
    from "elsa"."tec_elsa"."model_run_results"
  
    union all
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias  
  from "elsa"."tec_elsa"."snapshot_run_results"
)


select model_execution_id as alert_id,
       unique_id,
       cast(generated_at as timestamp) as detected_at,
       database_name,
       materialization,
       path,
       original_path,
       schema_name,
       message,
       owner as owners,
       tags,
       alias,
       status,
       full_refresh
from error_models
where True and lower(status) != ''success''and lower(status) != ''skipped''',NULL,NULL,'Thread-2 (worker)','view','{"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}',NULL)
  
[0m20:35:50.985961 [debug] [MainThread]: SQL status: INSERT 0 33 in 0.003 seconds
[0m20:35:50.990291 [debug] [MainThread]: On master: COMMIT
[0m20:35:50.992073 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:50.993098 [debug] [MainThread]: On master: COMMIT
[0m20:35:50.995413 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m20:35:50.998841 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m20:35:51.000511 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.071930 (1 runs)
[0m20:35:51.001955 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.024050 (1 runs)
[0m20:35:51.003280 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000636 (1 runs)
[0m20:35:51.004808 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.352990 (33 runs)
[0m20:35:51.006148 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.369302 (1 runs)
[0m20:35:51.009145 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.024839 (1 runs)
[0m20:35:51.010724 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.007255 (1 runs)
[0m20:35:51.012039 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.430433 (1 runs)
[0m20:35:51.013413 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.507664 (1 runs)
[0m20:35:51.014997 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m20:35:51.039003 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m20:35:51.128410 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:51.129679 [debug] [MainThread]: On master: BEGIN
[0m20:35:51.131038 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:35:51.131948 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:51.132947 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'tec_elsa'
        
      order by ordinal_position

  
[0m20:35:51.138456 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m20:35:51.143880 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."tec_elsa"."dbt_invocations"
[0m20:35:51.163765 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:35:51.165756 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:51.166873 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "elsa"."tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('b63bef1c-f249-4ff7-abf5-212ebea01119',NULL,NULL,NULL,'2025-07-20 20:35:34','2025-07-20 20:35:51','2025-07-20 20:35:51',
    current_timestamp::timestamp
,'run','1.10.4','0.19.0',False,'{}','{}','dev_elsa','elsa','bronze','dbt_elsa',4,'[]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,'airflow',NULL,'None/dags/None/grid','None/dags/None/grid?dag_run_id=None',NULL,'{"user": "elsalebihan"}')
  
[0m20:35:51.168765 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m20:35:51.171927 [debug] [MainThread]: On master: COMMIT
[0m20:35:51.173721 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:51.175594 [debug] [MainThread]: On master: COMMIT
[0m20:35:51.177843 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m20:35:51.180308 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m20:35:51.189398 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:35:51.193416 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:35:51.195000 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.78s]
[0m20:35:51.196209 [debug] [MainThread]: On master: Close
[0m20:35:51.197428 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:35:51.198377 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_models' was properly closed.
[0m20:35:51.199189 [debug] [MainThread]: Connection 'model.elementary.anomaly_threshold_sensitivity' was properly closed.
[0m20:35:51.199904 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_source_freshness' was properly closed.
[0m20:35:51.200554 [debug] [MainThread]: Connection 'model.elementary.dbt_artifacts_hashes' was properly closed.
[0m20:35:51.202027 [info ] [MainThread]: 
[0m20:35:51.204212 [info ] [MainThread]: Finished running 16 incremental models, 2 project hooks, 4 table models, 13 view models in 0 hours 0 minutes and 7.34 seconds (7.34s).
[0m20:35:51.221178 [debug] [MainThread]: Command end result
[0m20:35:51.542387 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:35:51.547840 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:35:51.567761 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:35:51.568814 [info ] [MainThread]: 
[0m20:35:51.570133 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m20:35:51.571757 [info ] [MainThread]: 
[0m20:35:51.573496 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m20:35:51.574994 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:35:51.576902 [info ] [MainThread]: 
[0m20:35:51.578711 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m20:35:51.580117 [info ] [MainThread]: 
[0m20:35:51.581924 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m20:35:51.583179 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "silver.consumption_history" does not exist
  LINE 13: FROM "elsa"."silver"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m20:35:51.584305 [info ] [MainThread]: 
[0m20:35:51.585438 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m20:35:51.586644 [info ] [MainThread]: 
[0m20:35:51.587783 [error] [MainThread]: [31mFailure in model test_connection (models/bronze/test_connection.sql)[0m
[0m20:35:51.590817 [error] [MainThread]:   Database Error in model test_connection (models/bronze/test_connection.sql)
  syntax error at or near ";"
  LINE 12: ...select current_database() as db, current_schema() as schema;
                                                                         ^
  compiled code at target/run/dbt_elsa/models/bronze/test_connection.sql
[0m20:35:51.592276 [info ] [MainThread]: 
[0m20:35:51.593821 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/test_connection.sql
[0m20:35:51.594954 [info ] [MainThread]: 
[0m20:35:51.596084 [info ] [MainThread]: Done. PASS=32 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=35
[0m20:35:51.598465 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 17.495176, "process_in_blocks": "0", "process_kernel_time": 0.533316, "process_mem_max_rss": "148160", "process_out_blocks": "13376", "process_user_time": 18.405731}
[0m20:35:51.599694 [debug] [MainThread]: Command `dbt run` failed at 20:35:51.599469 after 17.50 seconds
[0m20:35:51.600607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc094b443d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09058ddb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09058f9d0>]}
[0m20:35:51.601429 [debug] [MainThread]: Flushing usage events
[0m20:35:52.180752 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:38:28.630953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1df68af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1c9b4280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1c9b4220>]}


============================== 20:38:28.637683 | 6f1f7ce5-3f4a-4f08-853d-29240d737d72 ==============================
[0m20:38:28.637683 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:38:28.638943 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:38:28.937568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1c806b00>]}
[0m20:38:29.109204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1c9b05e0>]}
[0m20:38:29.122882 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:38:29.326766 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:38:29.641410 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m20:38:29.642491 [debug] [MainThread]: previous checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, current checksum: 0af36a85d50777368bfad96f7b079454a784073d22eee9066924278f802a5ad5
[0m20:38:29.643500 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m20:38:29.644501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1f273ca0>]}
[0m20:38:37.948367 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:38:37.975588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1ad56470>]}
[0m20:38:38.334917 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:38:38.339663 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:38:38.374209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1ae607f0>]}
[0m20:38:38.375534 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:38:38.376705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1ae60f40>]}
[0m20:38:38.381844 [info ] [MainThread]: 
[0m20:38:38.382966 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m20:38:38.384761 [info ] [MainThread]: 
[0m20:38:38.386266 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:38:38.393606 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m20:38:38.451311 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m20:38:38.452436 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m20:38:38.453306 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:38:38.464915 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.012 seconds
[0m20:38:38.467146 [debug] [ThreadPool]: On list_elsa: Close
[0m20:38:38.472494 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_tec_elsa)
[0m20:38:38.473726 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_bronze'
[0m20:38:38.487816 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m20:38:38.495449 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m20:38:38.497511 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m20:38:38.498495 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m20:38:38.499421 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:38:38.500363 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:38:38.510453 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m20:38:38.511257 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m20:38:38.512455 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m20:38:38.513682 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m20:38:38.514713 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:38:38.515997 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:38:38.520070 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:38:38.520758 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.003 seconds
[0m20:38:38.522559 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m20:38:38.525537 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m20:38:38.526845 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m20:38:38.527796 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m20:38:38.551854 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:38.552920 [debug] [MainThread]: On master: BEGIN
[0m20:38:38.553786 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:38:38.564252 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:38:38.565308 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:38.566414 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:38:38.571628 [debug] [MainThread]: SQL status: SELECT 26 in 0.004 seconds
[0m20:38:38.582329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1aeb1030>]}
[0m20:38:38.583507 [debug] [MainThread]: On master: ROLLBACK
[0m20:38:38.584692 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:38.585679 [debug] [MainThread]: On master: BEGIN
[0m20:38:38.587046 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:38:38.587997 [debug] [MainThread]: On master: COMMIT
[0m20:38:38.588828 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:38.589533 [debug] [MainThread]: On master: COMMIT
[0m20:38:38.590458 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:38:38.705162 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:38:38.714684 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:38:38.720770 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:38:38.722378 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.13s]
[0m20:38:38.723398 [info ] [MainThread]: 
[0m20:38:38.724420 [debug] [MainThread]: On master: Close
[0m20:38:38.734841 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m20:38:38.735738 [debug] [Thread-2 (]: Began running node model.dbt_elsa.test_connection
[0m20:38:38.737039 [info ] [Thread-1 (]: 1 of 2 START sql table model bronze.consumption ................................ [RUN]
[0m20:38:38.738688 [info ] [Thread-2 (]: 2 of 2 START sql table model bronze.test_connection ............................ [RUN]
[0m20:38:38.740438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now model.dbt_elsa.consumption)
[0m20:38:38.741717 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_elsa_bronze, now model.dbt_elsa.test_connection)
[0m20:38:38.743255 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m20:38:38.747206 [debug] [Thread-2 (]: Began compiling node model.dbt_elsa.test_connection
[0m20:38:38.754681 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m20:38:38.765147 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_elsa.test_connection"
[0m20:38:38.768306 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m20:38:38.769538 [debug] [Thread-2 (]: Began executing node model.dbt_elsa.test_connection
[0m20:38:38.885441 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m20:38:38.887365 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_elsa.test_connection"
[0m20:38:38.890103 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:38:38.891071 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:38:38.891711 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m20:38:38.892718 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: BEGIN
[0m20:38:38.893654 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:38:38.894542 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:38:38.905274 [debug] [Thread-2 (]: SQL status: BEGIN in 0.011 seconds
[0m20:38:38.906032 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:38:38.906909 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:38:38.907791 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m20:38:38.908762 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */

  
    

  create  table "elsa"."bronze"."test_connection__dbt_tmp"
  
  
    as
  
  (
    select current_database() as db, current_schema() as schema
  );
  
[0m20:38:38.909765 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "elsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m20:38:38.912127 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM bronze.rte_eco2mix
              ^

[0m20:38:38.914070 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.003 seconds
[0m20:38:38.915057 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m20:38:38.933272 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:38:38.934391 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m20:38:38.935341 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
alter table "elsa"."bronze"."test_connection__dbt_tmp" rename to "test_connection"
[0m20:38:38.939322 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:38:38.940029 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m20:38:38.942905 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1e1e4190>]}
[0m20:38:38.962357 [error] [Thread-1 (]: 1 of 2 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.20s]
[0m20:38:38.971903 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: COMMIT
[0m20:38:38.974601 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m20:38:38.976411 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:38:38.978153 [debug] [Thread-7 (]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m20:38:38.981955 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: COMMIT
[0m20:38:38.986018 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m20:38:39.003402 [debug] [Thread-2 (]: Applying DROP to: "elsa"."bronze"."test_connection__dbt_backup"
[0m20:38:39.012162 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:38:39.014076 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
drop table if exists "elsa"."bronze"."test_connection__dbt_backup" cascade
[0m20:38:39.016040 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:38:39.020815 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: Close
[0m20:38:39.023167 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f1f7ce5-3f4a-4f08-853d-29240d737d72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1f56d990>]}
[0m20:38:39.025537 [info ] [Thread-2 (]: 2 of 2 OK created sql table model bronze.test_connection ....................... [[32mSELECT 1[0m in 0.28s]
[0m20:38:39.028473 [debug] [Thread-2 (]: Finished running node model.dbt_elsa.test_connection
[0m20:38:39.034753 [info ] [MainThread]: 
[0m20:38:39.037062 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.038502 [debug] [MainThread]: On master: BEGIN
[0m20:38:39.040033 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:38:39.053517 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m20:38:39.054555 [debug] [MainThread]: On master: COMMIT
[0m20:38:39.055485 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.056333 [debug] [MainThread]: On master: COMMIT
[0m20:38:39.057395 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:38:39.102580 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.103915 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m20:38:39.107427 [debug] [MainThread]: SQL status: SELECT 127 in 0.002 seconds
[0m20:38:39.111595 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:38:39.153399 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m20:38:39.254750 [debug] [MainThread]: Elementary: [dbt_models] Flattened 33 artifacts.
[0m20:38:39.264749 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m20:38:39.266584 [debug] [MainThread]: Elementary: [dbt_models] Artifacts changed.
[0m20:38:39.280176 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."tec_elsa"."dbt_models"
[0m20:38:39.315361 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.316559 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250720203839295478203839306779"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m20:38:39.320254 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m20:38:39.363067 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.364419 [debug] [MainThread]: On master: BEGIN
[0m20:38:39.365734 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:38:39.366638 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.367620 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250720203839295478203839306779'
        
      order by ordinal_position

  
[0m20:38:39.374537 [debug] [MainThread]: SQL status: SELECT 1 in 0.006 seconds
[0m20:38:39.381074 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_models__tmp_20250720203839295478203839306779"
[0m20:38:39.448324 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:39.450099 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.451152 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250720203839295478203839306779"
         (metadata_hash) values
    ('3c23b8007b2c67ebb72075573a369c6b'),('7c94c6b43e2a60d4598ea1a65af26c41')
  
[0m20:38:39.452818 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m20:38:39.458188 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.459539 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_models__tmp_20250720203839456647203839456942"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."tec_elsa"."dbt_models"
        WHERE 1 = 0
    
  );
  
  
[0m20:38:39.462361 [debug] [MainThread]: SQL status: SELECT 0 in 0.001 seconds
[0m20:38:39.472102 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.473428 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_models__tmp_20250720203839456647203839456942'
        
      order by ordinal_position

  
[0m20:38:39.478663 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m20:38:39.483967 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_models__tmp_20250720203839456647203839456942"
[0m20:38:39.521815 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:39.524364 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.525848 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "dbt_models__tmp_20250720203839456647203839456942"
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,patch_path,generated_at,metadata_hash,unique_key,incremental_strategy,group_name,access) values
    ('model.dbt_elsa.test_connection','test_connection','1af223d964e4c892173cd5f2ae1c07b81960e6a9d1cd35c2edaaa1c268410f23','table','[]','{}','[]','elsa','bronze','[]','[]','','test_connection','dbt_elsa','models/bronze/test_connection.sql','bronze/test_connection.sql',NULL,'2025-07-20 20:38:39','bfac09d5bb4e04c117b4059882888701',NULL,NULL,NULL,'protected'),('model.dbt_elsa.consumption_history','consumption_history','33f89b5237b8aba200062254c24ad7543f11ae439567c7915cf4f5ad95c008c9','table','[]','{}','[]','elsa','bronze','[]','[]','The aim of this table is to consolidate history data for consumption
','consumption_history','dbt_elsa','models/silver/consumption_history.sql','silver/consumption_history.sql','dbt_elsa://models/silver/_elsa_bronze__models.yml','2025-07-20 20:38:39','c6c831b0b2cf3ab97902673fdade778c',NULL,NULL,NULL,'protected')
  
[0m20:38:39.528768 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m20:38:39.541648 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.546751 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."tec_elsa"."dbt_models"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_models__tmp_20250720203839295478203839306779");
        
        
            insert into "elsa"."tec_elsa"."dbt_models" select * from "dbt_models__tmp_20250720203839456647203839456942";
        
        commit;
    
  
[0m20:38:39.550530 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m20:38:39.559619 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250720203839295478203839306779"
[0m20:38:39.561239 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.563261 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250720203839295478203839306779" cascade
[0m20:38:39.566087 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m20:38:39.575561 [debug] [MainThread]: Applying DROP to: "dbt_models__tmp_20250720203839456647203839456942"
[0m20:38:39.579751 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.581232 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
drop table if exists "dbt_models__tmp_20250720203839456647203839456942" cascade
[0m20:38:39.584001 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m20:38:39.586008 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."tec_elsa"."dbt_models"
[0m20:38:39.588867 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m20:38:39.590586 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.099406 (1 runs)
[0m20:38:39.591941 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_columns_in_relation: 0:00:00.058247 (2 runs)
[0m20:38:39.593457 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001399 (2 runs)
[0m20:38:39.594707 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.066878 (4 runs)
[0m20:38:39.597024 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.get_insert_rows_queries: 0:00:00.080437 (2 runs)
[0m20:38:39.598722 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows.run_insert_rows_query: 0:00:00.014150 (2 runs)
[0m20:38:39.600484 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].insert_rows: 0:00:00.183446 (2 runs)
[0m20:38:39.601901 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.434958 (1 runs)
[0m20:38:39.605018 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m20:38:39.768101 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m20:38:39.770587 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m20:38:39.772061 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts changed.
[0m20:38:39.773707 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."tec_elsa"."dbt_tests"
[0m20:38:39.776685 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.777749 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250720203839775112203839775476"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m20:38:39.781154 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m20:38:39.789774 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.791003 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250720203839775112203839775476'
        
      order by ordinal_position

  
[0m20:38:39.794686 [debug] [MainThread]: SQL status: SELECT 1 in 0.003 seconds
[0m20:38:39.798197 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_tests__tmp_20250720203839775112203839775476"
[0m20:38:39.804153 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:39.806303 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.807566 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250720203839775112203839775476"
         (metadata_hash) values
    ('9244ab3196851fc590c004e833d6957a'),('c8858dc73b90355aea9b16e1c9bd6770')
  
[0m20:38:39.809050 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.000 seconds
[0m20:38:39.815948 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.817133 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_tests__tmp_20250720203839813185203839814740"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."tec_elsa"."dbt_tests"
        WHERE 1 = 0
    
  );
  
  
[0m20:38:39.819881 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m20:38:39.828692 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.829931 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_tests__tmp_20250720203839813185203839814740'
        
      order by ordinal_position

  
[0m20:38:39.834317 [debug] [MainThread]: SQL status: SELECT 29 in 0.003 seconds
[0m20:38:39.838395 [debug] [MainThread]: Elementary: Inserting 2 rows to table "dbt_tests__tmp_20250720203839813185203839814740"
[0m20:38:39.869563 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:39.871360 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.872562 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "dbt_tests__tmp_20250720203839813185203839814740"
         (unique_id,database_name,schema_name,name,short_name,alias,test_column_name,severity,warn_if,error_if,test_params,test_namespace,test_original_name,tags,model_tags,model_owners,meta,depends_on_macros,depends_on_nodes,parent_model_unique_id,description,package_name,type,original_path,path,generated_at,metadata_hash,quality_dimension,group_name) values
    ('test.dbt_elsa.not_null_consumption_history_created_at.1cd39d44b9','elsa','bronze','not_null_consumption_history_created_at','not_null','not_null_consumption_history_created_at','created_at','ERROR','!= 0','!= 0','{"column_name": "created_at", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_created_at.sql','2025-07-20 20:38:39','74e3435900f5472019e670236520300f','completeness',NULL),('test.dbt_elsa.not_null_consumption_history_date.b254ef3ed4','elsa','bronze','not_null_consumption_history_date','not_null','not_null_consumption_history_date','date','ERROR','!= 0','!= 0','{"column_name": "date", "model": "{{ get_where_subquery(ref(''consumption_history'')) }}"}',NULL,'not_null','[]','[]','[]','{}','["macro.dbt.test_not_null"]','["model.dbt_elsa.consumption_history"]','model.dbt_elsa.consumption_history','This test validates that there are no `null` values present in a column.','dbt_elsa','generic','models/silver/_elsa_bronze__models.yml','not_null_consumption_history_date.sql','2025-07-20 20:38:39','86ccb896bbf4c86cfbc4de4e060771eb','completeness',NULL)
  
[0m20:38:39.874465 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.001 seconds
[0m20:38:39.878616 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.880209 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."tec_elsa"."dbt_tests"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_tests__tmp_20250720203839775112203839775476");
        
        
            insert into "elsa"."tec_elsa"."dbt_tests" select * from "dbt_tests__tmp_20250720203839813185203839814740";
        
        commit;
    
  
[0m20:38:39.882704 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m20:38:39.890963 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250720203839775112203839775476"
[0m20:38:39.892404 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.893353 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250720203839775112203839775476" cascade
[0m20:38:39.896236 [debug] [MainThread]: SQL status: DROP TABLE in 0.002 seconds
[0m20:38:39.903953 [debug] [MainThread]: Applying DROP to: "dbt_tests__tmp_20250720203839813185203839814740"
[0m20:38:39.905415 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:39.906398 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
drop table if exists "dbt_tests__tmp_20250720203839813185203839814740" cascade
[0m20:38:39.908754 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m20:38:39.910790 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."tec_elsa"."dbt_tests"
[0m20:38:39.914156 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m20:38:39.915844 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.160796 (1 runs)
[0m20:38:39.917838 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_columns_in_relation: 0:00:00.028993 (2 runs)
[0m20:38:39.919582 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001296 (2 runs)
[0m20:38:39.920910 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.028495 (4 runs)
[0m20:38:39.922264 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.get_insert_rows_queries: 0:00:00.033268 (2 runs)
[0m20:38:39.923716 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows.run_insert_rows_query: 0:00:00.011615 (2 runs)
[0m20:38:39.924982 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].insert_rows: 0:00:00.083292 (2 runs)
[0m20:38:39.926485 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.308783 (1 runs)
[0m20:38:39.930016 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m20:38:39.958426 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m20:38:39.960590 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m20:38:39.962097 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m20:38:39.964809 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m20:38:39.966400 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.026397 (1 runs)
[0m20:38:39.967993 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.034782 (1 runs)
[0m20:38:39.971011 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m20:38:39.973884 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m20:38:39.976282 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m20:38:39.977797 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m20:38:39.981368 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m20:38:39.982874 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000740 (1 runs)
[0m20:38:39.984346 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.010177 (1 runs)
[0m20:38:39.987159 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m20:38:39.989443 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m20:38:39.991362 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m20:38:39.992830 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m20:38:39.995185 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m20:38:39.997683 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000539 (1 runs)
[0m20:38:39.999148 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.007911 (1 runs)
[0m20:38:40.002140 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m20:38:40.004446 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m20:38:40.006174 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m20:38:40.007586 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m20:38:40.009932 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m20:38:40.011452 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000543 (1 runs)
[0m20:38:40.013840 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.007703 (1 runs)
[0m20:38:40.018466 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m20:38:40.022512 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m20:38:40.025796 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m20:38:40.028315 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m20:38:40.032744 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m20:38:40.035185 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.001213 (1 runs)
[0m20:38:40.037428 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.014306 (1 runs)
[0m20:38:40.046910 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m20:38:40.051463 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m20:38:40.055122 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m20:38:40.057978 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m20:38:40.061564 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m20:38:40.065061 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.001141 (1 runs)
[0m20:38:40.067384 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.014598 (1 runs)
[0m20:38:40.072858 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m20:38:40.301478 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 87 artifacts.
[0m20:38:40.303489 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m20:38:40.305139 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts changed.
[0m20:38:40.311753 [debug] [MainThread]: Elementary: Deleting from and inserting to: "elsa"."tec_elsa"."dbt_columns"
[0m20:38:40.315931 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.317065 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250720203840314112203840314588"
  
  
    as
  
  (
    
        SELECT
        
            
                metadata_hash
            
        
        FROM "elsa"."tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m20:38:40.320149 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m20:38:40.329216 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.330746 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250720203840314112203840314588'
        
      order by ordinal_position

  
[0m20:38:40.334349 [debug] [MainThread]: SQL status: SELECT 1 in 0.003 seconds
[0m20:38:40.337435 [debug] [MainThread]: Elementary: Inserting 4 rows to table "dbt_columns__tmp_20250720203840314112203840314588"
[0m20:38:40.349942 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:40.351752 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.352670 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250720203840314112203840314588"
         (metadata_hash) values
    ('1749add022cd7cb8f4ef00d9fb52962b'),('243c9f9e7e825164d98ad7608783b7f2'),('9e50ce5a1027a44e7a7d1fb64e5c0d20'),('f032746724353f98be0936d4943034da')
  
[0m20:38:40.354109 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m20:38:40.359095 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.360302 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
  
    

  create temporary table "dbt_columns__tmp_20250720203840357703203840357980"
  
  
    as
  
  (
    
        SELECT
        
            *
        
        FROM "elsa"."tec_elsa"."dbt_columns"
        WHERE 1 = 0
    
  );
  
  
[0m20:38:40.363927 [debug] [MainThread]: SQL status: SELECT 0 in 0.002 seconds
[0m20:38:40.372403 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.373515 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dbt_columns__tmp_20250720203840357703203840357980'
        
      order by ordinal_position

  
[0m20:38:40.377274 [debug] [MainThread]: SQL status: SELECT 13 in 0.003 seconds
[0m20:38:40.381801 [debug] [MainThread]: Elementary: Inserting 4 rows to table "dbt_columns__tmp_20250720203840357703203840357980"
[0m20:38:40.415353 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:40.417264 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.418513 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "dbt_columns__tmp_20250720203840357703203840357980"
         (unique_id,parent_unique_id,name,data_type,tags,meta,database_name,schema_name,table_name,description,resource_type,generated_at,metadata_hash) values
    ('column.model.dbt_elsa.consumption_history.created_at','model.dbt_elsa.consumption_history','created_at','datetime','[]','{}','elsa','bronze','consumption_history','datetime','model','2025-07-20 20:38:40','459d5fd9dd3fc2af636f7ccd6d1e4390'),('column.model.dbt_elsa.consumption_history.date','model.dbt_elsa.consumption_history','date','date','[]','{}','elsa','bronze','consumption_history','date','model','2025-07-20 20:38:40','a2c72a9e53f093f32e547c075472c38f'),('column.model.dbt_elsa.consumption_history.filiere','model.dbt_elsa.consumption_history','filiere','text','[]','{}','elsa','bronze','consumption_history','filiere','model','2025-07-20 20:38:40','642a41c8141e4fbebd3e29d13641c01a'),('column.model.dbt_elsa.consumption_history.volume','model.dbt_elsa.consumption_history','volume','integer','[]','{}','elsa','bronze','consumption_history','volume','model','2025-07-20 20:38:40','5de2266142800ba55cb18fd1db535ecf')
  
[0m20:38:40.420413 [debug] [MainThread]: SQL status: INSERT 0 4 in 0.001 seconds
[0m20:38:40.424291 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.425403 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
        begin transaction;
        
            delete from "elsa"."tec_elsa"."dbt_columns"
            where
            metadata_hash is null
            or metadata_hash in (select metadata_hash from "dbt_columns__tmp_20250720203840314112203840314588");
        
        
            insert into "elsa"."tec_elsa"."dbt_columns" select * from "dbt_columns__tmp_20250720203840357703203840357980";
        
        commit;
    
  
[0m20:38:40.428003 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m20:38:40.436757 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250720203840314112203840314588"
[0m20:38:40.438087 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.439134 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250720203840314112203840314588" cascade
[0m20:38:40.441482 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m20:38:40.449654 [debug] [MainThread]: Applying DROP to: "dbt_columns__tmp_20250720203840357703203840357980"
[0m20:38:40.451118 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.452136 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
drop table if exists "dbt_columns__tmp_20250720203840357703203840357980" cascade
[0m20:38:40.454364 [debug] [MainThread]: SQL status: DROP TABLE in 0.001 seconds
[0m20:38:40.456170 [debug] [MainThread]: Elementary: Finished deleting from and inserting to: "elsa"."tec_elsa"."dbt_columns"
[0m20:38:40.458539 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m20:38:40.459829 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.225331 (1 runs)
[0m20:38:40.461180 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_columns_in_relation: 0:00:00.028506 (2 runs)
[0m20:38:40.462955 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.001060 (2 runs)
[0m20:38:40.464807 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.035657 (8 runs)
[0m20:38:40.466389 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.get_insert_rows_queries: 0:00:00.041879 (2 runs)
[0m20:38:40.467777 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows.run_insert_rows_query: 0:00:00.011369 (2 runs)
[0m20:38:40.470528 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].insert_rows: 0:00:00.091280 (2 runs)
[0m20:38:40.471781 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.385441 (1 runs)
[0m20:38:40.473023 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:38:40.479704 [debug] [MainThread]: Elementary: Uploading run results.
[0m20:38:40.482085 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m20:38:40.517170 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 2 artifacts.
[0m20:38:40.525101 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.526215 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'tec_elsa'
        
      order by ordinal_position

  
[0m20:38:40.531185 [debug] [MainThread]: SQL status: SELECT 23 in 0.004 seconds
[0m20:38:40.535192 [debug] [MainThread]: Elementary: Inserting 2 rows to table "elsa"."tec_elsa"."dbt_run_results"
[0m20:38:40.567119 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:40.569646 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.571009 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "elsa"."tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('6f1f7ce5-3f4a-4f08-853d-29240d737d72.model.dbt_elsa.consumption','model.dbt_elsa.consumption','6f1f7ce5-3f4a-4f08-853d-29240d737d72','2025-07-20 20:38:40',
    current_timestamp::timestamp
,'consumption','Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql','error','model',0.20085740089416504,'2025-07-20T20:38:38.770010Z','2025-07-20T20:38:38.934185Z','2025-07-20T20:38:38.748497Z','2025-07-20T20:38:38.767929Z',NULL,False,'SELECT
    id,
    created_at,
    (data->>''date'')::date AS date,
    (data->>''heure'')::time AS heure,   
    (data->>''gaz'')::int AS gaz,
    (data->>''nucleaire'')::int AS nucleaire,
    (data->>''charbon'')::int AS charbon,
    (data->>''solaire'')::int AS solaire,
    (data->>''eolien'')::int AS eolien,
    (data->>''hydraulique'')::int AS hydraulique,
    (data->>''bioenergies'')::int AS bioenergies,
    (data->>''autres'')::int AS autres,
    (data->>''prevision_j'')::int AS prevision_j,
    (data->>''prevision_j1'')::int AS prevision_j1
FROM bronze.rte_eco2mix',NULL,NULL,'Thread-1 (worker)','table','{}',NULL),('6f1f7ce5-3f4a-4f08-853d-29240d737d72.model.dbt_elsa.test_connection','model.dbt_elsa.test_connection','6f1f7ce5-3f4a-4f08-853d-29240d737d72','2025-07-20 20:38:40',
    current_timestamp::timestamp
,'test_connection','SELECT 1','success','model',0.28119683265686035,'2025-07-20T20:38:38.788438Z','2025-07-20T20:38:39.020569Z','2025-07-20T20:38:38.755481Z','2025-07-20T20:38:38.769301Z',1,False,'select current_database() as db, current_schema() as schema',NULL,NULL,'Thread-2 (worker)','table','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m20:38:40.573828 [debug] [MainThread]: SQL status: INSERT 0 2 in 0.002 seconds
[0m20:38:40.576898 [debug] [MainThread]: On master: COMMIT
[0m20:38:40.577999 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.579428 [debug] [MainThread]: On master: COMMIT
[0m20:38:40.580821 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:38:40.585548 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m20:38:40.588233 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.032991 (1 runs)
[0m20:38:40.590757 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.015631 (1 runs)
[0m20:38:40.592218 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000739 (1 runs)
[0m20:38:40.593670 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.027061 (2 runs)
[0m20:38:40.595064 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.029922 (1 runs)
[0m20:38:40.597370 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.007289 (1 runs)
[0m20:38:40.598854 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.005676 (1 runs)
[0m20:38:40.600142 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.064098 (1 runs)
[0m20:38:40.601580 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.102751 (1 runs)
[0m20:38:40.602833 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m20:38:40.626219 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m20:38:40.717141 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.718516 [debug] [MainThread]: On master: BEGIN
[0m20:38:40.719852 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:38:40.720867 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.721919 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'tec_elsa'
        
      order by ordinal_position

  
[0m20:38:40.726404 [debug] [MainThread]: SQL status: SELECT 35 in 0.003 seconds
[0m20:38:40.731509 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."tec_elsa"."dbt_invocations"
[0m20:38:40.752835 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:38:40.754783 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.755880 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "elsa"."tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('6f1f7ce5-3f4a-4f08-853d-29240d737d72',NULL,NULL,NULL,'2025-07-20 20:38:28','2025-07-20 20:38:40','2025-07-20 20:38:40',
    current_timestamp::timestamp
,'run','1.10.4','0.19.0',False,'{}','{}','dev_elsa','elsa','bronze','dbt_elsa',4,'["bronze"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,'airflow',NULL,'None/dags/None/grid','None/dags/None/grid?dag_run_id=None',NULL,'{"user": "elsalebihan"}')
  
[0m20:38:40.757711 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m20:38:40.760611 [debug] [MainThread]: On master: COMMIT
[0m20:38:40.761555 [debug] [MainThread]: Using postgres connection "master"
[0m20:38:40.763013 [debug] [MainThread]: On master: COMMIT
[0m20:38:40.764894 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m20:38:40.767545 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m20:38:40.776740 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:38:40.779800 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:38:40.781468 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.72s]
[0m20:38:40.782550 [debug] [MainThread]: On master: Close
[0m20:38:40.783789 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:38:40.784644 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m20:38:40.785606 [debug] [MainThread]: Connection 'model.dbt_elsa.test_connection' was properly closed.
[0m20:38:40.786542 [info ] [MainThread]: 
[0m20:38:40.788132 [info ] [MainThread]: Finished running 2 project hooks, 2 table models in 0 hours 0 minutes and 2.40 seconds (2.40s).
[0m20:38:40.791992 [debug] [MainThread]: Command end result
[0m20:38:41.102201 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:38:41.106523 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:38:41.118127 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:38:41.118967 [info ] [MainThread]: 
[0m20:38:41.120023 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:38:41.121350 [info ] [MainThread]: 
[0m20:38:41.122698 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m20:38:41.124018 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m20:38:41.125062 [info ] [MainThread]: 
[0m20:38:41.126943 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m20:38:41.130419 [info ] [MainThread]: 
[0m20:38:41.131916 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=4
[0m20:38:41.134325 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.595449, "process_in_blocks": "0", "process_kernel_time": 0.348156, "process_mem_max_rss": "141464", "process_out_blocks": "12445", "process_user_time": 14.129342}
[0m20:38:41.135457 [debug] [MainThread]: Command `dbt run` failed at 20:38:41.135319 after 12.60 seconds
[0m20:38:41.136359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb1ddf7f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb19d6ae60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb19d6b250>]}
[0m20:38:41.137239 [debug] [MainThread]: Flushing usage events
[0m20:38:41.672998 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:41:06.790238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe693174ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe691be0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe691be01f0>]}


============================== 20:41:06.797853 | b1fd825b-5e91-4b67-bae6-ca6f1da2d43f ==============================
[0m20:41:06.797853 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:41:06.799556 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run -s test_connection', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m20:41:07.087862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1fd825b-5e91-4b67-bae6-ca6f1da2d43f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe69474a080>]}
[0m20:41:07.179546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1fd825b-5e91-4b67-bae6-ca6f1da2d43f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe691adf100>]}
[0m20:41:07.181492 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:41:07.349071 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m20:41:08.199993 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:41:08.200959 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:41:08.212392 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m20:41:08.321197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1fd825b-5e91-4b67-bae6-ca6f1da2d43f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe69034e830>]}
[0m20:41:08.660810 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:41:08.666055 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:41:08.695448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1fd825b-5e91-4b67-bae6-ca6f1da2d43f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6903df4c0>]}
[0m20:41:08.697277 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m20:41:08.698918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1fd825b-5e91-4b67-bae6-ca6f1da2d43f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6903deda0>]}
[0m20:41:08.702135 [info ] [MainThread]: 
[0m20:41:08.703326 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m20:41:08.704401 [info ] [MainThread]: 
[0m20:41:08.706266 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:41:08.708213 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m20:41:08.771261 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m20:41:08.772365 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m20:41:08.773298 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:41:08.783855 [debug] [ThreadPool]: SQL status: SELECT 17 in 0.010 seconds
[0m20:41:08.786000 [debug] [ThreadPool]: On list_elsa: Close
[0m20:41:08.796024 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_elsa, now list_elsa_bronze)
[0m20:41:08.797520 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa_tec_elsa'
[0m20:41:08.809318 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m20:41:08.885369 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m20:41:08.886779 [debug] [ThreadPool]: On list_elsa_bronze: BEGIN
[0m20:41:08.888086 [debug] [ThreadPool]: On list_elsa_tec_elsa: BEGIN
[0m20:41:08.889303 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:41:08.890695 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:41:08.904914 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m20:41:08.906735 [debug] [ThreadPool]: Using postgres connection "list_elsa_bronze"
[0m20:41:08.907695 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m20:41:08.909341 [debug] [ThreadPool]: On list_elsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa_bronze"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:41:08.911107 [debug] [ThreadPool]: Using postgres connection "list_elsa_tec_elsa"
[0m20:41:08.914436 [debug] [ThreadPool]: On list_elsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa_tec_elsa"} */
select
      'elsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'elsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m20:41:08.918461 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m20:41:08.921452 [debug] [ThreadPool]: On list_elsa_bronze: ROLLBACK
[0m20:41:08.922230 [debug] [ThreadPool]: SQL status: SELECT 30 in 0.006 seconds
[0m20:41:08.923547 [debug] [ThreadPool]: On list_elsa_bronze: Close
[0m20:41:08.926156 [debug] [ThreadPool]: On list_elsa_tec_elsa: ROLLBACK
[0m20:41:08.928625 [debug] [ThreadPool]: On list_elsa_tec_elsa: Close
[0m20:41:08.948928 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:08.950014 [debug] [MainThread]: On master: BEGIN
[0m20:41:08.950808 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:41:08.960017 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m20:41:08.961086 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:08.962199 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:41:08.967845 [debug] [MainThread]: SQL status: SELECT 26 in 0.004 seconds
[0m20:41:08.977522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1fd825b-5e91-4b67-bae6-ca6f1da2d43f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6907d9210>]}
[0m20:41:08.978785 [debug] [MainThread]: On master: ROLLBACK
[0m20:41:08.980454 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:08.981758 [debug] [MainThread]: On master: BEGIN
[0m20:41:08.983203 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:41:08.984045 [debug] [MainThread]: On master: COMMIT
[0m20:41:08.984880 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:08.985596 [debug] [MainThread]: On master: COMMIT
[0m20:41:08.986501 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:41:09.043039 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m20:41:09.053076 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m20:41:09.061503 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m20:41:09.062949 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.08s]
[0m20:41:09.064308 [info ] [MainThread]: 
[0m20:41:09.065756 [debug] [MainThread]: On master: Close
[0m20:41:09.075790 [debug] [Thread-1 (]: Began running node model.dbt_elsa.test_connection
[0m20:41:09.077287 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.test_connection ............................ [RUN]
[0m20:41:09.078948 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_elsa_tec_elsa, now model.dbt_elsa.test_connection)
[0m20:41:09.081702 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.test_connection
[0m20:41:09.091259 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.test_connection"
[0m20:41:09.095150 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.test_connection
[0m20:41:09.160130 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.test_connection"
[0m20:41:09.163016 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:41:09.164523 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: BEGIN
[0m20:41:09.165921 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:41:09.176355 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m20:41:09.177519 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:41:09.178674 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */

  
    

  create  table "elsa"."bronze"."test_connection__dbt_tmp"
  
  
    as
  
  (
    select current_database() as db, current_schema() as schema
  );
  
[0m20:41:09.181360 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m20:41:09.198792 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:41:09.199877 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
alter table "elsa"."bronze"."test_connection" rename to "test_connection__dbt_backup"
[0m20:41:09.201304 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:41:09.209805 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:41:09.210874 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
alter table "elsa"."bronze"."test_connection__dbt_tmp" rename to "test_connection"
[0m20:41:09.212231 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:41:09.235678 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: COMMIT
[0m20:41:09.236854 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:41:09.237823 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: COMMIT
[0m20:41:09.239914 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:41:09.252230 [debug] [Thread-1 (]: Applying DROP to: "elsa"."bronze"."test_connection__dbt_backup"
[0m20:41:09.258516 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m20:41:09.259697 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
drop table if exists "elsa"."bronze"."test_connection__dbt_backup" cascade
[0m20:41:09.262261 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:41:09.266378 [debug] [Thread-1 (]: On model.dbt_elsa.test_connection: Close
[0m20:41:09.269340 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1fd825b-5e91-4b67-bae6-ca6f1da2d43f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6903b76d0>]}
[0m20:41:09.270925 [info ] [Thread-1 (]: 1 of 1 OK created sql table model bronze.test_connection ....................... [[32mSELECT 1[0m in 0.19s]
[0m20:41:09.272399 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.test_connection
[0m20:41:09.275547 [info ] [MainThread]: 
[0m20:41:09.276604 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:09.278139 [debug] [MainThread]: On master: BEGIN
[0m20:41:09.279158 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:41:09.289927 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:41:09.291202 [debug] [MainThread]: On master: COMMIT
[0m20:41:09.292177 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:09.293056 [debug] [MainThread]: On master: COMMIT
[0m20:41:09.294210 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:41:09.352594 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:09.353929 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from "elsa"."tec_elsa"."dbt_artifacts_hashes"
    order by metadata_hash
    
  
[0m20:41:09.357264 [debug] [MainThread]: SQL status: SELECT 127 in 0.002 seconds
[0m20:41:09.361408 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m20:41:09.402349 [debug] [MainThread]: Elementary: [dbt_models] Flattening the artifacts.
[0m20:41:09.500264 [debug] [MainThread]: Elementary: [dbt_models] Flattened 33 artifacts.
[0m20:41:09.509629 [debug] [MainThread]: Elementary: [dbt_models] Comparing the artifacts state.
[0m20:41:09.511254 [debug] [MainThread]: Elementary: [dbt_models] Artifacts did not change.
[0m20:41:09.513303 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_models]:
[0m20:41:09.515346 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models].artifacts_flatten: 0:00:00.095833 (1 runs)
[0m20:41:09.517379 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_models]: 0:00:00.110944 (1 runs)
[0m20:41:09.525149 [debug] [MainThread]: Elementary: [dbt_tests] Flattening the artifacts.
[0m20:41:09.697702 [debug] [MainThread]: Elementary: [dbt_tests] Flattened 5 artifacts.
[0m20:41:09.701338 [debug] [MainThread]: Elementary: [dbt_tests] Comparing the artifacts state.
[0m20:41:09.703181 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts did not change.
[0m20:41:09.705575 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_tests]:
[0m20:41:09.707227 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests].artifacts_flatten: 0:00:00.170053 (1 runs)
[0m20:41:09.708861 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_tests]: 0:00:00.180321 (1 runs)
[0m20:41:09.717594 [debug] [MainThread]: Elementary: [dbt_sources] Flattening the artifacts.
[0m20:41:09.752453 [debug] [MainThread]: Elementary: [dbt_sources] Flattened 2 artifacts.
[0m20:41:09.755535 [debug] [MainThread]: Elementary: [dbt_sources] Comparing the artifacts state.
[0m20:41:09.758228 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts did not change.
[0m20:41:09.760770 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_sources]:
[0m20:41:09.762154 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources].artifacts_flatten: 0:00:00.032394 (1 runs)
[0m20:41:09.763897 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_sources]: 0:00:00.043177 (1 runs)
[0m20:41:09.770743 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m20:41:09.773130 [debug] [MainThread]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m20:41:09.774875 [debug] [MainThread]: Elementary: [dbt_snapshots] Comparing the artifacts state.
[0m20:41:09.776150 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts did not change.
[0m20:41:09.778054 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_snapshots]:
[0m20:41:09.779302 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots].artifacts_flatten: 0:00:00.000726 (1 runs)
[0m20:41:09.781243 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_snapshots]: 0:00:00.007315 (1 runs)
[0m20:41:09.788245 [debug] [MainThread]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m20:41:09.790521 [debug] [MainThread]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m20:41:09.792378 [debug] [MainThread]: Elementary: [dbt_metrics] Comparing the artifacts state.
[0m20:41:09.793761 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts did not change.
[0m20:41:09.795708 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_metrics]:
[0m20:41:09.797414 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics].artifacts_flatten: 0:00:00.000623 (1 runs)
[0m20:41:09.799320 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_metrics]: 0:00:00.007400 (1 runs)
[0m20:41:09.806210 [debug] [MainThread]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m20:41:09.808528 [debug] [MainThread]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m20:41:09.810409 [debug] [MainThread]: Elementary: [dbt_exposures] Comparing the artifacts state.
[0m20:41:09.811830 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts did not change.
[0m20:41:09.814022 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_exposures]:
[0m20:41:09.815709 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures].artifacts_flatten: 0:00:00.000617 (1 runs)
[0m20:41:09.817238 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_exposures]: 0:00:00.007660 (1 runs)
[0m20:41:09.824199 [debug] [MainThread]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m20:41:09.826584 [debug] [MainThread]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m20:41:09.828428 [debug] [MainThread]: Elementary: [dbt_seeds] Comparing the artifacts state.
[0m20:41:09.830060 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts did not change.
[0m20:41:09.833103 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_seeds]:
[0m20:41:09.834470 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds].artifacts_flatten: 0:00:00.000739 (1 runs)
[0m20:41:09.835866 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_seeds]: 0:00:00.008814 (1 runs)
[0m20:41:09.842486 [debug] [MainThread]: Elementary: [dbt_groups] Flattening the artifacts.
[0m20:41:09.844791 [debug] [MainThread]: Elementary: [dbt_groups] Flattened 0 artifacts.
[0m20:41:09.846470 [debug] [MainThread]: Elementary: [dbt_groups] Comparing the artifacts state.
[0m20:41:09.848828 [debug] [MainThread]: Elementary: [dbt_groups] Artifacts did not change.
[0m20:41:09.851156 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_groups]:
[0m20:41:09.852462 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups].artifacts_flatten: 0:00:00.000537 (1 runs)
[0m20:41:09.853820 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_groups]: 0:00:00.008608 (1 runs)
[0m20:41:09.860824 [debug] [MainThread]: Elementary: [dbt_columns] Flattening the artifacts.
[0m20:41:10.055396 [debug] [MainThread]: Elementary: [dbt_columns] Flattened 87 artifacts.
[0m20:41:10.057511 [debug] [MainThread]: Elementary: [dbt_columns] Comparing the artifacts state.
[0m20:41:10.059263 [debug] [MainThread]: Elementary: [dbt_columns] Artifacts did not change.
[0m20:41:10.061338 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_columns]:
[0m20:41:10.063006 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns].artifacts_flatten: 0:00:00.192801 (1 runs)
[0m20:41:10.065090 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_columns]: 0:00:00.200486 (1 runs)
[0m20:41:10.066883 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m20:41:10.072764 [debug] [MainThread]: Elementary: Uploading run results.
[0m20:41:10.074332 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m20:41:10.105725 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 1 artifacts.
[0m20:41:10.145405 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.147030 [debug] [MainThread]: On master: BEGIN
[0m20:41:10.149212 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:41:10.150290 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.151470 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_run_results'
        
        and table_schema = 'tec_elsa'
        
      order by ordinal_position

  
[0m20:41:10.159469 [debug] [MainThread]: SQL status: SELECT 23 in 0.007 seconds
[0m20:41:10.166860 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."tec_elsa"."dbt_run_results"
[0m20:41:10.250504 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:41:10.252691 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.253875 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "elsa"."tec_elsa"."dbt_run_results"
         (model_execution_id,unique_id,invocation_id,generated_at,created_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id,materialization,adapter_response,group_name) values
    ('b1fd825b-5e91-4b67-bae6-ca6f1da2d43f.model.dbt_elsa.test_connection','model.dbt_elsa.test_connection','b1fd825b-5e91-4b67-bae6-ca6f1da2d43f','2025-07-20 20:41:10',
    current_timestamp::timestamp
,'test_connection','SELECT 1','success','model',0.1892237663269043,'2025-07-20T20:41:09.096137Z','2025-07-20T20:41:09.266148Z','2025-07-20T20:41:09.083385Z','2025-07-20T20:41:09.094868Z',1,False,'select current_database() as db, current_schema() as schema',NULL,NULL,'Thread-1 (worker)','table','{"_message": "SELECT 1", "code": "SELECT", "rows_affected": 1}',NULL)
  
[0m20:41:10.255768 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m20:41:10.258683 [debug] [MainThread]: On master: COMMIT
[0m20:41:10.259756 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.260700 [debug] [MainThread]: On master: COMMIT
[0m20:41:10.262806 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m20:41:10.266922 [debug] [MainThread]: Elementary: Measured durations for context - upload_artifacts_to_table[dbt_run_results]:
[0m20:41:10.268396 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].artifacts_flatten: 0:00:00.029464 (1 runs)
[0m20:41:10.269786 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_columns_in_relation: 0:00:00.042176 (1 runs)
[0m20:41:10.271211 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.base_query_calc: 0:00:00.000672 (1 runs)
[0m20:41:10.272416 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries.render_row_to_sql: 0:00:00.051439 (1 runs)
[0m20:41:10.273741 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.get_insert_rows_queries: 0:00:00.063433 (1 runs)
[0m20:41:10.275047 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.run_insert_rows_query: 0:00:00.005891 (1 runs)
[0m20:41:10.276286 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows.commit: 0:00:00.006231 (1 runs)
[0m20:41:10.277755 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results].insert_rows: 0:00:00.141406 (1 runs)
[0m20:41:10.279035 [debug] [MainThread]: Elementary:     upload_artifacts_to_table[dbt_run_results]: 0:00:00.192162 (1 runs)
[0m20:41:10.280674 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m20:41:10.306167 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m20:41:10.394416 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.395747 [debug] [MainThread]: On master: BEGIN
[0m20:41:10.397418 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:41:10.399053 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.400142 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "elsa".INFORMATION_SCHEMA.columns
      where table_name = 'dbt_invocations'
        
        and table_schema = 'tec_elsa'
        
      order by ordinal_position

  
[0m20:41:10.405231 [debug] [MainThread]: SQL status: SELECT 35 in 0.004 seconds
[0m20:41:10.409963 [debug] [MainThread]: Elementary: Inserting 1 rows to table "elsa"."tec_elsa"."dbt_invocations"
[0m20:41:10.431644 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m20:41:10.433871 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.435203 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */

    
       insert into "elsa"."tec_elsa"."dbt_invocations"
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,created_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user,job_url,job_run_url,account_id,target_adapter_specific_fields) values
    ('b1fd825b-5e91-4b67-bae6-ca6f1da2d43f',NULL,NULL,NULL,'2025-07-20 20:41:06','2025-07-20 20:41:10','2025-07-20 20:41:10',
    current_timestamp::timestamp
,'run','1.10.4','0.19.0',False,'{}','{}','dev_elsa','elsa','bronze','dbt_elsa',4,'["test_connection"]',NULL,NULL,'dbt_elsa',NULL,NULL,NULL,NULL,NULL,NULL,'airflow',NULL,'None/dags/None/grid','None/dags/None/grid?dag_run_id=None',NULL,'{"user": "elsalebihan"}')
  
[0m20:41:10.437092 [debug] [MainThread]: SQL status: INSERT 0 1 in 0.001 seconds
[0m20:41:10.440056 [debug] [MainThread]: On master: COMMIT
[0m20:41:10.441394 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:10.442739 [debug] [MainThread]: On master: COMMIT
[0m20:41:10.445097 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m20:41:10.448327 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m20:41:10.457925 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m20:41:10.461854 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m20:41:10.463449 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 1.17s]
[0m20:41:10.465768 [debug] [MainThread]: On master: Close
[0m20:41:10.467069 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:41:10.467993 [debug] [MainThread]: Connection 'list_elsa_bronze' was properly closed.
[0m20:41:10.468783 [debug] [MainThread]: Connection 'model.dbt_elsa.test_connection' was properly closed.
[0m20:41:10.470213 [info ] [MainThread]: 
[0m20:41:10.472509 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 1.76 seconds (1.76s).
[0m20:41:10.475845 [debug] [MainThread]: Command end result
[0m20:41:10.704522 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m20:41:10.708382 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m20:41:10.719667 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m20:41:10.720604 [info ] [MainThread]: 
[0m20:41:10.721748 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:41:10.722669 [info ] [MainThread]: 
[0m20:41:10.723724 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m20:41:10.725548 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.0209026, "process_in_blocks": "0", "process_kernel_time": 0.302693, "process_mem_max_rss": "132060", "process_out_blocks": "8283", "process_user_time": 5.46414}
[0m20:41:10.726709 [debug] [MainThread]: Command `dbt run` succeeded at 20:41:10.726530 after 4.02 seconds
[0m20:41:10.727732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe693174ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe69474a080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6930314b0>]}
[0m20:41:10.728968 [debug] [MainThread]: Flushing usage events
[0m20:41:11.269952 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:43:26.830646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8408a80b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84074ac280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84074ac220>]}


============================== 20:43:26.837668 | 040c967f-b8a7-4960-a0ba-76ccdb3054d0 ==============================
[0m20:43:26.837668 [info ] [MainThread]: Running with dbt=1.10.4
[0m20:43:26.838921 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug --target dev_elsa', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:43:26.851405 [info ] [MainThread]: dbt version: 1.10.4
[0m20:43:26.852631 [info ] [MainThread]: python version: 3.10.14
[0m20:43:26.854048 [info ] [MainThread]: python path: /home/airflow/.local/bin/python
[0m20:43:26.855711 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-x86_64-with-glibc2.36
[0m20:43:26.949158 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt_elsa
[0m20:43:26.950445 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt_elsa/profiles.yml
[0m20:43:26.951804 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt_elsa/dbt_project.yml
[0m20:43:26.953539 [info ] [MainThread]: adapter type: postgres
[0m20:43:26.954980 [info ] [MainThread]: adapter version: 1.9.0
[0m20:43:27.139791 [info ] [MainThread]: Configuration:
[0m20:43:27.141245 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:43:27.142556 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:43:27.143935 [info ] [MainThread]: Required dependencies:
[0m20:43:27.145205 [debug] [MainThread]: Executing "git --help"
[0m20:43:27.150186 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:43:27.151743 [debug] [MainThread]: STDERR: "b''"
[0m20:43:27.153035 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:43:27.154243 [info ] [MainThread]: Connection:
[0m20:43:27.155295 [info ] [MainThread]:   host: db
[0m20:43:27.156294 [info ] [MainThread]:   port: 5432
[0m20:43:27.157259 [info ] [MainThread]:   user: elsalebihan
[0m20:43:27.158341 [info ] [MainThread]:   database: elsa
[0m20:43:27.159362 [info ] [MainThread]:   schema: bronze
[0m20:43:27.160779 [info ] [MainThread]:   connect_timeout: 10
[0m20:43:27.162163 [info ] [MainThread]:   role: None
[0m20:43:27.163549 [info ] [MainThread]:   search_path: None
[0m20:43:27.165203 [info ] [MainThread]:   keepalives_idle: 0
[0m20:43:27.168515 [info ] [MainThread]:   sslmode: None
[0m20:43:27.169594 [info ] [MainThread]:   sslcert: None
[0m20:43:27.170614 [info ] [MainThread]:   sslkey: None
[0m20:43:27.171606 [info ] [MainThread]:   sslrootcert: None
[0m20:43:27.172504 [info ] [MainThread]:   application_name: dbt
[0m20:43:27.174180 [info ] [MainThread]:   retries: 1
[0m20:43:27.175468 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:43:27.288559 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:43:27.322921 [debug] [MainThread]: Using postgres connection "debug"
[0m20:43:27.324044 [debug] [MainThread]: On debug: select 1 as id
[0m20:43:27.324969 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:43:27.335902 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m20:43:27.337674 [debug] [MainThread]: On debug: Close
[0m20:43:27.338623 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m20:43:27.339785 [info ] [MainThread]: [32mAll checks passed![0m
[0m20:43:27.342047 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.5949787, "process_in_blocks": "0", "process_kernel_time": 0.172228, "process_mem_max_rss": "112816", "process_out_blocks": "12", "process_user_time": 2.706307}
[0m20:43:27.343397 [debug] [MainThread]: Command `dbt debug` succeeded at 20:43:27.343250 after 0.60 seconds
[0m20:43:27.344224 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:43:27.345056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8408a80b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f840893ed40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8406d1c970>]}
[0m20:43:27.346270 [debug] [MainThread]: Flushing usage events
[0m20:43:27.868780 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:34:31.565915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261f4c4b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261deac940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261deac8e0>]}


============================== 07:34:31.573186 | 41798bc5-1429-44d8-954a-b4821f5ee3bc ==============================
[0m07:34:31.573186 [info ] [MainThread]: Running with dbt=1.10.4
[0m07:34:31.574781 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt_elsa', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:34:31.942641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41798bc5-1429-44d8-954a-b4821f5ee3bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261de635b0>]}
[0m07:34:32.061278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41798bc5-1429-44d8-954a-b4821f5ee3bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26207fe260>]}
[0m07:34:32.063482 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:34:32.250042 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m07:34:33.272821 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:34:33.273705 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:34:33.286605 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m07:34:33.394227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41798bc5-1429-44d8-954a-b4821f5ee3bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261c512890>]}
[0m07:34:33.752583 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:34:33.756849 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:34:33.799051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41798bc5-1429-44d8-954a-b4821f5ee3bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261c5a7490>]}
[0m07:34:33.800244 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m07:34:33.801452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41798bc5-1429-44d8-954a-b4821f5ee3bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261c5a6d10>]}
[0m07:34:33.804896 [info ] [MainThread]: 
[0m07:34:33.805973 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m07:34:33.807859 [info ] [MainThread]: 
[0m07:34:33.810649 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:34:33.817847 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m07:34:33.880711 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m07:34:33.881918 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m07:34:33.882921 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:34:33.892139 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "db" (172.18.0.3), port 5432 failed: FATAL:  database "elsa" does not exist

[0m07:34:33.901847 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m07:34:33.903033 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m07:34:33.904329 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m07:34:33.905179 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m07:34:33.905949 [debug] [ThreadPool]: On list_elsa: No close available on handle
[0m07:34:33.906951 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:34:33.907714 [debug] [MainThread]: Connection 'list_elsa' was properly closed.
[0m07:34:33.908370 [info ] [MainThread]: 
[0m07:34:33.909197 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.10 seconds (0.10s).
[0m07:34:33.911393 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "db" (172.18.0.3), port 5432 failed: FATAL:  database "elsa" does not exist
  
[0m07:34:33.913219 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.439261, "process_in_blocks": "5008", "process_kernel_time": 0.351189, "process_mem_max_rss": "124496", "process_out_blocks": "4212", "process_user_time": 4.587342}
[0m07:34:33.914558 [debug] [MainThread]: Command `dbt run` failed at 07:34:33.914312 after 2.44 seconds
[0m07:34:33.915904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261f4c4b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261c5a7400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f261cf6c250>]}
[0m07:34:33.917192 [debug] [MainThread]: Flushing usage events
[0m07:34:34.483267 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:35:29.934753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd94f88a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd938c0280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd938c0220>]}


============================== 07:35:29.941275 | e46ad332-90fe-4122-94ff-8fc09ec78e43 ==============================
[0m07:35:29.941275 [info ] [MainThread]: Running with dbt=1.10.4
[0m07:35:29.942662 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m07:35:30.240583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e46ad332-90fe-4122-94ff-8fc09ec78e43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd93712860>]}
[0m07:35:30.340786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e46ad332-90fe-4122-94ff-8fc09ec78e43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd938bf190>]}
[0m07:35:30.342355 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:35:30.514649 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m07:35:31.366118 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:35:31.367040 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:35:31.380571 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m07:35:31.490964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e46ad332-90fe-4122-94ff-8fc09ec78e43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91f327d0>]}
[0m07:35:31.830868 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:35:31.834946 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:35:31.865549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e46ad332-90fe-4122-94ff-8fc09ec78e43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91fc6c80>]}
[0m07:35:31.866669 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m07:35:31.867569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e46ad332-90fe-4122-94ff-8fc09ec78e43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91fc5450>]}
[0m07:35:31.871098 [info ] [MainThread]: 
[0m07:35:31.872145 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m07:35:31.873140 [info ] [MainThread]: 
[0m07:35:31.874576 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:35:31.884742 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m07:35:31.938624 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m07:35:31.939699 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m07:35:31.940570 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:35:31.949493 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "db" (172.18.0.3), port 5432 failed: FATAL:  database "elsa" does not exist

[0m07:35:31.957907 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m07:35:31.958951 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m07:35:31.960139 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m07:35:31.961366 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m07:35:31.962441 [debug] [ThreadPool]: On list_elsa: No close available on handle
[0m07:35:31.963831 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:35:31.964566 [debug] [MainThread]: Connection 'list_elsa' was properly closed.
[0m07:35:31.965430 [info ] [MainThread]: 
[0m07:35:31.966518 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.09 seconds (0.09s).
[0m07:35:31.967973 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "db" (172.18.0.3), port 5432 failed: FATAL:  database "elsa" does not exist
  
[0m07:35:31.969853 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1213105, "process_in_blocks": "0", "process_kernel_time": 0.241998, "process_mem_max_rss": "124768", "process_out_blocks": "4212", "process_user_time": 3.874055}
[0m07:35:31.971611 [debug] [MainThread]: Command `dbt run` failed at 07:35:31.971333 after 2.12 seconds
[0m07:35:31.972743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd94f88a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd91fc7250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd92534a90>]}
[0m07:35:31.974533 [debug] [MainThread]: Flushing usage events
[0m07:35:32.483832 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:44:25.872673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2020234c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201e8e4250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201e8e41f0>]}


============================== 07:44:25.879820 | cd78f973-ad07-43f1-a06f-fbd5c00a527b ==============================
[0m07:44:25.879820 [info ] [MainThread]: Running with dbt=1.10.4
[0m07:44:25.881207 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select bronze', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:44:26.173510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cd78f973-ad07-43f1-a06f-fbd5c00a527b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20225713f0>]}
[0m07:44:26.265018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cd78f973-ad07-43f1-a06f-fbd5c00a527b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201f69ec20>]}
[0m07:44:26.266561 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:44:26.444855 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m07:44:27.400242 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:44:27.401520 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:44:27.414822 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m07:44:27.520600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd78f973-ad07-43f1-a06f-fbd5c00a527b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201cf52800>]}
[0m07:44:27.966876 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:44:27.974099 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:44:28.018536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd78f973-ad07-43f1-a06f-fbd5c00a527b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201cfe2c50>]}
[0m07:44:28.022891 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m07:44:28.025083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cd78f973-ad07-43f1-a06f-fbd5c00a527b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201cfe2d10>]}
[0m07:44:28.029265 [info ] [MainThread]: 
[0m07:44:28.032019 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m07:44:28.033296 [info ] [MainThread]: 
[0m07:44:28.037071 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:44:28.045404 [debug] [ThreadPool]: Acquiring new postgres connection 'list_elsa'
[0m07:44:28.102406 [debug] [ThreadPool]: Using postgres connection "list_elsa"
[0m07:44:28.103527 [debug] [ThreadPool]: On list_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m07:44:28.104352 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:44:28.113586 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "db" (172.18.0.3), port 5432 failed: FATAL:  database "elsa" does not exist

[0m07:44:28.122256 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_elsa"} */

    select distinct nspname from pg_namespace
  
[0m07:44:28.123337 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m07:44:28.124320 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m07:44:28.125122 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m07:44:28.125892 [debug] [ThreadPool]: On list_elsa: No close available on handle
[0m07:44:28.127220 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:44:28.127996 [debug] [MainThread]: Connection 'list_elsa' was properly closed.
[0m07:44:28.128717 [info ] [MainThread]: 
[0m07:44:28.129972 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.09 seconds (0.09s).
[0m07:44:28.131462 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "db" (172.18.0.3), port 5432 failed: FATAL:  database "elsa" does not exist
  
[0m07:44:28.133275 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.3496013, "process_in_blocks": "0", "process_kernel_time": 0.267788, "process_mem_max_rss": "124512", "process_out_blocks": "4940", "process_user_time": 3.882929}
[0m07:44:28.134743 [debug] [MainThread]: Command `dbt run` failed at 07:44:28.134503 after 2.35 seconds
[0m07:44:28.136274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2020234c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201cfe32e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f201d3f49d0>]}
[0m07:44:28.137894 [debug] [MainThread]: Flushing usage events
[0m07:44:28.689153 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:45:24.780840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0af538a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0adfe0280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0adfe0220>]}


============================== 07:45:24.787769 | e92b3a33-e131-4f43-b238-2d373ec86a29 ==============================
[0m07:45:24.787769 [info ] [MainThread]: Running with dbt=1.10.4
[0m07:45:24.789616 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select bronze', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:45:25.083716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b1b713f0>]}
[0m07:45:25.178700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0ade27f40>]}
[0m07:45:25.180256 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:45:25.357674 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m07:45:25.656788 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:45:25.658054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0aed27a60>]}
[0m07:45:33.757820 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m07:45:33.785094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0ac4c2ad0>]}
[0m07:45:34.136790 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:45:34.142102 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:45:34.175403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0ac534f10>]}
[0m07:45:34.176574 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m07:45:34.177557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0ac534160>]}
[0m07:45:34.180914 [info ] [MainThread]: 
[0m07:45:34.182020 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m07:45:34.183120 [info ] [MainThread]: 
[0m07:45:34.185334 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:45:34.193590 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m07:45:34.245520 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m07:45:34.246722 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m07:45:34.247605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:34.258048 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.010 seconds
[0m07:45:34.259999 [debug] [ThreadPool]: On list_dbelsa: Close
[0m07:45:34.261391 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbelsa, now create_dbelsa_bronze)
[0m07:45:34.262634 [debug] [ThreadPool]: Creating schema "database: "dbelsa"
schema: "bronze"
"
[0m07:45:34.273873 [debug] [ThreadPool]: Using postgres connection "create_dbelsa_bronze"
[0m07:45:34.274806 [debug] [ThreadPool]: On create_dbelsa_bronze: BEGIN
[0m07:45:34.275603 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:34.284556 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m07:45:34.285548 [debug] [ThreadPool]: Using postgres connection "create_dbelsa_bronze"
[0m07:45:34.286681 [debug] [ThreadPool]: On create_dbelsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "create_dbelsa_bronze"} */
create schema if not exists "bronze"
[0m07:45:34.291403 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.004 seconds
[0m07:45:34.293001 [debug] [ThreadPool]: On create_dbelsa_bronze: COMMIT
[0m07:45:34.293795 [debug] [ThreadPool]: Using postgres connection "create_dbelsa_bronze"
[0m07:45:34.294560 [debug] [ThreadPool]: On create_dbelsa_bronze: COMMIT
[0m07:45:34.296132 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m07:45:34.297047 [debug] [ThreadPool]: On create_dbelsa_bronze: Close
[0m07:45:34.302199 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dbelsa_bronze, now list_dbelsa_tec_elsa)
[0m07:45:34.303695 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa_bronze'
[0m07:45:34.316803 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:45:34.323185 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:45:34.324243 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: BEGIN
[0m07:45:34.325265 [debug] [ThreadPool]: On list_dbelsa_bronze: BEGIN
[0m07:45:34.326253 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:34.327193 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:34.336830 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m07:45:34.337521 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m07:45:34.338345 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:45:34.339172 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:45:34.340158 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_tec_elsa"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m07:45:34.341138 [debug] [ThreadPool]: On list_dbelsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_bronze"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m07:45:34.348870 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m07:45:34.349481 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m07:45:34.351368 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: ROLLBACK
[0m07:45:34.353349 [debug] [ThreadPool]: On list_dbelsa_bronze: ROLLBACK
[0m07:45:34.354966 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: Close
[0m07:45:34.355952 [debug] [ThreadPool]: On list_dbelsa_bronze: Close
[0m07:45:34.437142 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:34.438575 [debug] [MainThread]: On master: BEGIN
[0m07:45:34.439679 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:45:34.451627 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m07:45:34.452780 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:34.454475 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:45:34.464423 [debug] [MainThread]: SQL status: SELECT 0 in 0.008 seconds
[0m07:45:34.466611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0acf7a170>]}
[0m07:45:34.467787 [debug] [MainThread]: On master: ROLLBACK
[0m07:45:34.468965 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:34.470104 [debug] [MainThread]: On master: BEGIN
[0m07:45:34.471648 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m07:45:34.472565 [debug] [MainThread]: On master: COMMIT
[0m07:45:34.473428 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:34.474183 [debug] [MainThread]: On master: COMMIT
[0m07:45:34.475172 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:45:34.508657 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m07:45:34.517208 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m07:45:34.524617 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m07:45:34.525925 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.05s]
[0m07:45:34.527014 [info ] [MainThread]: 
[0m07:45:34.528273 [debug] [MainThread]: On master: Close
[0m07:45:34.539868 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m07:45:34.540646 [debug] [Thread-2 (]: Began running node model.dbt_elsa.test_connection
[0m07:45:34.541874 [info ] [Thread-1 (]: 1 of 2 START sql table model bronze.consumption ................................ [RUN]
[0m07:45:34.543520 [info ] [Thread-2 (]: 2 of 2 START sql table model bronze.test_connection ............................ [RUN]
[0m07:45:34.545556 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbelsa_bronze, now model.dbt_elsa.consumption)
[0m07:45:34.546849 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_dbelsa_tec_elsa, now model.dbt_elsa.test_connection)
[0m07:45:34.547981 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m07:45:34.549109 [debug] [Thread-2 (]: Began compiling node model.dbt_elsa.test_connection
[0m07:45:34.558288 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m07:45:34.566207 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_elsa.test_connection"
[0m07:45:34.570846 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m07:45:34.571967 [debug] [Thread-2 (]: Began executing node model.dbt_elsa.test_connection
[0m07:45:34.661974 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m07:45:34.666077 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_elsa.test_connection"
[0m07:45:34.669837 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:45:34.671072 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:45:34.671798 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m07:45:34.672774 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: BEGIN
[0m07:45:34.673735 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:45:34.674628 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m07:45:34.684915 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m07:45:34.685624 [debug] [Thread-2 (]: SQL status: BEGIN in 0.011 seconds
[0m07:45:34.686689 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:45:34.687883 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:45:34.689201 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "dbelsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m07:45:34.690507 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */

  
    

  create  table "dbelsa"."bronze"."test_connection__dbt_tmp"
  
  
    as
  
  (
    select current_database() as db, current_schema() as schema
  );
  
[0m07:45:34.693169 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.rte_eco2mix" does not exist
LINE 27: FROM bronze.rte_eco2mix
              ^

[0m07:45:34.694168 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: ROLLBACK
[0m07:45:34.695857 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m07:45:34.702020 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.010 seconds
[0m07:45:34.722315 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:45:34.723995 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
alter table "dbelsa"."bronze"."test_connection__dbt_tmp" rename to "test_connection"
[0m07:45:34.725945 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:45:34.727589 [debug] [Thread-1 (]: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m07:45:34.749214 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: COMMIT
[0m07:45:34.752062 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:45:34.752800 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0acf8ce50>]}
[0m07:45:34.753727 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: COMMIT
[0m07:45:34.755834 [error] [Thread-1 (]: 1 of 2 ERROR creating sql table model bronze.consumption ....................... [[31mERROR[0m in 0.20s]
[0m07:45:34.757900 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m07:45:34.758569 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m07:45:34.759762 [debug] [Thread-7 (]: Marking all children of 'model.dbt_elsa.consumption' to be skipped because of status 'error'.  Reason: Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql.
[0m07:45:34.775164 [debug] [Thread-2 (]: Applying DROP to: "dbelsa"."bronze"."test_connection__dbt_backup"
[0m07:45:34.784146 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:45:34.785458 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
drop table if exists "dbelsa"."bronze"."test_connection__dbt_backup" cascade
[0m07:45:34.787028 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:45:34.792161 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: Close
[0m07:45:34.793881 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e92b3a33-e131-4f43-b238-2d373ec86a29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b0ab5b70>]}
[0m07:45:34.796055 [info ] [Thread-2 (]: 2 of 2 OK created sql table model bronze.test_connection ....................... [[32mSELECT 1[0m in 0.25s]
[0m07:45:34.798042 [debug] [Thread-2 (]: Finished running node model.dbt_elsa.test_connection
[0m07:45:34.801462 [info ] [MainThread]: 
[0m07:45:34.802725 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:34.804763 [debug] [MainThread]: On master: BEGIN
[0m07:45:34.806459 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:45:34.818212 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m07:45:34.819473 [debug] [MainThread]: On master: COMMIT
[0m07:45:34.820718 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:34.821833 [debug] [MainThread]: On master: COMMIT
[0m07:45:34.823149 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:45:34.867185 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m07:45:34.875530 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m07:45:34.913646 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m07:45:34.916509 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m07:45:34.917745 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.09s]
[0m07:45:34.918839 [debug] [MainThread]: On master: Close
[0m07:45:34.920167 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:45:34.921158 [debug] [MainThread]: Connection 'model.dbt_elsa.test_connection' was properly closed.
[0m07:45:34.922156 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m07:45:34.923157 [info ] [MainThread]: 
[0m07:45:34.924614 [info ] [MainThread]: Finished running 2 project hooks, 2 table models in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m07:45:34.929330 [debug] [MainThread]: Command end result
[0m07:45:35.149665 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:45:35.153721 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:45:35.166111 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m07:45:35.167040 [info ] [MainThread]: 
[0m07:45:35.168176 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:45:35.169208 [info ] [MainThread]: 
[0m07:45:35.170806 [error] [MainThread]: [31mFailure in model consumption (models/bronze/consumption.sql)[0m
[0m07:45:35.172042 [error] [MainThread]:   Database Error in model consumption (models/bronze/consumption.sql)
  relation "bronze.rte_eco2mix" does not exist
  LINE 27: FROM bronze.rte_eco2mix
                ^
  compiled code at target/run/dbt_elsa/models/bronze/consumption.sql
[0m07:45:35.173097 [info ] [MainThread]: 
[0m07:45:35.175100 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/bronze/consumption.sql
[0m07:45:35.176968 [info ] [MainThread]: 
[0m07:45:35.181118 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=4
[0m07:45:35.183942 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.488066, "process_in_blocks": "1064", "process_kernel_time": 0.28226, "process_mem_max_rss": "140364", "process_out_blocks": "12369", "process_user_time": 12.110311}
[0m07:45:35.185482 [debug] [MainThread]: Command `dbt run` failed at 07:45:35.185114 after 10.49 seconds
[0m07:45:35.186739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0af538a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0ae1ecc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0ac56ca90>]}
[0m07:45:35.188625 [debug] [MainThread]: Flushing usage events
[0m07:45:35.672966 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:47:03.561173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1200b14ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11ff4d8250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11ff4d81f0>]}


============================== 07:47:03.568133 | 05e4e95e-3bcf-41f1-85dd-8835feb2c516 ==============================
[0m07:47:03.568133 [info ] [MainThread]: Running with dbt=1.10.4
[0m07:47:03.569419 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select bronze', 'send_anonymous_usage_stats': 'True'}
[0m07:47:03.848766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12009abd30>]}
[0m07:47:03.952544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11ff4aff10>]}
[0m07:47:03.954125 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:47:04.134845 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m07:47:05.061587 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:47:05.062493 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:47:05.074739 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m07:47:05.176249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11fdb4a830>]}
[0m07:47:05.535800 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:47:05.540664 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:47:05.570063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11fdbdf580>]}
[0m07:47:05.571689 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m07:47:05.573154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11fdbdf4c0>]}
[0m07:47:05.576553 [info ] [MainThread]: 
[0m07:47:05.577894 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m07:47:05.579539 [info ] [MainThread]: 
[0m07:47:05.581458 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:47:05.589640 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m07:47:05.645045 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m07:47:05.646102 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m07:47:05.646904 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:47:05.657788 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.011 seconds
[0m07:47:05.660074 [debug] [ThreadPool]: On list_dbelsa: Close
[0m07:47:05.665345 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbelsa, now list_dbelsa_tec_elsa)
[0m07:47:05.666574 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa_bronze'
[0m07:47:05.678470 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:47:05.753788 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:47:05.755331 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: BEGIN
[0m07:47:05.756951 [debug] [ThreadPool]: On list_dbelsa_bronze: BEGIN
[0m07:47:05.758325 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:47:05.759679 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:47:05.772051 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:47:05.772947 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m07:47:05.773875 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:47:05.775095 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:47:05.776275 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_tec_elsa"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m07:47:05.777651 [debug] [ThreadPool]: On list_dbelsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_bronze"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m07:47:05.782283 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m07:47:05.783107 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m07:47:05.785204 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: ROLLBACK
[0m07:47:05.787217 [debug] [ThreadPool]: On list_dbelsa_bronze: ROLLBACK
[0m07:47:05.788680 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: Close
[0m07:47:05.789822 [debug] [ThreadPool]: On list_dbelsa_bronze: Close
[0m07:47:05.803825 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:05.805097 [debug] [MainThread]: On master: BEGIN
[0m07:47:05.806263 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:47:05.815531 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m07:47:05.816601 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:05.817738 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:47:05.822577 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m07:47:05.824906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11fdffbbe0>]}
[0m07:47:05.825988 [debug] [MainThread]: On master: ROLLBACK
[0m07:47:05.827112 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:05.827929 [debug] [MainThread]: On master: BEGIN
[0m07:47:05.829121 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m07:47:05.829828 [debug] [MainThread]: On master: COMMIT
[0m07:47:05.830548 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:05.831263 [debug] [MainThread]: On master: COMMIT
[0m07:47:05.832182 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:47:05.890189 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m07:47:05.900401 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m07:47:05.909963 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m07:47:05.911641 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.08s]
[0m07:47:05.913270 [info ] [MainThread]: 
[0m07:47:05.915072 [debug] [MainThread]: On master: Close
[0m07:47:05.925783 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption
[0m07:47:05.927044 [debug] [Thread-2 (]: Began running node model.dbt_elsa.test_connection
[0m07:47:05.930262 [info ] [Thread-1 (]: 1 of 2 START sql table model bronze.consumption ................................ [RUN]
[0m07:47:05.932350 [info ] [Thread-2 (]: 2 of 2 START sql table model bronze.test_connection ............................ [RUN]
[0m07:47:05.952521 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbelsa_tec_elsa, now model.dbt_elsa.consumption)
[0m07:47:05.972480 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_dbelsa_bronze, now model.dbt_elsa.test_connection)
[0m07:47:05.991662 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption
[0m07:47:06.011199 [debug] [Thread-2 (]: Began compiling node model.dbt_elsa.test_connection
[0m07:47:06.018436 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption"
[0m07:47:06.026304 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_elsa.test_connection"
[0m07:47:06.029415 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption
[0m07:47:06.042091 [debug] [Thread-2 (]: Began executing node model.dbt_elsa.test_connection
[0m07:47:06.120305 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption"
[0m07:47:06.121407 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_elsa.test_connection"
[0m07:47:06.124172 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.125654 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: BEGIN
[0m07:47:06.126656 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:47:06.125119 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:47:06.128298 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: BEGIN
[0m07:47:06.129464 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m07:47:06.137318 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m07:47:06.138844 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.140413 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */

  
    

  create  table "dbelsa"."bronze"."consumption__dbt_tmp"
  
  
    as
  
  (
    SELECT
    id,
    created_at,
    (data->>'date')::date AS date,
    (data->>'heure')::time AS heure,   
    (data->>'gaz')::int AS gaz,
    (data->>'nucleaire')::int AS nucleaire,
    (data->>'charbon')::int AS charbon,
    (data->>'solaire')::int AS solaire,
    (data->>'eolien')::int AS eolien,
    (data->>'hydraulique')::int AS hydraulique,
    (data->>'bioenergies')::int AS bioenergies,
    (data->>'autres')::int AS autres,
    (data->>'prevision_j')::int AS prevision_j,
    (data->>'prevision_j1')::int AS prevision_j1
FROM bronze.rte_eco2mix
  );
  
[0m07:47:06.139771 [debug] [Thread-2 (]: SQL status: BEGIN in 0.010 seconds
[0m07:47:06.141917 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:47:06.142892 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */

  
    

  create  table "dbelsa"."bronze"."test_connection__dbt_tmp"
  
  
    as
  
  (
    select current_database() as db, current_schema() as schema
  );
  
[0m07:47:06.145058 [debug] [Thread-1 (]: SQL status: SELECT 96 in 0.004 seconds
[0m07:47:06.145691 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m07:47:06.163030 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.173067 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */
alter table "dbelsa"."bronze"."consumption__dbt_tmp" rename to "consumption"
[0m07:47:06.171449 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:47:06.175337 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
alter table "dbelsa"."bronze"."test_connection" rename to "test_connection__dbt_backup"
[0m07:47:06.174742 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:47:06.177039 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:47:06.205613 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:47:06.220639 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
alter table "dbelsa"."bronze"."test_connection__dbt_tmp" rename to "test_connection"
[0m07:47:06.219877 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.223673 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */

    
  
  comment on table "dbelsa"."bronze"."consumption" is $dbt_comment_literal_block$The aim of this table is to track houtly energy consumption for a given day
$dbt_comment_literal_block$;

  
[0m07:47:06.222883 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:47:06.230449 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: COMMIT
[0m07:47:06.232472 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:47:06.233640 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: COMMIT
[0m07:47:06.231427 [debug] [Thread-1 (]: SQL status: COMMENT in 0.007 seconds
[0m07:47:06.241219 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m07:47:06.283348 [debug] [Thread-2 (]: Applying DROP to: "dbelsa"."bronze"."test_connection__dbt_backup"
[0m07:47:06.286748 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.293406 [debug] [Thread-2 (]: Using postgres connection "model.dbt_elsa.test_connection"
[0m07:47:06.294579 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "dbelsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m07:47:06.295683 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.test_connection"} */
drop table if exists "dbelsa"."bronze"."test_connection__dbt_backup" cascade
[0m07:47:06.300705 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.003 seconds
[0m07:47:06.304558 [debug] [Thread-2 (]: On model.dbt_elsa.test_connection: Close
[0m07:47:06.307965 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11fd497340>]}
[0m07:47:06.309361 [info ] [Thread-2 (]: 2 of 2 OK created sql table model bronze.test_connection ....................... [[32mSELECT 1[0m in 0.33s]
[0m07:47:06.310980 [debug] [Thread-2 (]: Finished running node model.dbt_elsa.test_connection
[0m07:47:06.311642 [debug] [Thread-1 (]: SQL status: SELECT 14 in 0.015 seconds
[0m07:47:06.318715 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.320245 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */

    
  
  
    
    
    comment on column "dbelsa"."bronze"."consumption".id is $dbt_comment_literal_block$ID$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".gaz is $dbt_comment_literal_block$Production for gaz energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".nucleaire is $dbt_comment_literal_block$Production for nuclear energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".charbon is $dbt_comment_literal_block$Production for coal energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".solaire is $dbt_comment_literal_block$Production for solar energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".eolien is $dbt_comment_literal_block$Production for eolian energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".hydraulique is $dbt_comment_literal_block$Production for hydrolic energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".bioenergies is $dbt_comment_literal_block$Production for bioenergy energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".autres is $dbt_comment_literal_block$Production for other energy in TWH$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".prevision_j is $dbt_comment_literal_block$Pprevision_j$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption".prevision_j1 is $dbt_comment_literal_block$prevision_j1$dbt_comment_literal_block$;
  

  
[0m07:47:06.322408 [debug] [Thread-1 (]: SQL status: COMMENT in 0.001 seconds
[0m07:47:06.324760 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m07:47:06.325858 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.326772 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: COMMIT
[0m07:47:06.328715 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m07:47:06.335851 [debug] [Thread-1 (]: Applying DROP to: "dbelsa"."bronze"."consumption__dbt_backup"
[0m07:47:06.337334 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption"
[0m07:47:06.338637 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption"} */
drop table if exists "dbelsa"."bronze"."consumption__dbt_backup" cascade
[0m07:47:06.339986 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:47:06.342180 [debug] [Thread-1 (]: On model.dbt_elsa.consumption: Close
[0m07:47:06.343477 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05e4e95e-3bcf-41f1-85dd-8835feb2c516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11fd343fd0>]}
[0m07:47:06.345131 [info ] [Thread-1 (]: 1 of 2 OK created sql table model bronze.consumption ........................... [[32mSELECT 96[0m in 0.39s]
[0m07:47:06.346681 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption
[0m07:47:06.350093 [info ] [MainThread]: 
[0m07:47:06.351310 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:06.352584 [debug] [MainThread]: On master: BEGIN
[0m07:47:06.354405 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:47:06.364700 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m07:47:06.365610 [debug] [MainThread]: On master: COMMIT
[0m07:47:06.366394 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:06.367054 [debug] [MainThread]: On master: COMMIT
[0m07:47:06.368168 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:47:06.421490 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m07:47:06.429883 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m07:47:06.465860 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m07:47:06.468556 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m07:47:06.469971 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.10s]
[0m07:47:06.471320 [debug] [MainThread]: On master: Close
[0m07:47:06.472568 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:47:06.473430 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption' was properly closed.
[0m07:47:06.474294 [debug] [MainThread]: Connection 'model.dbt_elsa.test_connection' was properly closed.
[0m07:47:06.475402 [info ] [MainThread]: 
[0m07:47:06.477453 [info ] [MainThread]: Finished running 2 project hooks, 2 table models in 0 hours 0 minutes and 0.89 seconds (0.89s).
[0m07:47:06.480808 [debug] [MainThread]: Command end result
[0m07:47:06.700376 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:47:06.704010 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:47:06.715218 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m07:47:06.716073 [info ] [MainThread]: 
[0m07:47:06.717077 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:47:06.718001 [info ] [MainThread]: 
[0m07:47:06.718866 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m07:47:06.720836 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.2451804, "process_in_blocks": "0", "process_kernel_time": 0.304131, "process_mem_max_rss": "132600", "process_out_blocks": "8276", "process_user_time": 4.64813}
[0m07:47:06.722728 [debug] [MainThread]: Command `dbt run` succeeded at 07:47:06.722506 after 3.25 seconds
[0m07:47:06.724452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1200b14ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12009a6bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11ff4aff10>]}
[0m07:47:06.727501 [debug] [MainThread]: Flushing usage events
[0m07:47:07.252418 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:47:15.829540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc652c4af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc63cac280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc63cac220>]}


============================== 07:47:15.836183 | 2cb6b113-c9d8-434b-8526-8be05e6d53d9 ==============================
[0m07:47:15.836183 [info ] [MainThread]: Running with dbt=1.10.4
[0m07:47:15.837419 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select silver', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:47:16.128933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2cb6b113-c9d8-434b-8526-8be05e6d53d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc6517d5a0>]}
[0m07:47:16.227324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2cb6b113-c9d8-434b-8526-8be05e6d53d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc63c9efe0>]}
[0m07:47:16.229097 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:47:16.406181 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m07:47:17.174216 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:47:17.175292 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:47:17.187369 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m07:47:17.291098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2cb6b113-c9d8-434b-8526-8be05e6d53d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc62316860>]}
[0m07:47:17.636315 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:47:17.641104 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:47:17.674669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2cb6b113-c9d8-434b-8526-8be05e6d53d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc623ab5b0>]}
[0m07:47:17.675893 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m07:47:17.676940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cb6b113-c9d8-434b-8526-8be05e6d53d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc623ab4f0>]}
[0m07:47:17.679967 [info ] [MainThread]: 
[0m07:47:17.681048 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m07:47:17.682106 [info ] [MainThread]: 
[0m07:47:17.684231 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:47:17.686480 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m07:47:17.742812 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m07:47:17.743956 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m07:47:17.744870 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:47:17.755062 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.010 seconds
[0m07:47:17.757515 [debug] [ThreadPool]: On list_dbelsa: Close
[0m07:47:17.768052 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbelsa, now list_dbelsa_tec_elsa)
[0m07:47:17.769323 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa_bronze'
[0m07:47:17.781666 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:47:17.857309 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:47:17.858675 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: BEGIN
[0m07:47:17.860079 [debug] [ThreadPool]: On list_dbelsa_bronze: BEGIN
[0m07:47:17.861431 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:47:17.862848 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:47:17.875352 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:47:17.877106 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:47:17.877950 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m07:47:17.879033 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_tec_elsa"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m07:47:17.880321 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:47:17.882086 [debug] [ThreadPool]: On list_dbelsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_bronze"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m07:47:17.884999 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m07:47:17.887610 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: ROLLBACK
[0m07:47:17.888586 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.005 seconds
[0m07:47:17.890505 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: Close
[0m07:47:17.892650 [debug] [ThreadPool]: On list_dbelsa_bronze: ROLLBACK
[0m07:47:17.895514 [debug] [ThreadPool]: On list_dbelsa_bronze: Close
[0m07:47:17.915970 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:17.916884 [debug] [MainThread]: On master: BEGIN
[0m07:47:17.917669 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:47:17.927514 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m07:47:17.928893 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:17.930115 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:47:17.934244 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m07:47:17.936263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cb6b113-c9d8-434b-8526-8be05e6d53d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc627a42e0>]}
[0m07:47:17.937249 [debug] [MainThread]: On master: ROLLBACK
[0m07:47:17.938455 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:17.941037 [debug] [MainThread]: On master: BEGIN
[0m07:47:17.942729 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m07:47:17.943638 [debug] [MainThread]: On master: COMMIT
[0m07:47:17.944461 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:17.945245 [debug] [MainThread]: On master: COMMIT
[0m07:47:17.946147 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:47:18.003608 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m07:47:18.012461 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m07:47:18.018530 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m07:47:18.019955 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.07s]
[0m07:47:18.021068 [info ] [MainThread]: 
[0m07:47:18.022932 [debug] [MainThread]: On master: Close
[0m07:47:18.037847 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m07:47:18.040660 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption_history ........................ [RUN]
[0m07:47:18.042422 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbelsa_bronze, now model.dbt_elsa.consumption_history)
[0m07:47:18.043981 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m07:47:18.052326 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m07:47:18.055277 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m07:47:18.117531 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m07:47:18.120546 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:47:18.121716 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m07:47:18.122898 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:47:18.132483 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m07:47:18.133576 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:47:18.134636 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "dbelsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    SELECT *
FROM "dbelsa"."bronze"."consumption_history"
WHERE DATE(created_at) < CURRENT_DATE
UNION
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m07:47:18.136256 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bronze.consumption_history" does not exist
LINE 13: FROM "dbelsa"."bronze"."consumption_history"
              ^

[0m07:47:18.137224 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: ROLLBACK
[0m07:47:18.138625 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m07:47:18.142334 [debug] [Thread-1 (]: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "bronze.consumption_history" does not exist
  LINE 13: FROM "dbelsa"."bronze"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m07:47:18.145084 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cb6b113-c9d8-434b-8526-8be05e6d53d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc63e36cb0>]}
[0m07:47:18.146439 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model bronze.consumption_history ............... [[31mERROR[0m in 0.10s]
[0m07:47:18.148012 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m07:47:18.149278 [debug] [Thread-7 (]: Marking all children of 'model.dbt_elsa.consumption_history' to be skipped because of status 'error'.  Reason: Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "bronze.consumption_history" does not exist
  LINE 13: FROM "dbelsa"."bronze"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql.
[0m07:47:18.152806 [info ] [MainThread]: 
[0m07:47:18.154391 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:18.155910 [debug] [MainThread]: On master: BEGIN
[0m07:47:18.157287 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:47:18.167580 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m07:47:18.168540 [debug] [MainThread]: On master: COMMIT
[0m07:47:18.169426 [debug] [MainThread]: Using postgres connection "master"
[0m07:47:18.170183 [debug] [MainThread]: On master: COMMIT
[0m07:47:18.171101 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:47:18.224367 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m07:47:18.232574 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m07:47:18.268823 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m07:47:18.271881 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m07:47:18.273403 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.10s]
[0m07:47:18.274559 [debug] [MainThread]: On master: Close
[0m07:47:18.275661 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:47:18.276453 [debug] [MainThread]: Connection 'list_dbelsa_tec_elsa' was properly closed.
[0m07:47:18.277252 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m07:47:18.278193 [info ] [MainThread]: 
[0m07:47:18.279473 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.59 seconds (0.59s).
[0m07:47:18.282669 [debug] [MainThread]: Command end result
[0m07:47:18.488664 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:47:18.492922 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:47:18.504511 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m07:47:18.505963 [info ] [MainThread]: 
[0m07:47:18.507800 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:47:18.509322 [info ] [MainThread]: 
[0m07:47:18.510964 [error] [MainThread]: [31mFailure in model consumption_history (models/silver/consumption_history.sql)[0m
[0m07:47:18.512317 [error] [MainThread]:   Database Error in model consumption_history (models/silver/consumption_history.sql)
  relation "bronze.consumption_history" does not exist
  LINE 13: FROM "dbelsa"."bronze"."consumption_history"
                ^
  compiled code at target/run/dbt_elsa/models/silver/consumption_history.sql
[0m07:47:18.514573 [info ] [MainThread]: 
[0m07:47:18.517221 [info ] [MainThread]:   compiled code at target/compiled/dbt_elsa/models/silver/consumption_history.sql
[0m07:47:18.519291 [info ] [MainThread]: 
[0m07:47:18.521571 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=3
[0m07:47:18.524319 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.7781873, "process_in_blocks": "0", "process_kernel_time": 0.290871, "process_mem_max_rss": "130168", "process_out_blocks": "8261", "process_user_time": 4.401644}
[0m07:47:18.525908 [debug] [MainThread]: Command `dbt run` failed at 07:47:18.525590 after 2.78 seconds
[0m07:47:18.527611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc652c4af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc65153f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc6517d4e0>]}
[0m07:47:18.529468 [debug] [MainThread]: Flushing usage events
[0m07:47:19.014595 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:48:02.840678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f169435ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1692dc0280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1692dc0220>]}


============================== 07:48:02.847240 | 07de1254-7a8f-43d5-8ae5-375abefe3d8b ==============================
[0m07:48:02.847240 [info ] [MainThread]: Running with dbt=1.10.4
[0m07:48:02.848538 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt_elsa', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt_elsa/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select silver', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:48:03.147432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '07de1254-7a8f-43d5-8ae5-375abefe3d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16941f1150>]}
[0m07:48:03.240415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '07de1254-7a8f-43d5-8ae5-375abefe3d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1692d9b970>]}
[0m07:48:03.242025 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:48:03.410926 [debug] [MainThread]: checksum: 073cb5a296270136b24f9c040fdebd0642ef9c263903ef463bfe7e190c538da2, vars: {}, profile: , target: , version: 1.10.4
[0m07:48:04.177571 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:48:04.179234 [debug] [MainThread]: Partial parsing: updated file: dbt_elsa://models/silver/consumption_history.sql
[0m07:48:04.963331 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_elsa.gold
- seeds.dbt_elsa
[0m07:48:04.996225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07de1254-7a8f-43d5-8ae5-375abefe3d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1691591780>]}
[0m07:48:05.344903 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:48:05.348954 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:48:05.380540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07de1254-7a8f-43d5-8ae5-375abefe3d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1690e18d60>]}
[0m07:48:05.381821 [info ] [MainThread]: Found 33 models, 2 operations, 5 data tests, 2 sources, 1572 macros
[0m07:48:05.382912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07de1254-7a8f-43d5-8ae5-375abefe3d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1690e1a410>]}
[0m07:48:05.386403 [info ] [MainThread]: 
[0m07:48:05.387601 [info ] [MainThread]: Concurrency: 4 threads (target='dev_elsa')
[0m07:48:05.389296 [info ] [MainThread]: 
[0m07:48:05.391900 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:48:05.394183 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa'
[0m07:48:05.448810 [debug] [ThreadPool]: Using postgres connection "list_dbelsa"
[0m07:48:05.449929 [debug] [ThreadPool]: On list_dbelsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa"} */

    select distinct nspname from pg_namespace
  
[0m07:48:05.450915 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:48:05.461827 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.011 seconds
[0m07:48:05.463980 [debug] [ThreadPool]: On list_dbelsa: Close
[0m07:48:05.474497 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbelsa, now list_dbelsa_tec_elsa)
[0m07:48:05.475833 [debug] [ThreadPool]: Acquiring new postgres connection 'list_dbelsa_bronze'
[0m07:48:05.487176 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:48:05.493883 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:48:05.494895 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: BEGIN
[0m07:48:05.495880 [debug] [ThreadPool]: On list_dbelsa_bronze: BEGIN
[0m07:48:05.496975 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:48:05.497907 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:48:05.507511 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m07:48:05.508116 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m07:48:05.508892 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_bronze"
[0m07:48:05.509788 [debug] [ThreadPool]: Using postgres connection "list_dbelsa_tec_elsa"
[0m07:48:05.510698 [debug] [ThreadPool]: On list_dbelsa_bronze: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_bronze"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m07:48:05.511693 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "list_dbelsa_tec_elsa"} */
select
      'dbelsa' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'tec_elsa'
    union all
    select
      'dbelsa' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'tec_elsa'
  
[0m07:48:05.515929 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m07:48:05.516648 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m07:48:05.518477 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: ROLLBACK
[0m07:48:05.520424 [debug] [ThreadPool]: On list_dbelsa_bronze: ROLLBACK
[0m07:48:05.521574 [debug] [ThreadPool]: On list_dbelsa_tec_elsa: Close
[0m07:48:05.522600 [debug] [ThreadPool]: On list_dbelsa_bronze: Close
[0m07:48:05.538672 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:05.540160 [debug] [MainThread]: On master: BEGIN
[0m07:48:05.541299 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:48:05.550800 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m07:48:05.551878 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:05.553160 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:48:05.557973 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m07:48:05.560069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07de1254-7a8f-43d5-8ae5-375abefe3d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1690e18d60>]}
[0m07:48:05.561224 [debug] [MainThread]: On master: ROLLBACK
[0m07:48:05.562391 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:05.563171 [debug] [MainThread]: On master: BEGIN
[0m07:48:05.564339 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m07:48:05.565128 [debug] [MainThread]: On master: COMMIT
[0m07:48:05.565876 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:05.566602 [debug] [MainThread]: On master: COMMIT
[0m07:48:05.567465 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:48:05.622193 [debug] [MainThread]: Elementary: Materialization override is enabled.
[0m07:48:05.631141 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m07:48:05.637314 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m07:48:05.639063 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.07s]
[0m07:48:05.641157 [info ] [MainThread]: 
[0m07:48:05.642251 [debug] [MainThread]: On master: Close
[0m07:48:05.649978 [debug] [Thread-1 (]: Began running node model.dbt_elsa.consumption_history
[0m07:48:05.651823 [info ] [Thread-1 (]: 1 of 1 START sql table model bronze.consumption_history ........................ [RUN]
[0m07:48:05.653805 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbelsa_bronze, now model.dbt_elsa.consumption_history)
[0m07:48:05.654889 [debug] [Thread-1 (]: Began compiling node model.dbt_elsa.consumption_history
[0m07:48:05.664780 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_elsa.consumption_history"
[0m07:48:05.667454 [debug] [Thread-1 (]: Began executing node model.dbt_elsa.consumption_history
[0m07:48:05.734317 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_elsa.consumption_history"
[0m07:48:05.737053 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.738088 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: BEGIN
[0m07:48:05.739659 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:48:05.749876 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m07:48:05.751234 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.752323 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */

  
    

  create  table "dbelsa"."bronze"."consumption_history__dbt_tmp"
  
  
    as
  
  (
    /*
SELECT *
FROM "dbelsa"."bronze"."consumption_history"
WHERE DATE(created_at) < CURRENT_DATE
UNION
*/
SELECT 
    date,
    created_at,
    unpivot.filiere,
    SUM(unpivot.volume) AS volume
FROM bronze.consumption
JOIN LATERAL(VALUES
    ('gaz', consumption.gaz),
    ('nucleaire', consumption.nucleaire),
    ('charbon', consumption.charbon),
    ('solaire', consumption.solaire),
    ('eolien', consumption.eolien),
    ('hydraulique', consumption.hydraulique),
    ('bioenergies', consumption.bioenergies),
    ('autres', consumption.autres)
) unpivot(filiere, volume) ON TRUE
GROUP BY
    date,
    created_at,
    unpivot.filiere
  );
  
[0m07:48:05.759392 [debug] [Thread-1 (]: SQL status: SELECT 48 in 0.006 seconds
[0m07:48:05.777895 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.779316 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */
alter table "dbelsa"."bronze"."consumption_history__dbt_tmp" rename to "consumption_history"
[0m07:48:05.780795 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:48:05.814895 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.816217 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  comment on table "dbelsa"."bronze"."consumption_history" is $dbt_comment_literal_block$The aim of this table is to consolidate history data for consumption
$dbt_comment_literal_block$;

  
[0m07:48:05.817690 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m07:48:05.848328 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.849509 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "dbelsa".INFORMATION_SCHEMA.columns
      where table_name = 'consumption_history'
        
        and table_schema = 'bronze'
        
      order by ordinal_position

  
[0m07:48:05.857021 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.006 seconds
[0m07:48:05.862462 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.863720 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */

    
  
  
    
    
    comment on column "dbelsa"."bronze"."consumption_history".created_at is $dbt_comment_literal_block$datetime$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption_history".date is $dbt_comment_literal_block$date$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption_history".filiere is $dbt_comment_literal_block$filiere$dbt_comment_literal_block$;
  
    
    
    comment on column "dbelsa"."bronze"."consumption_history".volume is $dbt_comment_literal_block$volume$dbt_comment_literal_block$;
  

  
[0m07:48:05.865279 [debug] [Thread-1 (]: SQL status: COMMENT in 0.000 seconds
[0m07:48:05.867312 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m07:48:05.868326 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.869279 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: COMMIT
[0m07:48:05.871209 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m07:48:05.955566 [debug] [Thread-1 (]: Applying DROP to: "dbelsa"."bronze"."consumption_history__dbt_backup"
[0m07:48:05.963924 [debug] [Thread-1 (]: Using postgres connection "model.dbt_elsa.consumption_history"
[0m07:48:05.965273 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: /* {"app": "dbt", "dbt_version": "1.10.4", "profile_name": "dbt_elsa", "target_name": "dev_elsa", "node_id": "model.dbt_elsa.consumption_history"} */
drop table if exists "dbelsa"."bronze"."consumption_history__dbt_backup" cascade
[0m07:48:05.967155 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:48:05.971281 [debug] [Thread-1 (]: On model.dbt_elsa.consumption_history: Close
[0m07:48:05.974671 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07de1254-7a8f-43d5-8ae5-375abefe3d8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1695a64a30>]}
[0m07:48:05.976599 [info ] [Thread-1 (]: 1 of 1 OK created sql table model bronze.consumption_history ................... [[32mSELECT 48[0m in 0.32s]
[0m07:48:05.978476 [debug] [Thread-1 (]: Finished running node model.dbt_elsa.consumption_history
[0m07:48:05.981450 [info ] [MainThread]: 
[0m07:48:05.982507 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:05.983357 [debug] [MainThread]: On master: BEGIN
[0m07:48:05.984392 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:48:05.995020 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m07:48:05.996080 [debug] [MainThread]: On master: COMMIT
[0m07:48:05.996860 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:05.997622 [debug] [MainThread]: On master: COMMIT
[0m07:48:05.998514 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:48:06.049675 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m07:48:06.060456 [debug] [MainThread]: Elementary: Uploaded dbt artifacts.
[0m07:48:06.103460 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m07:48:06.106652 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m07:48:06.108410 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.11s]
[0m07:48:06.109968 [debug] [MainThread]: On master: Close
[0m07:48:06.111464 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:48:06.112514 [debug] [MainThread]: Connection 'list_dbelsa_tec_elsa' was properly closed.
[0m07:48:06.113956 [debug] [MainThread]: Connection 'model.dbt_elsa.consumption_history' was properly closed.
[0m07:48:06.115500 [info ] [MainThread]: 
[0m07:48:06.117524 [info ] [MainThread]: Finished running 2 project hooks, 1 table model in 0 hours 0 minutes and 0.72 seconds (0.72s).
[0m07:48:06.121222 [debug] [MainThread]: Command end result
[0m07:48:06.341598 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt_elsa/target/manifest.json
[0m07:48:06.345549 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt_elsa/target/semantic_manifest.json
[0m07:48:06.356376 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt_elsa/target/run_results.json
[0m07:48:06.357455 [info ] [MainThread]: 
[0m07:48:06.358522 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:48:06.359605 [info ] [MainThread]: 
[0m07:48:06.360712 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m07:48:06.362627 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.6074665, "process_in_blocks": "0", "process_kernel_time": 0.283959, "process_mem_max_rss": "137376", "process_out_blocks": "12387", "process_user_time": 5.294344}
[0m07:48:06.364008 [debug] [MainThread]: Command `dbt run` succeeded at 07:48:06.363801 after 3.61 seconds
[0m07:48:06.365768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f169435ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1692c12b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16941f1150>]}
[0m07:48:06.367019 [debug] [MainThread]: Flushing usage events
[0m07:48:06.855137 [debug] [MainThread]: An error was encountered while trying to flush usage events
